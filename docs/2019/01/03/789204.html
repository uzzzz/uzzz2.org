<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Kubernetes部署（十一）：管理之Helm和Rancher部署 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Kubernetes部署（十一）：管理之Helm和Rancher部署" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="相关内容： Kubernetes部署（一）：架构及功能说明Kubernetes部署（二）：系统环境初始化Kubernetes部署（三）：CA证书制作Kubernetes部署（四）：ETCD集群部署Kubernetes部署（五）：Haproxy、Keppalived部署Kubernetes部署（六）：Master节点部署Kubernetes部署（七）：Node节点部署Kubernetes部署（八）：Flannel网络部署Kubernetes部署（九）：CoreDNS、Dashboard、Ingress部署Kubernetes部署（十）：储存之glusterfs和heketi部署Kubernetes部署（十一）：管理之Helm和Rancher部署Kubernetes部署（十二）：helm部署harbor企业级镜像仓库 Helm部署 helm官方下载地址：https://github.com/helm/helm/releases 官方可用的chart列表：https://hub.kubeapps.com 所有的软件及配置文件都保存在前面文章提到的百度网盘里 ：百度共享链接在此文章里 helm简介 Helm是一种简化Kubernetes应用程序安装和管理的工具。可以把它想象成apt/yum/homebrew。 Helm有两部分：client(helm)和server(tiller),Tiller在您的Kubernetes集群内部运行，并管理chart的发布(安装)。 Helm可在您的笔记本电脑，或在任何位置运行。 chart是包含至少两件事的Helm包： 包的描述（Chart.yaml） 一个或多个模板，包含Kubernetes清单文件 chart可以存储在磁盘上，也可以从远程chart存储库（如Debian或RedHat包）中获取. 核心术语 Chart：一个helm程序包; Repository：Charts仓库，https/http服务器； Release：特定的Chart部署于目标集群上的一个实例； 程序架构 helm：客户端，管理本地的Chart仓库，管理Chart, 与Tiller服务器交互，发送Chart，实例安装、查询、卸载等 操作； Tiller：服务端，接收helm发来的Charts与Config，合并生成relase； helm部署 helm可以部署在任何机器上，不一定要在kubernetes的服务器上,但是需要安装kubectl，也就是说用户家目录下要有kube的配置文件，因为helm需要和apiServer通信。 [root@node-01 ~]# ll .kube/ total 12 drwxr-xr-x 3 root root 23 Dec 25 11:28 cache -rw------- 1 root root 6264 Dec 25 16:15 config drwxr-xr-x 3 root root 4096 Jan 2 15:09 http-cache 开始部署 [root@node-01 k8s]# wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# tar zxf helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# cd linux-amd64/ [root@node-01 linux-amd64]# mv helm /usr/bin/ 因某些原因我们无法直接从google下载tiller镜像，所以需要下载我网盘共享的镜像tiller-image-v2.12.1.tar.gz，然后在每个node节点加载镜像 [root@node-04 ~]# docker load &lt; tiller-image-v2.12.1.tar.gz apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system [root@node-01 helm]# kubectl create -f rbac-config.yaml [root@node-01 helm]# helm init --service-account tiller Creating /root/.helm Creating /root/.helm/repository Creating /root/.helm/repository/cache Creating /root/.helm/repository/local Creating /root/.helm/plugins Creating /root/.helm/starters Creating /root/.helm/cache/archive Creating /root/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /root/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure &#39;allow unauthenticated users&#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! [root@node-01 helm]# kubectl -n kube-system get pod|grep tiller tiller-deploy-85744d9bfb-cm5jz 1/1 Running 0 11m [root@node-01 helm]# helm version Client: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} Server: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} helm常用命令： release管理： install delete upgrade/rollback list history：release的历史信息； status：获取release状态信息； chart管理： create fetch get inspect package verify 至此helm就已经部署完了，下面会通过helm安装k8s的管理平台，也顺便演示helm的使用。 Rancher部署 rancher简介 Rancher是一个企业级多集群Kubernetes管理平台； 用户可以在Rancher上配置和管理公有云(如GKE、EKS、AKS、阿里云、华为云等)上托管的Kubernetes服务，亦可向Rancher中导入已有集群。 对于所有Kubernetes集群与服务，用户均可以在Rancher上进行集中身份认证(包括GitHub、AD/LDAP、SAML等)。 添加chart仓库 helm官方仓库没有rancher的chart包，所以我们需要添加rancher官方chart仓库。 [root@node-01 helm]# helm repo add rancher-stable https://releases.rancher.com/server-charts/stable &quot;rancher-stable&quot; has been added to your repositories [root@node-01 helm]# helm search rancher-stable/rancher NAME CHART VERSION APP VERSION DESCRIPTION rancher-stable/rancher 2018.12.4 v2.1.4 Install Rancher Server to manage Kubernetes clusters acro... 安装cert-manager 安装成功后会详细显示安装的所有资源 [root@node-01 helm]# helm install stable/cert-manager --name cert-manager --namespace kube-system NAME: cert-manager LAST DEPLOYED: Thu Jan 3 15:35:22 2019 NAMESPACE: kube-system STATUS: DEPLOYED RESOURCES: ==&gt; v1/ServiceAccount NAME SECRETS AGE cert-manager 1 1s ==&gt; v1beta1/ClusterRole NAME AGE cert-manager 1s ==&gt; v1beta1/ClusterRoleBinding NAME AGE cert-manager 1s ==&gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE cert-manager 1 1 1 0 1s ==&gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE cert-manager-7d4bfc44ff-5flvg 0/1 ContainerCreating 0 0s NOTES: cert-manager has been deployed successfully! In order to begin issuing certificates, you will need to set up a ClusterIssuer or Issuer resource (for example, by creating a &#39;letsencrypt-staging&#39; issuer). More information on the different types of issuers and how to configure them can be found in our documentation: https://cert-manager.readthedocs.io/en/latest/reference/issuers.html For information on how to configure cert-manager to automatically provision Certificates for Ingress resources, take a look at the `ingress-shim` documentation: https://cert-manager.readthedocs.io/en/latest/reference/ingress-shim.html [root@node-01 helm]# 安装rancher server [root@node-01 helm]# helm install rancher-stable/rancher --name rancher --namespace cattle-system --set hostname=rancher.cnlinux.club 默认情况下，Rancher会自动生成CA根证书并使用cert-manager颁发证书，因此，这里设置了 hostname=rancher.cnlinux.club，后续只能通过域名访问UI 为Agent Pod添加主机别名(可选) 如果你没有内部DNS服务器而是通过添加/etc/hosts主机别名的方式指定的Rancher server域名，那么不管通过哪种方式(自定义、导入、Host驱动等)创建K8S集群，K8S集群运行起来之后，因为cattle-cluster-agent Pod和cattle-node-agent无法通过DNS记录找到Rancher server,最终导致无法通信。 可以通过给cattle-cluster-agent Pod和cattle-node-agent添加主机别名(/etc/hosts)，让其可以正常通信(前提是IP地址可以互通)。 注意：替换以下命令中的域名和IP cattle-cluster-agent pod [root@node-01 helm]# kubectl -n cattle-system patch deployments cattle-cluster-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; cattle-node-agent pod [root@node-01 helm]# kubectl -n cattle-system patch daemonsets cattle-node-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; 访问rancher 通过浏览器访问https://rancher.cnlinux.club/，出现如下页面，然后设置密码 然后就可以出现如下界面，就证明已经正常运行了 3.至此就可以通过rancher来管理pod、ingress、service等资源了。 rancher也创建新的k8s集群，如果管理其他现有的k8s集群，可以选择如下图的导入 后续会陆续更新所有的k8s相关文档，如果你觉得我写的不错，希望大家多多关注点赞，非常感谢！ 转载于:https://blog.51cto.com/billy98/2338415" />
<meta property="og:description" content="相关内容： Kubernetes部署（一）：架构及功能说明Kubernetes部署（二）：系统环境初始化Kubernetes部署（三）：CA证书制作Kubernetes部署（四）：ETCD集群部署Kubernetes部署（五）：Haproxy、Keppalived部署Kubernetes部署（六）：Master节点部署Kubernetes部署（七）：Node节点部署Kubernetes部署（八）：Flannel网络部署Kubernetes部署（九）：CoreDNS、Dashboard、Ingress部署Kubernetes部署（十）：储存之glusterfs和heketi部署Kubernetes部署（十一）：管理之Helm和Rancher部署Kubernetes部署（十二）：helm部署harbor企业级镜像仓库 Helm部署 helm官方下载地址：https://github.com/helm/helm/releases 官方可用的chart列表：https://hub.kubeapps.com 所有的软件及配置文件都保存在前面文章提到的百度网盘里 ：百度共享链接在此文章里 helm简介 Helm是一种简化Kubernetes应用程序安装和管理的工具。可以把它想象成apt/yum/homebrew。 Helm有两部分：client(helm)和server(tiller),Tiller在您的Kubernetes集群内部运行，并管理chart的发布(安装)。 Helm可在您的笔记本电脑，或在任何位置运行。 chart是包含至少两件事的Helm包： 包的描述（Chart.yaml） 一个或多个模板，包含Kubernetes清单文件 chart可以存储在磁盘上，也可以从远程chart存储库（如Debian或RedHat包）中获取. 核心术语 Chart：一个helm程序包; Repository：Charts仓库，https/http服务器； Release：特定的Chart部署于目标集群上的一个实例； 程序架构 helm：客户端，管理本地的Chart仓库，管理Chart, 与Tiller服务器交互，发送Chart，实例安装、查询、卸载等 操作； Tiller：服务端，接收helm发来的Charts与Config，合并生成relase； helm部署 helm可以部署在任何机器上，不一定要在kubernetes的服务器上,但是需要安装kubectl，也就是说用户家目录下要有kube的配置文件，因为helm需要和apiServer通信。 [root@node-01 ~]# ll .kube/ total 12 drwxr-xr-x 3 root root 23 Dec 25 11:28 cache -rw------- 1 root root 6264 Dec 25 16:15 config drwxr-xr-x 3 root root 4096 Jan 2 15:09 http-cache 开始部署 [root@node-01 k8s]# wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# tar zxf helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# cd linux-amd64/ [root@node-01 linux-amd64]# mv helm /usr/bin/ 因某些原因我们无法直接从google下载tiller镜像，所以需要下载我网盘共享的镜像tiller-image-v2.12.1.tar.gz，然后在每个node节点加载镜像 [root@node-04 ~]# docker load &lt; tiller-image-v2.12.1.tar.gz apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system [root@node-01 helm]# kubectl create -f rbac-config.yaml [root@node-01 helm]# helm init --service-account tiller Creating /root/.helm Creating /root/.helm/repository Creating /root/.helm/repository/cache Creating /root/.helm/repository/local Creating /root/.helm/plugins Creating /root/.helm/starters Creating /root/.helm/cache/archive Creating /root/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /root/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure &#39;allow unauthenticated users&#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! [root@node-01 helm]# kubectl -n kube-system get pod|grep tiller tiller-deploy-85744d9bfb-cm5jz 1/1 Running 0 11m [root@node-01 helm]# helm version Client: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} Server: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} helm常用命令： release管理： install delete upgrade/rollback list history：release的历史信息； status：获取release状态信息； chart管理： create fetch get inspect package verify 至此helm就已经部署完了，下面会通过helm安装k8s的管理平台，也顺便演示helm的使用。 Rancher部署 rancher简介 Rancher是一个企业级多集群Kubernetes管理平台； 用户可以在Rancher上配置和管理公有云(如GKE、EKS、AKS、阿里云、华为云等)上托管的Kubernetes服务，亦可向Rancher中导入已有集群。 对于所有Kubernetes集群与服务，用户均可以在Rancher上进行集中身份认证(包括GitHub、AD/LDAP、SAML等)。 添加chart仓库 helm官方仓库没有rancher的chart包，所以我们需要添加rancher官方chart仓库。 [root@node-01 helm]# helm repo add rancher-stable https://releases.rancher.com/server-charts/stable &quot;rancher-stable&quot; has been added to your repositories [root@node-01 helm]# helm search rancher-stable/rancher NAME CHART VERSION APP VERSION DESCRIPTION rancher-stable/rancher 2018.12.4 v2.1.4 Install Rancher Server to manage Kubernetes clusters acro... 安装cert-manager 安装成功后会详细显示安装的所有资源 [root@node-01 helm]# helm install stable/cert-manager --name cert-manager --namespace kube-system NAME: cert-manager LAST DEPLOYED: Thu Jan 3 15:35:22 2019 NAMESPACE: kube-system STATUS: DEPLOYED RESOURCES: ==&gt; v1/ServiceAccount NAME SECRETS AGE cert-manager 1 1s ==&gt; v1beta1/ClusterRole NAME AGE cert-manager 1s ==&gt; v1beta1/ClusterRoleBinding NAME AGE cert-manager 1s ==&gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE cert-manager 1 1 1 0 1s ==&gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE cert-manager-7d4bfc44ff-5flvg 0/1 ContainerCreating 0 0s NOTES: cert-manager has been deployed successfully! In order to begin issuing certificates, you will need to set up a ClusterIssuer or Issuer resource (for example, by creating a &#39;letsencrypt-staging&#39; issuer). More information on the different types of issuers and how to configure them can be found in our documentation: https://cert-manager.readthedocs.io/en/latest/reference/issuers.html For information on how to configure cert-manager to automatically provision Certificates for Ingress resources, take a look at the `ingress-shim` documentation: https://cert-manager.readthedocs.io/en/latest/reference/ingress-shim.html [root@node-01 helm]# 安装rancher server [root@node-01 helm]# helm install rancher-stable/rancher --name rancher --namespace cattle-system --set hostname=rancher.cnlinux.club 默认情况下，Rancher会自动生成CA根证书并使用cert-manager颁发证书，因此，这里设置了 hostname=rancher.cnlinux.club，后续只能通过域名访问UI 为Agent Pod添加主机别名(可选) 如果你没有内部DNS服务器而是通过添加/etc/hosts主机别名的方式指定的Rancher server域名，那么不管通过哪种方式(自定义、导入、Host驱动等)创建K8S集群，K8S集群运行起来之后，因为cattle-cluster-agent Pod和cattle-node-agent无法通过DNS记录找到Rancher server,最终导致无法通信。 可以通过给cattle-cluster-agent Pod和cattle-node-agent添加主机别名(/etc/hosts)，让其可以正常通信(前提是IP地址可以互通)。 注意：替换以下命令中的域名和IP cattle-cluster-agent pod [root@node-01 helm]# kubectl -n cattle-system patch deployments cattle-cluster-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; cattle-node-agent pod [root@node-01 helm]# kubectl -n cattle-system patch daemonsets cattle-node-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; 访问rancher 通过浏览器访问https://rancher.cnlinux.club/，出现如下页面，然后设置密码 然后就可以出现如下界面，就证明已经正常运行了 3.至此就可以通过rancher来管理pod、ingress、service等资源了。 rancher也创建新的k8s集群，如果管理其他现有的k8s集群，可以选择如下图的导入 后续会陆续更新所有的k8s相关文档，如果你觉得我写的不错，希望大家多多关注点赞，非常感谢！ 转载于:https://blog.51cto.com/billy98/2338415" />
<link rel="canonical" href="https://uzzz.org/2019/01/03/789204.html" />
<meta property="og:url" content="https://uzzz.org/2019/01/03/789204.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-03T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"相关内容： Kubernetes部署（一）：架构及功能说明Kubernetes部署（二）：系统环境初始化Kubernetes部署（三）：CA证书制作Kubernetes部署（四）：ETCD集群部署Kubernetes部署（五）：Haproxy、Keppalived部署Kubernetes部署（六）：Master节点部署Kubernetes部署（七）：Node节点部署Kubernetes部署（八）：Flannel网络部署Kubernetes部署（九）：CoreDNS、Dashboard、Ingress部署Kubernetes部署（十）：储存之glusterfs和heketi部署Kubernetes部署（十一）：管理之Helm和Rancher部署Kubernetes部署（十二）：helm部署harbor企业级镜像仓库 Helm部署 helm官方下载地址：https://github.com/helm/helm/releases 官方可用的chart列表：https://hub.kubeapps.com 所有的软件及配置文件都保存在前面文章提到的百度网盘里 ：百度共享链接在此文章里 helm简介 Helm是一种简化Kubernetes应用程序安装和管理的工具。可以把它想象成apt/yum/homebrew。 Helm有两部分：client(helm)和server(tiller),Tiller在您的Kubernetes集群内部运行，并管理chart的发布(安装)。 Helm可在您的笔记本电脑，或在任何位置运行。 chart是包含至少两件事的Helm包： 包的描述（Chart.yaml） 一个或多个模板，包含Kubernetes清单文件 chart可以存储在磁盘上，也可以从远程chart存储库（如Debian或RedHat包）中获取. 核心术语 Chart：一个helm程序包; Repository：Charts仓库，https/http服务器； Release：特定的Chart部署于目标集群上的一个实例； 程序架构 helm：客户端，管理本地的Chart仓库，管理Chart, 与Tiller服务器交互，发送Chart，实例安装、查询、卸载等 操作； Tiller：服务端，接收helm发来的Charts与Config，合并生成relase； helm部署 helm可以部署在任何机器上，不一定要在kubernetes的服务器上,但是需要安装kubectl，也就是说用户家目录下要有kube的配置文件，因为helm需要和apiServer通信。 [root@node-01 ~]# ll .kube/ total 12 drwxr-xr-x 3 root root 23 Dec 25 11:28 cache -rw------- 1 root root 6264 Dec 25 16:15 config drwxr-xr-x 3 root root 4096 Jan 2 15:09 http-cache 开始部署 [root@node-01 k8s]# wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# tar zxf helm-v2.12.1-linux-amd64.tar.gz [root@node-01 k8s]# cd linux-amd64/ [root@node-01 linux-amd64]# mv helm /usr/bin/ 因某些原因我们无法直接从google下载tiller镜像，所以需要下载我网盘共享的镜像tiller-image-v2.12.1.tar.gz，然后在每个node节点加载镜像 [root@node-04 ~]# docker load &lt; tiller-image-v2.12.1.tar.gz apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system [root@node-01 helm]# kubectl create -f rbac-config.yaml [root@node-01 helm]# helm init --service-account tiller Creating /root/.helm Creating /root/.helm/repository Creating /root/.helm/repository/cache Creating /root/.helm/repository/local Creating /root/.helm/plugins Creating /root/.helm/starters Creating /root/.helm/cache/archive Creating /root/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /root/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure &#39;allow unauthenticated users&#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! [root@node-01 helm]# kubectl -n kube-system get pod|grep tiller tiller-deploy-85744d9bfb-cm5jz 1/1 Running 0 11m [root@node-01 helm]# helm version Client: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} Server: &amp;version.Version{SemVer:&quot;v2.12.1&quot;, GitCommit:&quot;02a47c7249b1fc6d8fd3b94e6b4babf9d818144e&quot;, GitTreeState:&quot;clean&quot;} helm常用命令： release管理： install delete upgrade/rollback list history：release的历史信息； status：获取release状态信息； chart管理： create fetch get inspect package verify 至此helm就已经部署完了，下面会通过helm安装k8s的管理平台，也顺便演示helm的使用。 Rancher部署 rancher简介 Rancher是一个企业级多集群Kubernetes管理平台； 用户可以在Rancher上配置和管理公有云(如GKE、EKS、AKS、阿里云、华为云等)上托管的Kubernetes服务，亦可向Rancher中导入已有集群。 对于所有Kubernetes集群与服务，用户均可以在Rancher上进行集中身份认证(包括GitHub、AD/LDAP、SAML等)。 添加chart仓库 helm官方仓库没有rancher的chart包，所以我们需要添加rancher官方chart仓库。 [root@node-01 helm]# helm repo add rancher-stable https://releases.rancher.com/server-charts/stable &quot;rancher-stable&quot; has been added to your repositories [root@node-01 helm]# helm search rancher-stable/rancher NAME CHART VERSION APP VERSION DESCRIPTION rancher-stable/rancher 2018.12.4 v2.1.4 Install Rancher Server to manage Kubernetes clusters acro... 安装cert-manager 安装成功后会详细显示安装的所有资源 [root@node-01 helm]# helm install stable/cert-manager --name cert-manager --namespace kube-system NAME: cert-manager LAST DEPLOYED: Thu Jan 3 15:35:22 2019 NAMESPACE: kube-system STATUS: DEPLOYED RESOURCES: ==&gt; v1/ServiceAccount NAME SECRETS AGE cert-manager 1 1s ==&gt; v1beta1/ClusterRole NAME AGE cert-manager 1s ==&gt; v1beta1/ClusterRoleBinding NAME AGE cert-manager 1s ==&gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE cert-manager 1 1 1 0 1s ==&gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE cert-manager-7d4bfc44ff-5flvg 0/1 ContainerCreating 0 0s NOTES: cert-manager has been deployed successfully! In order to begin issuing certificates, you will need to set up a ClusterIssuer or Issuer resource (for example, by creating a &#39;letsencrypt-staging&#39; issuer). More information on the different types of issuers and how to configure them can be found in our documentation: https://cert-manager.readthedocs.io/en/latest/reference/issuers.html For information on how to configure cert-manager to automatically provision Certificates for Ingress resources, take a look at the `ingress-shim` documentation: https://cert-manager.readthedocs.io/en/latest/reference/ingress-shim.html [root@node-01 helm]# 安装rancher server [root@node-01 helm]# helm install rancher-stable/rancher --name rancher --namespace cattle-system --set hostname=rancher.cnlinux.club 默认情况下，Rancher会自动生成CA根证书并使用cert-manager颁发证书，因此，这里设置了 hostname=rancher.cnlinux.club，后续只能通过域名访问UI 为Agent Pod添加主机别名(可选) 如果你没有内部DNS服务器而是通过添加/etc/hosts主机别名的方式指定的Rancher server域名，那么不管通过哪种方式(自定义、导入、Host驱动等)创建K8S集群，K8S集群运行起来之后，因为cattle-cluster-agent Pod和cattle-node-agent无法通过DNS记录找到Rancher server,最终导致无法通信。 可以通过给cattle-cluster-agent Pod和cattle-node-agent添加主机别名(/etc/hosts)，让其可以正常通信(前提是IP地址可以互通)。 注意：替换以下命令中的域名和IP cattle-cluster-agent pod [root@node-01 helm]# kubectl -n cattle-system patch deployments cattle-cluster-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; cattle-node-agent pod [root@node-01 helm]# kubectl -n cattle-system patch daemonsets cattle-node-agent --patch &#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.cnlinux.club&quot; ], &quot;ip&quot;: &quot;10.31.90.200&quot; } ] } } } }&#39; 访问rancher 通过浏览器访问https://rancher.cnlinux.club/，出现如下页面，然后设置密码 然后就可以出现如下界面，就证明已经正常运行了 3.至此就可以通过rancher来管理pod、ingress、service等资源了。 rancher也创建新的k8s集群，如果管理其他现有的k8s集群，可以选择如下图的导入 后续会陆续更新所有的k8s相关文档，如果你觉得我写的不错，希望大家多多关注点赞，非常感谢！ 转载于:https://blog.51cto.com/billy98/2338415","@type":"BlogPosting","url":"https://uzzz.org/2019/01/03/789204.html","headline":"Kubernetes部署（十一）：管理之Helm和Rancher部署","dateModified":"2019-01-03T00:00:00+08:00","datePublished":"2019-01-03T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/01/03/789204.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Kubernetes部署（十一）：管理之Helm和Rancher部署</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="con artical-content editor-preview-side">
   <h3>相关内容：</h3> 
   <p><a href="https://blog.51cto.com/billy98/2334654" rel="nofollow">Kubernetes部署（一）：架构及功能说明</a><br><a href="https://blog.51cto.com/billy98/2334685" rel="nofollow">Kubernetes部署（二）：系统环境初始化</a><br><a href="https://blog.51cto.com/billy98/2334704" rel="nofollow">Kubernetes部署（三）：CA证书制作</a><br><a href="https://blog.51cto.com/billy98/2334706" rel="nofollow">Kubernetes部署（四）：ETCD集群部署</a><br><a href="https://blog.51cto.com/billy98/2335056" rel="nofollow">Kubernetes部署（五）：Haproxy、Keppalived部署</a><br><a href="https://blog.51cto.com/billy98/2335161" rel="nofollow">Kubernetes部署（六）：Master节点部署</a><br><a href="https://blog.51cto.com/billy98/2335575" rel="nofollow">Kubernetes部署（七）：Node节点部署</a><br><a href="https://blog.51cto.com/billy98/2335580" rel="nofollow">Kubernetes部署（八）：Flannel网络部署</a><br><a href="https://blog.51cto.com/billy98/2336724" rel="nofollow">Kubernetes部署（九）：CoreDNS、Dashboard、Ingress部署</a><br><a href="https://blog.51cto.com/billy98/2337874" rel="nofollow">Kubernetes部署（十）：储存之glusterfs和heketi部署</a><br><a href="https://blog.51cto.com/billy98/2338415" rel="nofollow">Kubernetes部署（十一）：管理之Helm和Rancher部署</a><br><a href="https://blog.51cto.com/billy98/2345517" rel="nofollow">Kubernetes部署（十二）：helm部署harbor企业级镜像仓库</a></p> 
   <pre><code></code></pre> 
   <h2>Helm部署</h2> 
   <p>helm官方下载地址：<a href="https://github.com/helm/helm/releases" rel="nofollow">https://github.com/helm/helm/releases</a></p> 
   <p>官方可用的chart列表：<a href="https://hub.kubeapps.com" rel="nofollow">https://hub.kubeapps.com</a></p> 
   <blockquote> 
    <p>所有的软件及配置文件都保存在前面文章提到的百度网盘里 ：<a href="https://blog.51cto.com/billy98/2334685" rel="nofollow">百度共享链接在此文章里</a></p> 
   </blockquote> 
   <h3>helm简介</h3> 
   <p>Helm是一种简化Kubernetes应用程序安装和管理的工具。可以把它想象成apt/yum/homebrew。</p> 
   <ul>
    <li>Helm有两部分：client(helm)和server(tiller)<br>,Tiller在您的Kubernetes集群内部运行，并管理chart的发布(安装)。</li> 
    <li> <p>Helm可在您的笔记本电脑，或在任何位置运行。</p> </li> 
    <li>chart是包含至少两件事的Helm包： 
     <ul>
      <li>包的描述（Chart.yaml）</li> 
      <li>一个或多个模板，包含Kubernetes清单文件</li> 
     </ul></li> 
    <li>chart可以存储在磁盘上，也可以从远程chart存储库（如Debian或RedHat包）中获取.</li> 
   </ul>
   <h3>核心术语</h3> 
   <ul>
    <li>Chart：一个helm程序包;</li> 
    <li>Repository：Charts仓库，https/http服务器；</li> 
    <li>Release：特定的Chart部署于目标集群上的一个实例； <h3>程序架构</h3></li> 
    <li>helm：客户端，管理本地的Chart仓库，管理Chart, 与Tiller服务器交互，发送Chart，实例安装、查询、卸载等 操作；</li> 
    <li>Tiller：服务端，接收helm发来的Charts与Config，合并生成relase；</li> 
   </ul>
   <h3>helm部署</h3> 
   <ul>
    <li>helm可以部署在任何机器上，不一定要在kubernetes的服务器上,但是需要安装kubectl，也就是说用户家目录下要有kube的配置文件，因为helm需要和apiServer通信。 <pre><code>[root@node-01 ~]# ll .kube/
total 12
drwxr-xr-x 3 root root   23 Dec 25 11:28 cache
-rw------- 1 root root 6264 Dec 25 16:15 config
drwxr-xr-x 3 root root 4096 Jan  2 15:09 http-cache</code></pre></li> 
    <li>开始部署 <pre><code>[root@node-01 k8s]# wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.1-linux-amd64.tar.gz
[root@node-01 k8s]# tar zxf helm-v2.12.1-linux-amd64.tar.gz 
[root@node-01 k8s]# cd linux-amd64/
[root@node-01 linux-amd64]# mv helm /usr/bin/</code></pre></li> 
   </ul>
   <p>因某些原因我们无法直接从google下载tiller镜像，所以需要下载我网盘共享的镜像<code>tiller-image-v2.12.1.tar.gz</code>，然后在每个node节点加载镜像</p> 
   <pre><code>[root@node-04 ~]# docker load &lt; tiller-image-v2.12.1.tar.gz</code></pre> 
   <pre><code>apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system</code></pre> 
   <pre><code>[root@node-01 helm]# kubectl create -f rbac-config.yaml

[root@node-01 helm]# helm init --service-account tiller
Creating /root/.helm 
Creating /root/.helm/repository 
Creating /root/.helm/repository/cache 
Creating /root/.helm/repository/local 
Creating /root/.helm/plugins 
Creating /root/.helm/starters 
Creating /root/.helm/cache/archive 
Creating /root/.helm/repository/repositories.yaml 
Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com 
Adding local repo with URL: http://127.0.0.1:8879/charts 
$HELM_HOME has been configured at /root/.helm.

Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.

Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.
To prevent this, run `helm init` with the --tiller-tls-verify flag.
For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation
Happy Helming!

[root@node-01 helm]# kubectl -n kube-system get pod|grep tiller
tiller-deploy-85744d9bfb-cm5jz         1/1       Running   0          11m

[root@node-01 helm]# helm version
Client: &amp;version.Version{SemVer:"v2.12.1", GitCommit:"02a47c7249b1fc6d8fd3b94e6b4babf9d818144e", GitTreeState:"clean"}
Server: &amp;version.Version{SemVer:"v2.12.1", GitCommit:"02a47c7249b1fc6d8fd3b94e6b4babf9d818144e", GitTreeState:"clean"}</code></pre> 
   <h4>helm常用命令：</h4> 
   <ul>
    <li> <p>release管理： </p> 
     <ul>
      <li>install</li> 
      <li>delete</li> 
      <li>upgrade/rollback</li> 
      <li>list </li> 
      <li>history：release的历史信息；</li> 
      <li>status：获取release状态信息；</li> 
     </ul></li> 
    <li>chart管理： 
     <ul>
      <li>create </li> 
      <li>fetch </li> 
      <li>get </li> 
      <li>inspect </li> 
      <li>package </li> 
      <li>verify</li> 
     </ul></li> 
   </ul>
   <p>至此helm就已经部署完了，下面会通过helm安装k8s的管理平台，也顺便演示helm的使用。</p> 
   <h2>Rancher部署</h2> 
   <h3>rancher简介</h3> 
   <ul>
    <li>Rancher是一个企业级多集群Kubernetes管理平台；</li> 
    <li>用户可以在Rancher上配置和管理公有云(如GKE、EKS、AKS、阿里云、华为云等)上托管的Kubernetes服务，亦可向Rancher中导入已有集群。</li> 
    <li>对于所有Kubernetes集群与服务，用户均可以在Rancher上进行集中身份认证(包括GitHub、AD/LDAP、SAML等)。 <h3>添加chart仓库</h3> <p>helm官方仓库没有rancher的chart包，所以我们需要添加rancher官方chart仓库。</p> <pre><code>[root@node-01 helm]# helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
"rancher-stable" has been added to your repositories
[root@node-01 helm]# helm search rancher-stable/rancher                                            
NAME                    CHART VERSION   APP VERSION     DESCRIPTION                                                 
rancher-stable/rancher  2018.12.4       v2.1.4          Install Rancher Server to manage Kubernetes clusters acro...</code></pre> <h3>安装cert-manager</h3></li> 
    <li>安装成功后会详细显示安装的所有资源</li> 
   </ul>
   <pre><code>[root@node-01 helm]# helm install stable/cert-manager  --name cert-manager --namespace kube-system
NAME:   cert-manager
LAST DEPLOYED: Thu Jan  3 15:35:22 2019
NAMESPACE: kube-system
STATUS: DEPLOYED

RESOURCES:
==&gt; v1/ServiceAccount
NAME          SECRETS  AGE
cert-manager  1        1s

==&gt; v1beta1/ClusterRole
NAME          AGE
cert-manager  1s

==&gt; v1beta1/ClusterRoleBinding
NAME          AGE
cert-manager  1s

==&gt; v1beta1/Deployment
NAME          DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
cert-manager  1        1        1           0          1s

==&gt; v1/Pod(related)
NAME                           READY  STATUS             RESTARTS  AGE
cert-manager-7d4bfc44ff-5flvg  0/1    ContainerCreating  0         0s

NOTES:
cert-manager has been deployed successfully!

In order to begin issuing certificates, you will need to set up a ClusterIssuer
or Issuer resource (for example, by creating a 'letsencrypt-staging' issuer).

More information on the different types of issuers and how to configure them
can be found in our documentation:

https://cert-manager.readthedocs.io/en/latest/reference/issuers.html

For information on how to configure cert-manager to automatically provision
Certificates for Ingress resources, take a look at the `ingress-shim`
documentation:

https://cert-manager.readthedocs.io/en/latest/reference/ingress-shim.html

[root@node-01 helm]# </code></pre> 
   <h3>安装rancher server</h3> 
   <pre><code>[root@node-01 helm]# helm install rancher-stable/rancher --name rancher --namespace cattle-system --set hostname=rancher.cnlinux.club</code></pre> 
   <blockquote> 
    <p>默认情况下，Rancher会自动生成CA根证书并使用cert-manager颁发证书，因此，这里设置了 hostname=rancher.cnlinux.club，后续只能通过域名访问UI</p> 
   </blockquote> 
   <h3>为Agent Pod添加主机别名(可选)</h3> 
   <p>如果你没有内部DNS服务器而是通过添加/etc/hosts主机别名的方式指定的Rancher server域名，那么不管通过哪种方式(自定义、导入、Host驱动等)创建K8S集群，K8S集群运行起来之后，因为cattle-cluster-agent Pod和cattle-node-agent无法通过DNS记录找到Rancher server,最终导致无法通信。</p> 
   <p>可以通过给cattle-cluster-agent Pod和cattle-node-agent添加主机别名(/etc/hosts)，让其可以正常通信(前提是IP地址可以互通)。</p> 
   <blockquote> 
    <p>注意：替换以下命令中的域名和IP</p> 
   </blockquote> 
   <h4>cattle-cluster-agent pod</h4> 
   <pre><code>[root@node-01 helm]#  kubectl -n cattle-system patch  deployments cattle-cluster-agent --patch '{
    "spec": {
        "template": {
            "spec": {
                "hostAliases": [
                    {
                        "hostnames":
                        [
                            "rancher.cnlinux.club"
                        ],
                            "ip": "10.31.90.200"
                    }
                ]
            }
        }
    }
}'</code></pre> 
   <h4>cattle-node-agent pod</h4> 
   <pre><code>[root@node-01 helm]#  kubectl -n cattle-system patch  daemonsets cattle-node-agent --patch '{
    "spec": {
        "template": {
            "spec": {
                "hostAliases": [
                    {
                        "hostnames":
                        [
                            "rancher.cnlinux.club"
                        ],
                            "ip": "10.31.90.200"
                    }
                ]
            }
        }
    }
}'</code></pre> 
   <h4>访问rancher</h4> 
   <ol>
    <li>通过浏览器访问<a href="https://note.youdao.com/" rel="nofollow"></a><a href="https://rancher.cnlinux.club/" rel="nofollow">https://rancher.cnlinux.club/</a>，出现如下页面，然后设置密码</li> 
   </ol>
   <p><img src="https://note.youdao.com/yws/api/personal/file/WEB9475366573b5acc89c87173b06b67356?method=download&amp;shareKey=af8b08df3a431e51c7108af71e368921" alt="rancher"></p> 
   <ol start="2">
    <li>然后就可以出现如下界面，就证明已经正常运行了<br><img src="https://note.youdao.com/yws/api/personal/file/WEB30c23ca6edd2af6b476476bff0da91f9?method=download&amp;shareKey=03ebeda7aa39fa0d1a2d7e74aba71e43" alt="rancher4"></li> 
   </ol>
   <p>3.至此就可以通过rancher来管理pod、ingress、service等资源了。<br><img src="https://note.youdao.com/yws/api/personal/file/WEB961432aff2054c934061aed3b6aa67ae?method=download&amp;shareKey=b9c332c0fdf4ebaf220165ec886ed607" alt="rancher5"></p> 
   <ol start="4">
    <li>rancher也创建新的k8s集群，如果管理其他现有的k8s集群，可以选择如下图的导入<br><img src="https://note.youdao.com/yws/api/personal/file/WEB32af758b4258cfdf06f8df8539a69d40?method=download&amp;shareKey=6b53bed9594d95cae9697eaa36a9fab4" alt="rancher2"></li> 
   </ol>
   <p><img src="https://note.youdao.com/yws/api/personal/file/WEBc828f23224ebbaebbc11ce48df1d28c5?method=download&amp;shareKey=6cdfa9196d08da6c800d0943a7bb1ce1" alt="rancher3"></p> 
   <p><strong>后续会陆续更新所有的k8s相关文档，如果你觉得我写的不错，希望大家多多关注点赞，非常感谢！</strong></p>
  </div> 
  <p>转载于:https://blog.51cto.com/billy98/2338415</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
