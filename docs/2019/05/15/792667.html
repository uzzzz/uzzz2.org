<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>论文笔记-A Survey on Session-based Recommender Systems | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="论文笔记-A Survey on Session-based Recommender Systems" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="基于session的推荐系统综述 1 INTRODUCTION 2 FORMALIZATION AND NOTATIONS 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance 3.2 Data Characteristics and Complexity 3.3 Key Challenges 3.3.1 An Overview of Challenges in SBRS 3.3.2 A Categorization of Challenges in SBRS 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS 4.2 Attention in the Research Community 5 CATEGORIZATION AND SUMMARIZATION 5.1 Categorization from the Research Issue Perspective 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings. 5.1.2 How to Recommend: A Categorization of recommendation approaches. 5.2 A Categorization from the Technical Perspective 5.2.1 Model-Free Approaches. 5.2.2 Model-based Approaches. 5.2.3 Comparisons between Different Technical Approaches. 6 MODEL-FREE APPROACHES 6.1 Pattern/Rule-based Approaches 6.2 Sequential Pattern-based Approaches 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches 7.1.1 Basic Markov Chain-based Approaches. 7.1.2 Latent Markov Embedding-based Approaches. 7.2 Factorization Machine-based Approaches 7.3 Neural Model-based Approaches 7.3.1 Shallow Neural Models. 7.3.2 Deep Neural Models. 8 PROSPECTS AND FUTURE DIRECTIONS 8.1 Session-based Recommendations With General User Preference 8.2 Session-based Recommendations Considering More Contextual Factors 8.3 Session-based Recommendations With Noisy and Irrelevant Items 8.4 Session-based Recommendations for Multi-Step Recommendations 8.5 Session-based Recommendations With Cross-session Information 8.6 Session-based Recommendations with Cross-domain Information 文章链接 1 INTRODUCTION   推荐系统已经进化为一个基础性的工具，可以帮助用户做出合理的决策和选择，尤其是在大数据环境下，消费者不得不从大量的商品和服务中做出选择。提出了大量的RS模型和技术，许多并已成功应用。在这些RS模型中，content-based RS和协同过滤RS是两个代表性的推荐模型。学界和工业界已经证实了其有效性。   然而，上述的传统的RS仍存在许多缺点。其中一个就是这些模型只关注。其中一个比较严重的缺点是：这些模型只关注用户长期的、静态的偏好，而忽略了短期的交易模式。这种情况下, 用户在某个时间点的兴趣很可能被其历史浏览行为覆盖。这是因为RS挺长将一个基本交易单元（例如一个session）分解成更小粒度上的记录，然后再混合这些记录。这种分裂模式破坏了交易行为，其中就包括用户的偏好信息。   为解决以上问题，有必要考虑交易的结构。换句话说，有必要学习用户的交易行为。SBRS应势而出。这里，一个session可以理解为是包含了很多item（例如商品）的交易。和content-based RS、基于协同过滤的RS不同，SBRS综合考虑了session信息，并将一个session作为推荐的基本单元。如图1的底部所示，SBRS可以最大限度地减少由于忽略或者打破session结构而造成的信息损失。   除了在电子商务领域，SBRS还可以应用在网页推荐、POI推荐、旅游、歌曲、视频推荐等。为包含这些领域，这里的session就不仅仅指交易单元，而是在一段时间内，购买后者浏览的item的集合。   表1是SBRA和其他RS的对比。   在这篇综述中，将对SBRS进行全面系统的概述。将session作为推荐的基本单元，这是近年来一种相对新颖的推荐模型。 2 FORMALIZATION AND NOTATIONS   本节，我们将定义session和SBRS一些相关的概念。   Definition 2.1 (Session). 一个session指的是在一段时间内手机或者购买的item的集合。例如，一次交易中购买的item或用户一小段时间内听的歌曲也可以视为一个session。此外，用户在固定时间段内连续点击的网页也可以看做是一个session。   Definition 2.2 (Session-based recommender systems (SBRS)). 给定已有的session信息，如一个session的部分信息或者历史session，SBRA就是想依据一个session或者多个session之间的复杂关系预测出session中未知的部分或未来可能的session。   因此，SBRS可以分为两种：下一个item的推荐，这种推荐模型推荐的是当前session的一部分；下一个session的推荐。   同城，推荐应用程序，例如基于购物车的业务系统，会包含两个基本对象：user和item。用户集合为 U = { u 1 , u 2 , . . . , u ∣ U ∣ } U = \{u_{1}, u_{2}, ..., u_{|U|}\} U={u1​,u2​,...,u∣U∣​}， item集合为 I = { i 1 , i 2 , . . . , i ∣ I ∣ } I = \{i_{1}, i_{2},..., i_{|I|}\} I={i1​,i2​,...,i∣I∣​}。user和item的交互行为包括：click，buy等，是RS中重要的组成部分。例如，用户点击的所有的item形成click session；用户购买的item又可以形成交易session。通常，在一段时间内，一个用户发生交互的item构成一个session s = { i 1 , i 2 , . . . , i ∣ s ∣ } s = \{i_{1}, i_{2}, ..., i_{|s|}\} s={i1​,i2​,...,i∣s∣​}。Session的集合就是 S = { s 1 , s 2 , . . . , s ∣ S ∣ } S = \{s_{1}, s_{2}, ..., s_{|S|}\} S={s1​,s2​,...,s∣S∣​}。SBRS将未知的session作为目标 t \bm{t} t，利用已有的session信息来预测目标 t \bm{t} t。Session的上下文信息也可以分为两种，这取决于上下文是取自一个session还是多个。   Definition 2.3 (Intra-session context). 当前session记为 s n s_{n} sn​，intra-session context C I a C^{Ia} CIa就是在session s n s_{n} sn​中已知的item集合。即 C I a = { i ∣ i ∈ s n , i ̸ = i t } C^{Ia} = \{i | i \in s_{n}, i \not= i_{}t\} CIa={i∣i∈sn​,i̸​=i​t}， i t i_{t} it​就是session s n s_{n} sn​中的未知item。   Definition 2.4 (Inter-session context). 当前session记为 s n s_{n} sn​， C I e C^{Ie} CIe是在session s n s_{n} sn​之前的session集合，即 C I e = { s n − 1 , s n − 2 , . . . , s ∣ C I e ∣ } C^{Ie} = \{s_{n-1}, s_{n-2}, ..., s_{|C^{Ie}|}\} CIe={sn−1​,sn−2​,...,s∣CIe∣​}.   Definition 2.5 (Session-based recommendation task). 给定session，上下文 C C C，基于session的推荐任务就是学习一个映射 f f f，将 C C C映射到推荐目标 t \bm{t} t。session上下文是该任务中主要信息；有时，也会添加item特征，user特征等信息。   Definition 2.6 (Next-item(s) recommendations). 给定一个 C I a C^{Ia} CIa，这种推荐模式就是在 s n s_{n} sn​中预测下一个item。   Definition 2.7 (Next-session (next-basket) recommendations). 给定一个 C I e C^{Ie} CIe，这种推荐模式就是预测session s n s_{n} sn​中的items。 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance   SBRS在学术界，工业界均很重要。在研究领域，SBRS可以保持session的自然特征，避免局部信息损失。例如，如果不考虑session结构，item的共现信息可能会丢失。这些局部的交易信息，在一些特定业务场景中非常关键。 如果没有session信息， （a）容易产生重复推荐，即推荐相似或已现有相同的item；（b）用户的购物模式将消失，不能进行个性化推荐。（c）用户偏好转移（shift）消失，不能捕捉用户的当前的喜好；从一个session到另一个session时，用户的喜好通常是动态变化的；（d）不能捕捉短期、局部的用户喜好。在实际生产中，上述的RS只能捕捉用户长期或全局的喜好。   通过保留session结构并将session作为基本数据单元，SBRS将保留所有的局部信息。因此，SBRS更能提供可靠的推荐。SBRS更关注局部、动态的session。由于当前的或最近的session中的item已被选中，因此SBRS很容易避免推荐重复或者相似的item。此外，由于每个用户的item都是一个session，就更容易知道其交易模式。此外，SBRS中考虑的是当前或者最近的session中的item，而不是全部session中的item，这样就更容易捕获用户局部或短期内的喜好。更重要的是，SBRS容易捕获用户转移的偏好。   在工业应用领域，SBRS更重要。Session数据比其他数据（item特征，item排序）更重要。 3.2 Data Characteristics and Complexity   SBRS同样具有挑战性。在实际应用中，在session的数据集中是具有一个层级结构的，如图2所示的5级层级结构。从特征级到域级。在这5个层级中，中间的3层是session模型的核心。即item是关键部分，原因有二：一方面，item是session数据中的原子粒度的部件；另一方面，item扮演了大多数session模型中的重要角色。   每个item通过由多个异构的特征描述，如item类别、价格、生产地等。每种特征通常包含多个值。在大多数情况下，item之间的相关性是建立在齐共现的基础之上的。一般情况下，一个域中收集的数据会包含多个session。 3.3 Key Challenges   如图2所示，SBRS在每一个局部都有挑战性。 3.3.1 An Overview of Challenges in SBRS    (a) Inner-session challenges. Inner-session challenges发生在session内部，在session内部，结构复杂。一个层级结构包含多个层，Inner-session challenges就是在item level、feature level、feature value level以及这些level交互时的挑战。    (b) Inter-session challenges. Inter-session challenges是指session之间交互时的挑战，即图2中的session level。一点典型的挑战包括：session异构、session之间的依赖、动态session等。    ( c c c) Outer-session challenges. Outer-session challenges是指域level和model level的挑战。   与session相关的上下文指的是session发生时所处的环境信息，例如时间、地点、天气、季节、用户等。在SBRS中应该考虑上下文信息。 3.3.2 A Categorization of Challenges in SBRS   SBRS的所有挑战可以分为四种。    (a) The heterogeneity within each level 每个level是异构的。每个level的元素不同，则特征不同，从而不能平等对待。 Value异构：特征值分布不同。 Feature异构：一个item通常包含不同类型的feature，包括类别、数值。 Item异构：一个session钟的item分布也不相同。 Session异构：不同的上下文环境导致不用的session。有些可能是无关的，有些可能是噪声。 Context异构：上下文的信息不同。    (b) The couplings within each level 每个level的耦合信息，即每个level的交互挑战。 Value-level耦合：同一个特征不同值的交互（intra-feature），和不同特征的值的交互（inter-feature）。 Feature-level耦合：一个特征可能会影响其他特征。 Item-level耦合：在一个session钟，item之间的交互。 Session-level耦合：不同session的交互。在实际的交互场景中，最近的session可能会对当前的session产生影响。 Domain-level耦合：不同域之间的交互。 Contextual耦合：不同上下文信息的交互。    ( c c c) Other complexities within each level 每个level是相当复杂的。    (d) The interactions between different levels 不同level之间的交互，不同的level可能存在不同的交互关系。 Feature-item交互。 Session-item交互。 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS   SBRS研究从1990s以来，就有不同的研究内容：pattern-based RS，rule-based RS，sequence-based RS，transaction-based RS，session-aware RS等。我们将SBRS的研究分为你两个不同的阶段：1990-2010的model-free阶段；2010-至今，基于model的SBRS。第一个阶段，室友数据挖掘技术驱动的，包括模式挖掘、关联规则和序列挖掘。根据相应的文献研究，我们发现，2000s前后是这一阶段的高峰时期。第二阶段是由统计和机器学习驱动的，尤其是一些与时间序列相关的模型，包括马氏链、RNN等。由于深度学习的发展，自2017年以来model-based RS达到了峰值，许多研究相继出炉，可见图4。 4.2 Attention in the Research Community    数据挖掘相关的会议，如KDD， CIKM，WSDM，IJCAI，AAAI，ECML，Recsys，WWW，SIGIR。 5 CATEGORIZATION AND SUMMARIZATION   将SBRS研究分为以下几个领域。 5.1 Categorization from the Research Issue Perspective   SBRS研究关注的是推荐什么和如何推荐。推荐什么讨论的是研究任务、场景，这些都是优先设置的；如何推荐，这与3.3节中所列举的挑战是相关的。 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings.    通常情况下，SBRS中获取的session数据可以分为两类。第一个是像购物车一样的（如天猫数据集），这样的session又明确的内在session结构。例如，每个购物车界限清楚。在这种情况下，购物车是自然色session。    另外一种是类似于历史行为的数据，原始数据是事件记录的集合，例如电影数据、POI数据等。Event历史数据通常没有一个自然的session结构；换言之，没有一个明确的边界可以区分events。例如，一个用户经常只看某一部电影。因此，session特征是模糊的，数据不是那么strong。这类数据通常用某些技术，例如时间滑动窗口，将数据分成多个session。这种推荐任务是next event/action推荐。    (a) Next-Item(s) Recommendations. Next-item推荐指的是在一个session钟，推荐下一个或下几个item（session通常是购物车）。Next-item推荐是主流的和常见的推荐任务。如表3，是next-item推荐的相关研究。    (b) Next-Basket Recommendations. 在下一个session中推荐一个item。Next-basket推荐研究相对较少。见表3所示。    ( c c c) Next-Event/Action Recommendations. 推荐下一个event/action，如看电影或听歌等。这类研究数据没有session结果，相关研究见表3所示。 5.1.2 How to Recommend: A Categorization of recommendation approaches.   SBRS一个主要的驱动力就是耦合或依赖关系。这是由于特殊的设置导致的：给定session上下文，推荐系统会根据下一个上下文信息来寻找相应的items或events。如何推荐，本质上就是图2每层或不同层之间的复杂的依赖关系。根据session数据的层级结构，相应的推荐方法可以分为5个分支。    (a) Item-level Dependency Modeling. Item-level依赖建模是指对一个session内的item之间或event之间的依恋关系建模。近年来，许多研究是建立在这个分支上的。有几个典型的问题会对模型质量或性能产生影响。    - Ordered vs. unordered items. 现实场景中的session数据通常分为两种类型：有序和无序。根据session中是否存在item的排序关系来确定。例如，在医疗或基因表达数据中，顺序将相当严格。而购物车数据中，顺序是没有意义的，因为顾客挑选item时是随机的。   为此，一些方法假定session中的item有严格顺序，依据item之间的序列关系来确定item的顺序。一种简单的方法是基于序列模式挖掘的RS，显式地挖掘序列模式从而指导推荐。为获取session内item之间的隐藏序列关系，并保留原始的信息，可以采用马氏链、RNN等模型。马氏链和RNN模型在处理序列关系数据集时有巨大优势。   其他方法尝试放松或者抛弃这个顺序假设。基于模式/规则的方法相应而出，它们根据item的共现信息来显式地挖掘模式。为捕获item之间的隐藏关系，采用的方法包括：因子分解机，浅层NN， DNN， CNN。    - First-order dependency vs. higher-order dependency. 一些方法是建立在一阶的依赖关系之上的，只获取item之间的一阶依赖关系。在预测next item时，仅依赖前一个item。方法包括：一阶马氏链，因子分解机。然而，许多session数据不仅包括一阶依赖关系，还包括高阶的依赖关系在这种情况下，基于网络的方法更容易获取高阶依赖关系，这时的网络模型包括浅层和深层网络模型。    (b) Session-level Dependency Modelling. 指的是对session之间的依赖关系进行建模。由于session是建立在item之上的，所以对session-level的依赖关系进行建模往往就伴随着item-level的依赖关系建模。Session-level依赖关系建模分为next-item推荐和next-basket推荐。对于next-item推荐来说，session-level依赖关系建模，采用的是session之间的依赖关系，因此要考虑前面的sessions。因此，可以增强先验信息。在next-basket推荐中，session-level依赖关系建模对于获取session之间的依赖关系很有必要。   根据对session之间的依赖关系进行建模，session-level依赖关系建模也分为两种：    - Item dependency modelling. item依赖关系建模是对item之间的转换关系进行建模。Item可能来自不同的session，这种方法首先研究session之间item的转换关系，然后根据当前basket中的item预测下一个basket中出现的item。如因子分解机。    - Collective dependency modelling. 和上述方法不同，集合依赖关系建模通过将每个session作为一个整体来建立session之间的依赖关系。一个session的表示可以通过一个层级网络学习到，该模型首先学习item表示，然后集合session中每个item的表示。在训练过程中，下一个session来知道表示学习。    ( c c c) Feature-level Dependency Modelling. 指的是特征之间的依赖关系建模和feature-item关系建模。特征之间的依赖关系是一个item的特征可能会影响另一个特征。例如，不同国家的Apple价格也不一样。Feature-item的依赖关系建模指的是在一个session中，item出现的情况会受其特征的影响。如item属于同一类，但是作用是互补的，因此item会出现在同一个session中。Item feature的参与使得我们能更好的理解item的特征。因此，feature-level的依赖关系建模对冷启动的item是有好处的。   针对冷启动的item推荐目前已经取得了很多进展。但是，feature-level依赖关系建模扔处于早期研究阶段。    (d) Feature Value-level Dependency Modelling &amp; Domain-Level Dependency Modelling. 获取特征内部的依赖关系和特征值与特征item的交互关系。Domain-level依赖关系建模可以获取不同domain之间的依赖关系。据我们所致，在SBRS研究中，还没有人研究特征值-level和domain-level的依赖关系建模。但是这将是一个有前景的研究方向。 5.2 A Categorization from the Technical Perspective   从技术领域进行分类。 5.2.1 Model-Free Approaches. 依赖数据挖掘技术，没有复杂的数学模型。两个传统的方法是：pattern/rule-based RS用来处理无序的session数据；序列模式RS处理有序的session数据。    (a) Pattern/Rule-based Approaches. 首先利用挖掘频繁出现的模式或者连接规则，并用pattern-rule指导推荐。前提假设是消费者会遵从常见的购物模式。例如，用户经常购买面包和牛奶，这就是给购买牛奶的人推荐面包的理由。应用在无序的session数据上。    (b) Sequential Pattern-based Approaches. 为处理有严格顺序的item或基于时间因子的序列数据。首先挖掘一个序列模式，然后根据前面的item推荐出后面的item 。 5.2.2 Model-based Approaches.   基于模型的RS，往往有严格的假定。现有的基于模型的RS，可以分为三类。    (a) Markov Chain-based Approaches. 建立item之间的一阶依赖关系，利用的是转移概率。序列模式建模，模型容易过滤掉不常出现的item，这样会导致信息丢失。而基于马氏链的模型会综合考虑前面所有的item，降低信息损失。    (b) Factorization-based Approaches. 首先分解item的共现矩阵或item-to-item的转移概率矩阵为每个item的表示向量，然后预测接下来的item。这个方法区别于一般的因子分解机方法。    © Neural Model-based Approaches. 利用神经网络学习item之间或session之间的复杂的关系和交互，然后根据交互关系获得相应推荐。根据模型结构，可以分为浅层/深层模型，也成为embeddings model和representation model。 5.2.3 Comparisons between Different Technical Approaches.   不同技术的比较。model-free方法简单，直接，便于实现。由于pattern/rule-based和序列模式的方法只是基于频率进行建模的，这样就会过滤掉不常出现但是可能比较重要的item或模式。因此，model-free方法使用与经常出现的item的数据集。model-based方法对复杂的数据集处理效果更好。一方面，它们不会显式地过滤掉item或模式，将信息保留到最大程度；另一方面，由于方法复杂，可以处理复杂、隐式的数据关系，推荐结果更加可靠。表5是不同方法的比较。 6 MODEL-FREE APPROACHES   主要依赖于数据挖掘尤其是模式挖掘技术。基本思想是通过从session数据中挖掘共有的、显式地模式，然后用于推荐， 6.1 Pattern/Rule-based Approaches   主要包括了三个阶段：frequent模式挖掘，session匹配，item推荐。具体来说，给定item集合 I I I和对应的session集合 S S S，frequent模式集合为 P T = { p 1 , p 2 , . . . , p ∣ P T ∣ } PT = \{p_{1}, p_{2}, ..., p_{|PT|}\} PT={p1​,p2​,...,p∣PT∣​}是用模式挖掘算法挖掘到的。如Apriori和FP-Tree算法。对于给定的、部分session s ^ \hat{s} s^（例如，一次交易中选择的item），如果item i ^ \hat{i} i^存在，那么 s ^ ∪ i ^ ( i ^ ∈ I ∖ s ^ ) \hat{s} \cup \hat{i} (\hat{i} \in I \setminus \hat{s}) s^∪i^(i^∈I∖s^)就是一个frequent pattern，称 { s ^ ∪ i ^ } ∈ P T \{\hat{s} \cup \hat{i}\} \in PT {s^∪i^}∈PT。那么 i ^ \hat{i} i^就是候选item。进一步，如果条件概率 P ( i ^ ∣ s ^ ) &amp;gt; β P(\hat{i} | \hat{s}) &amp;gt; \beta P(i^∣s^)&gt;β，那么就将 i ^ \hat{i} i^加到候选列表中。   除了上面提到的pattern/rule-based RS框架外，还有许多变体。[83]将关联规则挖掘结合到协同过滤中，它们在模式挖掘中取代了最小支持约束来提高效率，以此来避免挖掘和用户无关的规则。考虑到不同item的重要性，[148]和[40]采用连续页面查看来衡量每个页面的重要性，然后利用这个权重，将这个权重加到关联规则挖掘中，简历加权的关联规则RS。通过挖掘用户行为模式，例如，文本导航页，关联规则挖掘则用来获取特定用户的喜好，以此获取更加个性化的推荐。其他工作将模式挖掘结合到协同过滤中来解决一些特殊问题，如稀疏性，健壮性和个性化。Pattern-based RS除了传统的购物车RS外， 还可以用于web推荐，音乐推荐等。 6.2 Sequential Pattern-based Approaches   虽然和pattern-based RS类似，sequential pattern based RS主要有两点不同： 1）它主要利用交叉session推荐来获取session内的依赖关系；2）考虑session的顺序，因此要结合序列数据。sequential pattern based RS也包含了三个阶段：sequential模式挖掘，序列匹配，获取推荐。   给定一个序列集合 Q = { q 1 , q 2 , . . . , q ∣ Q ∣ } Q = \{q_{1}, q_{2}, ..., q_{|Q|}\} Q={q1​,q2​,...,q∣Q∣​}，其中序列 q = { s 1 , s 2 , . . . , s ∣ q ∣ } q = \{s_{1}, s_{2}, ..., s_{|q|}\} q={s1​,s2​,...,s∣q∣​}是session的集合。   除了上述描述的基本框架外，还有许多扩展。一个典型的例子就是利用用户相关sequential pattern挖掘来做个性化推荐。另一个扩展是将sequential pattern和协同过滤融合。由于进行了组合，动态的单个模式和通用的偏好模型都将考虑到。 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches   利用马氏链在给定一个session内的一系列item以后，预测下一个item。为降低模型复杂度，许多RS都建立在一阶马氏链上。 7.1.1 Basic Markov Chain-based Approaches.   一般来说，基本的基于马氏链的RS很简单：首先在训练集的item序列上计算转移概率，然后将用户的购物序列和利用转移概率计算出的序列进行匹配。概率比较高的item将放到推荐列表中。   给定session集合 S S S，每个session s s s是有序的item序列。马氏链将所有的session编码到一个图 G G G中，每个item是一个节点，item的共现信息作为边。每个item的频率和共现信息作为边的权重。每个session是G中的一条路径。   马氏链是一个元组 { S T , P t , P 0 } \{ST, \bm{P_{t}}, P_{0}\} {ST,Pt​,P0​}， S T ST ST是状态空间，包含了 G G G中所有可见的节点； P t \bm{P_{t}} Pt​是 m ∗ m m * m m∗m的转移概率矩阵； P 0 P_{0} P0​是每个状态的初始概率。一阶转移概率定义为：                  然后就可以刘勇上述一阶马氏链模型估计shopping path的概率：                  给定item序列，可以选择概率比较更高的shopping path，并取给定的item作为先验信息。   除上面定义的基本马氏链RS外，还有许多变体。如，结合一阶和二阶马氏链模型；提出基于隐马氏链的概率模型。通过结合其他因素，一高推荐的准确性。 7.1.2 Latent Markov Embedding-based Approaches.   LME-based RS首先将马氏链嵌入到欧式空间中，然后计算item的转移概率，依据是欧氏距离。可以解决稀疏性问题。每个item i i i表示成向量 v i \bm{v_{i}} vi​，是一个 d d d维向量，转移概率 P ( i j − 1 → i j ) P(i_{j-1} \rightarrow i_{j}) P(ij−1​→ij​)。Shopping path q ′ = { i 1 → i 2 → . . . → i l } q &amp;#x27; = \{i_{1} \rightarrow i_{2} \rightarrow ... \rightarrow i_{l}\} q′={i1​→i2​→...→il​}的概率为：                  为获得个性化推荐，[46]提出PME模型，将users和items映射到欧式空间。[39]提出个性化排序肚量embedding学习。 7.2 Factorization Machine-based Approaches   近来，因子分解机常用来做推荐模型。一旦从观测数据中获得了个性化转移概率，对于每个用户 u u u就建立了一个转移矩阵 A u \bm{A^{u}} Au。因此，对于所有用户，转移Tensor A \rm{A} A。   因子分解模型仅建立在item的共现转移矩阵上，只能获取item的序列模型，但是忽略了用户的偏好。[82]结合矩阵分解和协同过滤来获取个人偏好和item转移模式。 7.3 Neural Model-based Approaches   基于神经网络的方法。 7.3.1 Shallow Neural Models.   浅层网络，或称为嵌入模型，包含浅层网络结构。将session中的item映射到一个隐空间，然后获取item之间的关系。隐向量表示包含了丰富的信息。   如[57]。wide-in，wide-out模型。首先将用户ID和item ID映射到隐向量表示，然后组合作为给定的上下文表示，输出预测的item。   网络利用Logistic函数映射用户 u u u和item i i i： v u = σ ( W : , u 1 ) \bm{v_{u}} = \sigma(\bm{W_{:, u}^{1}}) vu​=σ(W:,u1​) v i = σ ( W : , i 2 ) \bm{v_{i}} = \sigma(\bm{W_{:, i}^{2}}) vi​=σ(W:,i2​) 其中， W 1 , W 2 \bm{W^{1}}, \bm{W}^{2} W1,W2是权重矩阵.利用这种方法，每个用户和item都被映射成向量。   此外，将item特征融入到网络中可以解决冷启动推荐问题。 7.3.2 Deep Neural Models.   SBRS深度网络模型始于2016年，如GRU4Rec。在GRU4Rec基础上，提出了一系列模型。基于RNN的模型占据了主导地位，因为大多数session数据是序列化的。基于DNN的模型用来优化不同的表示，基于CNN的模型经常用来提取局部特征。    (a) RNN-based Models. Session集合 S S S， s s s是一次交易中的item集合，GRU4Rec将每个Session建模成一个序列，预测下一个元素的概率分布。GRU是ＲＮＮ单元，延长状态更新如下：                  每个GRU单元表示一个隐藏状态，GRU层包含了一系列GRU单元。输入 x t x_{t} xt​是session s s s中的item i t i_{t} it​的嵌入表示。因此，给定session s s s中的历史item，可以预测下一个item的概率分布。   为改进GRU4Rec，[124]采用序列处理和dropout来做数据增强。另外，预训练模型也经常使用。[11]提出了分层的RNN来提取交叉session的信息。   除了上述的GRU外，还有很多RNN的变体。DREAM学习用户的动态表示，其他的扩展包括：1）变分推理，处理不确定稀疏业务；2）其他信息如item特征，上下文因素。3）注意力机制。    (b) DNN-based Models. 除了RNN，DNN也可以用于SBRS中，尤其是当session中的item没有顺序时。[144]中，使用DNN学习session表示。    (b) CNN-based Models. CNN也可以用于SBRS中，原因有：1）CNN放松了session中item的顺序假定，模型更鲁邦；2）局部学习能力强，高效提取union-level依赖关系。 8 PROSPECTS AND FUTURE DIRECTIONS   分析不足和SBRS未来研究方向。SBRS是一个相对较新的领域。 8.1 Session-based Recommendations With General User Preference   SBRS通常忽略了一般用户的偏好，而其他传统方法却可以获取到。这可能导致不可靠的推荐。如何学习一般用户的喜好以及如何应用带SBRS中是一个挑战，这里谈论两点。   将用户偏好融入到SBRS中。用户对于他们购买的item的偏好可以利用user-item偏好矩阵获取。一个直观的方法是先利用传统方法预测用户在候选item上的偏好，然后利用偏好数据调整候选列表。例如，两个候选item在特定上下文中有相似的概率，一个对于特定用户来说有较高的偏好，那么该item会被放在前面。另外一种方法是将两个因素综合考虑。[155]利用GAN实现。   如何在没有偏好数据时将用户体验融入SBRS。现实情况中，偏好数据并不总司可以获取到的，因为用户不会对他们购买的所有item进行评分，这种情况下，基于购物车的交易数据通常认为是用户偏好的隐式反馈。 8.2 Session-based Recommendations Considering More Contextual Factors   推荐上下文是指在推荐时实际的环境。如季节，时间，地点，流行趋势等。这些会对推荐性能产生巨大影响，上下文信息在SBRS中很少采用。需要将更多因素融入到SBRS中，例如CRNN。 8.3 Session-based Recommendations With Noisy and Irrelevant Items   目前，sequential SBRS，如基于RNN，马氏链的模型都假设item有强依赖关系。然而，在实际业务数据中可能不是这样。随机选择的item和推荐的item可能没有关系，推荐结果可能会被噪声误导。 8.4 Session-based Recommendations for Multi-Step Recommendations   购物事件包含了多个步骤。例如，用户买了面包，他随后可能买芝士。 8.5 Session-based Recommendations With Cross-session Information   用户对next-item选择不仅仅取决于同一个session中的item，还可能取决于其他session中的item。 8.6 Session-based Recommendations with Cross-domain Information   用户购买的item涉及多个产品类别（域），不同的域可能不是独立的。" />
<meta property="og:description" content="基于session的推荐系统综述 1 INTRODUCTION 2 FORMALIZATION AND NOTATIONS 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance 3.2 Data Characteristics and Complexity 3.3 Key Challenges 3.3.1 An Overview of Challenges in SBRS 3.3.2 A Categorization of Challenges in SBRS 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS 4.2 Attention in the Research Community 5 CATEGORIZATION AND SUMMARIZATION 5.1 Categorization from the Research Issue Perspective 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings. 5.1.2 How to Recommend: A Categorization of recommendation approaches. 5.2 A Categorization from the Technical Perspective 5.2.1 Model-Free Approaches. 5.2.2 Model-based Approaches. 5.2.3 Comparisons between Different Technical Approaches. 6 MODEL-FREE APPROACHES 6.1 Pattern/Rule-based Approaches 6.2 Sequential Pattern-based Approaches 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches 7.1.1 Basic Markov Chain-based Approaches. 7.1.2 Latent Markov Embedding-based Approaches. 7.2 Factorization Machine-based Approaches 7.3 Neural Model-based Approaches 7.3.1 Shallow Neural Models. 7.3.2 Deep Neural Models. 8 PROSPECTS AND FUTURE DIRECTIONS 8.1 Session-based Recommendations With General User Preference 8.2 Session-based Recommendations Considering More Contextual Factors 8.3 Session-based Recommendations With Noisy and Irrelevant Items 8.4 Session-based Recommendations for Multi-Step Recommendations 8.5 Session-based Recommendations With Cross-session Information 8.6 Session-based Recommendations with Cross-domain Information 文章链接 1 INTRODUCTION   推荐系统已经进化为一个基础性的工具，可以帮助用户做出合理的决策和选择，尤其是在大数据环境下，消费者不得不从大量的商品和服务中做出选择。提出了大量的RS模型和技术，许多并已成功应用。在这些RS模型中，content-based RS和协同过滤RS是两个代表性的推荐模型。学界和工业界已经证实了其有效性。   然而，上述的传统的RS仍存在许多缺点。其中一个就是这些模型只关注。其中一个比较严重的缺点是：这些模型只关注用户长期的、静态的偏好，而忽略了短期的交易模式。这种情况下, 用户在某个时间点的兴趣很可能被其历史浏览行为覆盖。这是因为RS挺长将一个基本交易单元（例如一个session）分解成更小粒度上的记录，然后再混合这些记录。这种分裂模式破坏了交易行为，其中就包括用户的偏好信息。   为解决以上问题，有必要考虑交易的结构。换句话说，有必要学习用户的交易行为。SBRS应势而出。这里，一个session可以理解为是包含了很多item（例如商品）的交易。和content-based RS、基于协同过滤的RS不同，SBRS综合考虑了session信息，并将一个session作为推荐的基本单元。如图1的底部所示，SBRS可以最大限度地减少由于忽略或者打破session结构而造成的信息损失。   除了在电子商务领域，SBRS还可以应用在网页推荐、POI推荐、旅游、歌曲、视频推荐等。为包含这些领域，这里的session就不仅仅指交易单元，而是在一段时间内，购买后者浏览的item的集合。   表1是SBRA和其他RS的对比。   在这篇综述中，将对SBRS进行全面系统的概述。将session作为推荐的基本单元，这是近年来一种相对新颖的推荐模型。 2 FORMALIZATION AND NOTATIONS   本节，我们将定义session和SBRS一些相关的概念。   Definition 2.1 (Session). 一个session指的是在一段时间内手机或者购买的item的集合。例如，一次交易中购买的item或用户一小段时间内听的歌曲也可以视为一个session。此外，用户在固定时间段内连续点击的网页也可以看做是一个session。   Definition 2.2 (Session-based recommender systems (SBRS)). 给定已有的session信息，如一个session的部分信息或者历史session，SBRA就是想依据一个session或者多个session之间的复杂关系预测出session中未知的部分或未来可能的session。   因此，SBRS可以分为两种：下一个item的推荐，这种推荐模型推荐的是当前session的一部分；下一个session的推荐。   同城，推荐应用程序，例如基于购物车的业务系统，会包含两个基本对象：user和item。用户集合为 U = { u 1 , u 2 , . . . , u ∣ U ∣ } U = \{u_{1}, u_{2}, ..., u_{|U|}\} U={u1​,u2​,...,u∣U∣​}， item集合为 I = { i 1 , i 2 , . . . , i ∣ I ∣ } I = \{i_{1}, i_{2},..., i_{|I|}\} I={i1​,i2​,...,i∣I∣​}。user和item的交互行为包括：click，buy等，是RS中重要的组成部分。例如，用户点击的所有的item形成click session；用户购买的item又可以形成交易session。通常，在一段时间内，一个用户发生交互的item构成一个session s = { i 1 , i 2 , . . . , i ∣ s ∣ } s = \{i_{1}, i_{2}, ..., i_{|s|}\} s={i1​,i2​,...,i∣s∣​}。Session的集合就是 S = { s 1 , s 2 , . . . , s ∣ S ∣ } S = \{s_{1}, s_{2}, ..., s_{|S|}\} S={s1​,s2​,...,s∣S∣​}。SBRS将未知的session作为目标 t \bm{t} t，利用已有的session信息来预测目标 t \bm{t} t。Session的上下文信息也可以分为两种，这取决于上下文是取自一个session还是多个。   Definition 2.3 (Intra-session context). 当前session记为 s n s_{n} sn​，intra-session context C I a C^{Ia} CIa就是在session s n s_{n} sn​中已知的item集合。即 C I a = { i ∣ i ∈ s n , i ̸ = i t } C^{Ia} = \{i | i \in s_{n}, i \not= i_{}t\} CIa={i∣i∈sn​,i̸​=i​t}， i t i_{t} it​就是session s n s_{n} sn​中的未知item。   Definition 2.4 (Inter-session context). 当前session记为 s n s_{n} sn​， C I e C^{Ie} CIe是在session s n s_{n} sn​之前的session集合，即 C I e = { s n − 1 , s n − 2 , . . . , s ∣ C I e ∣ } C^{Ie} = \{s_{n-1}, s_{n-2}, ..., s_{|C^{Ie}|}\} CIe={sn−1​,sn−2​,...,s∣CIe∣​}.   Definition 2.5 (Session-based recommendation task). 给定session，上下文 C C C，基于session的推荐任务就是学习一个映射 f f f，将 C C C映射到推荐目标 t \bm{t} t。session上下文是该任务中主要信息；有时，也会添加item特征，user特征等信息。   Definition 2.6 (Next-item(s) recommendations). 给定一个 C I a C^{Ia} CIa，这种推荐模式就是在 s n s_{n} sn​中预测下一个item。   Definition 2.7 (Next-session (next-basket) recommendations). 给定一个 C I e C^{Ie} CIe，这种推荐模式就是预测session s n s_{n} sn​中的items。 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance   SBRS在学术界，工业界均很重要。在研究领域，SBRS可以保持session的自然特征，避免局部信息损失。例如，如果不考虑session结构，item的共现信息可能会丢失。这些局部的交易信息，在一些特定业务场景中非常关键。 如果没有session信息， （a）容易产生重复推荐，即推荐相似或已现有相同的item；（b）用户的购物模式将消失，不能进行个性化推荐。（c）用户偏好转移（shift）消失，不能捕捉用户的当前的喜好；从一个session到另一个session时，用户的喜好通常是动态变化的；（d）不能捕捉短期、局部的用户喜好。在实际生产中，上述的RS只能捕捉用户长期或全局的喜好。   通过保留session结构并将session作为基本数据单元，SBRS将保留所有的局部信息。因此，SBRS更能提供可靠的推荐。SBRS更关注局部、动态的session。由于当前的或最近的session中的item已被选中，因此SBRS很容易避免推荐重复或者相似的item。此外，由于每个用户的item都是一个session，就更容易知道其交易模式。此外，SBRS中考虑的是当前或者最近的session中的item，而不是全部session中的item，这样就更容易捕获用户局部或短期内的喜好。更重要的是，SBRS容易捕获用户转移的偏好。   在工业应用领域，SBRS更重要。Session数据比其他数据（item特征，item排序）更重要。 3.2 Data Characteristics and Complexity   SBRS同样具有挑战性。在实际应用中，在session的数据集中是具有一个层级结构的，如图2所示的5级层级结构。从特征级到域级。在这5个层级中，中间的3层是session模型的核心。即item是关键部分，原因有二：一方面，item是session数据中的原子粒度的部件；另一方面，item扮演了大多数session模型中的重要角色。   每个item通过由多个异构的特征描述，如item类别、价格、生产地等。每种特征通常包含多个值。在大多数情况下，item之间的相关性是建立在齐共现的基础之上的。一般情况下，一个域中收集的数据会包含多个session。 3.3 Key Challenges   如图2所示，SBRS在每一个局部都有挑战性。 3.3.1 An Overview of Challenges in SBRS    (a) Inner-session challenges. Inner-session challenges发生在session内部，在session内部，结构复杂。一个层级结构包含多个层，Inner-session challenges就是在item level、feature level、feature value level以及这些level交互时的挑战。    (b) Inter-session challenges. Inter-session challenges是指session之间交互时的挑战，即图2中的session level。一点典型的挑战包括：session异构、session之间的依赖、动态session等。    ( c c c) Outer-session challenges. Outer-session challenges是指域level和model level的挑战。   与session相关的上下文指的是session发生时所处的环境信息，例如时间、地点、天气、季节、用户等。在SBRS中应该考虑上下文信息。 3.3.2 A Categorization of Challenges in SBRS   SBRS的所有挑战可以分为四种。    (a) The heterogeneity within each level 每个level是异构的。每个level的元素不同，则特征不同，从而不能平等对待。 Value异构：特征值分布不同。 Feature异构：一个item通常包含不同类型的feature，包括类别、数值。 Item异构：一个session钟的item分布也不相同。 Session异构：不同的上下文环境导致不用的session。有些可能是无关的，有些可能是噪声。 Context异构：上下文的信息不同。    (b) The couplings within each level 每个level的耦合信息，即每个level的交互挑战。 Value-level耦合：同一个特征不同值的交互（intra-feature），和不同特征的值的交互（inter-feature）。 Feature-level耦合：一个特征可能会影响其他特征。 Item-level耦合：在一个session钟，item之间的交互。 Session-level耦合：不同session的交互。在实际的交互场景中，最近的session可能会对当前的session产生影响。 Domain-level耦合：不同域之间的交互。 Contextual耦合：不同上下文信息的交互。    ( c c c) Other complexities within each level 每个level是相当复杂的。    (d) The interactions between different levels 不同level之间的交互，不同的level可能存在不同的交互关系。 Feature-item交互。 Session-item交互。 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS   SBRS研究从1990s以来，就有不同的研究内容：pattern-based RS，rule-based RS，sequence-based RS，transaction-based RS，session-aware RS等。我们将SBRS的研究分为你两个不同的阶段：1990-2010的model-free阶段；2010-至今，基于model的SBRS。第一个阶段，室友数据挖掘技术驱动的，包括模式挖掘、关联规则和序列挖掘。根据相应的文献研究，我们发现，2000s前后是这一阶段的高峰时期。第二阶段是由统计和机器学习驱动的，尤其是一些与时间序列相关的模型，包括马氏链、RNN等。由于深度学习的发展，自2017年以来model-based RS达到了峰值，许多研究相继出炉，可见图4。 4.2 Attention in the Research Community    数据挖掘相关的会议，如KDD， CIKM，WSDM，IJCAI，AAAI，ECML，Recsys，WWW，SIGIR。 5 CATEGORIZATION AND SUMMARIZATION   将SBRS研究分为以下几个领域。 5.1 Categorization from the Research Issue Perspective   SBRS研究关注的是推荐什么和如何推荐。推荐什么讨论的是研究任务、场景，这些都是优先设置的；如何推荐，这与3.3节中所列举的挑战是相关的。 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings.    通常情况下，SBRS中获取的session数据可以分为两类。第一个是像购物车一样的（如天猫数据集），这样的session又明确的内在session结构。例如，每个购物车界限清楚。在这种情况下，购物车是自然色session。    另外一种是类似于历史行为的数据，原始数据是事件记录的集合，例如电影数据、POI数据等。Event历史数据通常没有一个自然的session结构；换言之，没有一个明确的边界可以区分events。例如，一个用户经常只看某一部电影。因此，session特征是模糊的，数据不是那么strong。这类数据通常用某些技术，例如时间滑动窗口，将数据分成多个session。这种推荐任务是next event/action推荐。    (a) Next-Item(s) Recommendations. Next-item推荐指的是在一个session钟，推荐下一个或下几个item（session通常是购物车）。Next-item推荐是主流的和常见的推荐任务。如表3，是next-item推荐的相关研究。    (b) Next-Basket Recommendations. 在下一个session中推荐一个item。Next-basket推荐研究相对较少。见表3所示。    ( c c c) Next-Event/Action Recommendations. 推荐下一个event/action，如看电影或听歌等。这类研究数据没有session结果，相关研究见表3所示。 5.1.2 How to Recommend: A Categorization of recommendation approaches.   SBRS一个主要的驱动力就是耦合或依赖关系。这是由于特殊的设置导致的：给定session上下文，推荐系统会根据下一个上下文信息来寻找相应的items或events。如何推荐，本质上就是图2每层或不同层之间的复杂的依赖关系。根据session数据的层级结构，相应的推荐方法可以分为5个分支。    (a) Item-level Dependency Modeling. Item-level依赖建模是指对一个session内的item之间或event之间的依恋关系建模。近年来，许多研究是建立在这个分支上的。有几个典型的问题会对模型质量或性能产生影响。    - Ordered vs. unordered items. 现实场景中的session数据通常分为两种类型：有序和无序。根据session中是否存在item的排序关系来确定。例如，在医疗或基因表达数据中，顺序将相当严格。而购物车数据中，顺序是没有意义的，因为顾客挑选item时是随机的。   为此，一些方法假定session中的item有严格顺序，依据item之间的序列关系来确定item的顺序。一种简单的方法是基于序列模式挖掘的RS，显式地挖掘序列模式从而指导推荐。为获取session内item之间的隐藏序列关系，并保留原始的信息，可以采用马氏链、RNN等模型。马氏链和RNN模型在处理序列关系数据集时有巨大优势。   其他方法尝试放松或者抛弃这个顺序假设。基于模式/规则的方法相应而出，它们根据item的共现信息来显式地挖掘模式。为捕获item之间的隐藏关系，采用的方法包括：因子分解机，浅层NN， DNN， CNN。    - First-order dependency vs. higher-order dependency. 一些方法是建立在一阶的依赖关系之上的，只获取item之间的一阶依赖关系。在预测next item时，仅依赖前一个item。方法包括：一阶马氏链，因子分解机。然而，许多session数据不仅包括一阶依赖关系，还包括高阶的依赖关系在这种情况下，基于网络的方法更容易获取高阶依赖关系，这时的网络模型包括浅层和深层网络模型。    (b) Session-level Dependency Modelling. 指的是对session之间的依赖关系进行建模。由于session是建立在item之上的，所以对session-level的依赖关系进行建模往往就伴随着item-level的依赖关系建模。Session-level依赖关系建模分为next-item推荐和next-basket推荐。对于next-item推荐来说，session-level依赖关系建模，采用的是session之间的依赖关系，因此要考虑前面的sessions。因此，可以增强先验信息。在next-basket推荐中，session-level依赖关系建模对于获取session之间的依赖关系很有必要。   根据对session之间的依赖关系进行建模，session-level依赖关系建模也分为两种：    - Item dependency modelling. item依赖关系建模是对item之间的转换关系进行建模。Item可能来自不同的session，这种方法首先研究session之间item的转换关系，然后根据当前basket中的item预测下一个basket中出现的item。如因子分解机。    - Collective dependency modelling. 和上述方法不同，集合依赖关系建模通过将每个session作为一个整体来建立session之间的依赖关系。一个session的表示可以通过一个层级网络学习到，该模型首先学习item表示，然后集合session中每个item的表示。在训练过程中，下一个session来知道表示学习。    ( c c c) Feature-level Dependency Modelling. 指的是特征之间的依赖关系建模和feature-item关系建模。特征之间的依赖关系是一个item的特征可能会影响另一个特征。例如，不同国家的Apple价格也不一样。Feature-item的依赖关系建模指的是在一个session中，item出现的情况会受其特征的影响。如item属于同一类，但是作用是互补的，因此item会出现在同一个session中。Item feature的参与使得我们能更好的理解item的特征。因此，feature-level的依赖关系建模对冷启动的item是有好处的。   针对冷启动的item推荐目前已经取得了很多进展。但是，feature-level依赖关系建模扔处于早期研究阶段。    (d) Feature Value-level Dependency Modelling &amp; Domain-Level Dependency Modelling. 获取特征内部的依赖关系和特征值与特征item的交互关系。Domain-level依赖关系建模可以获取不同domain之间的依赖关系。据我们所致，在SBRS研究中，还没有人研究特征值-level和domain-level的依赖关系建模。但是这将是一个有前景的研究方向。 5.2 A Categorization from the Technical Perspective   从技术领域进行分类。 5.2.1 Model-Free Approaches. 依赖数据挖掘技术，没有复杂的数学模型。两个传统的方法是：pattern/rule-based RS用来处理无序的session数据；序列模式RS处理有序的session数据。    (a) Pattern/Rule-based Approaches. 首先利用挖掘频繁出现的模式或者连接规则，并用pattern-rule指导推荐。前提假设是消费者会遵从常见的购物模式。例如，用户经常购买面包和牛奶，这就是给购买牛奶的人推荐面包的理由。应用在无序的session数据上。    (b) Sequential Pattern-based Approaches. 为处理有严格顺序的item或基于时间因子的序列数据。首先挖掘一个序列模式，然后根据前面的item推荐出后面的item 。 5.2.2 Model-based Approaches.   基于模型的RS，往往有严格的假定。现有的基于模型的RS，可以分为三类。    (a) Markov Chain-based Approaches. 建立item之间的一阶依赖关系，利用的是转移概率。序列模式建模，模型容易过滤掉不常出现的item，这样会导致信息丢失。而基于马氏链的模型会综合考虑前面所有的item，降低信息损失。    (b) Factorization-based Approaches. 首先分解item的共现矩阵或item-to-item的转移概率矩阵为每个item的表示向量，然后预测接下来的item。这个方法区别于一般的因子分解机方法。    © Neural Model-based Approaches. 利用神经网络学习item之间或session之间的复杂的关系和交互，然后根据交互关系获得相应推荐。根据模型结构，可以分为浅层/深层模型，也成为embeddings model和representation model。 5.2.3 Comparisons between Different Technical Approaches.   不同技术的比较。model-free方法简单，直接，便于实现。由于pattern/rule-based和序列模式的方法只是基于频率进行建模的，这样就会过滤掉不常出现但是可能比较重要的item或模式。因此，model-free方法使用与经常出现的item的数据集。model-based方法对复杂的数据集处理效果更好。一方面，它们不会显式地过滤掉item或模式，将信息保留到最大程度；另一方面，由于方法复杂，可以处理复杂、隐式的数据关系，推荐结果更加可靠。表5是不同方法的比较。 6 MODEL-FREE APPROACHES   主要依赖于数据挖掘尤其是模式挖掘技术。基本思想是通过从session数据中挖掘共有的、显式地模式，然后用于推荐， 6.1 Pattern/Rule-based Approaches   主要包括了三个阶段：frequent模式挖掘，session匹配，item推荐。具体来说，给定item集合 I I I和对应的session集合 S S S，frequent模式集合为 P T = { p 1 , p 2 , . . . , p ∣ P T ∣ } PT = \{p_{1}, p_{2}, ..., p_{|PT|}\} PT={p1​,p2​,...,p∣PT∣​}是用模式挖掘算法挖掘到的。如Apriori和FP-Tree算法。对于给定的、部分session s ^ \hat{s} s^（例如，一次交易中选择的item），如果item i ^ \hat{i} i^存在，那么 s ^ ∪ i ^ ( i ^ ∈ I ∖ s ^ ) \hat{s} \cup \hat{i} (\hat{i} \in I \setminus \hat{s}) s^∪i^(i^∈I∖s^)就是一个frequent pattern，称 { s ^ ∪ i ^ } ∈ P T \{\hat{s} \cup \hat{i}\} \in PT {s^∪i^}∈PT。那么 i ^ \hat{i} i^就是候选item。进一步，如果条件概率 P ( i ^ ∣ s ^ ) &amp;gt; β P(\hat{i} | \hat{s}) &amp;gt; \beta P(i^∣s^)&gt;β，那么就将 i ^ \hat{i} i^加到候选列表中。   除了上面提到的pattern/rule-based RS框架外，还有许多变体。[83]将关联规则挖掘结合到协同过滤中，它们在模式挖掘中取代了最小支持约束来提高效率，以此来避免挖掘和用户无关的规则。考虑到不同item的重要性，[148]和[40]采用连续页面查看来衡量每个页面的重要性，然后利用这个权重，将这个权重加到关联规则挖掘中，简历加权的关联规则RS。通过挖掘用户行为模式，例如，文本导航页，关联规则挖掘则用来获取特定用户的喜好，以此获取更加个性化的推荐。其他工作将模式挖掘结合到协同过滤中来解决一些特殊问题，如稀疏性，健壮性和个性化。Pattern-based RS除了传统的购物车RS外， 还可以用于web推荐，音乐推荐等。 6.2 Sequential Pattern-based Approaches   虽然和pattern-based RS类似，sequential pattern based RS主要有两点不同： 1）它主要利用交叉session推荐来获取session内的依赖关系；2）考虑session的顺序，因此要结合序列数据。sequential pattern based RS也包含了三个阶段：sequential模式挖掘，序列匹配，获取推荐。   给定一个序列集合 Q = { q 1 , q 2 , . . . , q ∣ Q ∣ } Q = \{q_{1}, q_{2}, ..., q_{|Q|}\} Q={q1​,q2​,...,q∣Q∣​}，其中序列 q = { s 1 , s 2 , . . . , s ∣ q ∣ } q = \{s_{1}, s_{2}, ..., s_{|q|}\} q={s1​,s2​,...,s∣q∣​}是session的集合。   除了上述描述的基本框架外，还有许多扩展。一个典型的例子就是利用用户相关sequential pattern挖掘来做个性化推荐。另一个扩展是将sequential pattern和协同过滤融合。由于进行了组合，动态的单个模式和通用的偏好模型都将考虑到。 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches   利用马氏链在给定一个session内的一系列item以后，预测下一个item。为降低模型复杂度，许多RS都建立在一阶马氏链上。 7.1.1 Basic Markov Chain-based Approaches.   一般来说，基本的基于马氏链的RS很简单：首先在训练集的item序列上计算转移概率，然后将用户的购物序列和利用转移概率计算出的序列进行匹配。概率比较高的item将放到推荐列表中。   给定session集合 S S S，每个session s s s是有序的item序列。马氏链将所有的session编码到一个图 G G G中，每个item是一个节点，item的共现信息作为边。每个item的频率和共现信息作为边的权重。每个session是G中的一条路径。   马氏链是一个元组 { S T , P t , P 0 } \{ST, \bm{P_{t}}, P_{0}\} {ST,Pt​,P0​}， S T ST ST是状态空间，包含了 G G G中所有可见的节点； P t \bm{P_{t}} Pt​是 m ∗ m m * m m∗m的转移概率矩阵； P 0 P_{0} P0​是每个状态的初始概率。一阶转移概率定义为：                  然后就可以刘勇上述一阶马氏链模型估计shopping path的概率：                  给定item序列，可以选择概率比较更高的shopping path，并取给定的item作为先验信息。   除上面定义的基本马氏链RS外，还有许多变体。如，结合一阶和二阶马氏链模型；提出基于隐马氏链的概率模型。通过结合其他因素，一高推荐的准确性。 7.1.2 Latent Markov Embedding-based Approaches.   LME-based RS首先将马氏链嵌入到欧式空间中，然后计算item的转移概率，依据是欧氏距离。可以解决稀疏性问题。每个item i i i表示成向量 v i \bm{v_{i}} vi​，是一个 d d d维向量，转移概率 P ( i j − 1 → i j ) P(i_{j-1} \rightarrow i_{j}) P(ij−1​→ij​)。Shopping path q ′ = { i 1 → i 2 → . . . → i l } q &amp;#x27; = \{i_{1} \rightarrow i_{2} \rightarrow ... \rightarrow i_{l}\} q′={i1​→i2​→...→il​}的概率为：                  为获得个性化推荐，[46]提出PME模型，将users和items映射到欧式空间。[39]提出个性化排序肚量embedding学习。 7.2 Factorization Machine-based Approaches   近来，因子分解机常用来做推荐模型。一旦从观测数据中获得了个性化转移概率，对于每个用户 u u u就建立了一个转移矩阵 A u \bm{A^{u}} Au。因此，对于所有用户，转移Tensor A \rm{A} A。   因子分解模型仅建立在item的共现转移矩阵上，只能获取item的序列模型，但是忽略了用户的偏好。[82]结合矩阵分解和协同过滤来获取个人偏好和item转移模式。 7.3 Neural Model-based Approaches   基于神经网络的方法。 7.3.1 Shallow Neural Models.   浅层网络，或称为嵌入模型，包含浅层网络结构。将session中的item映射到一个隐空间，然后获取item之间的关系。隐向量表示包含了丰富的信息。   如[57]。wide-in，wide-out模型。首先将用户ID和item ID映射到隐向量表示，然后组合作为给定的上下文表示，输出预测的item。   网络利用Logistic函数映射用户 u u u和item i i i： v u = σ ( W : , u 1 ) \bm{v_{u}} = \sigma(\bm{W_{:, u}^{1}}) vu​=σ(W:,u1​) v i = σ ( W : , i 2 ) \bm{v_{i}} = \sigma(\bm{W_{:, i}^{2}}) vi​=σ(W:,i2​) 其中， W 1 , W 2 \bm{W^{1}}, \bm{W}^{2} W1,W2是权重矩阵.利用这种方法，每个用户和item都被映射成向量。   此外，将item特征融入到网络中可以解决冷启动推荐问题。 7.3.2 Deep Neural Models.   SBRS深度网络模型始于2016年，如GRU4Rec。在GRU4Rec基础上，提出了一系列模型。基于RNN的模型占据了主导地位，因为大多数session数据是序列化的。基于DNN的模型用来优化不同的表示，基于CNN的模型经常用来提取局部特征。    (a) RNN-based Models. Session集合 S S S， s s s是一次交易中的item集合，GRU4Rec将每个Session建模成一个序列，预测下一个元素的概率分布。GRU是ＲＮＮ单元，延长状态更新如下：                  每个GRU单元表示一个隐藏状态，GRU层包含了一系列GRU单元。输入 x t x_{t} xt​是session s s s中的item i t i_{t} it​的嵌入表示。因此，给定session s s s中的历史item，可以预测下一个item的概率分布。   为改进GRU4Rec，[124]采用序列处理和dropout来做数据增强。另外，预训练模型也经常使用。[11]提出了分层的RNN来提取交叉session的信息。   除了上述的GRU外，还有很多RNN的变体。DREAM学习用户的动态表示，其他的扩展包括：1）变分推理，处理不确定稀疏业务；2）其他信息如item特征，上下文因素。3）注意力机制。    (b) DNN-based Models. 除了RNN，DNN也可以用于SBRS中，尤其是当session中的item没有顺序时。[144]中，使用DNN学习session表示。    (b) CNN-based Models. CNN也可以用于SBRS中，原因有：1）CNN放松了session中item的顺序假定，模型更鲁邦；2）局部学习能力强，高效提取union-level依赖关系。 8 PROSPECTS AND FUTURE DIRECTIONS   分析不足和SBRS未来研究方向。SBRS是一个相对较新的领域。 8.1 Session-based Recommendations With General User Preference   SBRS通常忽略了一般用户的偏好，而其他传统方法却可以获取到。这可能导致不可靠的推荐。如何学习一般用户的喜好以及如何应用带SBRS中是一个挑战，这里谈论两点。   将用户偏好融入到SBRS中。用户对于他们购买的item的偏好可以利用user-item偏好矩阵获取。一个直观的方法是先利用传统方法预测用户在候选item上的偏好，然后利用偏好数据调整候选列表。例如，两个候选item在特定上下文中有相似的概率，一个对于特定用户来说有较高的偏好，那么该item会被放在前面。另外一种方法是将两个因素综合考虑。[155]利用GAN实现。   如何在没有偏好数据时将用户体验融入SBRS。现实情况中，偏好数据并不总司可以获取到的，因为用户不会对他们购买的所有item进行评分，这种情况下，基于购物车的交易数据通常认为是用户偏好的隐式反馈。 8.2 Session-based Recommendations Considering More Contextual Factors   推荐上下文是指在推荐时实际的环境。如季节，时间，地点，流行趋势等。这些会对推荐性能产生巨大影响，上下文信息在SBRS中很少采用。需要将更多因素融入到SBRS中，例如CRNN。 8.3 Session-based Recommendations With Noisy and Irrelevant Items   目前，sequential SBRS，如基于RNN，马氏链的模型都假设item有强依赖关系。然而，在实际业务数据中可能不是这样。随机选择的item和推荐的item可能没有关系，推荐结果可能会被噪声误导。 8.4 Session-based Recommendations for Multi-Step Recommendations   购物事件包含了多个步骤。例如，用户买了面包，他随后可能买芝士。 8.5 Session-based Recommendations With Cross-session Information   用户对next-item选择不仅仅取决于同一个session中的item，还可能取决于其他session中的item。 8.6 Session-based Recommendations with Cross-domain Information   用户购买的item涉及多个产品类别（域），不同的域可能不是独立的。" />
<link rel="canonical" href="https://uzzz.org/2019/05/15/792667.html" />
<meta property="og:url" content="https://uzzz.org/2019/05/15/792667.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-15T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"基于session的推荐系统综述 1 INTRODUCTION 2 FORMALIZATION AND NOTATIONS 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance 3.2 Data Characteristics and Complexity 3.3 Key Challenges 3.3.1 An Overview of Challenges in SBRS 3.3.2 A Categorization of Challenges in SBRS 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS 4.2 Attention in the Research Community 5 CATEGORIZATION AND SUMMARIZATION 5.1 Categorization from the Research Issue Perspective 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings. 5.1.2 How to Recommend: A Categorization of recommendation approaches. 5.2 A Categorization from the Technical Perspective 5.2.1 Model-Free Approaches. 5.2.2 Model-based Approaches. 5.2.3 Comparisons between Different Technical Approaches. 6 MODEL-FREE APPROACHES 6.1 Pattern/Rule-based Approaches 6.2 Sequential Pattern-based Approaches 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches 7.1.1 Basic Markov Chain-based Approaches. 7.1.2 Latent Markov Embedding-based Approaches. 7.2 Factorization Machine-based Approaches 7.3 Neural Model-based Approaches 7.3.1 Shallow Neural Models. 7.3.2 Deep Neural Models. 8 PROSPECTS AND FUTURE DIRECTIONS 8.1 Session-based Recommendations With General User Preference 8.2 Session-based Recommendations Considering More Contextual Factors 8.3 Session-based Recommendations With Noisy and Irrelevant Items 8.4 Session-based Recommendations for Multi-Step Recommendations 8.5 Session-based Recommendations With Cross-session Information 8.6 Session-based Recommendations with Cross-domain Information 文章链接 1 INTRODUCTION   推荐系统已经进化为一个基础性的工具，可以帮助用户做出合理的决策和选择，尤其是在大数据环境下，消费者不得不从大量的商品和服务中做出选择。提出了大量的RS模型和技术，许多并已成功应用。在这些RS模型中，content-based RS和协同过滤RS是两个代表性的推荐模型。学界和工业界已经证实了其有效性。   然而，上述的传统的RS仍存在许多缺点。其中一个就是这些模型只关注。其中一个比较严重的缺点是：这些模型只关注用户长期的、静态的偏好，而忽略了短期的交易模式。这种情况下, 用户在某个时间点的兴趣很可能被其历史浏览行为覆盖。这是因为RS挺长将一个基本交易单元（例如一个session）分解成更小粒度上的记录，然后再混合这些记录。这种分裂模式破坏了交易行为，其中就包括用户的偏好信息。   为解决以上问题，有必要考虑交易的结构。换句话说，有必要学习用户的交易行为。SBRS应势而出。这里，一个session可以理解为是包含了很多item（例如商品）的交易。和content-based RS、基于协同过滤的RS不同，SBRS综合考虑了session信息，并将一个session作为推荐的基本单元。如图1的底部所示，SBRS可以最大限度地减少由于忽略或者打破session结构而造成的信息损失。   除了在电子商务领域，SBRS还可以应用在网页推荐、POI推荐、旅游、歌曲、视频推荐等。为包含这些领域，这里的session就不仅仅指交易单元，而是在一段时间内，购买后者浏览的item的集合。   表1是SBRA和其他RS的对比。   在这篇综述中，将对SBRS进行全面系统的概述。将session作为推荐的基本单元，这是近年来一种相对新颖的推荐模型。 2 FORMALIZATION AND NOTATIONS   本节，我们将定义session和SBRS一些相关的概念。   Definition 2.1 (Session). 一个session指的是在一段时间内手机或者购买的item的集合。例如，一次交易中购买的item或用户一小段时间内听的歌曲也可以视为一个session。此外，用户在固定时间段内连续点击的网页也可以看做是一个session。   Definition 2.2 (Session-based recommender systems (SBRS)). 给定已有的session信息，如一个session的部分信息或者历史session，SBRA就是想依据一个session或者多个session之间的复杂关系预测出session中未知的部分或未来可能的session。   因此，SBRS可以分为两种：下一个item的推荐，这种推荐模型推荐的是当前session的一部分；下一个session的推荐。   同城，推荐应用程序，例如基于购物车的业务系统，会包含两个基本对象：user和item。用户集合为 U = { u 1 , u 2 , . . . , u ∣ U ∣ } U = \\{u_{1}, u_{2}, ..., u_{|U|}\\} U={u1​,u2​,...,u∣U∣​}， item集合为 I = { i 1 , i 2 , . . . , i ∣ I ∣ } I = \\{i_{1}, i_{2},..., i_{|I|}\\} I={i1​,i2​,...,i∣I∣​}。user和item的交互行为包括：click，buy等，是RS中重要的组成部分。例如，用户点击的所有的item形成click session；用户购买的item又可以形成交易session。通常，在一段时间内，一个用户发生交互的item构成一个session s = { i 1 , i 2 , . . . , i ∣ s ∣ } s = \\{i_{1}, i_{2}, ..., i_{|s|}\\} s={i1​,i2​,...,i∣s∣​}。Session的集合就是 S = { s 1 , s 2 , . . . , s ∣ S ∣ } S = \\{s_{1}, s_{2}, ..., s_{|S|}\\} S={s1​,s2​,...,s∣S∣​}。SBRS将未知的session作为目标 t \\bm{t} t，利用已有的session信息来预测目标 t \\bm{t} t。Session的上下文信息也可以分为两种，这取决于上下文是取自一个session还是多个。   Definition 2.3 (Intra-session context). 当前session记为 s n s_{n} sn​，intra-session context C I a C^{Ia} CIa就是在session s n s_{n} sn​中已知的item集合。即 C I a = { i ∣ i ∈ s n , i ̸ = i t } C^{Ia} = \\{i | i \\in s_{n}, i \\not= i_{}t\\} CIa={i∣i∈sn​,i̸​=i​t}， i t i_{t} it​就是session s n s_{n} sn​中的未知item。   Definition 2.4 (Inter-session context). 当前session记为 s n s_{n} sn​， C I e C^{Ie} CIe是在session s n s_{n} sn​之前的session集合，即 C I e = { s n − 1 , s n − 2 , . . . , s ∣ C I e ∣ } C^{Ie} = \\{s_{n-1}, s_{n-2}, ..., s_{|C^{Ie}|}\\} CIe={sn−1​,sn−2​,...,s∣CIe∣​}.   Definition 2.5 (Session-based recommendation task). 给定session，上下文 C C C，基于session的推荐任务就是学习一个映射 f f f，将 C C C映射到推荐目标 t \\bm{t} t。session上下文是该任务中主要信息；有时，也会添加item特征，user特征等信息。   Definition 2.6 (Next-item(s) recommendations). 给定一个 C I a C^{Ia} CIa，这种推荐模式就是在 s n s_{n} sn​中预测下一个item。   Definition 2.7 (Next-session (next-basket) recommendations). 给定一个 C I e C^{Ie} CIe，这种推荐模式就是预测session s n s_{n} sn​中的items。 3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES 3.1 Values and Significance   SBRS在学术界，工业界均很重要。在研究领域，SBRS可以保持session的自然特征，避免局部信息损失。例如，如果不考虑session结构，item的共现信息可能会丢失。这些局部的交易信息，在一些特定业务场景中非常关键。 如果没有session信息， （a）容易产生重复推荐，即推荐相似或已现有相同的item；（b）用户的购物模式将消失，不能进行个性化推荐。（c）用户偏好转移（shift）消失，不能捕捉用户的当前的喜好；从一个session到另一个session时，用户的喜好通常是动态变化的；（d）不能捕捉短期、局部的用户喜好。在实际生产中，上述的RS只能捕捉用户长期或全局的喜好。   通过保留session结构并将session作为基本数据单元，SBRS将保留所有的局部信息。因此，SBRS更能提供可靠的推荐。SBRS更关注局部、动态的session。由于当前的或最近的session中的item已被选中，因此SBRS很容易避免推荐重复或者相似的item。此外，由于每个用户的item都是一个session，就更容易知道其交易模式。此外，SBRS中考虑的是当前或者最近的session中的item，而不是全部session中的item，这样就更容易捕获用户局部或短期内的喜好。更重要的是，SBRS容易捕获用户转移的偏好。   在工业应用领域，SBRS更重要。Session数据比其他数据（item特征，item排序）更重要。 3.2 Data Characteristics and Complexity   SBRS同样具有挑战性。在实际应用中，在session的数据集中是具有一个层级结构的，如图2所示的5级层级结构。从特征级到域级。在这5个层级中，中间的3层是session模型的核心。即item是关键部分，原因有二：一方面，item是session数据中的原子粒度的部件；另一方面，item扮演了大多数session模型中的重要角色。   每个item通过由多个异构的特征描述，如item类别、价格、生产地等。每种特征通常包含多个值。在大多数情况下，item之间的相关性是建立在齐共现的基础之上的。一般情况下，一个域中收集的数据会包含多个session。 3.3 Key Challenges   如图2所示，SBRS在每一个局部都有挑战性。 3.3.1 An Overview of Challenges in SBRS    (a) Inner-session challenges. Inner-session challenges发生在session内部，在session内部，结构复杂。一个层级结构包含多个层，Inner-session challenges就是在item level、feature level、feature value level以及这些level交互时的挑战。    (b) Inter-session challenges. Inter-session challenges是指session之间交互时的挑战，即图2中的session level。一点典型的挑战包括：session异构、session之间的依赖、动态session等。    ( c c c) Outer-session challenges. Outer-session challenges是指域level和model level的挑战。   与session相关的上下文指的是session发生时所处的环境信息，例如时间、地点、天气、季节、用户等。在SBRS中应该考虑上下文信息。 3.3.2 A Categorization of Challenges in SBRS   SBRS的所有挑战可以分为四种。    (a) The heterogeneity within each level 每个level是异构的。每个level的元素不同，则特征不同，从而不能平等对待。 Value异构：特征值分布不同。 Feature异构：一个item通常包含不同类型的feature，包括类别、数值。 Item异构：一个session钟的item分布也不相同。 Session异构：不同的上下文环境导致不用的session。有些可能是无关的，有些可能是噪声。 Context异构：上下文的信息不同。    (b) The couplings within each level 每个level的耦合信息，即每个level的交互挑战。 Value-level耦合：同一个特征不同值的交互（intra-feature），和不同特征的值的交互（inter-feature）。 Feature-level耦合：一个特征可能会影响其他特征。 Item-level耦合：在一个session钟，item之间的交互。 Session-level耦合：不同session的交互。在实际的交互场景中，最近的session可能会对当前的session产生影响。 Domain-level耦合：不同域之间的交互。 Contextual耦合：不同上下文信息的交互。    ( c c c) Other complexities within each level 每个level是相当复杂的。    (d) The interactions between different levels 不同level之间的交互，不同的level可能存在不同的交互关系。 Feature-item交互。 Session-item交互。 4 AN OVERVIEW OF SBRS 4.1 A Brief Evolutionary History of SBRS   SBRS研究从1990s以来，就有不同的研究内容：pattern-based RS，rule-based RS，sequence-based RS，transaction-based RS，session-aware RS等。我们将SBRS的研究分为你两个不同的阶段：1990-2010的model-free阶段；2010-至今，基于model的SBRS。第一个阶段，室友数据挖掘技术驱动的，包括模式挖掘、关联规则和序列挖掘。根据相应的文献研究，我们发现，2000s前后是这一阶段的高峰时期。第二阶段是由统计和机器学习驱动的，尤其是一些与时间序列相关的模型，包括马氏链、RNN等。由于深度学习的发展，自2017年以来model-based RS达到了峰值，许多研究相继出炉，可见图4。 4.2 Attention in the Research Community    数据挖掘相关的会议，如KDD， CIKM，WSDM，IJCAI，AAAI，ECML，Recsys，WWW，SIGIR。 5 CATEGORIZATION AND SUMMARIZATION   将SBRS研究分为以下几个领域。 5.1 Categorization from the Research Issue Perspective   SBRS研究关注的是推荐什么和如何推荐。推荐什么讨论的是研究任务、场景，这些都是优先设置的；如何推荐，这与3.3节中所列举的挑战是相关的。 5.1.1 What to Recommend: A categorization of recommendation scenarios and settings.    通常情况下，SBRS中获取的session数据可以分为两类。第一个是像购物车一样的（如天猫数据集），这样的session又明确的内在session结构。例如，每个购物车界限清楚。在这种情况下，购物车是自然色session。    另外一种是类似于历史行为的数据，原始数据是事件记录的集合，例如电影数据、POI数据等。Event历史数据通常没有一个自然的session结构；换言之，没有一个明确的边界可以区分events。例如，一个用户经常只看某一部电影。因此，session特征是模糊的，数据不是那么strong。这类数据通常用某些技术，例如时间滑动窗口，将数据分成多个session。这种推荐任务是next event/action推荐。    (a) Next-Item(s) Recommendations. Next-item推荐指的是在一个session钟，推荐下一个或下几个item（session通常是购物车）。Next-item推荐是主流的和常见的推荐任务。如表3，是next-item推荐的相关研究。    (b) Next-Basket Recommendations. 在下一个session中推荐一个item。Next-basket推荐研究相对较少。见表3所示。    ( c c c) Next-Event/Action Recommendations. 推荐下一个event/action，如看电影或听歌等。这类研究数据没有session结果，相关研究见表3所示。 5.1.2 How to Recommend: A Categorization of recommendation approaches.   SBRS一个主要的驱动力就是耦合或依赖关系。这是由于特殊的设置导致的：给定session上下文，推荐系统会根据下一个上下文信息来寻找相应的items或events。如何推荐，本质上就是图2每层或不同层之间的复杂的依赖关系。根据session数据的层级结构，相应的推荐方法可以分为5个分支。    (a) Item-level Dependency Modeling. Item-level依赖建模是指对一个session内的item之间或event之间的依恋关系建模。近年来，许多研究是建立在这个分支上的。有几个典型的问题会对模型质量或性能产生影响。    - Ordered vs. unordered items. 现实场景中的session数据通常分为两种类型：有序和无序。根据session中是否存在item的排序关系来确定。例如，在医疗或基因表达数据中，顺序将相当严格。而购物车数据中，顺序是没有意义的，因为顾客挑选item时是随机的。   为此，一些方法假定session中的item有严格顺序，依据item之间的序列关系来确定item的顺序。一种简单的方法是基于序列模式挖掘的RS，显式地挖掘序列模式从而指导推荐。为获取session内item之间的隐藏序列关系，并保留原始的信息，可以采用马氏链、RNN等模型。马氏链和RNN模型在处理序列关系数据集时有巨大优势。   其他方法尝试放松或者抛弃这个顺序假设。基于模式/规则的方法相应而出，它们根据item的共现信息来显式地挖掘模式。为捕获item之间的隐藏关系，采用的方法包括：因子分解机，浅层NN， DNN， CNN。    - First-order dependency vs. higher-order dependency. 一些方法是建立在一阶的依赖关系之上的，只获取item之间的一阶依赖关系。在预测next item时，仅依赖前一个item。方法包括：一阶马氏链，因子分解机。然而，许多session数据不仅包括一阶依赖关系，还包括高阶的依赖关系在这种情况下，基于网络的方法更容易获取高阶依赖关系，这时的网络模型包括浅层和深层网络模型。    (b) Session-level Dependency Modelling. 指的是对session之间的依赖关系进行建模。由于session是建立在item之上的，所以对session-level的依赖关系进行建模往往就伴随着item-level的依赖关系建模。Session-level依赖关系建模分为next-item推荐和next-basket推荐。对于next-item推荐来说，session-level依赖关系建模，采用的是session之间的依赖关系，因此要考虑前面的sessions。因此，可以增强先验信息。在next-basket推荐中，session-level依赖关系建模对于获取session之间的依赖关系很有必要。   根据对session之间的依赖关系进行建模，session-level依赖关系建模也分为两种：    - Item dependency modelling. item依赖关系建模是对item之间的转换关系进行建模。Item可能来自不同的session，这种方法首先研究session之间item的转换关系，然后根据当前basket中的item预测下一个basket中出现的item。如因子分解机。    - Collective dependency modelling. 和上述方法不同，集合依赖关系建模通过将每个session作为一个整体来建立session之间的依赖关系。一个session的表示可以通过一个层级网络学习到，该模型首先学习item表示，然后集合session中每个item的表示。在训练过程中，下一个session来知道表示学习。    ( c c c) Feature-level Dependency Modelling. 指的是特征之间的依赖关系建模和feature-item关系建模。特征之间的依赖关系是一个item的特征可能会影响另一个特征。例如，不同国家的Apple价格也不一样。Feature-item的依赖关系建模指的是在一个session中，item出现的情况会受其特征的影响。如item属于同一类，但是作用是互补的，因此item会出现在同一个session中。Item feature的参与使得我们能更好的理解item的特征。因此，feature-level的依赖关系建模对冷启动的item是有好处的。   针对冷启动的item推荐目前已经取得了很多进展。但是，feature-level依赖关系建模扔处于早期研究阶段。    (d) Feature Value-level Dependency Modelling &amp; Domain-Level Dependency Modelling. 获取特征内部的依赖关系和特征值与特征item的交互关系。Domain-level依赖关系建模可以获取不同domain之间的依赖关系。据我们所致，在SBRS研究中，还没有人研究特征值-level和domain-level的依赖关系建模。但是这将是一个有前景的研究方向。 5.2 A Categorization from the Technical Perspective   从技术领域进行分类。 5.2.1 Model-Free Approaches. 依赖数据挖掘技术，没有复杂的数学模型。两个传统的方法是：pattern/rule-based RS用来处理无序的session数据；序列模式RS处理有序的session数据。    (a) Pattern/Rule-based Approaches. 首先利用挖掘频繁出现的模式或者连接规则，并用pattern-rule指导推荐。前提假设是消费者会遵从常见的购物模式。例如，用户经常购买面包和牛奶，这就是给购买牛奶的人推荐面包的理由。应用在无序的session数据上。    (b) Sequential Pattern-based Approaches. 为处理有严格顺序的item或基于时间因子的序列数据。首先挖掘一个序列模式，然后根据前面的item推荐出后面的item 。 5.2.2 Model-based Approaches.   基于模型的RS，往往有严格的假定。现有的基于模型的RS，可以分为三类。    (a) Markov Chain-based Approaches. 建立item之间的一阶依赖关系，利用的是转移概率。序列模式建模，模型容易过滤掉不常出现的item，这样会导致信息丢失。而基于马氏链的模型会综合考虑前面所有的item，降低信息损失。    (b) Factorization-based Approaches. 首先分解item的共现矩阵或item-to-item的转移概率矩阵为每个item的表示向量，然后预测接下来的item。这个方法区别于一般的因子分解机方法。    © Neural Model-based Approaches. 利用神经网络学习item之间或session之间的复杂的关系和交互，然后根据交互关系获得相应推荐。根据模型结构，可以分为浅层/深层模型，也成为embeddings model和representation model。 5.2.3 Comparisons between Different Technical Approaches.   不同技术的比较。model-free方法简单，直接，便于实现。由于pattern/rule-based和序列模式的方法只是基于频率进行建模的，这样就会过滤掉不常出现但是可能比较重要的item或模式。因此，model-free方法使用与经常出现的item的数据集。model-based方法对复杂的数据集处理效果更好。一方面，它们不会显式地过滤掉item或模式，将信息保留到最大程度；另一方面，由于方法复杂，可以处理复杂、隐式的数据关系，推荐结果更加可靠。表5是不同方法的比较。 6 MODEL-FREE APPROACHES   主要依赖于数据挖掘尤其是模式挖掘技术。基本思想是通过从session数据中挖掘共有的、显式地模式，然后用于推荐， 6.1 Pattern/Rule-based Approaches   主要包括了三个阶段：frequent模式挖掘，session匹配，item推荐。具体来说，给定item集合 I I I和对应的session集合 S S S，frequent模式集合为 P T = { p 1 , p 2 , . . . , p ∣ P T ∣ } PT = \\{p_{1}, p_{2}, ..., p_{|PT|}\\} PT={p1​,p2​,...,p∣PT∣​}是用模式挖掘算法挖掘到的。如Apriori和FP-Tree算法。对于给定的、部分session s ^ \\hat{s} s^（例如，一次交易中选择的item），如果item i ^ \\hat{i} i^存在，那么 s ^ ∪ i ^ ( i ^ ∈ I ∖ s ^ ) \\hat{s} \\cup \\hat{i} (\\hat{i} \\in I \\setminus \\hat{s}) s^∪i^(i^∈I∖s^)就是一个frequent pattern，称 { s ^ ∪ i ^ } ∈ P T \\{\\hat{s} \\cup \\hat{i}\\} \\in PT {s^∪i^}∈PT。那么 i ^ \\hat{i} i^就是候选item。进一步，如果条件概率 P ( i ^ ∣ s ^ ) &amp;gt; β P(\\hat{i} | \\hat{s}) &amp;gt; \\beta P(i^∣s^)&gt;β，那么就将 i ^ \\hat{i} i^加到候选列表中。   除了上面提到的pattern/rule-based RS框架外，还有许多变体。[83]将关联规则挖掘结合到协同过滤中，它们在模式挖掘中取代了最小支持约束来提高效率，以此来避免挖掘和用户无关的规则。考虑到不同item的重要性，[148]和[40]采用连续页面查看来衡量每个页面的重要性，然后利用这个权重，将这个权重加到关联规则挖掘中，简历加权的关联规则RS。通过挖掘用户行为模式，例如，文本导航页，关联规则挖掘则用来获取特定用户的喜好，以此获取更加个性化的推荐。其他工作将模式挖掘结合到协同过滤中来解决一些特殊问题，如稀疏性，健壮性和个性化。Pattern-based RS除了传统的购物车RS外， 还可以用于web推荐，音乐推荐等。 6.2 Sequential Pattern-based Approaches   虽然和pattern-based RS类似，sequential pattern based RS主要有两点不同： 1）它主要利用交叉session推荐来获取session内的依赖关系；2）考虑session的顺序，因此要结合序列数据。sequential pattern based RS也包含了三个阶段：sequential模式挖掘，序列匹配，获取推荐。   给定一个序列集合 Q = { q 1 , q 2 , . . . , q ∣ Q ∣ } Q = \\{q_{1}, q_{2}, ..., q_{|Q|}\\} Q={q1​,q2​,...,q∣Q∣​}，其中序列 q = { s 1 , s 2 , . . . , s ∣ q ∣ } q = \\{s_{1}, s_{2}, ..., s_{|q|}\\} q={s1​,s2​,...,s∣q∣​}是session的集合。   除了上述描述的基本框架外，还有许多扩展。一个典型的例子就是利用用户相关sequential pattern挖掘来做个性化推荐。另一个扩展是将sequential pattern和协同过滤融合。由于进行了组合，动态的单个模式和通用的偏好模型都将考虑到。 7 MODEL-BASED APPROACHES 7.1 Markov Chain-based Approaches   利用马氏链在给定一个session内的一系列item以后，预测下一个item。为降低模型复杂度，许多RS都建立在一阶马氏链上。 7.1.1 Basic Markov Chain-based Approaches.   一般来说，基本的基于马氏链的RS很简单：首先在训练集的item序列上计算转移概率，然后将用户的购物序列和利用转移概率计算出的序列进行匹配。概率比较高的item将放到推荐列表中。   给定session集合 S S S，每个session s s s是有序的item序列。马氏链将所有的session编码到一个图 G G G中，每个item是一个节点，item的共现信息作为边。每个item的频率和共现信息作为边的权重。每个session是G中的一条路径。   马氏链是一个元组 { S T , P t , P 0 } \\{ST, \\bm{P_{t}}, P_{0}\\} {ST,Pt​,P0​}， S T ST ST是状态空间，包含了 G G G中所有可见的节点； P t \\bm{P_{t}} Pt​是 m ∗ m m * m m∗m的转移概率矩阵； P 0 P_{0} P0​是每个状态的初始概率。一阶转移概率定义为：                  然后就可以刘勇上述一阶马氏链模型估计shopping path的概率：                  给定item序列，可以选择概率比较更高的shopping path，并取给定的item作为先验信息。   除上面定义的基本马氏链RS外，还有许多变体。如，结合一阶和二阶马氏链模型；提出基于隐马氏链的概率模型。通过结合其他因素，一高推荐的准确性。 7.1.2 Latent Markov Embedding-based Approaches.   LME-based RS首先将马氏链嵌入到欧式空间中，然后计算item的转移概率，依据是欧氏距离。可以解决稀疏性问题。每个item i i i表示成向量 v i \\bm{v_{i}} vi​，是一个 d d d维向量，转移概率 P ( i j − 1 → i j ) P(i_{j-1} \\rightarrow i_{j}) P(ij−1​→ij​)。Shopping path q ′ = { i 1 → i 2 → . . . → i l } q &amp;#x27; = \\{i_{1} \\rightarrow i_{2} \\rightarrow ... \\rightarrow i_{l}\\} q′={i1​→i2​→...→il​}的概率为：                  为获得个性化推荐，[46]提出PME模型，将users和items映射到欧式空间。[39]提出个性化排序肚量embedding学习。 7.2 Factorization Machine-based Approaches   近来，因子分解机常用来做推荐模型。一旦从观测数据中获得了个性化转移概率，对于每个用户 u u u就建立了一个转移矩阵 A u \\bm{A^{u}} Au。因此，对于所有用户，转移Tensor A \\rm{A} A。   因子分解模型仅建立在item的共现转移矩阵上，只能获取item的序列模型，但是忽略了用户的偏好。[82]结合矩阵分解和协同过滤来获取个人偏好和item转移模式。 7.3 Neural Model-based Approaches   基于神经网络的方法。 7.3.1 Shallow Neural Models.   浅层网络，或称为嵌入模型，包含浅层网络结构。将session中的item映射到一个隐空间，然后获取item之间的关系。隐向量表示包含了丰富的信息。   如[57]。wide-in，wide-out模型。首先将用户ID和item ID映射到隐向量表示，然后组合作为给定的上下文表示，输出预测的item。   网络利用Logistic函数映射用户 u u u和item i i i： v u = σ ( W : , u 1 ) \\bm{v_{u}} = \\sigma(\\bm{W_{:, u}^{1}}) vu​=σ(W:,u1​) v i = σ ( W : , i 2 ) \\bm{v_{i}} = \\sigma(\\bm{W_{:, i}^{2}}) vi​=σ(W:,i2​) 其中， W 1 , W 2 \\bm{W^{1}}, \\bm{W}^{2} W1,W2是权重矩阵.利用这种方法，每个用户和item都被映射成向量。   此外，将item特征融入到网络中可以解决冷启动推荐问题。 7.3.2 Deep Neural Models.   SBRS深度网络模型始于2016年，如GRU4Rec。在GRU4Rec基础上，提出了一系列模型。基于RNN的模型占据了主导地位，因为大多数session数据是序列化的。基于DNN的模型用来优化不同的表示，基于CNN的模型经常用来提取局部特征。    (a) RNN-based Models. Session集合 S S S， s s s是一次交易中的item集合，GRU4Rec将每个Session建模成一个序列，预测下一个元素的概率分布。GRU是ＲＮＮ单元，延长状态更新如下：                  每个GRU单元表示一个隐藏状态，GRU层包含了一系列GRU单元。输入 x t x_{t} xt​是session s s s中的item i t i_{t} it​的嵌入表示。因此，给定session s s s中的历史item，可以预测下一个item的概率分布。   为改进GRU4Rec，[124]采用序列处理和dropout来做数据增强。另外，预训练模型也经常使用。[11]提出了分层的RNN来提取交叉session的信息。   除了上述的GRU外，还有很多RNN的变体。DREAM学习用户的动态表示，其他的扩展包括：1）变分推理，处理不确定稀疏业务；2）其他信息如item特征，上下文因素。3）注意力机制。    (b) DNN-based Models. 除了RNN，DNN也可以用于SBRS中，尤其是当session中的item没有顺序时。[144]中，使用DNN学习session表示。    (b) CNN-based Models. CNN也可以用于SBRS中，原因有：1）CNN放松了session中item的顺序假定，模型更鲁邦；2）局部学习能力强，高效提取union-level依赖关系。 8 PROSPECTS AND FUTURE DIRECTIONS   分析不足和SBRS未来研究方向。SBRS是一个相对较新的领域。 8.1 Session-based Recommendations With General User Preference   SBRS通常忽略了一般用户的偏好，而其他传统方法却可以获取到。这可能导致不可靠的推荐。如何学习一般用户的喜好以及如何应用带SBRS中是一个挑战，这里谈论两点。   将用户偏好融入到SBRS中。用户对于他们购买的item的偏好可以利用user-item偏好矩阵获取。一个直观的方法是先利用传统方法预测用户在候选item上的偏好，然后利用偏好数据调整候选列表。例如，两个候选item在特定上下文中有相似的概率，一个对于特定用户来说有较高的偏好，那么该item会被放在前面。另外一种方法是将两个因素综合考虑。[155]利用GAN实现。   如何在没有偏好数据时将用户体验融入SBRS。现实情况中，偏好数据并不总司可以获取到的，因为用户不会对他们购买的所有item进行评分，这种情况下，基于购物车的交易数据通常认为是用户偏好的隐式反馈。 8.2 Session-based Recommendations Considering More Contextual Factors   推荐上下文是指在推荐时实际的环境。如季节，时间，地点，流行趋势等。这些会对推荐性能产生巨大影响，上下文信息在SBRS中很少采用。需要将更多因素融入到SBRS中，例如CRNN。 8.3 Session-based Recommendations With Noisy and Irrelevant Items   目前，sequential SBRS，如基于RNN，马氏链的模型都假设item有强依赖关系。然而，在实际业务数据中可能不是这样。随机选择的item和推荐的item可能没有关系，推荐结果可能会被噪声误导。 8.4 Session-based Recommendations for Multi-Step Recommendations   购物事件包含了多个步骤。例如，用户买了面包，他随后可能买芝士。 8.5 Session-based Recommendations With Cross-session Information   用户对next-item选择不仅仅取决于同一个session中的item，还可能取决于其他session中的item。 8.6 Session-based Recommendations with Cross-domain Information   用户购买的item涉及多个产品类别（域），不同的域可能不是独立的。","@type":"BlogPosting","url":"https://uzzz.org/2019/05/15/792667.html","headline":"论文笔记-A Survey on Session-based Recommender Systems","dateModified":"2019-05-15T00:00:00+08:00","datePublished":"2019-05-15T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/05/15/792667.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>论文笔记-A Survey on Session-based Recommender Systems</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p></p>
  <div class="toc">
   <h3>基于session的推荐系统综述</h3>
   <ul>
    <li><a href="#1_INTRODUCTION_2" rel="nofollow" data-token="77aaf1061c1d8a3c14ea7cdd8ab76fba">1 INTRODUCTION</a></li>
    <li><a href="#2_FORMALIZATION_AND_NOTATIONS_11" rel="nofollow" data-token="025f0a476973ad1cdf511a576827d436">2 FORMALIZATION AND NOTATIONS</a></li>
    <li><a href="#3_SIGNIFICANCE_COMPLEXITY_AND_KEY_CHALLENGES_23" rel="nofollow" data-token="a0e232b05cb709d4bd85ce276a96995e">3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES</a></li>
    <ul>
     <li><a href="#31_Values_and_Significance_24" rel="nofollow" data-token="53e4f21410d4931baf1f09a8b5708a11">3.1 Values and Significance</a></li>
     <li><a href="#32_Data_Characteristics_and_Complexity_28" rel="nofollow" data-token="092fc1e0d1706e2a08396c910e06bbe4">3.2 Data Characteristics and Complexity</a></li>
     <li><a href="#33_Key_Challenges_32" rel="nofollow" data-token="803be96339c78cd1c6537d919ff2eb5b">3.3 Key Challenges</a></li>
     <ul>
      <li><a href="#331_An_Overview_of_Challenges_in_SBRS_34" rel="nofollow" data-token="29f0b08da700408d129547f7cf30f6be">3.3.1 An Overview of Challenges in SBRS</a></li>
      <li><a href="#332_A_Categorization_of_Challenges_in_SBRS_39" rel="nofollow" data-token="7d9479a4323a40c914767f2b52dac886">3.3.2 A Categorization of Challenges in SBRS</a></li>
     </ul>
    </ul>
    <li><a href="#4_AN_OVERVIEW_OF_SBRS_62" rel="nofollow" data-token="2a3a12ffe488dad815d0f53eb0e55072">4 AN OVERVIEW OF SBRS</a></li>
    <ul>
     <li><a href="#41_A_Brief_Evolutionary_History_of_SBRS_63" rel="nofollow" data-token="d705b408576515aa1a4dd00fd7c8aac8">4.1 A Brief Evolutionary History of SBRS</a></li>
     <li><a href="#42_Attention_in_the_Research_Community_66" rel="nofollow" data-token="7931b1d8540aa2103a7f9440020b907e">4.2 Attention in the Research Community</a></li>
    </ul>
    <li><a href="#5_CATEGORIZATION_AND_SUMMARIZATION_68" rel="nofollow" data-token="c35c0b8254cfbc254a0e6329b1469605">5 CATEGORIZATION AND SUMMARIZATION</a></li>
    <ul>
     <li><a href="#51_Categorization_from_the_Research_Issue_Perspective_70" rel="nofollow" data-token="2e6588cad1f508ef2706f26b455df9cc">5.1 Categorization from the Research Issue Perspective</a></li>
     <ul>
      <li><a href="#511_What_to_Recommend_A_categorization_of_recommendation_scenarios_and_settings_72" rel="nofollow" data-token="ed3cb49d1d1c4dc093d82a0806dd6044">5.1.1 What to Recommend: A categorization of recommendation scenarios and settings.</a></li>
      <li><a href="#512_How_to_Recommend_A_Categorization_of_recommendation_approaches_79" rel="nofollow" data-token="ef907ea2d846c8d7c2fb1978a8766f52">5.1.2 How to Recommend: A Categorization of recommendation approaches.</a></li>
     </ul>
     <li><a href="#52_A_Categorization_from_the_Technical_Perspective_94" rel="nofollow" data-token="9b6aa39a89b8dac67f5b2e29dd7a7e4f">5.2 A Categorization from the Technical Perspective</a></li>
     <ul>
      <li><a href="#521_ModelFree_Approaches_96" rel="nofollow" data-token="c35cb5b5e9f98e9b1b824b18ec829d9c">5.2.1 Model-Free Approaches.</a></li>
      <li><a href="#522_Modelbased_Approaches_100" rel="nofollow" data-token="e8ceda29089184c9bbe3f8289f6ef2d1">5.2.2 Model-based Approaches.</a></li>
      <li><a href="#523_Comparisons_between_Different_Technical_Approaches_105" rel="nofollow" data-token="c2766d919d5019250a023984fa29c7ff">5.2.3 Comparisons between Different Technical Approaches.</a></li>
     </ul>
    </ul>
    <li><a href="#6_MODELFREE_APPROACHES_108" rel="nofollow" data-token="fb227b47ba45632487650e335e5faa49">6 MODEL-FREE APPROACHES</a></li>
    <ul>
     <li><a href="#61_PatternRulebased_Approaches_110" rel="nofollow" data-token="b6b8a3763a96622cd408db22831b3908">6.1 Pattern/Rule-based Approaches</a></li>
     <li><a href="#62_Sequential_Patternbased_Approaches_113" rel="nofollow" data-token="7bc78862138fb18b12a3ba8fcd852570">6.2 Sequential Pattern-based Approaches</a></li>
    </ul>
    <li><a href="#7_MODELBASED_APPROACHES_117" rel="nofollow" data-token="d6307819003b10df150e77a8726b694a">7 MODEL-BASED APPROACHES</a></li>
    <ul>
     <li><a href="#71_Markov_Chainbased_Approaches_118" rel="nofollow" data-token="21d3fdef0a239fb15dbfc29939243b72">7.1 Markov Chain-based Approaches</a></li>
     <ul>
      <li><a href="#711_Basic_Markov_Chainbased_Approaches_120" rel="nofollow" data-token="95727f39a1e7a542104c2024bb4a6d52">7.1.1 Basic Markov Chain-based Approaches.</a></li>
      <li><a href="#712_Latent_Markov_Embeddingbased_Approaches_129" rel="nofollow" data-token="ba205053c27dbf5dac3460172fa7f9a5">7.1.2 Latent Markov Embedding-based Approaches.</a></li>
     </ul>
     <li><a href="#72_Factorization_Machinebased_Approaches_134" rel="nofollow" data-token="b32daf1e3a6656af3d76de50e09a76f6">7.2 Factorization Machine-based Approaches</a></li>
     <li><a href="#73_Neural_Modelbased_Approaches_137" rel="nofollow" data-token="c82a4a98d58a349243b576e759994297">7.3 Neural Model-based Approaches</a></li>
     <ul>
      <li><a href="#731_Shallow_Neural_Models_139" rel="nofollow" data-token="bfad3f2f4e3f6c1624fa4fad21a11521">7.3.1 Shallow Neural Models.</a></li>
      <li><a href="#732_Deep_Neural_Models_151" rel="nofollow" data-token="3a16da86e5dcad46ac10fe805b06d181">7.3.2 Deep Neural Models.</a></li>
     </ul>
    </ul>
    <li><a href="#8_PROSPECTS_AND_FUTURE_DIRECTIONS_160" rel="nofollow" data-token="3d864a80b3ed0d9edfeec06a8c7c7f9b">8 PROSPECTS AND FUTURE DIRECTIONS</a></li>
    <ul>
     <li><a href="#81_Sessionbased_Recommendations_With_General_User_Preference_162" rel="nofollow" data-token="2b2dedfd93b483a7b55d0fbfb4eebd79">8.1 Session-based Recommendations With General User Preference</a></li>
     <ul>
      <li><a href="#82_Sessionbased_Recommendations_Considering_More_Contextual_Factors_166" rel="nofollow" data-token="7b86716438525cb30cdb649fbee4c296">8.2 Session-based Recommendations Considering More Contextual Factors</a></li>
      <li><a href="#83_Sessionbased_Recommendations_With_Noisy_and_Irrelevant_Items_168" rel="nofollow" data-token="f3c0d2886368038634226caa5ba37511">8.3 Session-based Recommendations With Noisy and Irrelevant Items</a></li>
      <li><a href="#84_Sessionbased_Recommendations_for_MultiStep_Recommendations_170" rel="nofollow" data-token="2d3b24d800aedbf9963254b261fb68dd">8.4 Session-based Recommendations for Multi-Step Recommendations</a></li>
      <li><a href="#85_Sessionbased_Recommendations_With_Crosssession_Information_172" rel="nofollow" data-token="64ca7de240c91d815367ba54637ec711">8.5 Session-based Recommendations With Cross-session Information</a></li>
      <li><a href="#86_Sessionbased_Recommendations_with_Crossdomain_Information_174" rel="nofollow" data-token="04e3df5f8ec715ad7db084e13819252a">8.6 Session-based Recommendations with Cross-domain Information</a></li>
     </ul>
    </ul>
   </ul>
  </div>
  <br> 
  <a href="https://arxiv.org/abs/1902.04864" rel="nofollow" data-token="24a5b03598380cf425ddaab95adb7416">文章链接</a>
  <p></p> 
  <h1><a id="1_INTRODUCTION_2"></a>1 INTRODUCTION</h1> 
  <p>  推荐系统已经进化为一个基础性的工具，可以帮助用户做出合理的决策和选择，尤其是在大数据环境下，消费者不得不从大量的商品和服务中做出选择。提出了大量的RS模型和技术，许多并已成功应用。在这些RS模型中，content-based RS和协同过滤RS是两个代表性的推荐模型。学界和工业界已经证实了其有效性。<br>   然而，上述的传统的RS仍存在许多缺点。其中一个就是这些模型只关注。其中一个比较严重的缺点是：这些模型只关注用户长期的、静态的偏好，而忽略了短期的交易模式。这种情况下, 用户在某个时间点的兴趣很可能被其历史浏览行为覆盖。这是因为RS挺长将一个基本交易单元（例如一个session）分解成更小粒度上的记录，然后再混合这些记录。这种分裂模式破坏了交易行为，其中就包括用户的偏好信息。<br>   为解决以上问题，有必要考虑交易的结构。换句话说，有必要学习用户的交易行为。SBRS应势而出。这里，一个session可以理解为是包含了很多item（例如商品）的交易。和content-based RS、基于协同过滤的RS不同，SBRS综合考虑了session信息，并将一个session作为推荐的基本单元。如图1的底部所示，SBRS可以最大限度地减少由于忽略或者打破session结构而造成的信息损失。<br>   除了在电子商务领域，SBRS还可以应用在网页推荐、POI推荐、旅游、歌曲、视频推荐等。为包含这些领域，这里的session就不仅仅指交易单元，而是在一段时间内，购买后者浏览的item的集合。<br>   表1是SBRA和其他RS的对比。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603102720336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>   在这篇综述中，将对SBRS进行全面系统的概述。将session作为推荐的基本单元，这是近年来一种相对新颖的推荐模型。</p> 
  <h1><a id="2_FORMALIZATION_AND_NOTATIONS_11"></a>2 FORMALIZATION AND NOTATIONS</h1> 
  <p>  本节，我们将定义session和SBRS一些相关的概念。<br>   <em><strong>Definition 2.1 (Session).</strong></em> 一个session指的是在一段时间内手机或者购买的item的集合。例如，一次交易中购买的item或用户一小段时间内听的歌曲也可以视为一个session。此外，用户在固定时间段内连续点击的网页也可以看做是一个session。<br>   <em><strong>Definition 2.2 (Session-based recommender systems (SBRS)).</strong></em> 给定已有的session信息，如一个session的部分信息或者历史session，SBRA就是想依据一个session或者多个session之间的复杂关系预测出session中未知的部分或未来可能的session。<br>   因此，SBRS可以分为两种：下一个item的推荐，这种推荐模型推荐的是当前session的一部分；下一个session的推荐。<br>   同城，推荐应用程序，例如基于购物车的业务系统，会包含两个基本对象：user和item。用户集合为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          U
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           u
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           u
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           u
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            U
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         U = \{u_{1}, u_{2}, ..., u_{|U|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.10903em;">U</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight" style="margin-right: 0.10903em;">U</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>， item集合为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          I
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            I
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         I = \{i_{1}, i_{2},..., i_{|I|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>。user和item的交互行为包括：click，buy等，是RS中重要的组成部分。例如，用户点击的所有的item形成click session；用户购买的item又可以形成交易session。通常，在一段时间内，一个用户发生交互的item构成一个session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          s
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            s
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         s = \{i_{1}, i_{2}, ..., i_{|s|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">s</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight">s</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>。Session的集合就是<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            S
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         S = \{s_{1}, s_{2}, ..., s_{|S|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight" style="margin-right: 0.05764em;">S</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>。SBRS将未知的session作为目标<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi mathvariant="bold-italic">
          t
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.63492em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">t</span></span></span></span></span></span></span>，利用已有的session信息来预测目标<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi mathvariant="bold-italic">
          t
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.63492em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">t</span></span></span></span></span></span></span>。Session的上下文信息也可以分为两种，这取决于上下文是取自一个session还是多个。<br>   <em><strong>Definition 2.3 (Intra-session context).</strong></em> 当前session记为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，intra-session context <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            a
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ia}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">a</span></span></span></span></span></span></span></span></span></span></span></span></span>就是在session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中已知的item集合。即<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            a
           </mi>
          </mrow>
         </msup>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <mi>
          i
         </mi>
         <mi mathvariant="normal">
          ∣
         </mi>
         <mi>
          i
         </mi>
         <mo>
          ∈
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi>
          i
         </mi>
         <mpadded width="0px">
          <mo>
           ̸
          </mo>
         </mpadded>
         <mo>
          =
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mrow></mrow>
         </msub>
         <mi>
          t
         </mi>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ia} = \{i | i \in s_{n}, i \not= i_{}t\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">a</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord mathit">i</span><span class="mord">∣</span><span class="mord mathit">i</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathit">i</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="rlap"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="inner"><span class="mrel latin_fallback"≯</span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.19444em;"><span class=""></span></span></span></span></span></span></span><span class="base"><span class="strut" style="height: 0.36687em; vertical-align: 0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class="" style="top: -1.85em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathit">t</span><span class="mclose">}</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           i
          </mi>
          <mi>
           t
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         i_{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.80952em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>就是session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中的未知item。<br>   <em><strong>Definition 2.4 (Inter-session context).</strong></em> 当前session记为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            e
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ie}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span>是在session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>之前的session集合，即<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            e
           </mi>
          </mrow>
         </msup>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mrow>
           <mi>
            n
           </mi>
           <mo>
            −
           </mo>
           <mn>
            1
           </mn>
          </mrow>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mrow>
           <mi>
            n
           </mi>
           <mo>
            −
           </mo>
           <mn>
            2
           </mn>
          </mrow>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <msup>
            <mi>
             C
            </mi>
            <mrow>
             <mi>
              I
             </mi>
             <mi>
              e
             </mi>
            </mrow>
           </msup>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ie} = \{s_{n-1}, s_{n-2}, ..., s_{|C^{Ie}|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">e</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.12206em; vertical-align: -0.372065em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.50293em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.774093em;"><span class="" style="top: -2.786em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">e</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.372065em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>.<br>   <em><strong>Definition 2.5 (Session-based recommendation task).</strong></em> 给定session，上下文<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          C
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         C
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.07153em;">C</span></span></span></span></span>，基于session的推荐任务就是学习一个映射<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          f
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         f
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathit" style="margin-right: 0.10764em;">f</span></span></span></span></span>，将<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          C
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         C
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.07153em;">C</span></span></span></span></span>映射到推荐目标<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi mathvariant="bold-italic">
          t
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.63492em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">t</span></span></span></span></span></span></span>。session上下文是该任务中主要信息；有时，也会添加item特征，user特征等信息。<br>   <em><strong>Definition 2.6 (Next-item(s) recommendations).</strong></em> 给定一个<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            a
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ia}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">a</span></span></span></span></span></span></span></span></span></span></span></span></span>，这种推荐模式就是在<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中预测下一个item。<br>   <em><strong>Definition 2.7 (Next-session (next-basket) recommendations).</strong></em> 给定一个<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           C
          </mi>
          <mrow>
           <mi>
            I
           </mi>
           <mi>
            e
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         C^{Ie}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.07847em;">I</span><span class="mord mathit mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span>，这种推荐模式就是预测session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           s
          </mi>
          <mi>
           n
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         s_{n}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中的items。</p> 
  <h1><a id="3_SIGNIFICANCE_COMPLEXITY_AND_KEY_CHALLENGES_23"></a>3 SIGNIFICANCE, COMPLEXITY AND KEY CHALLENGES</h1> 
  <h2><a id="31_Values_and_Significance_24"></a>3.1 Values and Significance</h2> 
  <p>  SBRS在学术界，工业界均很重要。在研究领域，SBRS可以保持session的自然特征，避免局部信息损失。例如，如果不考虑session结构，item的共现信息可能会丢失。这些局部的交易信息，在一些特定业务场景中非常关键。 如果没有session信息， （a）容易产生重复推荐，即推荐相似或已现有相同的item；（b）用户的购物模式将消失，不能进行个性化推荐。（c）用户偏好转移（shift）消失，不能捕捉用户的当前的喜好；从一个session到另一个session时，用户的喜好通常是动态变化的；（d）不能捕捉短期、局部的用户喜好。在实际生产中，上述的RS只能捕捉用户长期或全局的喜好。<br>   通过保留session结构并将session作为基本数据单元，SBRS将保留所有的局部信息。因此，SBRS更能提供可靠的推荐。SBRS更关注局部、动态的session。由于当前的或最近的session中的item已被选中，因此SBRS很容易避免推荐重复或者相似的item。此外，由于每个用户的item都是一个session，就更容易知道其交易模式。此外，SBRS中考虑的是当前或者最近的session中的item，而不是全部session中的item，这样就更容易捕获用户局部或短期内的喜好。更重要的是，SBRS容易捕获用户转移的偏好。<br>   在工业应用领域，SBRS更重要。Session数据比其他数据（item特征，item排序）更重要。</p> 
  <h2><a id="32_Data_Characteristics_and_Complexity_28"></a>3.2 Data Characteristics and Complexity</h2> 
  <p>  SBRS同样具有挑战性。在实际应用中，在session的数据集中是具有一个层级结构的，如图2所示的5级层级结构。从特征级到域级。在这5个层级中，中间的3层是session模型的核心。即item是关键部分，原因有二：一方面，item是session数据中的原子粒度的部件；另一方面，item扮演了大多数session模型中的重要角色。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603102637677.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>   每个item通过由多个异构的特征描述，如item类别、价格、生产地等。每种特征通常包含多个值。在大多数情况下，item之间的相关性是建立在齐共现的基础之上的。一般情况下，一个域中收集的数据会包含多个session。</p> 
  <h2><a id="33_Key_Challenges_32"></a>3.3 Key Challenges</h2> 
  <p>  如图2所示，SBRS在每一个局部都有挑战性。</p> 
  <h3><a id="331_An_Overview_of_Challenges_in_SBRS_34"></a>3.3.1 An Overview of Challenges in SBRS</h3> 
  <p>   <em><strong>(a) Inner-session challenges.</strong></em> Inner-session challenges发生在session内部，在session内部，结构复杂。一个层级结构包含多个层，Inner-session challenges就是在item level、feature level、feature value level以及这些level交互时的挑战。<br>    <em><strong>(b) Inter-session challenges.</strong></em> Inter-session challenges是指session之间交互时的挑战，即图2中的session level。一点典型的挑战包括：session异构、session之间的依赖、动态session等。<br>    <em><strong>(<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            c
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           c
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">c</span></span></span></span></span>) Outer-session challenges.</strong></em> Outer-session challenges是指域level和model level的挑战。<br>   与session相关的上下文指的是session发生时所处的环境信息，例如时间、地点、天气、季节、用户等。在SBRS中应该考虑上下文信息。</p> 
  <h3><a id="332_A_Categorization_of_Challenges_in_SBRS_39"></a>3.3.2 A Categorization of Challenges in SBRS</h3> 
  <p>  SBRS的所有挑战可以分为四种。<br>    <em><strong>(a) The heterogeneity within each level</strong></em> 每个level是异构的。每个level的元素不同，则特征不同，从而不能平等对待。</p> 
  <ul> 
   <li>Value异构：特征值分布不同。</li> 
   <li>Feature异构：一个item通常包含不同类型的feature，包括类别、数值。</li> 
   <li>Item异构：一个session钟的item分布也不相同。</li> 
   <li>Session异构：不同的上下文环境导致不用的session。有些可能是无关的，有些可能是噪声。</li> 
   <li>Context异构：上下文的信息不同。</li> 
  </ul> 
  <p>   <em><strong>(b) The couplings within each level</strong></em> 每个level的耦合信息，即每个level的交互挑战。</p> 
  <ul> 
   <li>Value-level耦合：同一个特征不同值的交互（intra-feature），和不同特征的值的交互（inter-feature）。</li> 
   <li>Feature-level耦合：一个特征可能会影响其他特征。</li> 
   <li>Item-level耦合：在一个session钟，item之间的交互。</li> 
   <li>Session-level耦合：不同session的交互。在实际的交互场景中，最近的session可能会对当前的session产生影响。</li> 
   <li>Domain-level耦合：不同域之间的交互。</li> 
   <li>Contextual耦合：不同上下文信息的交互。</li> 
  </ul> 
  <p>   <em><strong>(<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            c
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           c
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">c</span></span></span></span></span>) Other complexities within each level</strong></em> 每个level是相当复杂的。<br>    <em><strong>(d) The interactions between different levels</strong></em> 不同level之间的交互，不同的level可能存在不同的交互关系。</p> 
  <ul> 
   <li>Feature-item交互。</li> 
   <li>Session-item交互。</li> 
  </ul> 
  <h1><a id="4_AN_OVERVIEW_OF_SBRS_62"></a>4 AN OVERVIEW OF SBRS</h1> 
  <h2><a id="41_A_Brief_Evolutionary_History_of_SBRS_63"></a>4.1 A Brief Evolutionary History of SBRS</h2> 
  <p>  SBRS研究从1990s以来，就有不同的研究内容：pattern-based RS，rule-based RS，sequence-based RS，transaction-based RS，session-aware RS等。我们将SBRS的研究分为你两个不同的阶段：1990-2010的model-free阶段；2010-至今，基于model的SBRS。第一个阶段，室友数据挖掘技术驱动的，包括模式挖掘、关联规则和序列挖掘。根据相应的文献研究，我们发现，2000s前后是这一阶段的高峰时期。第二阶段是由统计和机器学习驱动的，尤其是一些与时间序列相关的模型，包括马氏链、RNN等。由于深度学习的发展，自2017年以来model-based RS达到了峰值，许多研究相继出炉，可见图4。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603110458930.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="42_Attention_in_the_Research_Community_66"></a>4.2 Attention in the Research Community</h2> 
  <p>   数据挖掘相关的会议，如KDD， CIKM，WSDM，IJCAI，AAAI，ECML，Recsys，WWW，SIGIR。</p> 
  <h1><a id="5_CATEGORIZATION_AND_SUMMARIZATION_68"></a>5 CATEGORIZATION AND SUMMARIZATION</h1> 
  <p>  将SBRS研究分为以下几个领域。</p> 
  <h2><a id="51_Categorization_from_the_Research_Issue_Perspective_70"></a>5.1 Categorization from the Research Issue Perspective</h2> 
  <p>  SBRS研究关注的是推荐什么和如何推荐。推荐什么讨论的是研究任务、场景，这些都是优先设置的；如何推荐，这与3.3节中所列举的挑战是相关的。</p> 
  <h3><a id="511_What_to_Recommend_A_categorization_of_recommendation_scenarios_and_settings_72"></a>5.1.1 What to Recommend: A categorization of recommendation scenarios and settings.</h3> 
  <p>   通常情况下，SBRS中获取的session数据可以分为两类。第一个是像购物车一样的（如天猫数据集），这样的session又明确的内在session结构。例如，每个购物车界限清楚。在这种情况下，购物车是自然色session。<br>    另外一种是类似于历史行为的数据，原始数据是事件记录的集合，例如电影数据、POI数据等。Event历史数据通常没有一个自然的session结构；换言之，没有一个明确的边界可以区分events。例如，一个用户经常只看某一部电影。因此，session特征是模糊的，数据不是那么strong。这类数据通常用某些技术，例如时间滑动窗口，将数据分成多个session。这种推荐任务是next event/action推荐。<br>    <em><strong>(a) Next-Item(s) Recommendations.</strong></em> Next-item推荐指的是在一个session钟，推荐下一个或下几个item（session通常是购物车）。Next-item推荐是主流的和常见的推荐任务。如表3，是next-item推荐的相关研究。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603111928393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>    <em><strong>(b) Next-Basket Recommendations.</strong></em> 在下一个session中推荐一个item。Next-basket推荐研究相对较少。见表3所示。<br>    <em><strong>(<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            c
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           c
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">c</span></span></span></span></span>) Next-Event/Action Recommendations.</strong></em> 推荐下一个event/action，如看电影或听歌等。这类研究数据没有session结果，相关研究见表3所示。</p> 
  <h3><a id="512_How_to_Recommend_A_Categorization_of_recommendation_approaches_79"></a>5.1.2 How to Recommend: A Categorization of recommendation approaches.</h3> 
  <p>  SBRS一个主要的驱动力就是耦合或依赖关系。这是由于特殊的设置导致的：给定session上下文，推荐系统会根据下一个上下文信息来寻找相应的items或events。如何推荐，本质上就是图2每层或不同层之间的复杂的依赖关系。根据session数据的层级结构，相应的推荐方法可以分为5个分支。<br>    <em><strong>(a) Item-level Dependency Modeling.</strong></em> Item-level依赖建模是指对一个session内的item之间或event之间的依恋关系建模。近年来，许多研究是建立在这个分支上的。有几个典型的问题会对模型质量或性能产生影响。<br>    - <em><strong>Ordered vs. unordered items.</strong></em> 现实场景中的session数据通常分为两种类型：有序和无序。根据session中是否存在item的排序关系来确定。例如，在医疗或基因表达数据中，顺序将相当严格。而购物车数据中，顺序是没有意义的，因为顾客挑选item时是随机的。<br>   为此，一些方法假定session中的item有严格顺序，依据item之间的序列关系来确定item的顺序。一种简单的方法是基于序列模式挖掘的RS，显式地挖掘序列模式从而指导推荐。为获取session内item之间的隐藏序列关系，并保留原始的信息，可以采用马氏链、RNN等模型。马氏链和RNN模型在处理序列关系数据集时有巨大优势。<br>   其他方法尝试放松或者抛弃这个顺序假设。基于模式/规则的方法相应而出，它们根据item的共现信息来显式地挖掘模式。为捕获item之间的隐藏关系，采用的方法包括：因子分解机，浅层NN， DNN， CNN。<br>    - <em><strong>First-order dependency vs. higher-order dependency.</strong></em> 一些方法是建立在一阶的依赖关系之上的，只获取item之间的一阶依赖关系。在预测next item时，仅依赖前一个item。方法包括：一阶马氏链，因子分解机。然而，许多session数据不仅包括一阶依赖关系，还包括高阶的依赖关系在这种情况下，基于网络的方法更容易获取高阶依赖关系，这时的网络模型包括浅层和深层网络模型。<br>    <em><strong>(b) Session-level Dependency Modelling.</strong></em> 指的是对session之间的依赖关系进行建模。由于session是建立在item之上的，所以对session-level的依赖关系进行建模往往就伴随着item-level的依赖关系建模。Session-level依赖关系建模分为next-item推荐和next-basket推荐。对于next-item推荐来说，session-level依赖关系建模，采用的是session之间的依赖关系，因此要考虑前面的sessions。因此，可以增强先验信息。在next-basket推荐中，session-level依赖关系建模对于获取session之间的依赖关系很有必要。<br>   根据对session之间的依赖关系进行建模，session-level依赖关系建模也分为两种：<br>    - <em><strong>Item dependency modelling.</strong></em> item依赖关系建模是对item之间的转换关系进行建模。Item可能来自不同的session，这种方法首先研究session之间item的转换关系，然后根据当前basket中的item预测下一个basket中出现的item。如因子分解机。<br>    - <em><strong>Collective dependency modelling.</strong></em> 和上述方法不同，集合依赖关系建模通过将每个session作为一个整体来建立session之间的依赖关系。一个session的表示可以通过一个层级网络学习到，该模型首先学习item表示，然后集合session中每个item的表示。在训练过程中，下一个session来知道表示学习。<br>    <em><strong>(<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            c
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           c
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">c</span></span></span></span></span>) Feature-level Dependency Modelling.</strong></em> 指的是特征之间的依赖关系建模和feature-item关系建模。特征之间的依赖关系是一个item的特征可能会影响另一个特征。例如，不同国家的Apple价格也不一样。Feature-item的依赖关系建模指的是在一个session中，item出现的情况会受其特征的影响。如item属于同一类，但是作用是互补的，因此item会出现在同一个session中。Item feature的参与使得我们能更好的理解item的特征。因此，feature-level的依赖关系建模对冷启动的item是有好处的。</p> 
  <p>  针对冷启动的item推荐目前已经取得了很多进展。但是，feature-level依赖关系建模扔处于早期研究阶段。<br>    <em><strong>(d) Feature Value-level Dependency Modelling &amp; Domain-Level Dependency Modelling.</strong></em> 获取特征内部的依赖关系和特征值与特征item的交互关系。Domain-level依赖关系建模可以获取不同domain之间的依赖关系。据我们所致，在SBRS研究中，还没有人研究特征值-level和domain-level的依赖关系建模。但是这将是一个有前景的研究方向。</p> 
  <h2><a id="52_A_Categorization_from_the_Technical_Perspective_94"></a>5.2 A Categorization from the Technical Perspective</h2> 
  <p>  从技术领域进行分类。</p> 
  <h3><a id="521_ModelFree_Approaches_96"></a>5.2.1 Model-Free Approaches.</h3> 
  <p>依赖数据挖掘技术，没有复杂的数学模型。两个传统的方法是：pattern/rule-based RS用来处理无序的session数据；序列模式RS处理有序的session数据。<br>    <em><strong>(a) Pattern/Rule-based Approaches.</strong></em> 首先利用挖掘频繁出现的模式或者连接规则，并用pattern-rule指导推荐。前提假设是消费者会遵从常见的购物模式。例如，用户经常购买面包和牛奶，这就是给购买牛奶的人推荐面包的理由。应用在无序的session数据上。<br>    <em><strong>(b) Sequential Pattern-based Approaches.</strong></em> 为处理有严格顺序的item或基于时间因子的序列数据。首先挖掘一个序列模式，然后根据前面的item推荐出后面的item 。</p> 
  <h3><a id="522_Modelbased_Approaches_100"></a>5.2.2 Model-based Approaches.</h3> 
  <p>  基于模型的RS，往往有严格的假定。现有的基于模型的RS，可以分为三类。<br>    <em><strong>(a) Markov Chain-based Approaches.</strong></em> 建立item之间的一阶依赖关系，利用的是转移概率。序列模式建模，模型容易过滤掉不常出现的item，这样会导致信息丢失。而基于马氏链的模型会综合考虑前面所有的item，降低信息损失。<br>    <em><strong>(b) Factorization-based Approaches.</strong></em> 首先分解item的共现矩阵或item-to-item的转移概率矩阵为每个item的表示向量，然后预测接下来的item。这个方法区别于一般的因子分解机方法。<br>    <em><strong>© Neural Model-based Approaches.</strong></em> 利用神经网络学习item之间或session之间的复杂的关系和交互，然后根据交互关系获得相应推荐。根据模型结构，可以分为浅层/深层模型，也成为embeddings model和representation model。</p> 
  <h3><a id="523_Comparisons_between_Different_Technical_Approaches_105"></a>5.2.3 Comparisons between Different Technical Approaches.</h3> 
  <p>  不同技术的比较。model-free方法简单，直接，便于实现。由于pattern/rule-based和序列模式的方法只是基于频率进行建模的，这样就会过滤掉不常出现但是可能比较重要的item或模式。因此，model-free方法使用与经常出现的item的数据集。model-based方法对复杂的数据集处理效果更好。一方面，它们不会显式地过滤掉item或模式，将信息保留到最大程度；另一方面，由于方法复杂，可以处理复杂、隐式的数据关系，推荐结果更加可靠。表5是不同方法的比较。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603134419381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h1><a id="6_MODELFREE_APPROACHES_108"></a>6 MODEL-FREE APPROACHES</h1> 
  <p>  主要依赖于数据挖掘尤其是模式挖掘技术。基本思想是通过从session数据中挖掘共有的、显式地模式，然后用于推荐，</p> 
  <h2><a id="61_PatternRulebased_Approaches_110"></a>6.1 Pattern/Rule-based Approaches</h2> 
  <p>  主要包括了三个阶段：frequent模式挖掘，session匹配，item推荐。具体来说，给定item集合<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          I
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         I
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span></span></span></span></span>和对应的session集合<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         S
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span></span></span></span></span>，frequent模式集合为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
         <mi>
          T
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           p
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           p
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           p
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            P
           </mi>
           <mi>
            T
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         PT = \{p_{1}, p_{2}, ..., p_{|PT|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight" style="margin-right: 0.13889em;">P</span><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>是用模式挖掘算法挖掘到的。如Apriori和FP-Tree算法。对于给定的、部分session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           s
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{s}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">s</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span></span></span></span></span>（例如，一次交易中选择的item），如果item <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{i}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92296em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span></span></span></span></span>存在，那么<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           s
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          ∪
         </mo>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          (
         </mo>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          ∈
         </mo>
         <mi>
          I
         </mi>
         <mo>
          ∖
         </mo>
         <mover accent="true">
          <mi>
           s
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{s} \cup \hat{i} (\hat{i} \in I \setminus \hat{s})
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">s</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.17296em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∖</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">s</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>就是一个frequent pattern，称<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mo>
          {
         </mo>
         <mover accent="true">
          <mi>
           s
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          ∪
         </mo>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          }
         </mo>
         <mo>
          ∈
         </mo>
         <mi>
          P
         </mi>
         <mi>
          T
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \{\hat{s} \cup \hat{i}\} \in PT
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">s</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.17296em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span></span></span></span></span>。那么<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{i}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92296em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span></span></span></span></span>就是候选item。进一步，如果条件概率<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
         <mo>
          (
         </mo>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mi mathvariant="normal">
          ∣
         </mi>
         <mover accent="true">
          <mi>
           s
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          )
         </mo>
         <mo>
          &amp;gt;
         </mo>
         <mi>
          β
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         P(\hat{i} | \hat{s}) &amp;gt; \beta
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.17296em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="mord">∣</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">s</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathit" style="margin-right: 0.05278em;">β</span></span></span></span></span>，那么就将<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           i
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{i}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92296em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92296em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">i</span></span></span><span class="" style="top: -3.22852em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span></span></span></span></span>加到候选列表中。<br>   除了上面提到的pattern/rule-based RS框架外，还有许多变体。[83]将关联规则挖掘结合到协同过滤中，它们在模式挖掘中取代了最小支持约束来提高效率，以此来避免挖掘和用户无关的规则。考虑到不同item的重要性，[148]和[40]采用连续页面查看来衡量每个页面的重要性，然后利用这个权重，将这个权重加到关联规则挖掘中，简历加权的关联规则RS。通过挖掘用户行为模式，例如，文本导航页，关联规则挖掘则用来获取特定用户的喜好，以此获取更加个性化的推荐。其他工作将模式挖掘结合到协同过滤中来解决一些特殊问题，如稀疏性，健壮性和个性化。Pattern-based RS除了传统的购物车RS外， 还可以用于web推荐，音乐推荐等。</p> 
  <h2><a id="62_Sequential_Patternbased_Approaches_113"></a>6.2 Sequential Pattern-based Approaches</h2> 
  <p>  虽然和pattern-based RS类似，sequential pattern based RS主要有两点不同： 1）它主要利用交叉session推荐来获取session内的依赖关系；2）考虑session的顺序，因此要结合序列数据。sequential pattern based RS也包含了三个阶段：sequential模式挖掘，序列匹配，获取推荐。<br>   给定一个序列集合<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          Q
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           q
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           q
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           q
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            Q
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         Q = \{q_{1}, q_{2}, ..., q_{|Q|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord mathit">Q</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight">Q</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>，其中序列<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          q
         </mi>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           s
          </mi>
          <mrow>
           <mi mathvariant="normal">
            ∣
           </mi>
           <mi>
            q
           </mi>
           <mi mathvariant="normal">
            ∣
           </mi>
          </mrow>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         q = \{s_{1}, s_{2}, ..., s_{|q|}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">q</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathit mtight" style="margin-right: 0.03588em;">q</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>是session的集合。<br>   除了上述描述的基本框架外，还有许多扩展。一个典型的例子就是利用用户相关sequential pattern挖掘来做个性化推荐。另一个扩展是将sequential pattern和协同过滤融合。由于进行了组合，动态的单个模式和通用的偏好模型都将考虑到。</p> 
  <h1><a id="7_MODELBASED_APPROACHES_117"></a>7 MODEL-BASED APPROACHES</h1> 
  <h2><a id="71_Markov_Chainbased_Approaches_118"></a>7.1 Markov Chain-based Approaches</h2> 
  <p>  利用马氏链在给定一个session内的一系列item以后，预测下一个item。为降低模型复杂度，许多RS都建立在一阶马氏链上。</p> 
  <h3><a id="711_Basic_Markov_Chainbased_Approaches_120"></a>7.1.1 Basic Markov Chain-based Approaches.</h3> 
  <p>  一般来说，基本的基于马氏链的RS很简单：首先在训练集的item序列上计算转移概率，然后将用户的购物序列和利用转移概率计算出的序列进行匹配。概率比较高的item将放到推荐列表中。<br>   给定session集合<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         S
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span></span></span></span></span>，每个session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         s
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">s</span></span></span></span></span>是有序的item序列。马氏链将所有的session编码到一个图<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          G
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         G
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit">G</span></span></span></span></span>中，每个item是一个节点，item的共现信息作为边。每个item的频率和共现信息作为边的权重。每个session是G中的一条路径。<br>   马氏链是一个元组<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mo>
          {
         </mo>
         <mi>
          S
         </mi>
         <mi>
          T
         </mi>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi mathvariant="bold-italic">
           P
          </mi>
          <mi mathvariant="bold-italic">
           t
          </mi>
         </msub>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           P
          </mi>
          <mn>
           0
          </mn>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         \{ST, \bm{P_{t}}, P_{0}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord mathit" style="margin-right: 0.05764em;">S</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.294444em;"><span class="" style="top: -2.55em; margin-left: -0.15972em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
         <mi>
          T
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         ST
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span><span class="mord mathit" style="margin-right: 0.13889em;">T</span></span></span></span></span>是状态空间，包含了<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          G
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         G
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit">G</span></span></span></span></span>中所有可见的节点；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi mathvariant="bold-italic">
           P
          </mi>
          <mi mathvariant="bold-italic">
           t
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{P_{t}}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83611em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.294444em;"><span class="" style="top: -2.55em; margin-left: -0.15972em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span>是<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          m
         </mi>
         <mo>
          ∗
         </mo>
         <mi>
          m
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         m * m
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.46528em; vertical-align: 0em;"></span><span class="mord mathit">m</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">m</span></span></span></span></span>的转移概率矩阵；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           P
          </mi>
          <mn>
           0
          </mn>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         P_{0}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是每个状态的初始概率。一阶转移概率定义为：<br>               <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019060314135014.png" alt="在这里插入图片描述"><br>   然后就可以刘勇上述一阶马氏链模型估计shopping path的概率：<br>               <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019060314151889.png" alt="在这里插入图片描述"><br>   给定item序列，可以选择概率比较更高的shopping path，并取给定的item作为先验信息。<br>   除上面定义的基本马氏链RS外，还有许多变体。如，结合一阶和二阶马氏链模型；提出基于隐马氏链的概率模型。通过结合其他因素，一高推荐的准确性。</p> 
  <h3><a id="712_Latent_Markov_Embeddingbased_Approaches_129"></a>7.1.2 Latent Markov Embedding-based Approaches.</h3> 
  <p>  LME-based RS首先将马氏链嵌入到欧式空间中，然后计算item的转移概率，依据是欧氏距离。可以解决稀疏性问题。每个item <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          i
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         i
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit">i</span></span></span></span></span>表示成向量<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi mathvariant="bold-italic">
           v
          </mi>
          <mi mathvariant="bold-italic">
           i
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{v_{i}}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.59444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.335282em;"><span class="" style="top: -2.55em; margin-left: -0.03704em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span>，是一个<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          d
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         d
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">d</span></span></span></span></span>维向量，转移概率<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
         <mo>
          (
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mrow>
           <mi>
            j
           </mi>
           <mo>
            −
           </mo>
           <mn>
            1
           </mn>
          </mrow>
         </msub>
         <mo>
          →
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mi>
           j
          </mi>
         </msub>
         <mo>
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         P(i_{j-1} \rightarrow i_{j})
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.05724em;">j</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>。Shopping path <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           q
          </mi>
          <mo mathvariant="normal">
           ′
          </mo>
         </msup>
         <mo>
          =
         </mo>
         <mo>
          {
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           1
          </mn>
         </msub>
         <mo>
          →
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mn>
           2
          </mn>
         </msub>
         <mo>
          →
         </mo>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mi mathvariant="normal">
          .
         </mi>
         <mo>
          →
         </mo>
         <msub>
          <mi>
           i
          </mi>
          <mi>
           l
          </mi>
         </msub>
         <mo>
          }
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         q &amp;#x27; = \{i_{1} \rightarrow i_{2} \rightarrow ... \rightarrow i_{l}\}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.946332em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.80952em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.36687em; vertical-align: 0em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>的概率为：<br>               <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603142116446.png" alt="在这里插入图片描述"><br>   为获得个性化推荐，[46]提出PME模型，将users和items映射到欧式空间。[39]提出个性化排序肚量embedding学习。</p> 
  <h2><a id="72_Factorization_Machinebased_Approaches_134"></a>7.2 Factorization Machine-based Approaches</h2> 
  <p>  近来，因子分解机常用来做推荐模型。一旦从观测数据中获得了个性化转移概率，对于每个用户<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          u
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         u
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">u</span></span></span></span></span>就建立了一个转移矩阵<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi mathvariant="bold-italic">
           A
          </mi>
          <mi mathvariant="bold-italic">
           u
          </mi>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{A^{u}}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.674108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">u</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>。因此，对于所有用户，转移Tensor <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi mathvariant="normal">
          A
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \rm{A}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">A</span></span></span></span></span></span></span>。<br>   因子分解模型仅建立在item的共现转移矩阵上，只能获取item的序列模型，但是忽略了用户的偏好。[82]结合矩阵分解和协同过滤来获取个人偏好和item转移模式。</p> 
  <h2><a id="73_Neural_Modelbased_Approaches_137"></a>7.3 Neural Model-based Approaches</h2> 
  <p>  基于神经网络的方法。</p> 
  <h3><a id="731_Shallow_Neural_Models_139"></a>7.3.1 Shallow Neural Models.</h3> 
  <p>  浅层网络，或称为嵌入模型，包含浅层网络结构。将session中的item映射到一个隐空间，然后获取item之间的关系。隐向量表示包含了丰富的信息。<br>   如[57]。wide-in，wide-out模型。首先将用户ID和item ID映射到隐向量表示，然后组合作为给定的上下文表示，输出预测的item。<br>   网络利用Logistic函数映射用户<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          u
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         u
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">u</span></span></span></span></span>和item <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          i
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         i
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit">i</span></span></span></span></span>：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi mathvariant="bold-italic">
            v
           </mi>
           <mi mathvariant="bold-italic">
            u
           </mi>
          </msub>
          <mo>
           =
          </mo>
          <mi>
           σ
          </mi>
          <mo>
           (
          </mo>
          <msubsup>
           <mi mathvariant="bold-italic">
            W
           </mi>
           <mrow>
            <mo>
             :
            </mo>
            <mo separator="true">
             ,
            </mo>
            <mi mathvariant="bold-italic">
             u
            </mi>
           </mrow>
           <mn mathvariant="bold-italic">
            1
           </mn>
          </msubsup>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
           \bm{v_{u}} = \sigma(\bm{W_{:, u}^{1}}) 
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.59444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.161108em;"><span class="" style="top: -2.55em; margin-left: -0.03704em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.24722em; vertical-align: -0.383108em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -2.453em; margin-left: -0.15972em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mathbf mtight">:</span><span class="mpunct mathbf mtight">,</span><span class="mord boldsymbol mtight">u</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi mathvariant="bold-italic">
            v
           </mi>
           <mi mathvariant="bold-italic">
            i
           </mi>
          </msub>
          <mo>
           =
          </mo>
          <mi>
           σ
          </mi>
          <mo>
           (
          </mo>
          <msubsup>
           <mi mathvariant="bold-italic">
            W
           </mi>
           <mrow>
            <mo>
             :
            </mo>
            <mo separator="true">
             ,
            </mo>
            <mi mathvariant="bold-italic">
             i
            </mi>
           </mrow>
           <mn mathvariant="bold-italic">
            2
           </mn>
          </msubsup>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
           \bm{v_{i}} = \sigma(\bm{W_{:, i}^{2}}) 
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.59444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.335282em;"><span class="" style="top: -2.55em; margin-left: -0.03704em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord boldsymbol mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.24722em; vertical-align: -0.383108em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -2.453em; margin-left: -0.15972em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mathbf mtight">:</span><span class="mpunct mathbf mtight">,</span><span class="mord boldsymbol mtight">i</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 其中，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi mathvariant="bold-italic">
           W
          </mi>
          <mn mathvariant="bold-italic">
           1
          </mn>
         </msup>
         <mo separator="true">
          ,
         </mo>
         <msup>
          <mi mathvariant="bold-italic">
           W
          </mi>
          <mn>
           2
          </mn>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         \bm{W^{1}}, \bm{W}^{2}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.08456em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">1</span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.15972em;">W</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.890118em;"><span class="" style="top: -3.13901em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span>是权重矩阵.利用这种方法，每个用户和item都被映射成向量。<br>   此外，将item特征融入到网络中可以解决冷启动推荐问题。</p> 
  <h3><a id="732_Deep_Neural_Models_151"></a>7.3.2 Deep Neural Models.</h3> 
  <p>  SBRS深度网络模型始于2016年，如GRU4Rec。在GRU4Rec基础上，提出了一系列模型。基于RNN的模型占据了主导地位，因为大多数session数据是序列化的。基于DNN的模型用来优化不同的表示，基于CNN的模型经常用来提取局部特征。<br>    <em><strong>(a) RNN-based Models.</strong></em> Session集合<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         S
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         s
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">s</span></span></span></span></span>是一次交易中的item集合，GRU4Rec将每个Session建模成一个序列，预测下一个元素的概率分布。GRU是ＲＮＮ单元，延长状态更新如下：<br>               <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190603144030542.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwOTY1NzUz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>   每个GRU单元表示一个隐藏状态，GRU层包含了一系列GRU单元。输入<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           x
          </mi>
          <mi>
           t
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         x_{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         s
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">s</span></span></span></span></span>中的item <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           i
          </mi>
          <mi>
           t
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         i_{t}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.80952em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的嵌入表示。因此，给定session <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         s
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">s</span></span></span></span></span>中的历史item，可以预测下一个item的概率分布。<br>   为改进GRU4Rec，[124]采用序列处理和dropout来做数据增强。另外，预训练模型也经常使用。[11]提出了分层的RNN来提取交叉session的信息。<br>   除了上述的GRU外，还有很多RNN的变体。DREAM学习用户的动态表示，其他的扩展包括：1）变分推理，处理不确定稀疏业务；2）其他信息如item特征，上下文因素。3）注意力机制。<br>    (<em><strong>b) DNN-based Models.</strong></em> 除了RNN，DNN也可以用于SBRS中，尤其是当session中的item没有顺序时。[144]中，使用DNN学习session表示。<br>    (<em><strong>b) CNN-based Models.</strong></em> CNN也可以用于SBRS中，原因有：1）CNN放松了session中item的顺序假定，模型更鲁邦；2）局部学习能力强，高效提取union-level依赖关系。</p> 
  <h1><a id="8_PROSPECTS_AND_FUTURE_DIRECTIONS_160"></a>8 PROSPECTS AND FUTURE DIRECTIONS</h1> 
  <p>  分析不足和SBRS未来研究方向。SBRS是一个相对较新的领域。</p> 
  <h2><a id="81_Sessionbased_Recommendations_With_General_User_Preference_162"></a>8.1 Session-based Recommendations With General User Preference</h2> 
  <p>  SBRS通常忽略了一般用户的偏好，而其他传统方法却可以获取到。这可能导致不可靠的推荐。如何学习一般用户的喜好以及如何应用带SBRS中是一个挑战，这里谈论两点。<br>   将用户偏好融入到SBRS中。用户对于他们购买的item的偏好可以利用user-item偏好矩阵获取。一个直观的方法是先利用传统方法预测用户在候选item上的偏好，然后利用偏好数据调整候选列表。例如，两个候选item在特定上下文中有相似的概率，一个对于特定用户来说有较高的偏好，那么该item会被放在前面。另外一种方法是将两个因素综合考虑。[155]利用GAN实现。<br>   如何在没有偏好数据时将用户体验融入SBRS。现实情况中，偏好数据并不总司可以获取到的，因为用户不会对他们购买的所有item进行评分，这种情况下，基于购物车的交易数据通常认为是用户偏好的隐式反馈。</p> 
  <h3><a id="82_Sessionbased_Recommendations_Considering_More_Contextual_Factors_166"></a>8.2 Session-based Recommendations Considering More Contextual Factors</h3> 
  <p>  推荐上下文是指在推荐时实际的环境。如季节，时间，地点，流行趋势等。这些会对推荐性能产生巨大影响，上下文信息在SBRS中很少采用。需要将更多因素融入到SBRS中，例如CRNN。</p> 
  <h3><a id="83_Sessionbased_Recommendations_With_Noisy_and_Irrelevant_Items_168"></a>8.3 Session-based Recommendations With Noisy and Irrelevant Items</h3> 
  <p>  目前，sequential SBRS，如基于RNN，马氏链的模型都假设item有强依赖关系。然而，在实际业务数据中可能不是这样。随机选择的item和推荐的item可能没有关系，推荐结果可能会被噪声误导。</p> 
  <h3><a id="84_Sessionbased_Recommendations_for_MultiStep_Recommendations_170"></a>8.4 Session-based Recommendations for Multi-Step Recommendations</h3> 
  <p>  购物事件包含了多个步骤。例如，用户买了面包，他随后可能买芝士。</p> 
  <h3><a id="85_Sessionbased_Recommendations_With_Crosssession_Information_172"></a>8.5 Session-based Recommendations With Cross-session Information</h3> 
  <p>  用户对next-item选择不仅仅取决于同一个session中的item，还可能取决于其他session中的item。</p> 
  <h3><a id="86_Sessionbased_Recommendations_with_Crossdomain_Information_174"></a>8.6 Session-based Recommendations with Cross-domain Information</h3> 
  <p>  用户购买的item涉及多个产品类别（域），不同的域可能不是独立的。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
