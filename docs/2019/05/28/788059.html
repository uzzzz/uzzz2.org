<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>分布式key value存储 - - KVStore ：一个数据共享的地方 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="分布式key value存储 - - KVStore ：一个数据共享的地方" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp; KVStore API 基本的 Push 和 Pull 操作 key-value pairs 列表的接口 &nbsp; &nbsp; 分布式的键值对的存储(Ditstributed Key-value Store) KVStore是一个数据共享的地方。我们可以把它认为他是一个简单的类横跨不同的设备(GPUS和不同的机器)，在这里设备将会压入和提取数据。 &nbsp; mxnet深度学习(KVS) 初始化 让我们考虑一个简单的例子:初始化一个(int,NDAarray)对用来存储，然后把它的值再提取出来。 &gt;&gt;&gt; kv = mx.kv.create(&#39;local&#39;) # create a local kv store. &gt;&gt;&gt; shape = (2,3) &gt;&gt;&gt; kv.init(3, mx.nd.ones(shape)*2) &gt;&gt;&gt; a = mx.nd.zeros(shape) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 2. 2. 2.] [ 2. 2. 2.]] 我们把一个2x3的矩阵存在序号为3的地方，并把它从kv里面取出来。 压入，聚合，更新 对于被初始化的键，我们可以压入一个新值用相同的模型。 &gt;&gt;&gt; kv.push(3, mx.nd.ones(shape)*8) &gt;&gt;&gt; kv.pull(3, out = a) # pull out the value &gt;&gt;&gt; print a.asnumpy() [[ 8. 8. 8.] [ 8. 8. 8.]] 用来压入的数据可以来自于任何设备上。另外，我们可以压入几个值在同一个键上，在这里KVStore将首先把这些值加起来然后把这些聚合的值给压入。 &gt;&gt;&gt; gpus = [mx.gpu(i) for i in range(4)] &gt;&gt;&gt; b = [mx.nd.ones(shape, gpu) for gpu in gpus] &gt;&gt;&gt; kv.push(3, b) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 4. 4. 4.] [ 4. 4. 4.]] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;........... &nbsp; 单机4个GPU，kvstore为device，为什么一个gpu显存占用非常大 单机4个GPU，kvstore为device，为什么其中一个gpu显存占用非常大。 比如在resnet101中，把classes num设为100000，其中一个gpu就炸了。 因为第一个做了参数服务器啊，改local吧。可以参考Insightface &nbsp; 当kvstore=‘local’时，单卡训练的显存消耗比多卡多很多 MXNet版本：v1.3.0 问题描述： 在搞模型并行的项目，使用mx.mod.Module, 其中mod.fit()的时候设置kvstore=mx.kvstore.create(‘local’); 多卡(比如2卡)batch-size=2*N的时候，显存在10G左右，训练正常； 单卡的时候，batch-size=N，训练时显存直接爆掉; 按道理上面2种情况下显存消耗应该基本一致才对，跟踪定位发现在下面函数中单卡显存OOM; https://discuss.gluon.ai/t/topic/9252 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="&nbsp; KVStore API 基本的 Push 和 Pull 操作 key-value pairs 列表的接口 &nbsp; &nbsp; 分布式的键值对的存储(Ditstributed Key-value Store) KVStore是一个数据共享的地方。我们可以把它认为他是一个简单的类横跨不同的设备(GPUS和不同的机器)，在这里设备将会压入和提取数据。 &nbsp; mxnet深度学习(KVS) 初始化 让我们考虑一个简单的例子:初始化一个(int,NDAarray)对用来存储，然后把它的值再提取出来。 &gt;&gt;&gt; kv = mx.kv.create(&#39;local&#39;) # create a local kv store. &gt;&gt;&gt; shape = (2,3) &gt;&gt;&gt; kv.init(3, mx.nd.ones(shape)*2) &gt;&gt;&gt; a = mx.nd.zeros(shape) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 2. 2. 2.] [ 2. 2. 2.]] 我们把一个2x3的矩阵存在序号为3的地方，并把它从kv里面取出来。 压入，聚合，更新 对于被初始化的键，我们可以压入一个新值用相同的模型。 &gt;&gt;&gt; kv.push(3, mx.nd.ones(shape)*8) &gt;&gt;&gt; kv.pull(3, out = a) # pull out the value &gt;&gt;&gt; print a.asnumpy() [[ 8. 8. 8.] [ 8. 8. 8.]] 用来压入的数据可以来自于任何设备上。另外，我们可以压入几个值在同一个键上，在这里KVStore将首先把这些值加起来然后把这些聚合的值给压入。 &gt;&gt;&gt; gpus = [mx.gpu(i) for i in range(4)] &gt;&gt;&gt; b = [mx.nd.ones(shape, gpu) for gpu in gpus] &gt;&gt;&gt; kv.push(3, b) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 4. 4. 4.] [ 4. 4. 4.]] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;........... &nbsp; 单机4个GPU，kvstore为device，为什么一个gpu显存占用非常大 单机4个GPU，kvstore为device，为什么其中一个gpu显存占用非常大。 比如在resnet101中，把classes num设为100000，其中一个gpu就炸了。 因为第一个做了参数服务器啊，改local吧。可以参考Insightface &nbsp; 当kvstore=‘local’时，单卡训练的显存消耗比多卡多很多 MXNet版本：v1.3.0 问题描述： 在搞模型并行的项目，使用mx.mod.Module, 其中mod.fit()的时候设置kvstore=mx.kvstore.create(‘local’); 多卡(比如2卡)batch-size=2*N的时候，显存在10G左右，训练正常； 单卡的时候，batch-size=N，训练时显存直接爆掉; 按道理上面2种情况下显存消耗应该基本一致才对，跟踪定位发现在下面函数中单卡显存OOM; https://discuss.gluon.ai/t/topic/9252 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/05/28/788059.html" />
<meta property="og:url" content="https://uzzz.org/2019/05/28/788059.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-28T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp; KVStore API 基本的 Push 和 Pull 操作 key-value pairs 列表的接口 &nbsp; &nbsp; 分布式的键值对的存储(Ditstributed Key-value Store) KVStore是一个数据共享的地方。我们可以把它认为他是一个简单的类横跨不同的设备(GPUS和不同的机器)，在这里设备将会压入和提取数据。 &nbsp; mxnet深度学习(KVS) 初始化 让我们考虑一个简单的例子:初始化一个(int,NDAarray)对用来存储，然后把它的值再提取出来。 &gt;&gt;&gt; kv = mx.kv.create(&#39;local&#39;) # create a local kv store. &gt;&gt;&gt; shape = (2,3) &gt;&gt;&gt; kv.init(3, mx.nd.ones(shape)*2) &gt;&gt;&gt; a = mx.nd.zeros(shape) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 2. 2. 2.] [ 2. 2. 2.]] 我们把一个2x3的矩阵存在序号为3的地方，并把它从kv里面取出来。 压入，聚合，更新 对于被初始化的键，我们可以压入一个新值用相同的模型。 &gt;&gt;&gt; kv.push(3, mx.nd.ones(shape)*8) &gt;&gt;&gt; kv.pull(3, out = a) # pull out the value &gt;&gt;&gt; print a.asnumpy() [[ 8. 8. 8.] [ 8. 8. 8.]] 用来压入的数据可以来自于任何设备上。另外，我们可以压入几个值在同一个键上，在这里KVStore将首先把这些值加起来然后把这些聚合的值给压入。 &gt;&gt;&gt; gpus = [mx.gpu(i) for i in range(4)] &gt;&gt;&gt; b = [mx.nd.ones(shape, gpu) for gpu in gpus] &gt;&gt;&gt; kv.push(3, b) &gt;&gt;&gt; kv.pull(3, out = a) &gt;&gt;&gt; print a.asnumpy() [[ 4. 4. 4.] [ 4. 4. 4.]] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;........... &nbsp; 单机4个GPU，kvstore为device，为什么一个gpu显存占用非常大 单机4个GPU，kvstore为device，为什么其中一个gpu显存占用非常大。 比如在resnet101中，把classes num设为100000，其中一个gpu就炸了。 因为第一个做了参数服务器啊，改local吧。可以参考Insightface &nbsp; 当kvstore=‘local’时，单卡训练的显存消耗比多卡多很多 MXNet版本：v1.3.0 问题描述： 在搞模型并行的项目，使用mx.mod.Module, 其中mod.fit()的时候设置kvstore=mx.kvstore.create(‘local’); 多卡(比如2卡)batch-size=2*N的时候，显存在10G左右，训练正常； 单卡的时候，batch-size=N，训练时显存直接爆掉; 按道理上面2种情况下显存消耗应该基本一致才对，跟踪定位发现在下面函数中单卡显存OOM; https://discuss.gluon.ai/t/topic/9252 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/05/28/788059.html","headline":"分布式key value存储 - - KVStore ：一个数据共享的地方","dateModified":"2019-05-28T00:00:00+08:00","datePublished":"2019-05-28T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/05/28/788059.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>分布式key value存储 - - KVStore ：一个数据共享的地方</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>&nbsp;</p> 
  <h1><a href="https://www.jianshu.com/p/6c97dc54b1b4" rel="nofollow">KVStore API</a></h1> 
  <ul>
   <li><a href="https://www.jianshu.com/p/6c97dc54b1b4#basic-push-and-pull" rel="nofollow">基本的 Push 和 Pull 操作</a></li> 
   <li><a href="https://www.jianshu.com/p/6c97dc54b1b4#interface-for-list-key-value-pairs" rel="nofollow">key-value pairs 列表的接口</a></li> 
   <li>&nbsp;</li> 
  </ul>
  <h2>&nbsp;</h2> 
  <h2>分布式的键值对的存储(Ditstributed Key-value Store)</h2> 
  <p>KVStore是一个数据共享的地方。我们可以把它认为他是一个简单的类横跨不同的设备(GPUS和不同的机器)，在这里设备将会压入和提取数据。</p> 
  <p>&nbsp;</p> 
  <h1><a href="https://blog.csdn.net/qq_25491201/article/details/51277977" rel="nofollow">mxnet深度学习</a>(KVS)</h1> 
  <h2>初始化</h2> 
  <p>让我们考虑一个简单的例子:初始化一个(int,NDAarray)对用来存储，然后把它的值再提取出来。</p> 
  <pre class="has">
<code class="language-python">&gt;&gt;&gt; kv = mx.kv.create('local') # create a local kv store.
&gt;&gt;&gt; shape = (2,3)
&gt;&gt;&gt; kv.init(3, mx.nd.ones(shape)*2)
&gt;&gt;&gt; a = mx.nd.zeros(shape)
&gt;&gt;&gt; kv.pull(3, out = a)
&gt;&gt;&gt; print a.asnumpy()
[[ 2.  2.  2.]
 [ 2.  2.  2.]]
</code></pre> 
  <p>我们把一个2x3的矩阵存在序号为3的地方，并把它从kv里面取出来。</p> 
  <h2>压入，聚合，更新</h2> 
  <p>对于被初始化的键，我们可以压入一个新值用相同的模型。</p> 
  <pre class="has">
<code class="language-python">&gt;&gt;&gt; kv.push(3, mx.nd.ones(shape)*8)
&gt;&gt;&gt; kv.pull(3, out = a) # pull out the value
&gt;&gt;&gt; print a.asnumpy()
[[ 8.  8.  8.]
 [ 8.  8.  8.]]</code></pre> 
  <p>用来压入的数据可以来自于任何设备上。另外，我们可以压入几个值在同一个键上，在这里KVStore将首先把这些值加起来然后把这些聚合的值给压入。</p> 
  <pre class="has">
<code class="language-python">&gt;&gt;&gt; gpus = [mx.gpu(i) for i in range(4)]
&gt;&gt;&gt; b = [mx.nd.ones(shape, gpu) for gpu in gpus]
&gt;&gt;&gt; kv.push(3, b)
&gt;&gt;&gt; kv.pull(3, out = a)
&gt;&gt;&gt; print a.asnumpy()
[[ 4.  4.  4.]
 [ 4.  4.  4.]]</code></pre> 
  <p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<a href="https://blog.csdn.net/qq_25491201/article/details/51277977" rel="nofollow">...........</a></strong></p> 
  <p>&nbsp;</p> 
  <h1><a href="https://discuss.gluon.ai/t/topic/7185" rel="nofollow">单机4个GPU，kvstore为device，为什么一个gpu显存占用非常大</a></h1> 
  <p>单机4个GPU，kvstore为device，为什么其中一个gpu显存占用非常大。<br> 比如在resnet101中，把classes num设为100000，其中一个gpu就炸了。</p> 
  <p>因为第一个做了参数服务器啊，改local吧。可以参考Insightface</p> 
  <p>&nbsp;</p> 
  <h1><a href="https://discuss.gluon.ai/t/topic/9252" rel="nofollow">当kvstore=‘local’时，单卡训练的显存消耗比多卡多很多</a></h1> 
  <h3>MXNet版本：v1.3.0</h3> 
  <h3>问题描述：</h3> 
  <p>在搞模型并行的项目，使用<code>mx.mod.Module</code>, 其中<code>mod.fit()</code>的时候设置<code>kvstore=mx.kvstore.create(‘local’)</code>;</p> 
  <ol>
   <li> <p>多卡(比如2卡)batch-size=2*N的时候，显存在10G左右，训练正常；</p> </li> 
   <li> <p>单卡的时候，batch-size=N，训练时显存直接爆掉;</p> </li> 
  </ol>
  <p>按道理上面2种情况下显存消耗应该基本一致才对，跟踪定位发现在下面函数中单卡显存OOM;</p> 
  <p><a href="https://discuss.gluon.ai/t/topic/9252" rel="nofollow">https://discuss.gluon.ai/t/topic/9252</a></p> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" height="862" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190528102019266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RvbnkyMjc4,size_16,color_FFFFFF,t_70" width="967"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
