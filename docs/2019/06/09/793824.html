<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>人脸表情识别系统介绍——上篇（python实现，含UI界面及完整代码） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="人脸表情识别系统介绍——上篇（python实现，含UI界面及完整代码）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="摘要：这篇博文介绍基于深度卷积神经网络实现的人脸表情识别系统，系统程序由Keras, OpenCv, PyQt5的库实现，训练测试集采用fer2013表情库。如图系统可通过摄像头获取实时画面并识别其中的人脸表情，也可以通过读取图片识别，本文提供完整的程序文件并详细介绍其实现过程。博文要点如下： 表情识别数据集 搭建表情识别的模型 数据增强的批量训练 系统UI界面的实现 点击跳转至博文涉及的全部文件下载页 1. 前言 &nbsp;&nbsp;&nbsp;&nbsp;在这个人工智能成为超级大热门的时代，人脸表情识别已成为其中的一项研究热点，而卷积神经网络、深度信念网络和多层感知器等相关算法在人脸面部表情识别领域的运用最为广泛。面部的表情中包含了太多的信息，轻微的表情变化都会反映出人心理的变化，可想而知如果机器能敏锐地识别人脸中表达的情感该是多么令人兴奋的事。 &nbsp;&nbsp;&nbsp;&nbsp;学习和研究了挺久的深度学习，偶然看到IEEE上面一篇质量很高的文章，里面介绍的是利用深度神经网络实现的面部表情识别，研读下来让我深受启发。于是自己动手做了这个项目，如今SCI论文已投稿，这里特此将前期工作作个总结，希望能给类似工作的朋友带来一点帮助。由于论文尚未公开，这里使用的是已有的模型——如今CNN的主流框架之mini_XCEPTION，该模型性能也已是不错的了，论文中改进的更高性能模型尚不便给出，后面会分享给大家，敬请关注。 2. 表情识别数据集 &nbsp;&nbsp;&nbsp;&nbsp;目前，现有的公开的人脸表情数据集比较少，并且数量级比较小。比较有名的广泛用于人脸表情识别系统的数据集Extended Cohn-Kanada (CK+)是由P.Lucy收集的。CK+数据集包含123 个对象的327 个被标记的表情图片序列，共分为正常、生气、蔑视、厌恶、恐惧、开心和伤心七种表情。对于每一个图片序列，只有最后一帧被提供了表情标签，所以共有327 个图像被标记。为了增加数据，我们把每个视频序列的最后三帧图像作为训练样本。这样CK+数据总共被标记的有981 张图片。这个数据库是人脸表情识别中比较流行的一个数据库，很多文章都会用到这个数据做测试，可通过下面的链接下载。 官网链接：The Extended Cohn-Kanade Dataset(CK+) 网盘链接：百度网盘下载（提取码：8r15） &nbsp;&nbsp;&nbsp;&nbsp;Kaggle是Kaggle人脸表情分析比赛提供的一个数据集。该数据集含28709 张训练样本，3859 张验证数据集和3859 张测试样本，共35887 张包含生气、厌恶、恐惧、高兴、悲伤、惊讶和正常七种类别的图像，图像分辨率为48×48。该数据集中的图像大都在平面和非平面上有旋转，并且很多图像都有手、头发和围巾等的遮挡物的遮挡。该数据库是2013年Kaggle比赛的数据，由于这个数据库大多是从网络爬虫下载的，存在一定的误差性。这个数据库的人为准确率是65%±5%。 官网链接：FER2013 网盘链接：百度网盘下载（提取码：t7xj） &nbsp;&nbsp;&nbsp;&nbsp;由于FER2013数据集数据更加齐全，同时更加符合实际生活的场景，所以这里主要选取FER2013训练和测试模型。为了防止网络过快地过拟合，可以人为的做一些图像变换，例如翻转，旋转，切割等。上述操作称为数据增强。数据操作还有另一大好处是扩大数据库的数据量，使得训练的网络鲁棒性更强。下载数据集保存在fer2013的文件夹下，为了对数据集进行处理，采用如下代码载入和进行图片预处理： import pandas as pd import cv2 import numpy as np dataset_path = &#39;fer2013/fer2013/fer2013.csv&#39; # 文件保存位置 image_size=(48,48) # 图片大小 # 载入数据 def load_fer2013(): data = pd.read_csv(dataset_path) pixels = data[&#39;pixels&#39;].tolist() width, height = 48, 48 faces = [] for pixel_sequence in pixels: face = [int(pixel) for pixel in pixel_sequence.split(&#39; &#39;)] face = np.asarray(face).reshape(width, height) face = cv2.resize(face.astype(&#39;uint8&#39;),image_size) faces.append(face.astype(&#39;float32&#39;)) faces = np.asarray(faces) faces = np.expand_dims(faces, -1) emotions = pd.get_dummies(data[&#39;emotion&#39;]).as_matrix() return faces, emotions # 将数据归一化 def preprocess_input(x, v2=True): x = x.astype(&#39;float32&#39;) x = x / 255.0 if v2: x = x - 0.5 x = x * 2.0 return x &nbsp;&nbsp;&nbsp;&nbsp;载入数据后将数据集划分为训练集和测试集，在程序中调用上面的函数代码如下： from load_and_process import load_fer2013 from load_and_process import preprocess_input from sklearn.model_selection import train_test_split # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) 3. 搭建表情识别的模型 &nbsp;&nbsp;&nbsp;&nbsp;接下来就是搭建表情识别的模型了，这里用到的是CNN的主流框架之mini_XCEPTION。XCEPTION是Google继Inception后提出的对Inception v3的另一种改进，主要是采用深度可分离的卷积（depthwise separable convolution）来替换原来Inception v3中的卷积操作。XCEPTION的网络结构在ImageNet数据集（Inception v3的设计解决目标）上略优于Inception v3，并且在包含3.5亿个图像甚至更大的图像分类数据集上明显优于Inception v3，而两个结构保持了相同数目的参数，性能增益来自于更加有效地使用模型参数，详细可参考论文：Xception: Deep Learning with Depthwise Separable Convolutions，论文Real-time Convolutional Neural Networks for Emotion and Gender Classification等。 &nbsp;&nbsp;&nbsp;&nbsp;既然这样的网络能获得更好结果又是主流，那当然有必要作为对比算法实现以下了，这里博主模型这部分的代码引用了GitHub:https://github.com/oarriaga/face_classification中的模型（其他地方也能找到这个模型的类似代码），模型框图如上图所示，其代码如下： def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01): regularization = l2(l2_regularization) # base img_input = Input(input_shape) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) # module 1 residual = Conv2D(16, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 2 residual = Conv2D(32, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 3 residual = Conv2D(64, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 4 residual = Conv2D(128, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) x = Conv2D(num_classes, (3, 3), #kernel_regularizer=regularization, padding=&#39;same&#39;)(x) x = GlobalAveragePooling2D()(x) output = Activation(&#39;softmax&#39;,name=&#39;predictions&#39;)(x) model = Model(img_input, output) return model 4. 数据增强的批量训练 &nbsp;&nbsp;&nbsp;&nbsp;神经网络的训练需要大量的数据，数据的量决定了网络模型可以达到的高度，网络模型尽量地逼近这个高度。然而对于人脸表情的数据来说，都只存在少量的数据Extended Cohn-Kanada (CK+)的数据量是远远不够的，并且CK+多是比较夸张的数据。Kaggle Fer2013数据集也不过只有3万多数据量，而且有很多遮挡、角度等外界影响因素。既然收集数据要花费很大的人力物力，那么我们就用技术解决这个问题，为避免重复开发首先还是看看有没有写好的库。博主又通读了遍Keras官方文档，其中ImageDataGenerator的图片生成器就可完成这一目标。 为了尽量利用我们有限的训练数据，我们将通过一系列随机变换堆数据进行提升，这样我们的模型将看不到任何两张完全相同的图片，这有利于我们抑制过拟合，使得模型的泛化能力更好。在Keras中，这个步骤可以通过keras.preprocessing.image.ImageGenerator来实现，这个类使你可以：在训练过程中，设置要施行的随机变换通过.flow或.flow_from_directory(directory)方法实例化一个针对图像batch的生成器，这些生成器可以被用作keras模型相关方法的输入，如fit_generator，evaluate_generator和predict_generator。——Keras官方文档 &nbsp;&nbsp;&nbsp;&nbsp;ImageDataGenerator()是一个图片生成器，同时也可以在batch中对数据进行增强，扩充数据集大小（比如进行旋转，变形，归一化等），增强模型的泛化能力。结合前面的模型和数据训练部分的代码如下： &quot;&quot;&quot; Description: 训练人脸表情识别程序 &quot;&quot;&quot; from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping from keras.callbacks import ReduceLROnPlateau from keras.preprocessing.image import ImageDataGenerator from load_and_process import load_fer2013 from load_and_process import preprocess_input from models.cnn import mini_XCEPTION from sklearn.model_selection import train_test_split # 参数 batch_size = 32 num_epochs = 10000 input_shape = (48, 48, 1) validation_split = .2 verbose = 1 num_classes = 7 patience = 50 base_path = &#39;models/&#39; # 构建模型 model = mini_XCEPTION(input_shape, num_classes) model.compile(optimizer=&#39;adam&#39;, # 优化器采用adam loss=&#39;categorical_crossentropy&#39;, # 多分类的对数损失函数 metrics=[&#39;accuracy&#39;]) model.summary() # 定义回调函数 Callbacks 用于训练过程 log_file_path = base_path + &#39;_emotion_training.log&#39; csv_logger = CSVLogger(log_file_path, append=False) early_stop = EarlyStopping(&#39;val_loss&#39;, patience=patience) reduce_lr = ReduceLROnPlateau(&#39;val_loss&#39;, factor=0.1, patience=int(patience/4), verbose=1) # 模型位置及命名 trained_models_path = base_path + &#39;_mini_XCEPTION&#39; model_names = trained_models_path + &#39;.{epoch:02d}-{val_acc:.2f}.hdf5&#39; # 定义模型权重位置、命名等 model_checkpoint = ModelCheckpoint(model_names, &#39;val_loss&#39;, verbose=1, save_best_only=True) callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr] # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) # 图片产生器，在批量中对数据进行增强，扩充数据集大小 data_generator = ImageDataGenerator( featurewise_center=False, featurewise_std_normalization=False, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=.1, horizontal_flip=True) # 利用数据增强进行训练 model.fit_generator(data_generator.flow(xtrain, ytrain, batch_size), steps_per_epoch=len(xtrain) / batch_size, epochs=num_epochs, verbose=1, callbacks=callbacks, validation_data=(xtest,ytest)) &nbsp;&nbsp;&nbsp;&nbsp;以上代码中设置了训练时的结果输出，在训练结束后会将训练的模型保存为hdf5文件到自己指定的文件夹下，由于数据量大模型的训练时间会比较长，建议使用GPU加速。训练结束后测试得到混淆矩阵如下： &nbsp;&nbsp;&nbsp;&nbsp;训练的模型综合在FER2013数据集上的分类准确率为66%，后续调整之后达到了70%，算是中等偏上水平，其实并非模型不好而是在数据预处理、超参数的选取上有很大的可提升空间，当然也可使用其他的模型，譬如可参考论文：Extended deep neural network for facial emotion recognition，大家可自行研究，这里就不多介绍了。 5. 系统UI界面的实现 &nbsp;&nbsp;&nbsp;&nbsp;上面的模型训练好了，但对于我们来说它的作用就只是知道了其准确率还行，其实深度学习的目的最重要还是应用，是时候用上面的模型做点酷酷的东西了。可不可以用上面的模型识别下自己表达的情绪呢？不如做个系统调取摄像头对实时画面中的表情进行识别并显示识别结果，既能可视化的检测模型的实用性能，同时使得整个项目生动有趣激发自己的创造性，当你向别人介绍你的项目时也显得高大上。这里采用PyQt5进行设计，首先看一下最后的效果图，运行后的界面如下： &nbsp;&nbsp;&nbsp;&nbsp;设计功能：一、可选择模型文件后基于该模型进行识别；二、打开摄像头识别实时画面中的人脸表情；三、选择一张人脸图片，对其中的表情进行识别。选择一张图片测试识别效果，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;博主对UI界面的要求是可以简单但颜值必须高，必须高，实用简约高颜值是我奉行的标准，以上的界面几经修改才有了上面的效果。当然博主的目的并不单纯的想秀，而是借此做一个测试模型的系统，可以选择模型、训练测试集等以便界面化地对后面的模型进行各种测试评估，生成用于论文的特定结果数据图或表格等，这个测试系统后面有机会分享给大家。 &nbsp;&nbsp;&nbsp;&nbsp;系统UI界面的实现这部分又设计PyQt5的许多内容，在这一篇博文中介绍恐怕尾大不掉，效果也不好，所以更多的细节内容将在后面的博文中介绍，敬请期待！有需要的朋友可通过下面的链接下载这部分的文件。 【下载链接】 &nbsp;&nbsp;&nbsp;&nbsp;若您想获得博文中涉及的实现完整全部程序文件（包括数据集，py, UI文件等，如下图），这里已打包上传至博主的CSDN下载资源中。如果您没有积分或C币，可点赞关注后（支持一下吧）在评论中留下邮箱，我会第一时间发给你。文件下载链接如下： 下载链接1：人脸表情识别系统完整程序资源 下载链接2：训练用到的数据集（提取码：t7xj） 【运行程序须知】 &nbsp;&nbsp;&nbsp;&nbsp;要安装的库如上图（以上是博主安装的版本），如您想直接运行界面程序，只需在下载链接1中的文件后，运行runMain.py程序。 &nbsp;&nbsp;&nbsp;&nbsp;如您想重新训练模型，下载链接1中的文件后，运行前请下载链接2中的数据集解压到的csv文件放到 fer2013\fer2013 的文件夹下，运行train_emotion_classifier.py程序即可重新训练。 5. 结束语 &nbsp;&nbsp;&nbsp;&nbsp;由于博主能力有限，博文中提及的方法与代码即使经过测试，也难免会有疏漏之处。希望您能热心指出其中的错误，以便下次修改时能以一个更完美更严谨的样子，呈现在大家面前。同时如果有更好的实现方法也请您不吝赐教。 &nbsp;&nbsp;&nbsp;&nbsp;大家的点赞和关注是博主最大的动力，博主所有博文中的代码文件都可分享给您，如果您想要获取博文中的完整代码文件，可通过C币或积分下载，没有C币或积分的朋友可在关注、点赞博文后提供邮箱，我会在第一时间发送给您。博主后面会有更多的分享，敬请关注哦！ 参考文献： [1] Chollet F. Xception: Deep learning with depthwise separable convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1251-1258. [2] Arriaga O, Valdenegro-Toro M, Plöger P. Real-time convolutional neural networks for emotion and gender classification[J]. arXiv preprint arXiv:1710.07557, 2017. [3] Jain D K, Shamsolmoali P, Sehdev P. Extended deep neural network for facial emotion recognition[J]. Pattern Recognition Letters, 2019, 120: 69-74." />
<meta property="og:description" content="摘要：这篇博文介绍基于深度卷积神经网络实现的人脸表情识别系统，系统程序由Keras, OpenCv, PyQt5的库实现，训练测试集采用fer2013表情库。如图系统可通过摄像头获取实时画面并识别其中的人脸表情，也可以通过读取图片识别，本文提供完整的程序文件并详细介绍其实现过程。博文要点如下： 表情识别数据集 搭建表情识别的模型 数据增强的批量训练 系统UI界面的实现 点击跳转至博文涉及的全部文件下载页 1. 前言 &nbsp;&nbsp;&nbsp;&nbsp;在这个人工智能成为超级大热门的时代，人脸表情识别已成为其中的一项研究热点，而卷积神经网络、深度信念网络和多层感知器等相关算法在人脸面部表情识别领域的运用最为广泛。面部的表情中包含了太多的信息，轻微的表情变化都会反映出人心理的变化，可想而知如果机器能敏锐地识别人脸中表达的情感该是多么令人兴奋的事。 &nbsp;&nbsp;&nbsp;&nbsp;学习和研究了挺久的深度学习，偶然看到IEEE上面一篇质量很高的文章，里面介绍的是利用深度神经网络实现的面部表情识别，研读下来让我深受启发。于是自己动手做了这个项目，如今SCI论文已投稿，这里特此将前期工作作个总结，希望能给类似工作的朋友带来一点帮助。由于论文尚未公开，这里使用的是已有的模型——如今CNN的主流框架之mini_XCEPTION，该模型性能也已是不错的了，论文中改进的更高性能模型尚不便给出，后面会分享给大家，敬请关注。 2. 表情识别数据集 &nbsp;&nbsp;&nbsp;&nbsp;目前，现有的公开的人脸表情数据集比较少，并且数量级比较小。比较有名的广泛用于人脸表情识别系统的数据集Extended Cohn-Kanada (CK+)是由P.Lucy收集的。CK+数据集包含123 个对象的327 个被标记的表情图片序列，共分为正常、生气、蔑视、厌恶、恐惧、开心和伤心七种表情。对于每一个图片序列，只有最后一帧被提供了表情标签，所以共有327 个图像被标记。为了增加数据，我们把每个视频序列的最后三帧图像作为训练样本。这样CK+数据总共被标记的有981 张图片。这个数据库是人脸表情识别中比较流行的一个数据库，很多文章都会用到这个数据做测试，可通过下面的链接下载。 官网链接：The Extended Cohn-Kanade Dataset(CK+) 网盘链接：百度网盘下载（提取码：8r15） &nbsp;&nbsp;&nbsp;&nbsp;Kaggle是Kaggle人脸表情分析比赛提供的一个数据集。该数据集含28709 张训练样本，3859 张验证数据集和3859 张测试样本，共35887 张包含生气、厌恶、恐惧、高兴、悲伤、惊讶和正常七种类别的图像，图像分辨率为48×48。该数据集中的图像大都在平面和非平面上有旋转，并且很多图像都有手、头发和围巾等的遮挡物的遮挡。该数据库是2013年Kaggle比赛的数据，由于这个数据库大多是从网络爬虫下载的，存在一定的误差性。这个数据库的人为准确率是65%±5%。 官网链接：FER2013 网盘链接：百度网盘下载（提取码：t7xj） &nbsp;&nbsp;&nbsp;&nbsp;由于FER2013数据集数据更加齐全，同时更加符合实际生活的场景，所以这里主要选取FER2013训练和测试模型。为了防止网络过快地过拟合，可以人为的做一些图像变换，例如翻转，旋转，切割等。上述操作称为数据增强。数据操作还有另一大好处是扩大数据库的数据量，使得训练的网络鲁棒性更强。下载数据集保存在fer2013的文件夹下，为了对数据集进行处理，采用如下代码载入和进行图片预处理： import pandas as pd import cv2 import numpy as np dataset_path = &#39;fer2013/fer2013/fer2013.csv&#39; # 文件保存位置 image_size=(48,48) # 图片大小 # 载入数据 def load_fer2013(): data = pd.read_csv(dataset_path) pixels = data[&#39;pixels&#39;].tolist() width, height = 48, 48 faces = [] for pixel_sequence in pixels: face = [int(pixel) for pixel in pixel_sequence.split(&#39; &#39;)] face = np.asarray(face).reshape(width, height) face = cv2.resize(face.astype(&#39;uint8&#39;),image_size) faces.append(face.astype(&#39;float32&#39;)) faces = np.asarray(faces) faces = np.expand_dims(faces, -1) emotions = pd.get_dummies(data[&#39;emotion&#39;]).as_matrix() return faces, emotions # 将数据归一化 def preprocess_input(x, v2=True): x = x.astype(&#39;float32&#39;) x = x / 255.0 if v2: x = x - 0.5 x = x * 2.0 return x &nbsp;&nbsp;&nbsp;&nbsp;载入数据后将数据集划分为训练集和测试集，在程序中调用上面的函数代码如下： from load_and_process import load_fer2013 from load_and_process import preprocess_input from sklearn.model_selection import train_test_split # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) 3. 搭建表情识别的模型 &nbsp;&nbsp;&nbsp;&nbsp;接下来就是搭建表情识别的模型了，这里用到的是CNN的主流框架之mini_XCEPTION。XCEPTION是Google继Inception后提出的对Inception v3的另一种改进，主要是采用深度可分离的卷积（depthwise separable convolution）来替换原来Inception v3中的卷积操作。XCEPTION的网络结构在ImageNet数据集（Inception v3的设计解决目标）上略优于Inception v3，并且在包含3.5亿个图像甚至更大的图像分类数据集上明显优于Inception v3，而两个结构保持了相同数目的参数，性能增益来自于更加有效地使用模型参数，详细可参考论文：Xception: Deep Learning with Depthwise Separable Convolutions，论文Real-time Convolutional Neural Networks for Emotion and Gender Classification等。 &nbsp;&nbsp;&nbsp;&nbsp;既然这样的网络能获得更好结果又是主流，那当然有必要作为对比算法实现以下了，这里博主模型这部分的代码引用了GitHub:https://github.com/oarriaga/face_classification中的模型（其他地方也能找到这个模型的类似代码），模型框图如上图所示，其代码如下： def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01): regularization = l2(l2_regularization) # base img_input = Input(input_shape) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) # module 1 residual = Conv2D(16, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 2 residual = Conv2D(32, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 3 residual = Conv2D(64, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 4 residual = Conv2D(128, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) x = Conv2D(num_classes, (3, 3), #kernel_regularizer=regularization, padding=&#39;same&#39;)(x) x = GlobalAveragePooling2D()(x) output = Activation(&#39;softmax&#39;,name=&#39;predictions&#39;)(x) model = Model(img_input, output) return model 4. 数据增强的批量训练 &nbsp;&nbsp;&nbsp;&nbsp;神经网络的训练需要大量的数据，数据的量决定了网络模型可以达到的高度，网络模型尽量地逼近这个高度。然而对于人脸表情的数据来说，都只存在少量的数据Extended Cohn-Kanada (CK+)的数据量是远远不够的，并且CK+多是比较夸张的数据。Kaggle Fer2013数据集也不过只有3万多数据量，而且有很多遮挡、角度等外界影响因素。既然收集数据要花费很大的人力物力，那么我们就用技术解决这个问题，为避免重复开发首先还是看看有没有写好的库。博主又通读了遍Keras官方文档，其中ImageDataGenerator的图片生成器就可完成这一目标。 为了尽量利用我们有限的训练数据，我们将通过一系列随机变换堆数据进行提升，这样我们的模型将看不到任何两张完全相同的图片，这有利于我们抑制过拟合，使得模型的泛化能力更好。在Keras中，这个步骤可以通过keras.preprocessing.image.ImageGenerator来实现，这个类使你可以：在训练过程中，设置要施行的随机变换通过.flow或.flow_from_directory(directory)方法实例化一个针对图像batch的生成器，这些生成器可以被用作keras模型相关方法的输入，如fit_generator，evaluate_generator和predict_generator。——Keras官方文档 &nbsp;&nbsp;&nbsp;&nbsp;ImageDataGenerator()是一个图片生成器，同时也可以在batch中对数据进行增强，扩充数据集大小（比如进行旋转，变形，归一化等），增强模型的泛化能力。结合前面的模型和数据训练部分的代码如下： &quot;&quot;&quot; Description: 训练人脸表情识别程序 &quot;&quot;&quot; from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping from keras.callbacks import ReduceLROnPlateau from keras.preprocessing.image import ImageDataGenerator from load_and_process import load_fer2013 from load_and_process import preprocess_input from models.cnn import mini_XCEPTION from sklearn.model_selection import train_test_split # 参数 batch_size = 32 num_epochs = 10000 input_shape = (48, 48, 1) validation_split = .2 verbose = 1 num_classes = 7 patience = 50 base_path = &#39;models/&#39; # 构建模型 model = mini_XCEPTION(input_shape, num_classes) model.compile(optimizer=&#39;adam&#39;, # 优化器采用adam loss=&#39;categorical_crossentropy&#39;, # 多分类的对数损失函数 metrics=[&#39;accuracy&#39;]) model.summary() # 定义回调函数 Callbacks 用于训练过程 log_file_path = base_path + &#39;_emotion_training.log&#39; csv_logger = CSVLogger(log_file_path, append=False) early_stop = EarlyStopping(&#39;val_loss&#39;, patience=patience) reduce_lr = ReduceLROnPlateau(&#39;val_loss&#39;, factor=0.1, patience=int(patience/4), verbose=1) # 模型位置及命名 trained_models_path = base_path + &#39;_mini_XCEPTION&#39; model_names = trained_models_path + &#39;.{epoch:02d}-{val_acc:.2f}.hdf5&#39; # 定义模型权重位置、命名等 model_checkpoint = ModelCheckpoint(model_names, &#39;val_loss&#39;, verbose=1, save_best_only=True) callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr] # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) # 图片产生器，在批量中对数据进行增强，扩充数据集大小 data_generator = ImageDataGenerator( featurewise_center=False, featurewise_std_normalization=False, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=.1, horizontal_flip=True) # 利用数据增强进行训练 model.fit_generator(data_generator.flow(xtrain, ytrain, batch_size), steps_per_epoch=len(xtrain) / batch_size, epochs=num_epochs, verbose=1, callbacks=callbacks, validation_data=(xtest,ytest)) &nbsp;&nbsp;&nbsp;&nbsp;以上代码中设置了训练时的结果输出，在训练结束后会将训练的模型保存为hdf5文件到自己指定的文件夹下，由于数据量大模型的训练时间会比较长，建议使用GPU加速。训练结束后测试得到混淆矩阵如下： &nbsp;&nbsp;&nbsp;&nbsp;训练的模型综合在FER2013数据集上的分类准确率为66%，后续调整之后达到了70%，算是中等偏上水平，其实并非模型不好而是在数据预处理、超参数的选取上有很大的可提升空间，当然也可使用其他的模型，譬如可参考论文：Extended deep neural network for facial emotion recognition，大家可自行研究，这里就不多介绍了。 5. 系统UI界面的实现 &nbsp;&nbsp;&nbsp;&nbsp;上面的模型训练好了，但对于我们来说它的作用就只是知道了其准确率还行，其实深度学习的目的最重要还是应用，是时候用上面的模型做点酷酷的东西了。可不可以用上面的模型识别下自己表达的情绪呢？不如做个系统调取摄像头对实时画面中的表情进行识别并显示识别结果，既能可视化的检测模型的实用性能，同时使得整个项目生动有趣激发自己的创造性，当你向别人介绍你的项目时也显得高大上。这里采用PyQt5进行设计，首先看一下最后的效果图，运行后的界面如下： &nbsp;&nbsp;&nbsp;&nbsp;设计功能：一、可选择模型文件后基于该模型进行识别；二、打开摄像头识别实时画面中的人脸表情；三、选择一张人脸图片，对其中的表情进行识别。选择一张图片测试识别效果，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;博主对UI界面的要求是可以简单但颜值必须高，必须高，实用简约高颜值是我奉行的标准，以上的界面几经修改才有了上面的效果。当然博主的目的并不单纯的想秀，而是借此做一个测试模型的系统，可以选择模型、训练测试集等以便界面化地对后面的模型进行各种测试评估，生成用于论文的特定结果数据图或表格等，这个测试系统后面有机会分享给大家。 &nbsp;&nbsp;&nbsp;&nbsp;系统UI界面的实现这部分又设计PyQt5的许多内容，在这一篇博文中介绍恐怕尾大不掉，效果也不好，所以更多的细节内容将在后面的博文中介绍，敬请期待！有需要的朋友可通过下面的链接下载这部分的文件。 【下载链接】 &nbsp;&nbsp;&nbsp;&nbsp;若您想获得博文中涉及的实现完整全部程序文件（包括数据集，py, UI文件等，如下图），这里已打包上传至博主的CSDN下载资源中。如果您没有积分或C币，可点赞关注后（支持一下吧）在评论中留下邮箱，我会第一时间发给你。文件下载链接如下： 下载链接1：人脸表情识别系统完整程序资源 下载链接2：训练用到的数据集（提取码：t7xj） 【运行程序须知】 &nbsp;&nbsp;&nbsp;&nbsp;要安装的库如上图（以上是博主安装的版本），如您想直接运行界面程序，只需在下载链接1中的文件后，运行runMain.py程序。 &nbsp;&nbsp;&nbsp;&nbsp;如您想重新训练模型，下载链接1中的文件后，运行前请下载链接2中的数据集解压到的csv文件放到 fer2013\fer2013 的文件夹下，运行train_emotion_classifier.py程序即可重新训练。 5. 结束语 &nbsp;&nbsp;&nbsp;&nbsp;由于博主能力有限，博文中提及的方法与代码即使经过测试，也难免会有疏漏之处。希望您能热心指出其中的错误，以便下次修改时能以一个更完美更严谨的样子，呈现在大家面前。同时如果有更好的实现方法也请您不吝赐教。 &nbsp;&nbsp;&nbsp;&nbsp;大家的点赞和关注是博主最大的动力，博主所有博文中的代码文件都可分享给您，如果您想要获取博文中的完整代码文件，可通过C币或积分下载，没有C币或积分的朋友可在关注、点赞博文后提供邮箱，我会在第一时间发送给您。博主后面会有更多的分享，敬请关注哦！ 参考文献： [1] Chollet F. Xception: Deep learning with depthwise separable convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1251-1258. [2] Arriaga O, Valdenegro-Toro M, Plöger P. Real-time convolutional neural networks for emotion and gender classification[J]. arXiv preprint arXiv:1710.07557, 2017. [3] Jain D K, Shamsolmoali P, Sehdev P. Extended deep neural network for facial emotion recognition[J]. Pattern Recognition Letters, 2019, 120: 69-74." />
<link rel="canonical" href="https://uzzz.org/2019/06/09/793824.html" />
<meta property="og:url" content="https://uzzz.org/2019/06/09/793824.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"摘要：这篇博文介绍基于深度卷积神经网络实现的人脸表情识别系统，系统程序由Keras, OpenCv, PyQt5的库实现，训练测试集采用fer2013表情库。如图系统可通过摄像头获取实时画面并识别其中的人脸表情，也可以通过读取图片识别，本文提供完整的程序文件并详细介绍其实现过程。博文要点如下： 表情识别数据集 搭建表情识别的模型 数据增强的批量训练 系统UI界面的实现 点击跳转至博文涉及的全部文件下载页 1. 前言 &nbsp;&nbsp;&nbsp;&nbsp;在这个人工智能成为超级大热门的时代，人脸表情识别已成为其中的一项研究热点，而卷积神经网络、深度信念网络和多层感知器等相关算法在人脸面部表情识别领域的运用最为广泛。面部的表情中包含了太多的信息，轻微的表情变化都会反映出人心理的变化，可想而知如果机器能敏锐地识别人脸中表达的情感该是多么令人兴奋的事。 &nbsp;&nbsp;&nbsp;&nbsp;学习和研究了挺久的深度学习，偶然看到IEEE上面一篇质量很高的文章，里面介绍的是利用深度神经网络实现的面部表情识别，研读下来让我深受启发。于是自己动手做了这个项目，如今SCI论文已投稿，这里特此将前期工作作个总结，希望能给类似工作的朋友带来一点帮助。由于论文尚未公开，这里使用的是已有的模型——如今CNN的主流框架之mini_XCEPTION，该模型性能也已是不错的了，论文中改进的更高性能模型尚不便给出，后面会分享给大家，敬请关注。 2. 表情识别数据集 &nbsp;&nbsp;&nbsp;&nbsp;目前，现有的公开的人脸表情数据集比较少，并且数量级比较小。比较有名的广泛用于人脸表情识别系统的数据集Extended Cohn-Kanada (CK+)是由P.Lucy收集的。CK+数据集包含123 个对象的327 个被标记的表情图片序列，共分为正常、生气、蔑视、厌恶、恐惧、开心和伤心七种表情。对于每一个图片序列，只有最后一帧被提供了表情标签，所以共有327 个图像被标记。为了增加数据，我们把每个视频序列的最后三帧图像作为训练样本。这样CK+数据总共被标记的有981 张图片。这个数据库是人脸表情识别中比较流行的一个数据库，很多文章都会用到这个数据做测试，可通过下面的链接下载。 官网链接：The Extended Cohn-Kanade Dataset(CK+) 网盘链接：百度网盘下载（提取码：8r15） &nbsp;&nbsp;&nbsp;&nbsp;Kaggle是Kaggle人脸表情分析比赛提供的一个数据集。该数据集含28709 张训练样本，3859 张验证数据集和3859 张测试样本，共35887 张包含生气、厌恶、恐惧、高兴、悲伤、惊讶和正常七种类别的图像，图像分辨率为48×48。该数据集中的图像大都在平面和非平面上有旋转，并且很多图像都有手、头发和围巾等的遮挡物的遮挡。该数据库是2013年Kaggle比赛的数据，由于这个数据库大多是从网络爬虫下载的，存在一定的误差性。这个数据库的人为准确率是65%±5%。 官网链接：FER2013 网盘链接：百度网盘下载（提取码：t7xj） &nbsp;&nbsp;&nbsp;&nbsp;由于FER2013数据集数据更加齐全，同时更加符合实际生活的场景，所以这里主要选取FER2013训练和测试模型。为了防止网络过快地过拟合，可以人为的做一些图像变换，例如翻转，旋转，切割等。上述操作称为数据增强。数据操作还有另一大好处是扩大数据库的数据量，使得训练的网络鲁棒性更强。下载数据集保存在fer2013的文件夹下，为了对数据集进行处理，采用如下代码载入和进行图片预处理： import pandas as pd import cv2 import numpy as np dataset_path = &#39;fer2013/fer2013/fer2013.csv&#39; # 文件保存位置 image_size=(48,48) # 图片大小 # 载入数据 def load_fer2013(): data = pd.read_csv(dataset_path) pixels = data[&#39;pixels&#39;].tolist() width, height = 48, 48 faces = [] for pixel_sequence in pixels: face = [int(pixel) for pixel in pixel_sequence.split(&#39; &#39;)] face = np.asarray(face).reshape(width, height) face = cv2.resize(face.astype(&#39;uint8&#39;),image_size) faces.append(face.astype(&#39;float32&#39;)) faces = np.asarray(faces) faces = np.expand_dims(faces, -1) emotions = pd.get_dummies(data[&#39;emotion&#39;]).as_matrix() return faces, emotions # 将数据归一化 def preprocess_input(x, v2=True): x = x.astype(&#39;float32&#39;) x = x / 255.0 if v2: x = x - 0.5 x = x * 2.0 return x &nbsp;&nbsp;&nbsp;&nbsp;载入数据后将数据集划分为训练集和测试集，在程序中调用上面的函数代码如下： from load_and_process import load_fer2013 from load_and_process import preprocess_input from sklearn.model_selection import train_test_split # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) 3. 搭建表情识别的模型 &nbsp;&nbsp;&nbsp;&nbsp;接下来就是搭建表情识别的模型了，这里用到的是CNN的主流框架之mini_XCEPTION。XCEPTION是Google继Inception后提出的对Inception v3的另一种改进，主要是采用深度可分离的卷积（depthwise separable convolution）来替换原来Inception v3中的卷积操作。XCEPTION的网络结构在ImageNet数据集（Inception v3的设计解决目标）上略优于Inception v3，并且在包含3.5亿个图像甚至更大的图像分类数据集上明显优于Inception v3，而两个结构保持了相同数目的参数，性能增益来自于更加有效地使用模型参数，详细可参考论文：Xception: Deep Learning with Depthwise Separable Convolutions，论文Real-time Convolutional Neural Networks for Emotion and Gender Classification等。 &nbsp;&nbsp;&nbsp;&nbsp;既然这样的网络能获得更好结果又是主流，那当然有必要作为对比算法实现以下了，这里博主模型这部分的代码引用了GitHub:https://github.com/oarriaga/face_classification中的模型（其他地方也能找到这个模型的类似代码），模型框图如上图所示，其代码如下： def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01): regularization = l2(l2_regularization) # base img_input = Input(input_shape) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) # module 1 residual = Conv2D(16, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(16, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 2 residual = Conv2D(32, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(32, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 3 residual = Conv2D(64, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(64, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) # module 4 residual = Conv2D(128, (1, 1), strides=(2, 2), padding=&#39;same&#39;, use_bias=False)(x) residual = BatchNormalization()(residual) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = SeparableConv2D(128, (3, 3), padding=&#39;same&#39;, kernel_regularizer=regularization, use_bias=False)(x) x = BatchNormalization()(x) x = MaxPooling2D((3, 3), strides=(2, 2), padding=&#39;same&#39;)(x) x = layers.add([x, residual]) x = Conv2D(num_classes, (3, 3), #kernel_regularizer=regularization, padding=&#39;same&#39;)(x) x = GlobalAveragePooling2D()(x) output = Activation(&#39;softmax&#39;,name=&#39;predictions&#39;)(x) model = Model(img_input, output) return model 4. 数据增强的批量训练 &nbsp;&nbsp;&nbsp;&nbsp;神经网络的训练需要大量的数据，数据的量决定了网络模型可以达到的高度，网络模型尽量地逼近这个高度。然而对于人脸表情的数据来说，都只存在少量的数据Extended Cohn-Kanada (CK+)的数据量是远远不够的，并且CK+多是比较夸张的数据。Kaggle Fer2013数据集也不过只有3万多数据量，而且有很多遮挡、角度等外界影响因素。既然收集数据要花费很大的人力物力，那么我们就用技术解决这个问题，为避免重复开发首先还是看看有没有写好的库。博主又通读了遍Keras官方文档，其中ImageDataGenerator的图片生成器就可完成这一目标。 为了尽量利用我们有限的训练数据，我们将通过一系列随机变换堆数据进行提升，这样我们的模型将看不到任何两张完全相同的图片，这有利于我们抑制过拟合，使得模型的泛化能力更好。在Keras中，这个步骤可以通过keras.preprocessing.image.ImageGenerator来实现，这个类使你可以：在训练过程中，设置要施行的随机变换通过.flow或.flow_from_directory(directory)方法实例化一个针对图像batch的生成器，这些生成器可以被用作keras模型相关方法的输入，如fit_generator，evaluate_generator和predict_generator。——Keras官方文档 &nbsp;&nbsp;&nbsp;&nbsp;ImageDataGenerator()是一个图片生成器，同时也可以在batch中对数据进行增强，扩充数据集大小（比如进行旋转，变形，归一化等），增强模型的泛化能力。结合前面的模型和数据训练部分的代码如下： &quot;&quot;&quot; Description: 训练人脸表情识别程序 &quot;&quot;&quot; from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping from keras.callbacks import ReduceLROnPlateau from keras.preprocessing.image import ImageDataGenerator from load_and_process import load_fer2013 from load_and_process import preprocess_input from models.cnn import mini_XCEPTION from sklearn.model_selection import train_test_split # 参数 batch_size = 32 num_epochs = 10000 input_shape = (48, 48, 1) validation_split = .2 verbose = 1 num_classes = 7 patience = 50 base_path = &#39;models/&#39; # 构建模型 model = mini_XCEPTION(input_shape, num_classes) model.compile(optimizer=&#39;adam&#39;, # 优化器采用adam loss=&#39;categorical_crossentropy&#39;, # 多分类的对数损失函数 metrics=[&#39;accuracy&#39;]) model.summary() # 定义回调函数 Callbacks 用于训练过程 log_file_path = base_path + &#39;_emotion_training.log&#39; csv_logger = CSVLogger(log_file_path, append=False) early_stop = EarlyStopping(&#39;val_loss&#39;, patience=patience) reduce_lr = ReduceLROnPlateau(&#39;val_loss&#39;, factor=0.1, patience=int(patience/4), verbose=1) # 模型位置及命名 trained_models_path = base_path + &#39;_mini_XCEPTION&#39; model_names = trained_models_path + &#39;.{epoch:02d}-{val_acc:.2f}.hdf5&#39; # 定义模型权重位置、命名等 model_checkpoint = ModelCheckpoint(model_names, &#39;val_loss&#39;, verbose=1, save_best_only=True) callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr] # 载入数据集 faces, emotions = load_fer2013() faces = preprocess_input(faces) num_samples, num_classes = emotions.shape # 划分训练、测试集 xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True) # 图片产生器，在批量中对数据进行增强，扩充数据集大小 data_generator = ImageDataGenerator( featurewise_center=False, featurewise_std_normalization=False, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=.1, horizontal_flip=True) # 利用数据增强进行训练 model.fit_generator(data_generator.flow(xtrain, ytrain, batch_size), steps_per_epoch=len(xtrain) / batch_size, epochs=num_epochs, verbose=1, callbacks=callbacks, validation_data=(xtest,ytest)) &nbsp;&nbsp;&nbsp;&nbsp;以上代码中设置了训练时的结果输出，在训练结束后会将训练的模型保存为hdf5文件到自己指定的文件夹下，由于数据量大模型的训练时间会比较长，建议使用GPU加速。训练结束后测试得到混淆矩阵如下： &nbsp;&nbsp;&nbsp;&nbsp;训练的模型综合在FER2013数据集上的分类准确率为66%，后续调整之后达到了70%，算是中等偏上水平，其实并非模型不好而是在数据预处理、超参数的选取上有很大的可提升空间，当然也可使用其他的模型，譬如可参考论文：Extended deep neural network for facial emotion recognition，大家可自行研究，这里就不多介绍了。 5. 系统UI界面的实现 &nbsp;&nbsp;&nbsp;&nbsp;上面的模型训练好了，但对于我们来说它的作用就只是知道了其准确率还行，其实深度学习的目的最重要还是应用，是时候用上面的模型做点酷酷的东西了。可不可以用上面的模型识别下自己表达的情绪呢？不如做个系统调取摄像头对实时画面中的表情进行识别并显示识别结果，既能可视化的检测模型的实用性能，同时使得整个项目生动有趣激发自己的创造性，当你向别人介绍你的项目时也显得高大上。这里采用PyQt5进行设计，首先看一下最后的效果图，运行后的界面如下： &nbsp;&nbsp;&nbsp;&nbsp;设计功能：一、可选择模型文件后基于该模型进行识别；二、打开摄像头识别实时画面中的人脸表情；三、选择一张人脸图片，对其中的表情进行识别。选择一张图片测试识别效果，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;博主对UI界面的要求是可以简单但颜值必须高，必须高，实用简约高颜值是我奉行的标准，以上的界面几经修改才有了上面的效果。当然博主的目的并不单纯的想秀，而是借此做一个测试模型的系统，可以选择模型、训练测试集等以便界面化地对后面的模型进行各种测试评估，生成用于论文的特定结果数据图或表格等，这个测试系统后面有机会分享给大家。 &nbsp;&nbsp;&nbsp;&nbsp;系统UI界面的实现这部分又设计PyQt5的许多内容，在这一篇博文中介绍恐怕尾大不掉，效果也不好，所以更多的细节内容将在后面的博文中介绍，敬请期待！有需要的朋友可通过下面的链接下载这部分的文件。 【下载链接】 &nbsp;&nbsp;&nbsp;&nbsp;若您想获得博文中涉及的实现完整全部程序文件（包括数据集，py, UI文件等，如下图），这里已打包上传至博主的CSDN下载资源中。如果您没有积分或C币，可点赞关注后（支持一下吧）在评论中留下邮箱，我会第一时间发给你。文件下载链接如下： 下载链接1：人脸表情识别系统完整程序资源 下载链接2：训练用到的数据集（提取码：t7xj） 【运行程序须知】 &nbsp;&nbsp;&nbsp;&nbsp;要安装的库如上图（以上是博主安装的版本），如您想直接运行界面程序，只需在下载链接1中的文件后，运行runMain.py程序。 &nbsp;&nbsp;&nbsp;&nbsp;如您想重新训练模型，下载链接1中的文件后，运行前请下载链接2中的数据集解压到的csv文件放到 fer2013\\fer2013 的文件夹下，运行train_emotion_classifier.py程序即可重新训练。 5. 结束语 &nbsp;&nbsp;&nbsp;&nbsp;由于博主能力有限，博文中提及的方法与代码即使经过测试，也难免会有疏漏之处。希望您能热心指出其中的错误，以便下次修改时能以一个更完美更严谨的样子，呈现在大家面前。同时如果有更好的实现方法也请您不吝赐教。 &nbsp;&nbsp;&nbsp;&nbsp;大家的点赞和关注是博主最大的动力，博主所有博文中的代码文件都可分享给您，如果您想要获取博文中的完整代码文件，可通过C币或积分下载，没有C币或积分的朋友可在关注、点赞博文后提供邮箱，我会在第一时间发送给您。博主后面会有更多的分享，敬请关注哦！ 参考文献： [1] Chollet F. Xception: Deep learning with depthwise separable convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1251-1258. [2] Arriaga O, Valdenegro-Toro M, Plöger P. Real-time convolutional neural networks for emotion and gender classification[J]. arXiv preprint arXiv:1710.07557, 2017. [3] Jain D K, Shamsolmoali P, Sehdev P. Extended deep neural network for facial emotion recognition[J]. Pattern Recognition Letters, 2019, 120: 69-74.","@type":"BlogPosting","url":"https://uzzz.org/2019/06/09/793824.html","headline":"人脸表情识别系统介绍——上篇（python实现，含UI界面及完整代码）","dateModified":"2019-06-09T00:00:00+08:00","datePublished":"2019-06-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/06/09/793824.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>人脸表情识别系统介绍——上篇（python实现，含UI界面及完整代码）</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-tomorrow-night"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190608195255663.gif" width="545" height="477" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">摘要：这篇博文介绍基于深度卷积神经网络实现的人脸表情识别系统，系统程序由<font face="Times New Roman " size="4"><em>Keras, OpenCv, PyQt5</em></font>的库实现，训练测试集采用<font face="Times New Roman " size="4"><em>fer2013</em></font>表情库。如图系统可通过摄像头获取实时画面并识别其中的人脸表情，也可以通过读取图片识别，本文提供完整的程序文件并详细介绍其实现过程。博文要点如下：</font></p> 
  <ul> 
   <li><strong><a href="#title1" rel="nofollow" data-token="1a0de679a2346462559e7e324f0df304"><font face="仿宋" size="4">表情识别数据集</font></a></strong></li> 
   <li><strong><a href="#title2" rel="nofollow" data-token="8be88614b81f6df8d0c47f029d1ea397"><font face="仿宋" size="4">搭建表情识别的模型</font></a></strong></li> 
   <li><strong><a href="#title3" rel="nofollow" data-token="ec7f780c465b58dc91fa5f953b7dabda"><font face="仿宋" size="4">数据增强的批量训练</font></a></strong></li> 
   <li><strong><a href="#title4" rel="nofollow" data-token="2ca5634bc57cb0250cbbc3a17466ef5b"><font face="仿宋" size="4">系统UI界面的实现</font></a></strong></li> 
  </ul> 
  <p><a href="#i1" rel="nofollow" data-token="51e90fffbf7cdfd47fa8a5fd31c1adae"><font face="楷体" color="Green" size="4">点击跳转至博文涉及的全部文件下载页</font></a></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609154640396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" alt="图片展示"> 
  </center>
  <hr> 
  <h1><a id="font_face_size51_font_19"></a><font face="华文行楷" size="5">1. 前言</font></h1> 
  <p><font face="仿宋" size="4"> &nbsp;&nbsp;&nbsp;&nbsp;在这个人工智能成为超级大热门的时代，人脸表情识别已成为其中的一项研究热点，而卷积神经网络、深度信念网络和多层感知器等相关算法在人脸面部表情识别领域的运用最为广泛。面部的表情中包含了太多的信息，轻微的表情变化都会反映出人心理的变化，可想而知如果机器能敏锐地识别人脸中表达的情感该是多么令人兴奋的事。</font></p> 
  <p><font face="仿宋" size="4"> &nbsp;&nbsp;&nbsp;&nbsp;学习和研究了挺久的深度学习，偶然看到<font face="Times New Roman " size="4"><em>IEEE</em></font>上面一篇质量很高的文章，里面介绍的是利用深度神经网络实现的面部表情识别，研读下来让我深受启发。于是自己动手做了这个项目，如今<font face="Times New Roman " size="4"><em>SCI</em></font>论文已投稿，这里特此将前期工作作个总结，希望能给类似工作的朋友带来一点帮助。由于论文尚未公开，这里使用的是已有的模型——如今<font face="Times New Roman " size="4"><em>CNN</em></font>的主流框架之<font face="Times New Roman " size="4"><em>mini_XCEPTION</em></font>，该模型性能也已是不错的了，论文中改进的更高性能模型尚不便给出，后面会分享给大家，敬请关注。</font></p> 
  <hr> 
  <p><span id="title1"></span></p> 
  <h1><a id="font_face_size52_font_28"></a><font face="华文行楷" size="5">2. 表情识别数据集</font></h1> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;目前，现有的公开的人脸表情数据集比较少，并且数量级比较小。比较有名的广泛用于人脸表情识别系统的数据集<font face="Times New Roman " size="4"><em>Extended Cohn-Kanada (CK+)</em></font>是由<font face="Times New Roman " size="4"><em>P</em></font>.<font face="Times New Roman " size="4"><em>Lucy</em></font>收集的。<font face="Times New Roman " size="4"><em>CK+</em></font>数据集包含<font face="Times New Roman " size="4"><em>123</em></font> 个对象的<font face="Times New Roman " size="4"><em>327</em></font> 个被标记的表情图片序列，共分为正常、生气、蔑视、厌恶、恐惧、开心和伤心七种表情。对于每一个图片序列，只有最后一帧被提供了表情标签，所以共有<font face="Times New Roman " size="4"><em>327</em></font> 个图像被标记。为了增加数据，我们把每个视频序列的最后三帧图像作为训练样本。这样<font face="Times New Roman " size="4"><em>CK+</em></font>数据总共被标记的有<font face="Times New Roman " size="4"><em>981</em></font> 张图片。这个数据库是人脸表情识别中比较流行的一个数据库，很多文章都会用到这个数据做测试，可通过下面的链接下载。</font><br> <font face="仿宋" size="4">官网链接：<a href="http://www.pitt.edu/~emotion/ck-spread.htm" rel="nofollow" data-token="6172b4bf56755d1efedf55c47016251e"><font face="Times New Roman " size="4"><em>The Extended Cohn-Kanade Dataset(CK+)</em></font></a></font><br> <font face="仿宋" size="4">网盘链接：<a href="https://pan.baidu.com/s/1tR6VZM92gH1aMD4_O0LHgw" rel="nofollow" data-token="e8b5201e1064abbb27ea5d00cf166581"><font face="微软雅黑" size="4">百度网盘下载（提取码：<font face="Times New Roman " size="4"><em>8r15</em></font>）</font></a></font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609142047718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="490" height="211" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;<font face="Times New Roman " size="4"><em>Kaggle</em></font>是<font face="Times New Roman " size="4"><em>Kaggle</em></font>人脸表情分析比赛提供的一个数据集。该数据集含<font face="Times New Roman " size="4"><em>28709</em></font> 张训练样本，<font face="Times New Roman " size="4"><em>3859</em></font> 张验证数据集和<font face="Times New Roman " size="4"><em>3859</em></font> 张测试样本，共<font face="Times New Roman " size="4"><em>35887</em></font> 张包含生气、厌恶、恐惧、高兴、悲伤、惊讶和正常七种类别的图像，图像分辨率为<font face="Times New Roman " size="4"><em>48×48</em></font>。该数据集中的图像大都在平面和非平面上有旋转，并且很多图像都有手、头发和围巾等的遮挡物的遮挡。该数据库是2013年<font face="Times New Roman " size="4"><em>Kaggle</em></font>比赛的数据，由于这个数据库大多是从网络爬虫下载的，存在一定的误差性。这个数据库的人为准确率是<font face="Times New Roman " size="4"><em>65%±5%</em></font>。</font><br> <font face="仿宋" size="4">官网链接：<a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" rel="nofollow" data-token="6b3201c56cbc99d4f568e48fcbbdb60c"><font face="Times New Roman " size="4"><em>FER2013</em></font></a></font><br> <font face="仿宋" size="4">网盘链接：<a href="https://pan.baidu.com/s/1dEQyqgpX3azvN5DfY4RKzA" rel="nofollow" data-token="95c097fdb857030b2da1530b5f4f5280"><font face="微软雅黑" size="4">百度网盘下载（提取码：<font face="Times New Roman " size="4"><em>t7xj</em></font></font>）</a></font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019060914293759.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="433" height="343" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;由于<font face="Times New Roman " size="4"><em>FER2013</em></font>数据集数据更加齐全，同时更加符合实际生活的场景，所以这里主要选取<font face="Times New Roman " size="4"><em>FER2013</em></font>训练和测试模型。为了防止网络过快地过拟合，可以人为的做一些图像变换，例如翻转，旋转，切割等。上述操作称为数据增强。数据操作还有另一大好处是扩大数据库的数据量，使得训练的网络鲁棒性更强。下载数据集保存在<font face="Times New Roman " size="4"><em>fer2013</em></font>的文件夹下，为了对数据集进行处理，采用如下代码载入和进行图片预处理：</font></p> 
  <pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

dataset_path <span class="token operator">=</span> <span class="token string">'fer2013/fer2013/fer2013.csv'</span> <span class="token comment"># 文件保存位置</span>
image_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">48</span><span class="token punctuation">,</span><span class="token number">48</span><span class="token punctuation">)</span> <span class="token comment"># 图片大小</span>

<span class="token comment"># 载入数据</span>
<span class="token keyword">def</span> <span class="token function">load_fer2013</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>dataset_path<span class="token punctuation">)</span>
        pixels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'pixels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        width<span class="token punctuation">,</span> height <span class="token operator">=</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">48</span>
        faces <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> pixel_sequence <span class="token keyword">in</span> pixels<span class="token punctuation">:</span>
            face <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>pixel<span class="token punctuation">)</span> <span class="token keyword">for</span> pixel <span class="token keyword">in</span> pixel_sequence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            face <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>face<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span>
            face <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>face<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'uint8'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>image_size<span class="token punctuation">)</span>
            faces<span class="token punctuation">.</span>append<span class="token punctuation">(</span>face<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        faces <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>faces<span class="token punctuation">)</span>
        faces <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>faces<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        emotions <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'emotion'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_matrix<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> faces<span class="token punctuation">,</span> emotions

<span class="token comment"># 将数据归一化</span>
<span class="token keyword">def</span> <span class="token function">preprocess_input</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> v2<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> x <span class="token operator">/</span> <span class="token number">255.0</span>
    <span class="token keyword">if</span> v2<span class="token punctuation">:</span>
        x <span class="token operator">=</span> x <span class="token operator">-</span> <span class="token number">0.5</span>
        x <span class="token operator">=</span> x <span class="token operator">*</span> <span class="token number">2.0</span>
    <span class="token keyword">return</span> x
</code></pre> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;载入数据后将数据集划分为训练集和测试集，在程序中调用上面的函数代码如下：</font></p> 
  <pre><code class="prism language-python"><span class="token keyword">from</span> load_and_process <span class="token keyword">import</span> load_fer2013
<span class="token keyword">from</span> load_and_process <span class="token keyword">import</span> preprocess_input
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># 载入数据集</span>
faces<span class="token punctuation">,</span> emotions <span class="token operator">=</span> load_fer2013<span class="token punctuation">(</span><span class="token punctuation">)</span>
faces <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>faces<span class="token punctuation">)</span>
num_samples<span class="token punctuation">,</span> num_classes <span class="token operator">=</span> emotions<span class="token punctuation">.</span>shape

<span class="token comment"># 划分训练、测试集</span>
xtrain<span class="token punctuation">,</span> xtest<span class="token punctuation">,</span>ytrain<span class="token punctuation">,</span>ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>faces<span class="token punctuation">,</span> emotions<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
  <hr> 
  <p><span id="title2"></span></p> 
  <h1><a id="font_face_size53_font_96"></a><font face="华文行楷" size="5">3. 搭建表情识别的模型</font></h1> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;接下来就是搭建表情识别的模型了，这里用到的是<font face="Times New Roman " size="4"><em>CNN</em></font>的主流框架之<font face="Times New Roman " size="4"><em>mini_XCEPTION</em></font>。<font face="Times New Roman " size="4"><em>XCEPTION</em></font>是<font face="Times New Roman " size="4"><em>Google</em></font>继<font face="Times New Roman " size="4"><em>Inception</em></font>后提出的对<font face="Times New Roman " size="4"><em>Inception v3</em></font>的另一种改进，主要是采用深度可分离的卷积（<font face="Times New Roman " size="4"><em>depthwise separable convolution</em></font>）来替换原来<font face="Times New Roman " size="4"><em>Inception v3</em></font>中的卷积操作。<font face="Times New Roman " size="4"><em>XCEPTION</em></font>的网络结构在<font face="Times New Roman " size="4"><em>ImageNet</em></font>数据集（<font face="Times New Roman " size="4"><em>Inception v3</em></font>的设计解决目标）上略优于<font face="Times New Roman " size="4"><em>Inception v3</em></font>，并且在包含3.5亿个图像甚至更大的图像分类数据集上明显优于<font face="Times New Roman " size="4"><em>Inception v3</em></font>，而两个结构保持了相同数目的参数，性能增益来自于更加有效地使用模型参数，详细可参考论文：<a href="https://arxiv.org/abs/1610.02357" rel="nofollow" data-token="d6dedabb7399fbcb13a857f067bc18d1"><font face="Times New Roman " size="4"><em>Xception: Deep Learning with Depthwise Separable Convolutions</em></font></a>，论文<a href="https://arxiv.org/abs/1710.07557" rel="nofollow" data-token="c2b0861c5098b89feb111597f6357851"><font face="Times New Roman " size="4"><em>Real-time Convolutional Neural Networks for Emotion and Gender Classification</em></font></a>等。</font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609152347165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="344" height="482" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;既然这样的网络能获得更好结果又是主流，那当然有必要作为对比算法实现以下了，这里博主模型这部分的代码引用了<a href="https://github.com/oarriaga/face_classification" rel="nofollow" data-token="5004a8b9b757cbfc23a0e1a3ce18710c"><font face="Times New Roman " size="4"><em>GitHub:https://github.com/oarriaga/face_classification</em></font></a>中的模型（其他地方也能找到这个模型的类似代码），模型框图如上图所示，其代码如下：</font></p> 
  <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">mini_XCEPTION</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> l2_regularization<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    regularization <span class="token operator">=</span> l2<span class="token punctuation">(</span>l2_regularization<span class="token punctuation">)</span>

    <span class="token comment"># base</span>
    img_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                                            use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>img_input<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                                            use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># module 1</span>
    residual <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    residual <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>residual<span class="token punctuation">)</span>

    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> residual<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># module 2</span>
    residual <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    residual <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>residual<span class="token punctuation">)</span>

    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> residual<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># module 3</span>
    residual <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    residual <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>residual<span class="token punctuation">)</span>

    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> residual<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># module 4</span>
    residual <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    residual <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>residual<span class="token punctuation">)</span>

    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> SeparableConv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
                        kernel_regularizer<span class="token operator">=</span>regularization<span class="token punctuation">,</span>
                        use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> residual<span class="token punctuation">]</span><span class="token punctuation">)</span>

    x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment">#kernel_regularizer=regularization,</span>
            padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    output <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'softmax'</span><span class="token punctuation">,</span>name<span class="token operator">=</span><span class="token string">'predictions'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>img_input<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
  <hr> 
  <p><span id="title3"></span></p> 
  <h1><a id="font_face_size54_font_203"></a><font face="华文行楷" size="5">4. 数据增强的批量训练</font></h1> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;神经网络的训练需要大量的数据，数据的量决定了网络模型可以达到的高度，网络模型尽量地逼近这个高度。然而对于人脸表情的数据来说，都只存在少量的数据<font face="Times New Roman " size="4"><em>Extended Cohn-Kanada (CK+)</em></font>的数据量是远远不够的，并且<font face="Times New Roman " size="4"><em>CK+</em></font>多是比较夸张的数据。<font face="Times New Roman " size="4"><em>Kaggle Fer2013</em></font>数据集也不过只有3万多数据量，而且有很多遮挡、角度等外界影响因素。既然收集数据要花费很大的人力物力，那么我们就用技术解决这个问题，为避免重复开发首先还是看看有没有写好的库。博主又通读了遍<font face="Times New Roman " size="4"><em>Keras</em></font>官方文档，其中<font face="Times New Roman " size="4"><em>ImageDataGenerator</em></font>的图片生成器就可完成这一目标。</font></p> 
  <blockquote> 
   <p><font face="仿宋" size="4">为了尽量利用我们有限的训练数据，我们将通过一系列随机变换堆数据进行提升，这样我们的模型将看不到任何两张完全相同的图片，这有利于我们抑制过拟合，使得模型的泛化能力更好。在<font face="Times New Roman " size="4"><em>Keras</em></font>中，这个步骤可以通过<font face="Times New Roman " size="4"><em>keras</em></font>.<font face="Times New Roman " size="4"><em>preprocessing</em></font>.<font face="Times New Roman " size="4"><em>image</em></font>.<font face="Times New Roman " size="4"><em>ImageGenerator</em></font>来实现，这个类使你可以：在训练过程中，设置要施行的随机变换通过.<font face="Times New Roman " size="4"><em>flow</em></font>或.<font face="Times New Roman " size="4"><em>flow_from_directory(directory)</em></font>方法实例化一个针对图像<font face="Times New Roman " size="4"><em>batch</em></font>的生成器，这些生成器可以被用作<font face="Times New Roman " size="4"><em>keras</em></font>模型相关方法的输入，如<font face="Times New Roman " size="4"><em>fit_generator，evaluate_generator</em></font>和<font face="Times New Roman " size="4"><em>predict_generator</em></font>。——<a href="https://keras-cn.readthedocs.io/en/latest/legacy/blog/image_classification_using_very_little_data/#_6" rel="nofollow" data-token="3542e2e16d14b3441bcaff08d23830df"><font face="Times New Roman " size="4"><em>Keras</em></font><font face="仿宋" size="4">官方文档</font></a></font></p> 
  </blockquote> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;<font face="Times New Roman " size="4"><em>ImageDataGenerator</em></font>()是一个图片生成器，同时也可以在<font face="Times New Roman " size="4"><em>batch</em></font>中对数据进行增强，扩充数据集大小（比如进行旋转，变形，归一化等），增强模型的泛化能力。结合前面的模型和数据训练部分的代码如下：</font></p> 
  <pre><code class="prism language-python"><span class="token triple-quoted-string string">""" Description: 训练人脸表情识别程序 """</span>

<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> CSVLogger<span class="token punctuation">,</span> ModelCheckpoint<span class="token punctuation">,</span> EarlyStopping
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> ReduceLROnPlateau
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator
<span class="token keyword">from</span> load_and_process <span class="token keyword">import</span> load_fer2013
<span class="token keyword">from</span> load_and_process <span class="token keyword">import</span> preprocess_input
<span class="token keyword">from</span> models<span class="token punctuation">.</span>cnn <span class="token keyword">import</span> mini_XCEPTION
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># 参数</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>
num_epochs <span class="token operator">=</span> <span class="token number">10000</span>
input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
validation_split <span class="token operator">=</span> <span class="token number">.2</span>
verbose <span class="token operator">=</span> <span class="token number">1</span>
num_classes <span class="token operator">=</span> <span class="token number">7</span>
patience <span class="token operator">=</span> <span class="token number">50</span>
base_path <span class="token operator">=</span> <span class="token string">'models/'</span>

<span class="token comment"># 构建模型</span>
model <span class="token operator">=</span> mini_XCEPTION<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span> <span class="token comment"># 优化器采用adam</span>
              loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span> <span class="token comment"># 多分类的对数损失函数</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义回调函数 Callbacks 用于训练过程</span>
log_file_path <span class="token operator">=</span> base_path <span class="token operator">+</span> <span class="token string">'_emotion_training.log'</span>
csv_logger <span class="token operator">=</span> CSVLogger<span class="token punctuation">(</span>log_file_path<span class="token punctuation">,</span> append<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
early_stop <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span>patience<span class="token punctuation">)</span>
reduce_lr <span class="token operator">=</span> ReduceLROnPlateau<span class="token punctuation">(</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> factor<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                              patience<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>patience<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># 模型位置及命名</span>
trained_models_path <span class="token operator">=</span> base_path <span class="token operator">+</span> <span class="token string">'_mini_XCEPTION'</span>
model_names <span class="token operator">=</span> trained_models_path <span class="token operator">+</span> <span class="token string">'.{epoch:02d}-{val_acc:.2f}.hdf5'</span>

<span class="token comment"># 定义模型权重位置、命名等</span>
model_checkpoint <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>model_names<span class="token punctuation">,</span>
                                   <span class="token string">'val_loss'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                    save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
callbacks <span class="token operator">=</span> <span class="token punctuation">[</span>model_checkpoint<span class="token punctuation">,</span> csv_logger<span class="token punctuation">,</span> early_stop<span class="token punctuation">,</span> reduce_lr<span class="token punctuation">]</span>

<span class="token comment"># 载入数据集</span>
faces<span class="token punctuation">,</span> emotions <span class="token operator">=</span> load_fer2013<span class="token punctuation">(</span><span class="token punctuation">)</span>
faces <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>faces<span class="token punctuation">)</span>
num_samples<span class="token punctuation">,</span> num_classes <span class="token operator">=</span> emotions<span class="token punctuation">.</span>shape

<span class="token comment"># 划分训练、测试集</span>
xtrain<span class="token punctuation">,</span> xtest<span class="token punctuation">,</span>ytrain<span class="token punctuation">,</span>ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>faces<span class="token punctuation">,</span> emotions<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 图片产生器，在批量中对数据进行增强，扩充数据集大小</span>
data_generator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>
                        featurewise_center<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                        featurewise_std_normalization<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                        rotation_range<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
                        width_shift_range<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                        height_shift_range<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                        zoom_range<span class="token operator">=</span><span class="token number">.1</span><span class="token punctuation">,</span>
                        horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 利用数据增强进行训练</span>
model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>data_generator<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>xtrain<span class="token punctuation">,</span> ytrain<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        steps_per_epoch<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>xtrain<span class="token punctuation">)</span> <span class="token operator">/</span> batch_size<span class="token punctuation">,</span>
                        epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span>
                        verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span>callbacks<span class="token punctuation">,</span>
                        validation_data<span class="token operator">=</span><span class="token punctuation">(</span>xtest<span class="token punctuation">,</span>ytest<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;以上代码中设置了训练时的结果输出，在训练结束后会将训练的模型保存为<font face="Times New Roman " size="4"><em>hdf5</em></font>文件到自己指定的文件夹下，由于数据量大模型的训练时间会比较长，建议使用<font face="Times New Roman " size="4"><em>GPU</em></font>加速。训练结束后测试得到混淆矩阵如下：</font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609152114443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="460" height="400" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;训练的模型综合在<font face="Times New Roman " size="4"><em>FER2013</em></font>数据集上的分类准确率为<font face="Times New Roman " size="4"><em>66%</em></font>，后续调整之后达到了<font face="Times New Roman " size="4"><em>70%</em></font>，算是中等偏上水平，其实并非模型不好而是在数据预处理、超参数的选取上有很大的可提升空间，当然也可使用其他的模型，譬如可参考论文：<a href="https://www.sciencedirect.com/science/article/pii/S016786551930008X#bib0001" rel="nofollow" data-token="ef64e36d3320136616b80e3a2e1b3ec0"><font face="Times New Roman " size="4"><em>Extended deep neural network for facial emotion recognition</em></font></a>，大家可自行研究，这里就不多介绍了。</font></p> 
  <hr> 
  <p><span id="title4"></span></p> 
  <h1><a id="font_face_size55_font_faceTimes_New_Roman__UIfontfont_292"></a><font face="华文行楷" size="5">5. 系统<font face="Times New Roman "><em>UI</em></font>界面的实现</font></h1> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;上面的模型训练好了，但对于我们来说它的作用就只是知道了其准确率还行，其实深度学习的目的最重要还是应用，是时候用上面的模型做点酷酷的东西了。可不可以用上面的模型识别下自己表达的情绪呢？不如做个系统调取摄像头对实时画面中的表情进行识别并显示识别结果，既能可视化的检测模型的实用性能，同时使得整个项目生动有趣激发自己的创造性，当你向别人介绍你的项目时也显得高大上。这里采用<font face="Times New Roman " size="4"><em>PyQt5</em></font>进行设计，首先看一下最后的效果图，运行后的界面如下：</font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609162354917.gif" width="545" height="477" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;设计功能：一、可选择模型文件后基于该模型进行识别；二、打开摄像头识别实时画面中的人脸表情；三、选择一张人脸图片，对其中的表情进行识别。选择一张图片测试识别效果，如下图所示：</font></p> 
  <center>
   <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609161242639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="545" height="477" alt="图片展示"> 
  </center>
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;博主对<font face="Times New Roman " size="4"><em>UI</em></font>界面的要求是可以简单但颜值必须高，必须高，实用简约高颜值是我奉行的标准，以上的界面几经修改才有了上面的效果。当然博主的目的并不单纯的想秀，而是借此做一个测试模型的系统，可以选择模型、训练测试集等以便界面化地对后面的模型进行各种测试评估，生成用于论文的特定结果数据图或表格等，这个测试系统后面有机会分享给大家。</font></p> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;系统<font face="Times New Roman "><em>UI</em></font>界面的实现这部分又设计<font face="Times New Roman " size="4"><em>PyQt5</em></font>的许多内容，在这一篇博文中介绍恐怕尾大不掉，效果也不好，所以更多的细节内容将在后面的博文中介绍，敬请期待！有需要的朋友可通过下面的链接下载这部分的文件。</font></p> 
  <p><span id="i1"></span><br> 【<font face="华文行楷" size="5">下载链接</font>】<br> <font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;若您想获得博文中涉及的实现完整全部程序文件（包括数据集，<em>py, UI</em>文件等，如下图），这里已打包上传至博主的<font face="Times New Roman" size="4"><em>CSDN</em></font>下载资源中。如果您没有积分或<font face="Times New Roman" size="4"><em>C</em></font>币，可点赞关注后（支持一下吧）在评论中留下邮箱，我会第一时间发给你。文件下载链接如下：</font><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609164821163.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly93dXhpYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" alt="下载的文件情况"><br> <font face="微软雅黑" size="4">下载链接1：<a href="https://download.csdn.net/download/qq_32892383/11231539" rel="nofollow" data-token="e386a4df8b8f071498293343f8deabe6">人脸表情识别系统完整程序资源</a></font><br> <font face="微软雅黑" size="4">下载链接2：<a href="https://pan.baidu.com/s/1dEQyqgpX3azvN5DfY4RKzA" rel="nofollow" data-token="95c097fdb857030b2da1530b5f4f5280">训练用到的数据集（提取码：<font face="Times New Roman " size="4"><em>t7xj</em></font>）</a></font></p> 
  <p><font face="仿宋" size="4"><strong>【运行程序须知】</strong></font><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609171257682.PNG" alt="在这里插入图片描述"><br> <font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;要安装的库如上图（以上是博主安装的版本），如您想直接运行界面程序，只需在下载链接1中的文件后，运行<font face="Times New Roman" size="4"><em>runMain</em>.<em>py</em></font>程序。</font></p> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;如您想重新训练模型，下载链接1中的文件后，运行前请下载链接2中的数据集解压到的<font face="Times New Roman" size="4"><em>csv</em></font>文件放到 <font face="Times New Roman" size="4" color="blue">fer2013\fer2013</font> 的文件夹下，运行<font face="Times New Roman" size="4"><em>train_emotion_classifier</em>.<em>py</em></font>程序即可重新训练。</font></p> 
  <hr> 
  <h1><a id="font_face_size55_font_322"></a><font face="华文行楷" size="5">5. 结束语</font></h1> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;由于博主能力有限，博文中提及的方法与代码即使经过测试，也难免会有疏漏之处。希望您能热心指出其中的错误，以便下次修改时能以一个更完美更严谨的样子，呈现在大家面前。同时如果有更好的实现方法也请您不吝赐教。</font></p> 
  <p><font face="仿宋" size="4">&nbsp;&nbsp;&nbsp;&nbsp;大家的点赞和关注是博主最大的动力，博主所有博文中的代码文件都可分享给您，如果您想要获取博文中的完整代码文件，可通过C币或积分下载，没有C币或积分的朋友可在关注、点赞博文后提供邮箱，我会在第一时间发送给您。博主后面会有更多的分享，敬请关注哦！</font></p> 
  <p><font face="仿宋" size="4">参考文献：</font><br> [1] <a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html" rel="nofollow" data-token="e50cf8e13548436d813d248ed21a2357"><font face="Times New Roman " size="4"><em>Chollet F. Xception: Deep learning with depthwise separable convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1251-1258</em></font>.</a><br> [2] <a href="https://arxiv.org/abs/1710.07557" rel="nofollow" data-token="c2b0861c5098b89feb111597f6357851"><font face="Times New Roman " size="4"><em>Arriaga O, Valdenegro-Toro M, Plöger P. Real-time convolutional neural networks for emotion and gender classification[J]. arXiv preprint arXiv:1710.07557, 2017</em></font>.</a><br> [3] <a href="https://www.sciencedirect.com/science/article/pii/S016786551930008X" rel="nofollow" data-token="4af2d3656461c6b3cd338f3b54e6066c"><font face="Times New Roman " size="4"><em>Jain D K, Shamsolmoali P, Sehdev P. Extended deep neural network for facial emotion recognition[J]. Pattern Recognition Letters, 2019, 120: 69-74</em></font>.</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
