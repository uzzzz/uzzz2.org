<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>【Hadoop】完全分布式安装 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="【Hadoop】完全分布式安装" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="一、集群搭建之主节点 1、下载安装包及测试文档 2、安装Java JDK 3、Hadoop安装 4、修改hosts文件 5、创建数据文件夹 6、修改hadoop hadoop-env.sh文件配置 7、修改hadoop core-site.xml文件配置 8、修改hadoop hdfs-site.xml文件配置 9、修改hadoop yarn-site.xml文件配置 10、修改hadoop mapred-site.xml文件配置 11、修改hadoop slaves文件配置 12、创建公钥 13、拷贝公钥，过程中需要输入zhangyu用户的密码 14、拷贝文件到所有从节点 15、格式化分布式文件系统 16、启动Hadoop 17、查看Hadoop进程 18、在命令行中输入以下代码，打开Hadoop WebUI管理界面： 19、测试HDFS集群以及MapReduce任务程序 二、集群搭建之从节点1 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹： 三、集群搭建之从节点2 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹 进入主界面：一个主结点，两个从结点 一、集群搭建之主节点 1、下载安装包及测试文档 切换目录到/tmp cd /tmp 下载Hadoop安装包 wget http://59.74.172.143:60000/hadoop-2.6.0-cdh5.4.5.tar.gz 下载JDK安装包 wget http://59.74.172.143:60000/jdk-7u75-linux-x64.tar.gz 下载实验测试数据 wget http://59.74.172.143:60000/word.txt 2、安装Java JDK 这里安装的版本是jdk-7u75-linux-x64.tar.gz； 当前是普通用户，超级管理员才能对/opt目录进行操作，所有要使用sudo命令获取获取特权才能成功解压； 命令将其解压到/opt目录下： sudo tar -zxvf /tmp/jdk-7u75-linux-x64.tar.gz -C /opt/ 并将解压后的文件夹jdk-7u75-linux-x64改名为java： sudo mv /opt/jdk1.7.0_75 /opt/java 修改java目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/java jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 在文档末端添加如下内容： export JAVA_HOME=/opt/java export PATH=JAVAHOME/bin: JAVAH​OME/bin:PATH 刷新环境变量： source /etc/profile 刷新环境变量后，可以通过java的家目录找到java可使用的命令。 利用java查看版本号命令验证是否安装成功： java -version 正常结果显示如下： 3、Hadoop安装 这里安装的版本是hadoop-2.6.0-cdh5.4.5.tar.gz；命令将其解压到/opt目录下： sudo tar -zxvf /tmp/hadoop-2.6.0-cdh5.4.5.tar.gz -C /opt/ 并将解压后的文件夹hadoop-2.6.0-cdh5.4.5改名为hadoop： sudo mv /opt/hadoop-2.6.0-cdh5.4.5 /opt/hadoop 修改hadoop目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/hadoop jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 末端添加如下内容： export HADOOP_HOME=/opt/hadoop export PATH=HADOOPHOME/bin: HADOOPH​OME/bin:PATH 刷新环境变量： source /etc/profile 利用hadoop查看版本号命令验证是否安装成功： hadoop version 正常结果显示如下： 4、修改hosts文件 获取网卡信息得命令有：ifconfig 和 ip a ；使用获取网卡信息得命令，查看到当前节点的IP地址；编辑/etc/hosts文件： sudo vim /etc/hosts 添加本机IP地址对应本机映射名和其它节点IP地址对应映射名： 0.0.0.0 master 0.0.0.0 slave1 0.0.0.0 slave2 节点IP地址即”内网管理地址“ 配置完hosts文件，可以通过映射名访问对应的IP地址； 5、创建数据文件夹 sudo mkdir /data 所有者修改为当前用户： sudo chown -R zhangyu.zhangyu /data 6、修改hadoop hadoop-env.sh文件配置 vim /opt/hadoop/etc/hadoop/hadoop-env.sh 将JAVA_HOME修改成java所在目录： export JAVA_HOME=/opt/java/ 7、修改hadoop core-site.xml文件配置 编辑core-site.xml文件： vim /opt/hadoop/etc/hadoop/core-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000/&lt;/value&gt; &lt;description&gt;NameNode URI&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 这里有两项配置： 一项是hadoop.tmp.dir，配置hadoop处理过程中，临时文件的存储位置。这里的目录/data/需要提前创建。 另一项是fs.defaultFS，配置hadoop HDFS文件系统的地址。 8、修改hadoop hdfs-site.xml文件配置 编辑hdfs-site.xml文件： vim /opt/hadoop/etc/hadoop/hdfs-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置项说明： dfs.namenode.name.dir，配置元数据信息存储位置； dfs.datanode.data.dir，配置具体数据存储位置； dfs.replication，配置每个数据库备份数，由于目前我们使用1台节点，所以，设置为1，如果设置为2的话，运行会报错。 9、修改hadoop yarn-site.xml文件配置 编辑yarn-site.xml文件： vim /opt/hadoop/etc/hadoop/yarn-site.xml 替换为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里的配置是指定所用服务。 10、修改hadoop mapred-site.xml文件配置 创建mapred-site.xml文件： vim /opt/hadoop/etc/hadoop/mapred-site.xml 输入为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里指定mapreduce任务处理所使用的框架。 11、修改hadoop slaves文件配置 vim /opt/hadoop/etc/hadoop/slaves 覆盖写入主节点映射名和从节点映射名： master slave1 slave2 12、创建公钥 在zhangyu用户下创建公钥： ssh-keygen 出现如下内容： Enter file in which to save the key (/home/zhangyu/.ssh/id_rsa): 直接使用默认选项，回车即可，出现如下内容： Enter passphrase (empty for no passphrase): 直接回车，出现内容： Enter same passphrase again: 直接回车，创建完成，结果内容如下： 13、拷贝公钥，过程中需要输入zhangyu用户的密码 ssh-copy-id master ssh-copy-id slave1 ssh-copy-id slave2 提示：命令执行过程中需要输入“yes”和密码“zhangyu”。三台节点请依次执行完成。 测试连接是否正常： ssh master 输入exit退出测试： ssh slave1 输入exit退出测试： ssh slave2 输入exit退出测试： 测试中可以看出，连接各节点时，无需输入密码，因为已经设置好授权秘钥。 14、拷贝文件到所有从节点 scp -r /opt/java/ /opt/hadoop/ slave1:/tmp/ scp -r /opt/java/ /opt/hadoop/ slave2:/tmp/ 至此，主节点配置完成。" />
<meta property="og:description" content="一、集群搭建之主节点 1、下载安装包及测试文档 2、安装Java JDK 3、Hadoop安装 4、修改hosts文件 5、创建数据文件夹 6、修改hadoop hadoop-env.sh文件配置 7、修改hadoop core-site.xml文件配置 8、修改hadoop hdfs-site.xml文件配置 9、修改hadoop yarn-site.xml文件配置 10、修改hadoop mapred-site.xml文件配置 11、修改hadoop slaves文件配置 12、创建公钥 13、拷贝公钥，过程中需要输入zhangyu用户的密码 14、拷贝文件到所有从节点 15、格式化分布式文件系统 16、启动Hadoop 17、查看Hadoop进程 18、在命令行中输入以下代码，打开Hadoop WebUI管理界面： 19、测试HDFS集群以及MapReduce任务程序 二、集群搭建之从节点1 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹： 三、集群搭建之从节点2 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹 进入主界面：一个主结点，两个从结点 一、集群搭建之主节点 1、下载安装包及测试文档 切换目录到/tmp cd /tmp 下载Hadoop安装包 wget http://59.74.172.143:60000/hadoop-2.6.0-cdh5.4.5.tar.gz 下载JDK安装包 wget http://59.74.172.143:60000/jdk-7u75-linux-x64.tar.gz 下载实验测试数据 wget http://59.74.172.143:60000/word.txt 2、安装Java JDK 这里安装的版本是jdk-7u75-linux-x64.tar.gz； 当前是普通用户，超级管理员才能对/opt目录进行操作，所有要使用sudo命令获取获取特权才能成功解压； 命令将其解压到/opt目录下： sudo tar -zxvf /tmp/jdk-7u75-linux-x64.tar.gz -C /opt/ 并将解压后的文件夹jdk-7u75-linux-x64改名为java： sudo mv /opt/jdk1.7.0_75 /opt/java 修改java目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/java jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 在文档末端添加如下内容： export JAVA_HOME=/opt/java export PATH=JAVAHOME/bin: JAVAH​OME/bin:PATH 刷新环境变量： source /etc/profile 刷新环境变量后，可以通过java的家目录找到java可使用的命令。 利用java查看版本号命令验证是否安装成功： java -version 正常结果显示如下： 3、Hadoop安装 这里安装的版本是hadoop-2.6.0-cdh5.4.5.tar.gz；命令将其解压到/opt目录下： sudo tar -zxvf /tmp/hadoop-2.6.0-cdh5.4.5.tar.gz -C /opt/ 并将解压后的文件夹hadoop-2.6.0-cdh5.4.5改名为hadoop： sudo mv /opt/hadoop-2.6.0-cdh5.4.5 /opt/hadoop 修改hadoop目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/hadoop jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 末端添加如下内容： export HADOOP_HOME=/opt/hadoop export PATH=HADOOPHOME/bin: HADOOPH​OME/bin:PATH 刷新环境变量： source /etc/profile 利用hadoop查看版本号命令验证是否安装成功： hadoop version 正常结果显示如下： 4、修改hosts文件 获取网卡信息得命令有：ifconfig 和 ip a ；使用获取网卡信息得命令，查看到当前节点的IP地址；编辑/etc/hosts文件： sudo vim /etc/hosts 添加本机IP地址对应本机映射名和其它节点IP地址对应映射名： 0.0.0.0 master 0.0.0.0 slave1 0.0.0.0 slave2 节点IP地址即”内网管理地址“ 配置完hosts文件，可以通过映射名访问对应的IP地址； 5、创建数据文件夹 sudo mkdir /data 所有者修改为当前用户： sudo chown -R zhangyu.zhangyu /data 6、修改hadoop hadoop-env.sh文件配置 vim /opt/hadoop/etc/hadoop/hadoop-env.sh 将JAVA_HOME修改成java所在目录： export JAVA_HOME=/opt/java/ 7、修改hadoop core-site.xml文件配置 编辑core-site.xml文件： vim /opt/hadoop/etc/hadoop/core-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000/&lt;/value&gt; &lt;description&gt;NameNode URI&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 这里有两项配置： 一项是hadoop.tmp.dir，配置hadoop处理过程中，临时文件的存储位置。这里的目录/data/需要提前创建。 另一项是fs.defaultFS，配置hadoop HDFS文件系统的地址。 8、修改hadoop hdfs-site.xml文件配置 编辑hdfs-site.xml文件： vim /opt/hadoop/etc/hadoop/hdfs-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置项说明： dfs.namenode.name.dir，配置元数据信息存储位置； dfs.datanode.data.dir，配置具体数据存储位置； dfs.replication，配置每个数据库备份数，由于目前我们使用1台节点，所以，设置为1，如果设置为2的话，运行会报错。 9、修改hadoop yarn-site.xml文件配置 编辑yarn-site.xml文件： vim /opt/hadoop/etc/hadoop/yarn-site.xml 替换为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里的配置是指定所用服务。 10、修改hadoop mapred-site.xml文件配置 创建mapred-site.xml文件： vim /opt/hadoop/etc/hadoop/mapred-site.xml 输入为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里指定mapreduce任务处理所使用的框架。 11、修改hadoop slaves文件配置 vim /opt/hadoop/etc/hadoop/slaves 覆盖写入主节点映射名和从节点映射名： master slave1 slave2 12、创建公钥 在zhangyu用户下创建公钥： ssh-keygen 出现如下内容： Enter file in which to save the key (/home/zhangyu/.ssh/id_rsa): 直接使用默认选项，回车即可，出现如下内容： Enter passphrase (empty for no passphrase): 直接回车，出现内容： Enter same passphrase again: 直接回车，创建完成，结果内容如下： 13、拷贝公钥，过程中需要输入zhangyu用户的密码 ssh-copy-id master ssh-copy-id slave1 ssh-copy-id slave2 提示：命令执行过程中需要输入“yes”和密码“zhangyu”。三台节点请依次执行完成。 测试连接是否正常： ssh master 输入exit退出测试： ssh slave1 输入exit退出测试： ssh slave2 输入exit退出测试： 测试中可以看出，连接各节点时，无需输入密码，因为已经设置好授权秘钥。 14、拷贝文件到所有从节点 scp -r /opt/java/ /opt/hadoop/ slave1:/tmp/ scp -r /opt/java/ /opt/hadoop/ slave2:/tmp/ 至此，主节点配置完成。" />
<link rel="canonical" href="https://uzzz.org/2019/06/11/789494.html" />
<meta property="og:url" content="https://uzzz.org/2019/06/11/789494.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-11T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"一、集群搭建之主节点 1、下载安装包及测试文档 2、安装Java JDK 3、Hadoop安装 4、修改hosts文件 5、创建数据文件夹 6、修改hadoop hadoop-env.sh文件配置 7、修改hadoop core-site.xml文件配置 8、修改hadoop hdfs-site.xml文件配置 9、修改hadoop yarn-site.xml文件配置 10、修改hadoop mapred-site.xml文件配置 11、修改hadoop slaves文件配置 12、创建公钥 13、拷贝公钥，过程中需要输入zhangyu用户的密码 14、拷贝文件到所有从节点 15、格式化分布式文件系统 16、启动Hadoop 17、查看Hadoop进程 18、在命令行中输入以下代码，打开Hadoop WebUI管理界面： 19、测试HDFS集群以及MapReduce任务程序 二、集群搭建之从节点1 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹： 三、集群搭建之从节点2 1、Java环境配置 2、修改hosts文件 3、创建公钥 4、Hadoop环境配置 5、创建数据文件夹 进入主界面：一个主结点，两个从结点 一、集群搭建之主节点 1、下载安装包及测试文档 切换目录到/tmp cd /tmp 下载Hadoop安装包 wget http://59.74.172.143:60000/hadoop-2.6.0-cdh5.4.5.tar.gz 下载JDK安装包 wget http://59.74.172.143:60000/jdk-7u75-linux-x64.tar.gz 下载实验测试数据 wget http://59.74.172.143:60000/word.txt 2、安装Java JDK 这里安装的版本是jdk-7u75-linux-x64.tar.gz； 当前是普通用户，超级管理员才能对/opt目录进行操作，所有要使用sudo命令获取获取特权才能成功解压； 命令将其解压到/opt目录下： sudo tar -zxvf /tmp/jdk-7u75-linux-x64.tar.gz -C /opt/ 并将解压后的文件夹jdk-7u75-linux-x64改名为java： sudo mv /opt/jdk1.7.0_75 /opt/java 修改java目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/java jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 在文档末端添加如下内容： export JAVA_HOME=/opt/java export PATH=JAVAHOME/bin: JAVAH​OME/bin:PATH 刷新环境变量： source /etc/profile 刷新环境变量后，可以通过java的家目录找到java可使用的命令。 利用java查看版本号命令验证是否安装成功： java -version 正常结果显示如下： 3、Hadoop安装 这里安装的版本是hadoop-2.6.0-cdh5.4.5.tar.gz；命令将其解压到/opt目录下： sudo tar -zxvf /tmp/hadoop-2.6.0-cdh5.4.5.tar.gz -C /opt/ 并将解压后的文件夹hadoop-2.6.0-cdh5.4.5改名为hadoop： sudo mv /opt/hadoop-2.6.0-cdh5.4.5 /opt/hadoop 修改hadoop目录的所属用户和所属组： sudo chown -R zhangyu.zhangyu /opt/hadoop jdk安装完配置环境变量，编辑/etc/profile： sudo vim /etc/profile 末端添加如下内容： export HADOOP_HOME=/opt/hadoop export PATH=HADOOPHOME/bin: HADOOPH​OME/bin:PATH 刷新环境变量： source /etc/profile 利用hadoop查看版本号命令验证是否安装成功： hadoop version 正常结果显示如下： 4、修改hosts文件 获取网卡信息得命令有：ifconfig 和 ip a ；使用获取网卡信息得命令，查看到当前节点的IP地址；编辑/etc/hosts文件： sudo vim /etc/hosts 添加本机IP地址对应本机映射名和其它节点IP地址对应映射名： 0.0.0.0 master 0.0.0.0 slave1 0.0.0.0 slave2 节点IP地址即”内网管理地址“ 配置完hosts文件，可以通过映射名访问对应的IP地址； 5、创建数据文件夹 sudo mkdir /data 所有者修改为当前用户： sudo chown -R zhangyu.zhangyu /data 6、修改hadoop hadoop-env.sh文件配置 vim /opt/hadoop/etc/hadoop/hadoop-env.sh 将JAVA_HOME修改成java所在目录： export JAVA_HOME=/opt/java/ 7、修改hadoop core-site.xml文件配置 编辑core-site.xml文件： vim /opt/hadoop/etc/hadoop/core-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000/&lt;/value&gt; &lt;description&gt;NameNode URI&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 这里有两项配置： 一项是hadoop.tmp.dir，配置hadoop处理过程中，临时文件的存储位置。这里的目录/data/需要提前创建。 另一项是fs.defaultFS，配置hadoop HDFS文件系统的地址。 8、修改hadoop hdfs-site.xml文件配置 编辑hdfs-site.xml文件： vim /opt/hadoop/etc/hadoop/hdfs-site.xml 替换为下面的xml文本： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/tmp/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置项说明： dfs.namenode.name.dir，配置元数据信息存储位置； dfs.datanode.data.dir，配置具体数据存储位置； dfs.replication，配置每个数据库备份数，由于目前我们使用1台节点，所以，设置为1，如果设置为2的话，运行会报错。 9、修改hadoop yarn-site.xml文件配置 编辑yarn-site.xml文件： vim /opt/hadoop/etc/hadoop/yarn-site.xml 替换为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里的配置是指定所用服务。 10、修改hadoop mapred-site.xml文件配置 创建mapred-site.xml文件： vim /opt/hadoop/etc/hadoop/mapred-site.xml 输入为下面的xml文本： view plain copy &lt;?xml version=&quot;1.0&quot;?&gt; &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 这里指定mapreduce任务处理所使用的框架。 11、修改hadoop slaves文件配置 vim /opt/hadoop/etc/hadoop/slaves 覆盖写入主节点映射名和从节点映射名： master slave1 slave2 12、创建公钥 在zhangyu用户下创建公钥： ssh-keygen 出现如下内容： Enter file in which to save the key (/home/zhangyu/.ssh/id_rsa): 直接使用默认选项，回车即可，出现如下内容： Enter passphrase (empty for no passphrase): 直接回车，出现内容： Enter same passphrase again: 直接回车，创建完成，结果内容如下： 13、拷贝公钥，过程中需要输入zhangyu用户的密码 ssh-copy-id master ssh-copy-id slave1 ssh-copy-id slave2 提示：命令执行过程中需要输入“yes”和密码“zhangyu”。三台节点请依次执行完成。 测试连接是否正常： ssh master 输入exit退出测试： ssh slave1 输入exit退出测试： ssh slave2 输入exit退出测试： 测试中可以看出，连接各节点时，无需输入密码，因为已经设置好授权秘钥。 14、拷贝文件到所有从节点 scp -r /opt/java/ /opt/hadoop/ slave1:/tmp/ scp -r /opt/java/ /opt/hadoop/ slave2:/tmp/ 至此，主节点配置完成。","@type":"BlogPosting","url":"https://uzzz.org/2019/06/11/789494.html","headline":"【Hadoop】完全分布式安装","dateModified":"2019-06-11T00:00:00+08:00","datePublished":"2019-06-11T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/06/11/789494.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>【Hadoop】完全分布式安装</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="_0"></a>一、集群搭建之主节点</h2> 
  <pre><code>                1、下载安装包及测试文档
                2、安装Java JDK
                3、Hadoop安装
                4、修改hosts文件
                5、创建数据文件夹
                6、修改hadoop hadoop-env.sh文件配置
                7、修改hadoop core-site.xml文件配置
                8、修改hadoop hdfs-site.xml文件配置
                9、修改hadoop yarn-site.xml文件配置
                10、修改hadoop mapred-site.xml文件配置
                11、修改hadoop slaves文件配置
                12、创建公钥
                13、拷贝公钥，过程中需要输入zhangyu用户的密码
                14、拷贝文件到所有从节点
                15、格式化分布式文件系统
                16、启动Hadoop
                17、查看Hadoop进程
                18、在命令行中输入以下代码，打开Hadoop WebUI管理界面：
                19、测试HDFS集群以及MapReduce任务程序
</code></pre> 
  <h2><a id="1_23"></a>二、集群搭建之从节点1</h2> 
  <pre><code>                1、Java环境配置
                2、修改hosts文件
                3、创建公钥
                4、Hadoop环境配置
                5、创建数据文件夹：
</code></pre> 
  <h2><a id="2_32"></a>三、集群搭建之从节点2</h2> 
  <pre><code>                1、Java环境配置
                2、修改hosts文件
                3、创建公钥
                4、Hadoop环境配置
                5、创建数据文件夹
</code></pre> 
  <p>进入主界面：一个主结点，两个从结点<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611195946286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAzOTM0Nw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 一、集群搭建之主节点<br> 1、下载安装包及测试文档</p> 
  <p>切换目录到/tmp</p> 
  <p>cd /tmp<br> 下载Hadoop安装包</p> 
  <p>wget <a href="http://59.74.172.143:60000/hadoop-2.6.0-cdh5.4.5.tar.gz" rel="nofollow">http://59.74.172.143:60000/hadoop-2.6.0-cdh5.4.5.tar.gz</a><br> 下载JDK安装包</p> 
  <p>wget <a href="http://59.74.172.143:60000/jdk-7u75-linux-x64.tar.gz" rel="nofollow">http://59.74.172.143:60000/jdk-7u75-linux-x64.tar.gz</a><br> 下载实验测试数据</p> 
  <p>wget <a href="http://59.74.172.143:60000/word.txt" rel="nofollow">http://59.74.172.143:60000/word.txt</a></p> 
  <p>2、安装Java JDK</p> 
  <p>这里安装的版本是jdk-7u75-linux-x64.tar.gz；</p> 
  <p>当前是普通用户，超级管理员才能对/opt目录进行操作，所有要使用sudo命令获取获取特权才能成功解压； 命令将其解压到/opt目录下：</p> 
  <p>sudo tar -zxvf /tmp/jdk-7u75-linux-x64.tar.gz -C /opt/<br> 并将解压后的文件夹jdk-7u75-linux-x64改名为java：</p> 
  <p>sudo mv /opt/jdk1.7.0_75 /opt/java<br> 修改java目录的所属用户和所属组：</p> 
  <p>sudo chown -R zhangyu.zhangyu /opt/java<br> jdk安装完配置环境变量，编辑/etc/profile：</p> 
  <p>sudo vim /etc/profile<br> 在文档末端添加如下内容：</p> 
  <p>export JAVA_HOME=/opt/java<br> export PATH=JAVAHOME/bin:</p> 
  <p>JAVAH​OME/bin:PATH<br> 刷新环境变量：</p> 
  <p>source /etc/profile<br> 刷新环境变量后，可以通过java的家目录找到java可使用的命令。 利用java查看版本号命令验证是否安装成功：</p> 
  <p>java -version<br> 正常结果显示如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611200050874.png" alt="在这里插入图片描述">3、Hadoop安装</p> 
  <p>这里安装的版本是hadoop-2.6.0-cdh5.4.5.tar.gz；命令将其解压到/opt目录下：</p> 
  <p>sudo tar -zxvf /tmp/hadoop-2.6.0-cdh5.4.5.tar.gz -C /opt/<br> 并将解压后的文件夹hadoop-2.6.0-cdh5.4.5改名为hadoop：</p> 
  <p>sudo mv /opt/hadoop-2.6.0-cdh5.4.5 /opt/hadoop<br> 修改hadoop目录的所属用户和所属组：</p> 
  <p>sudo chown -R zhangyu.zhangyu /opt/hadoop<br> jdk安装完配置环境变量，编辑/etc/profile：</p> 
  <p>sudo vim /etc/profile<br> 末端添加如下内容：</p> 
  <p>export HADOOP_HOME=/opt/hadoop<br> export PATH=HADOOPHOME/bin:</p> 
  <p>HADOOPH​OME/bin:PATH<br> 刷新环境变量：</p> 
  <p>source /etc/profile<br> 利用hadoop查看版本号命令验证是否安装成功：</p> 
  <p>hadoop version<br> 正常结果显示如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611200148701.png" alt="在这里插入图片描述">4、修改hosts文件</p> 
  <p>获取网卡信息得命令有：ifconfig 和 ip a ；使用获取网卡信息得命令，查看到当前节点的IP地址；编辑/etc/hosts文件：</p> 
  <p>sudo vim /etc/hosts<br> 添加本机IP地址对应本机映射名和其它节点IP地址对应映射名：</p> 
  <p>0.0.0.0 master<br> 0.0.0.0 slave1<br> 0.0.0.0 slave2<br> 节点IP地址即”内网管理地址“</p> 
  <p>配置完hosts文件，可以通过映射名访问对应的IP地址；</p> 
  <p>5、创建数据文件夹</p> 
  <p>sudo mkdir /data<br> 所有者修改为当前用户：</p> 
  <p>sudo chown -R zhangyu.zhangyu /data</p> 
  <p>6、修改hadoop hadoop-env.sh文件配置</p> 
  <p>vim /opt/hadoop/etc/hadoop/hadoop-env.sh<br> 将JAVA_HOME修改成java所在目录：</p> 
  <p>export JAVA_HOME=/opt/java/</p> 
  <p>7、修改hadoop core-site.xml文件配置</p> 
  <p>编辑core-site.xml文件：</p> 
  <p>vim /opt/hadoop/etc/hadoop/core-site.xml<br> 替换为下面的xml文本：</p> 
  <pre><code>&lt;?xml version="1.0"?&gt;  
&lt;?xml-stylesheet type="text/xsl"   
        href="configuration.xsl"?&gt;  
&lt;configuration&gt;  
&lt;property&gt;  
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;  
    &lt;value&gt;/data/tmp/hadoop/tmp&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
    &lt;name&gt;fs.defaultFS&lt;/name&gt;  
    &lt;value&gt;hdfs://master:9000/&lt;/value&gt;  
    &lt;description&gt;NameNode URI&lt;/description&gt;  
&lt;/property&gt;  
&lt;/configuration&gt;  

</code></pre> 
  <p>这里有两项配置：</p> 
  <p>一项是hadoop.tmp.dir，配置hadoop处理过程中，临时文件的存储位置。这里的目录/data/需要提前创建。 另一项是fs.defaultFS，配置hadoop HDFS文件系统的地址。</p> 
  <p>8、修改hadoop hdfs-site.xml文件配置</p> 
  <p>编辑hdfs-site.xml文件：</p> 
  <p>vim /opt/hadoop/etc/hadoop/hdfs-site.xml<br> 替换为下面的xml文本：</p> 
  <pre><code>&lt;?xml version="1.0"?&gt;  
&lt;?xml-stylesheet type="text/xsl"   
       href="configuration.xsl"?&gt;  
&lt;configuration&gt;  
&lt;property&gt;  
   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;  
   &lt;value&gt;/data/tmp/hadoop/hdfs/name&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;  
   &lt;value&gt;/data/tmp/hadoop/hdfs/data&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
    &lt;name&gt;dfs.replication&lt;/name&gt;  
    &lt;value&gt;1&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
    &lt;name&gt;dfs.permissions&lt;/name&gt;  
    &lt;value&gt;false&lt;/value&gt;  
&lt;/property&gt;  
&lt;/configuration&gt;  

</code></pre> 
  <p>配置项说明：</p> 
  <p>dfs.namenode.name.dir，配置元数据信息存储位置； dfs.datanode.data.dir，配置具体数据存储位置； dfs.replication，配置每个数据库备份数，由于目前我们使用1台节点，所以，设置为1，如果设置为2的话，运行会报错。</p> 
  <p>9、修改hadoop yarn-site.xml文件配置</p> 
  <p>编辑yarn-site.xml文件：<br> vim /opt/hadoop/etc/hadoop/yarn-site.xml<br> 替换为下面的xml文本：</p> 
  <pre><code>view plain copy
&lt;?xml version="1.0"?&gt;  
&lt;?xml-stylesheet type="text/xsl"  
        href="configuration.xsl"?&gt;  
&lt;configuration&gt;  
&lt;property&gt;  
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;  
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  
&lt;/property&gt;  
&lt;/configuration&gt;  

</code></pre> 
  <p>这里的配置是指定所用服务。</p> 
  <p>10、修改hadoop mapred-site.xml文件配置</p> 
  <p>创建mapred-site.xml文件：</p> 
  <p>vim /opt/hadoop/etc/hadoop/mapred-site.xml<br> 输入为下面的xml文本：</p> 
  <pre><code>view plain copy
&lt;?xml version="1.0"?&gt;  
&lt;?xml-stylesheet type="text/xsl"   
        href="configuration.xsl"?&gt;  
&lt;configuration&gt;  
&lt;property&gt;  
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;  
    &lt;value&gt;yarn&lt;/value&gt;  
&lt;/property&gt;  
&lt;/configuration&gt;  

</code></pre> 
  <p>这里指定mapreduce任务处理所使用的框架。</p> 
  <p>11、修改hadoop slaves文件配置</p> 
  <p>vim /opt/hadoop/etc/hadoop/slaves<br> 覆盖写入主节点映射名和从节点映射名：</p> 
  <p>master<br> slave1<br> slave2</p> 
  <p>12、创建公钥</p> 
  <p>在zhangyu用户下创建公钥：</p> 
  <p>ssh-keygen<br> 出现如下内容：</p> 
  <p>Enter file in which to save the key (/home/zhangyu/.ssh/id_rsa):</p> 
  <p>直接使用默认选项，回车即可，出现如下内容：</p> 
  <p>Enter passphrase (empty for no passphrase):</p> 
  <p>直接回车，出现内容：</p> 
  <p>Enter same passphrase again:</p> 
  <p>直接回车，创建完成，结果内容如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611200917281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAzOTM0Nw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">13、拷贝公钥，过程中需要输入zhangyu用户的密码</p> 
  <p>ssh-copy-id master</p> 
  <p>ssh-copy-id slave1</p> 
  <p>ssh-copy-id slave2<br> 提示：命令执行过程中需要输入“yes”和密码“zhangyu”。三台节点请依次执行完成。</p> 
  <p>测试连接是否正常：</p> 
  <p>ssh master<br> 输入exit退出测试：</p> 
  <p>ssh slave1<br> 输入exit退出测试：</p> 
  <p>ssh slave2<br> 输入exit退出测试：</p> 
  <p>测试中可以看出，连接各节点时，无需输入密码，因为已经设置好授权秘钥。</p> 
  <p>14、拷贝文件到所有从节点</p> 
  <p>scp -r /opt/java/ /opt/hadoop/ slave1:/tmp/</p> 
  <p>scp -r /opt/java/ /opt/hadoop/ slave2:/tmp/<br> 至此，主节点配置完成。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
