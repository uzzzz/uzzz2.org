<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>HDFS读流程解析(附中文翻译) | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="HDFS读流程解析(附中文翻译)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Hadoop HDFS Data Read Operations HDFS读流程图 i) Client opens the file it wishes to read by calling open() on the FileSystem object, which for HDFS is an instance of DistributedFileSystem. 客户端打开文件, 并调用FileSystem类的open()方法来读文件. 对于HDFS而言是一个DistributedFileSystem的实例. ii) DistributedFileSystem calls the namenode using RPC to determine the locations of the blocks for the first few blocks in the file. For each block, the namenode returns the addresses of the datanodes that have a copy of that block and datanode are sorted according to their proximity to the client. DistributedFileSystem发送请求给namenode使用RPC(Rmove Procedure Call)去确定文件中前几个数据块的地址. 对每个数据块, namenode返回拥有该数据块的datanode的地址, 并根据datanode离客户端的距离对他们进行排序. iii) DistributedFileSystem returns a FSDataInputStream to the client for it to read data from. FSDataInputStream, thus, wraps the DFSInputStream which manages the datanode and namenode I/O. Client calls read() on the stream. DFSInputStream which has stored the datanode addresses then connects to the closest datanode for the first block in the file. DistributedFileSystem返回一个FSDataInputStream给客户端来读取数据.因此 FSDataInputSrteam包装管理datanode和namenode I/O的DFSInputStream. 客户端发送read()方法给stream. DFSInputStram存储了datanode的地址, 然后连接离文件中第一个数据块最近的datanode. iv) Data is streamed from the datanode back to the client, as a result client can call read() repeatedly on the stream. When the block ends, DFSInputStream will close the connection to the datanode and then finds the best datanode for the next block. 数据从datanode以流的形式返回客户端, 客户端在流上重复read()方法. 当数据块结束时, DFSInputStream将关闭与datanode的连接并寻找下一个数据块最佳的datanode. v) If the DFSInputStream encounters an error while communicating with a datanode, it will try the next closest one for that block. It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks. The DFSInputStream also verifies checksums for the data transferred to it from the datanode. If it finds a block, it reports this to the namenode before the DFSInputStream attempts to read a replica of the block from another datanode. 如果DFSInputStream在与datanode通信时发生错误, 它将试图连接离数据块最近的一个节点. 同时还会记住连接失败的datanode, 以防在连接其他块的时候重复访问他们. DFSinputStream也会核实从datanode传输的数据的校验码. 如果发现损坏块, 它将在DFSInputStream试图从其他datanode读取块副本之前, 报告给namenode. vi) When the client has finished reading the data, it calls close() on the stream. 当客户端完成数据读取后将会调用流的close()方法. 为了确保博主自身的理解和翻译不影响到别人, 特地附上英文原版. 本文章英文部分搬运自https://data-flair.training/blogs/hadoop-hdfs-data-read-and-write-operations/" />
<meta property="og:description" content="Hadoop HDFS Data Read Operations HDFS读流程图 i) Client opens the file it wishes to read by calling open() on the FileSystem object, which for HDFS is an instance of DistributedFileSystem. 客户端打开文件, 并调用FileSystem类的open()方法来读文件. 对于HDFS而言是一个DistributedFileSystem的实例. ii) DistributedFileSystem calls the namenode using RPC to determine the locations of the blocks for the first few blocks in the file. For each block, the namenode returns the addresses of the datanodes that have a copy of that block and datanode are sorted according to their proximity to the client. DistributedFileSystem发送请求给namenode使用RPC(Rmove Procedure Call)去确定文件中前几个数据块的地址. 对每个数据块, namenode返回拥有该数据块的datanode的地址, 并根据datanode离客户端的距离对他们进行排序. iii) DistributedFileSystem returns a FSDataInputStream to the client for it to read data from. FSDataInputStream, thus, wraps the DFSInputStream which manages the datanode and namenode I/O. Client calls read() on the stream. DFSInputStream which has stored the datanode addresses then connects to the closest datanode for the first block in the file. DistributedFileSystem返回一个FSDataInputStream给客户端来读取数据.因此 FSDataInputSrteam包装管理datanode和namenode I/O的DFSInputStream. 客户端发送read()方法给stream. DFSInputStram存储了datanode的地址, 然后连接离文件中第一个数据块最近的datanode. iv) Data is streamed from the datanode back to the client, as a result client can call read() repeatedly on the stream. When the block ends, DFSInputStream will close the connection to the datanode and then finds the best datanode for the next block. 数据从datanode以流的形式返回客户端, 客户端在流上重复read()方法. 当数据块结束时, DFSInputStream将关闭与datanode的连接并寻找下一个数据块最佳的datanode. v) If the DFSInputStream encounters an error while communicating with a datanode, it will try the next closest one for that block. It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks. The DFSInputStream also verifies checksums for the data transferred to it from the datanode. If it finds a block, it reports this to the namenode before the DFSInputStream attempts to read a replica of the block from another datanode. 如果DFSInputStream在与datanode通信时发生错误, 它将试图连接离数据块最近的一个节点. 同时还会记住连接失败的datanode, 以防在连接其他块的时候重复访问他们. DFSinputStream也会核实从datanode传输的数据的校验码. 如果发现损坏块, 它将在DFSInputStream试图从其他datanode读取块副本之前, 报告给namenode. vi) When the client has finished reading the data, it calls close() on the stream. 当客户端完成数据读取后将会调用流的close()方法. 为了确保博主自身的理解和翻译不影响到别人, 特地附上英文原版. 本文章英文部分搬运自https://data-flair.training/blogs/hadoop-hdfs-data-read-and-write-operations/" />
<link rel="canonical" href="https://uzzz.org/2019/06/11/790497.html" />
<meta property="og:url" content="https://uzzz.org/2019/06/11/790497.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-11T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Hadoop HDFS Data Read Operations HDFS读流程图 i) Client opens the file it wishes to read by calling open() on the FileSystem object, which for HDFS is an instance of DistributedFileSystem. 客户端打开文件, 并调用FileSystem类的open()方法来读文件. 对于HDFS而言是一个DistributedFileSystem的实例. ii) DistributedFileSystem calls the namenode using RPC to determine the locations of the blocks for the first few blocks in the file. For each block, the namenode returns the addresses of the datanodes that have a copy of that block and datanode are sorted according to their proximity to the client. DistributedFileSystem发送请求给namenode使用RPC(Rmove Procedure Call)去确定文件中前几个数据块的地址. 对每个数据块, namenode返回拥有该数据块的datanode的地址, 并根据datanode离客户端的距离对他们进行排序. iii) DistributedFileSystem returns a FSDataInputStream to the client for it to read data from. FSDataInputStream, thus, wraps the DFSInputStream which manages the datanode and namenode I/O. Client calls read() on the stream. DFSInputStream which has stored the datanode addresses then connects to the closest datanode for the first block in the file. DistributedFileSystem返回一个FSDataInputStream给客户端来读取数据.因此 FSDataInputSrteam包装管理datanode和namenode I/O的DFSInputStream. 客户端发送read()方法给stream. DFSInputStram存储了datanode的地址, 然后连接离文件中第一个数据块最近的datanode. iv) Data is streamed from the datanode back to the client, as a result client can call read() repeatedly on the stream. When the block ends, DFSInputStream will close the connection to the datanode and then finds the best datanode for the next block. 数据从datanode以流的形式返回客户端, 客户端在流上重复read()方法. 当数据块结束时, DFSInputStream将关闭与datanode的连接并寻找下一个数据块最佳的datanode. v) If the DFSInputStream encounters an error while communicating with a datanode, it will try the next closest one for that block. It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks. The DFSInputStream also verifies checksums for the data transferred to it from the datanode. If it finds a block, it reports this to the namenode before the DFSInputStream attempts to read a replica of the block from another datanode. 如果DFSInputStream在与datanode通信时发生错误, 它将试图连接离数据块最近的一个节点. 同时还会记住连接失败的datanode, 以防在连接其他块的时候重复访问他们. DFSinputStream也会核实从datanode传输的数据的校验码. 如果发现损坏块, 它将在DFSInputStream试图从其他datanode读取块副本之前, 报告给namenode. vi) When the client has finished reading the data, it calls close() on the stream. 当客户端完成数据读取后将会调用流的close()方法. 为了确保博主自身的理解和翻译不影响到别人, 特地附上英文原版. 本文章英文部分搬运自https://data-flair.training/blogs/hadoop-hdfs-data-read-and-write-operations/","@type":"BlogPosting","url":"https://uzzz.org/2019/06/11/790497.html","headline":"HDFS读流程解析(附中文翻译)","dateModified":"2019-06-11T00:00:00+08:00","datePublished":"2019-06-11T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/06/11/790497.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>HDFS读流程解析(附中文翻译)</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix" data-track-view="{&quot;mod&quot;:&quot;popu_307&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/Dota_Data/article/details/91461966,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_307&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/Dota_Data/article/details/91461966&quot;}"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="Hadoop_HDFS_Data_Read__Operations_0"></a>Hadoop HDFS Data Read Operations</h2> 
  <p>HDFS读流程图<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611201237434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RvdGFfRGF0YQ==,size_16,color_FFFFFF,t_70" alt="HDFS读流程图"><br> <strong>i)</strong> Client opens the file it wishes to read by calling open() on the FileSystem object, which for HDFS is an instance of DistributedFileSystem.</p> 
  <p>客户端打开文件, 并调用FileSystem类的open()方法来读文件. 对于HDFS而言是一个DistributedFileSystem的实例.</p> 
  <p><strong>ii)</strong> DistributedFileSystem calls the namenode using RPC to determine the locations of the blocks for the first few blocks in the file. For each block, the namenode returns the addresses of the datanodes that have a copy of that block and datanode are sorted according to their proximity to the client.</p> 
  <p>DistributedFileSystem发送请求给namenode使用RPC(Rmove Procedure Call)去确定文件中前几个数据块的地址. 对每个数据块, namenode返回拥有该数据块的datanode的地址, 并根据datanode离客户端的距离对他们进行排序.</p> 
  <p><strong>iii)</strong> DistributedFileSystem returns a FSDataInputStream to the client for it to read data from. FSDataInputStream, thus, wraps the DFSInputStream which manages the datanode and namenode I/O. Client calls read() on the stream. DFSInputStream which has stored the datanode addresses then connects to the closest datanode for the first block in the file.</p> 
  <p>DistributedFileSystem返回一个FSDataInputStream给客户端来读取数据.因此 FSDataInputSrteam包装管理datanode和namenode I/O的DFSInputStream. 客户端发送read()方法给stream. DFSInputStram存储了datanode的地址, 然后连接离文件中第一个数据块最近的datanode.</p> 
  <p><strong>iv)</strong> Data is streamed from the datanode back to the client, as a result client can call read() repeatedly on the stream. When the block ends, DFSInputStream will close the connection to the datanode and then finds the best datanode for the next block.</p> 
  <p>数据从datanode以流的形式返回客户端, 客户端在流上重复read()方法. 当数据块结束时, DFSInputStream将关闭与datanode的连接并寻找下一个数据块最佳的datanode.</p> 
  <p><strong>v)</strong> If the DFSInputStream encounters an error while communicating with a datanode, it will try the next closest one for that block. It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks. The DFSInputStream also verifies checksums for the data transferred to it from the datanode. If it finds a block, it reports this to the namenode before the DFSInputStream attempts to read a replica of the block from another datanode.</p> 
  <p>如果DFSInputStream在与datanode通信时发生错误, 它将试图连接离数据块最近的一个节点. 同时还会记住连接失败的datanode, 以防在连接其他块的时候重复访问他们. DFSinputStream也会核实从datanode传输的数据的校验码. 如果发现损坏块, 它将在DFSInputStream试图从其他datanode读取块副本之前, 报告给namenode.</p> 
  <p><strong>vi)</strong> When the client has finished reading the data, it calls close() on the stream.</p> 
  <p>当客户端完成数据读取后将会调用流的close()方法.</p> 
  <p><strong>为了确保博主自身的理解和翻译不影响到别人, 特地附上英文原版.<br> 本文章英文部分搬运自<a href="https://data-flair.training/blogs/hadoop-hdfs-data-read-and-write-operations/" rel="nofollow">https://data-flair.training/blogs/hadoop-hdfs-data-read-and-write-operations/</a></strong></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
