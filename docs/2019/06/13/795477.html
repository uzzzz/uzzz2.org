<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>R语言实现MCMC中的Metropolis–Hastings算法与吉布斯采样 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="R语言实现MCMC中的Metropolis–Hastings算法与吉布斯采样" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;原文：http://tecdat.cn/?p=3772 &nbsp; 创建测试数据 作为第一步，我们创建一些测试数据，用于拟合我们的模型。让我们假设预测变量和响应变量之间存在线性关系，因此我们采用线性模型并添加一些噪声。 我将x值平衡在零附近以“去相关”斜率和截距。结果应该看起来像右边的 &nbsp; trueA &lt;- 5 trueB &lt;- 0 trueSd &lt;- 10 sampleSize &lt;- 31 &nbsp; # create independent x-values x &lt;- (-(sampleSize-1)/2):((sampleSize-1)/2) # create dependent values according to ax + b + N(0,sd) y &lt;-&nbsp; trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd) &nbsp; plot(x,y, main=&quot;Test Data&quot;) 图 定义统计模型 下一步是指定统计模型。我们已经知道数据是用x和y之间的线性关系y = a * x + b和带有标准差sd的正常误差模型N（0，sd）创建的，所以让我们使用相同的模型进行拟合，看看如果我们可以检索我们的原始参数值。 从模型中导出似然函数 为了估计贝叶斯分析中的参数，我们需要导出我们想要拟合的模型的似然函数。可能性是我们期望观察到的数据以我们所看到的模型的参数为条件发生的概率（密度）。因此，假设我们的线性模型y = b + a * x + N（0，sd）将参数（a，b，sd）作为输入，我们必须返回在此模型下获得上述测试数据的概率（这听起来更复杂，正如你在代码中看到的那样，我们只是计算预测y = b + a * x和观察到的y之间的差异，然后我们必须查找概率密度（使用dnorm）发生这种偏差。 likelihood &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;pred = a*x + b &nbsp; &nbsp; &nbsp;sumll = sum(singlelikelihoods) &nbsp; &nbsp; &nbsp;(sumll)&nbsp;&nbsp; } &nbsp; &nbsp;slopevalues &lt;- function(x){return(likelihood(c(x, trueB, trueSd)))} &nbsp; &nbsp; 斜率参数的对数似然曲线 作为说明，代码的最后几行绘制了斜率参数a的一系列参数值的似然性。结果应该看起来像右边的情节。 为什么我们使用对数 您可能已经注意到我返回似然函数中概率的对数，这也是我对所有数据点的概率求和的原因（乘积的对数等于对数之和）。我们为什么要做这个？你不必这样做，但这是强烈建议的，因为很多小概率乘以的可能性很快就会变得非常小（比如10 ^ -34）。在某些阶段，计算机程序正在进入数字舍入或下溢问题。所以，底线：当你用可能性编程时，总是使用对数！ 定义先验 作为第二步，与贝叶斯统计中一样，我们必须为每个参数指定先验分布。为了方便起见，我对所有三个参数使用了均匀分布和正态分布。&nbsp;无信息先验通常是1 / sigma的比例（如果你想了解原因，请看这里）。当你认真地深入了解贝叶斯统计数据时，这个东西很重要，但我不想让代码在这里更加混乱。 # Prior distribution prior &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;aprior =&nbsp;&nbsp;(a, min=0, max=10, log = T) &nbsp;&nbsp;&nbsp;&nbsp;bprior = dnorm(b, sd = 5, log = T) &nbsp;} &nbsp;后验 先验和可能性的乘积是MCMC将要处理的实际数量。这个函数被称为后验（或者确切地说，它在被归一化之后称为后验，MCMC将为我们做，但让我们暂时不挑剔）。同样，在这里我们使用总和，因为我们使用对数。 posterior &lt;- function(param){ &nbsp;&nbsp;&nbsp;return (&nbsp;(param) + prior(param)) } &nbsp;MCMC 现在，实际上是Metropolis-Hastings算法。该算法最常见的应用之一（如本例所示）是从贝叶斯统计中的后验密度中提取样本。然而，原则上，该算法可用于从任何可积函数中进行采样。因此，该算法的目的是在参数空间中跳转，但是以某种方式使得在某一点上的概率与我们采样的函数成比例（这通常称为目标函数）。在我们的例子中，这是上面定义的后验。 这是通过 从随机参数值开始 根据称为提议函数的某个概率密度，选择接近旧值的新参数值 以概率p（新）/ p（旧）跳到这个新点，其中p是目标函数，p&gt; 1表示跳跃 考虑为什么会起作用很有趣，但目前我可以向你保证 - 当我们运行这个算法时，它访问的参数的分布会收敛到目标分布p。那么，让我们在R中得到这个： ######## Metropolis algorithm ################ &nbsp; proposalfunction &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3))) } &nbsp; run_metropolis_MCMC &lt;- function(startvalue, iterations){ &nbsp; &nbsp; &nbsp;&nbsp;for (i in 1:iterations){ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (runif(1) &lt; probab){ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = proposal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}else{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = chain[i,] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;return(chain) } &nbsp; &nbsp;chain = run_metropolis_MCMC(startvalue, 10000) &nbsp; burnIn = 5000 acceptance = 1-mean(duplicated(chain[-(1:burnIn),])) 再次，使用后验的对数可能在开始时有点混乱，特别是当您查看计算接受概率的行时（probab = exp（后验（建议） - 后验（链[i，]）） ）。要理解我们为什么这样做，请注意p1 / p2 = exp [log（p1）-log（p2）]。 算法的第一步可能受初始值的偏差，因此通常被丢弃用于进一步分析 。要看的一个有趣的输出是接受率： 接受标准拒绝提案的频率是多少？接受率可以受提议函数的影响：通常，提案越接近，接受率越大。然而，非常高的接受率通常是无益的：这意味着算法“停留”在同一点 。可以证明，20％到30％的接受率对于典型应用来说是最佳的 。 &nbsp; ### Summary: ####################### &nbsp; par(mfrow = c(2,3)) hist( [-(1:burnIn),1],nclass=30, , main=&quot;Posterior of a&quot;, xlab=&quot;True value = red line&quot; ) abline(v = mean(chain[-(1:burnIn),1])) &nbsp; &nbsp; # for comparison: summary(lm(y~x)) 生成的图应该类似于下图。您可以看到我们或多或少地检索了用于创建数据的原始参数，并且您还看到我们获得了一个围绕最高后验值的特定区域，这些区域也有一些数据支持，这是贝叶斯相当于置信度的间隔。 图：上排显示斜率（a）的后验估计，截距（b）和误差的标准偏差（sd）。下一行显示马尔可夫链参数值。 &nbsp; 还有问题吗？请在下面留言！ &nbsp;" />
<meta property="og:description" content="&nbsp;原文：http://tecdat.cn/?p=3772 &nbsp; 创建测试数据 作为第一步，我们创建一些测试数据，用于拟合我们的模型。让我们假设预测变量和响应变量之间存在线性关系，因此我们采用线性模型并添加一些噪声。 我将x值平衡在零附近以“去相关”斜率和截距。结果应该看起来像右边的 &nbsp; trueA &lt;- 5 trueB &lt;- 0 trueSd &lt;- 10 sampleSize &lt;- 31 &nbsp; # create independent x-values x &lt;- (-(sampleSize-1)/2):((sampleSize-1)/2) # create dependent values according to ax + b + N(0,sd) y &lt;-&nbsp; trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd) &nbsp; plot(x,y, main=&quot;Test Data&quot;) 图 定义统计模型 下一步是指定统计模型。我们已经知道数据是用x和y之间的线性关系y = a * x + b和带有标准差sd的正常误差模型N（0，sd）创建的，所以让我们使用相同的模型进行拟合，看看如果我们可以检索我们的原始参数值。 从模型中导出似然函数 为了估计贝叶斯分析中的参数，我们需要导出我们想要拟合的模型的似然函数。可能性是我们期望观察到的数据以我们所看到的模型的参数为条件发生的概率（密度）。因此，假设我们的线性模型y = b + a * x + N（0，sd）将参数（a，b，sd）作为输入，我们必须返回在此模型下获得上述测试数据的概率（这听起来更复杂，正如你在代码中看到的那样，我们只是计算预测y = b + a * x和观察到的y之间的差异，然后我们必须查找概率密度（使用dnorm）发生这种偏差。 likelihood &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;pred = a*x + b &nbsp; &nbsp; &nbsp;sumll = sum(singlelikelihoods) &nbsp; &nbsp; &nbsp;(sumll)&nbsp;&nbsp; } &nbsp; &nbsp;slopevalues &lt;- function(x){return(likelihood(c(x, trueB, trueSd)))} &nbsp; &nbsp; 斜率参数的对数似然曲线 作为说明，代码的最后几行绘制了斜率参数a的一系列参数值的似然性。结果应该看起来像右边的情节。 为什么我们使用对数 您可能已经注意到我返回似然函数中概率的对数，这也是我对所有数据点的概率求和的原因（乘积的对数等于对数之和）。我们为什么要做这个？你不必这样做，但这是强烈建议的，因为很多小概率乘以的可能性很快就会变得非常小（比如10 ^ -34）。在某些阶段，计算机程序正在进入数字舍入或下溢问题。所以，底线：当你用可能性编程时，总是使用对数！ 定义先验 作为第二步，与贝叶斯统计中一样，我们必须为每个参数指定先验分布。为了方便起见，我对所有三个参数使用了均匀分布和正态分布。&nbsp;无信息先验通常是1 / sigma的比例（如果你想了解原因，请看这里）。当你认真地深入了解贝叶斯统计数据时，这个东西很重要，但我不想让代码在这里更加混乱。 # Prior distribution prior &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;aprior =&nbsp;&nbsp;(a, min=0, max=10, log = T) &nbsp;&nbsp;&nbsp;&nbsp;bprior = dnorm(b, sd = 5, log = T) &nbsp;} &nbsp;后验 先验和可能性的乘积是MCMC将要处理的实际数量。这个函数被称为后验（或者确切地说，它在被归一化之后称为后验，MCMC将为我们做，但让我们暂时不挑剔）。同样，在这里我们使用总和，因为我们使用对数。 posterior &lt;- function(param){ &nbsp;&nbsp;&nbsp;return (&nbsp;(param) + prior(param)) } &nbsp;MCMC 现在，实际上是Metropolis-Hastings算法。该算法最常见的应用之一（如本例所示）是从贝叶斯统计中的后验密度中提取样本。然而，原则上，该算法可用于从任何可积函数中进行采样。因此，该算法的目的是在参数空间中跳转，但是以某种方式使得在某一点上的概率与我们采样的函数成比例（这通常称为目标函数）。在我们的例子中，这是上面定义的后验。 这是通过 从随机参数值开始 根据称为提议函数的某个概率密度，选择接近旧值的新参数值 以概率p（新）/ p（旧）跳到这个新点，其中p是目标函数，p&gt; 1表示跳跃 考虑为什么会起作用很有趣，但目前我可以向你保证 - 当我们运行这个算法时，它访问的参数的分布会收敛到目标分布p。那么，让我们在R中得到这个： ######## Metropolis algorithm ################ &nbsp; proposalfunction &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3))) } &nbsp; run_metropolis_MCMC &lt;- function(startvalue, iterations){ &nbsp; &nbsp; &nbsp;&nbsp;for (i in 1:iterations){ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (runif(1) &lt; probab){ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = proposal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}else{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = chain[i,] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;return(chain) } &nbsp; &nbsp;chain = run_metropolis_MCMC(startvalue, 10000) &nbsp; burnIn = 5000 acceptance = 1-mean(duplicated(chain[-(1:burnIn),])) 再次，使用后验的对数可能在开始时有点混乱，特别是当您查看计算接受概率的行时（probab = exp（后验（建议） - 后验（链[i，]）） ）。要理解我们为什么这样做，请注意p1 / p2 = exp [log（p1）-log（p2）]。 算法的第一步可能受初始值的偏差，因此通常被丢弃用于进一步分析 。要看的一个有趣的输出是接受率： 接受标准拒绝提案的频率是多少？接受率可以受提议函数的影响：通常，提案越接近，接受率越大。然而，非常高的接受率通常是无益的：这意味着算法“停留”在同一点 。可以证明，20％到30％的接受率对于典型应用来说是最佳的 。 &nbsp; ### Summary: ####################### &nbsp; par(mfrow = c(2,3)) hist( [-(1:burnIn),1],nclass=30, , main=&quot;Posterior of a&quot;, xlab=&quot;True value = red line&quot; ) abline(v = mean(chain[-(1:burnIn),1])) &nbsp; &nbsp; # for comparison: summary(lm(y~x)) 生成的图应该类似于下图。您可以看到我们或多或少地检索了用于创建数据的原始参数，并且您还看到我们获得了一个围绕最高后验值的特定区域，这些区域也有一些数据支持，这是贝叶斯相当于置信度的间隔。 图：上排显示斜率（a）的后验估计，截距（b）和误差的标准偏差（sd）。下一行显示马尔可夫链参数值。 &nbsp; 还有问题吗？请在下面留言！ &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/06/13/795477.html" />
<meta property="og:url" content="https://uzzz.org/2019/06/13/795477.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-13T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;原文：http://tecdat.cn/?p=3772 &nbsp; 创建测试数据 作为第一步，我们创建一些测试数据，用于拟合我们的模型。让我们假设预测变量和响应变量之间存在线性关系，因此我们采用线性模型并添加一些噪声。 我将x值平衡在零附近以“去相关”斜率和截距。结果应该看起来像右边的 &nbsp; trueA &lt;- 5 trueB &lt;- 0 trueSd &lt;- 10 sampleSize &lt;- 31 &nbsp; # create independent x-values x &lt;- (-(sampleSize-1)/2):((sampleSize-1)/2) # create dependent values according to ax + b + N(0,sd) y &lt;-&nbsp; trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd) &nbsp; plot(x,y, main=&quot;Test Data&quot;) 图 定义统计模型 下一步是指定统计模型。我们已经知道数据是用x和y之间的线性关系y = a * x + b和带有标准差sd的正常误差模型N（0，sd）创建的，所以让我们使用相同的模型进行拟合，看看如果我们可以检索我们的原始参数值。 从模型中导出似然函数 为了估计贝叶斯分析中的参数，我们需要导出我们想要拟合的模型的似然函数。可能性是我们期望观察到的数据以我们所看到的模型的参数为条件发生的概率（密度）。因此，假设我们的线性模型y = b + a * x + N（0，sd）将参数（a，b，sd）作为输入，我们必须返回在此模型下获得上述测试数据的概率（这听起来更复杂，正如你在代码中看到的那样，我们只是计算预测y = b + a * x和观察到的y之间的差异，然后我们必须查找概率密度（使用dnorm）发生这种偏差。 likelihood &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;pred = a*x + b &nbsp; &nbsp; &nbsp;sumll = sum(singlelikelihoods) &nbsp; &nbsp; &nbsp;(sumll)&nbsp;&nbsp; } &nbsp; &nbsp;slopevalues &lt;- function(x){return(likelihood(c(x, trueB, trueSd)))} &nbsp; &nbsp; 斜率参数的对数似然曲线 作为说明，代码的最后几行绘制了斜率参数a的一系列参数值的似然性。结果应该看起来像右边的情节。 为什么我们使用对数 您可能已经注意到我返回似然函数中概率的对数，这也是我对所有数据点的概率求和的原因（乘积的对数等于对数之和）。我们为什么要做这个？你不必这样做，但这是强烈建议的，因为很多小概率乘以的可能性很快就会变得非常小（比如10 ^ -34）。在某些阶段，计算机程序正在进入数字舍入或下溢问题。所以，底线：当你用可能性编程时，总是使用对数！ 定义先验 作为第二步，与贝叶斯统计中一样，我们必须为每个参数指定先验分布。为了方便起见，我对所有三个参数使用了均匀分布和正态分布。&nbsp;无信息先验通常是1 / sigma的比例（如果你想了解原因，请看这里）。当你认真地深入了解贝叶斯统计数据时，这个东西很重要，但我不想让代码在这里更加混乱。 # Prior distribution prior &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;a = param[1] &nbsp;&nbsp;&nbsp;&nbsp;b = param[2] &nbsp;&nbsp;&nbsp;&nbsp;sd = param[3] &nbsp;&nbsp;&nbsp;&nbsp;aprior =&nbsp;&nbsp;(a, min=0, max=10, log = T) &nbsp;&nbsp;&nbsp;&nbsp;bprior = dnorm(b, sd = 5, log = T) &nbsp;} &nbsp;后验 先验和可能性的乘积是MCMC将要处理的实际数量。这个函数被称为后验（或者确切地说，它在被归一化之后称为后验，MCMC将为我们做，但让我们暂时不挑剔）。同样，在这里我们使用总和，因为我们使用对数。 posterior &lt;- function(param){ &nbsp;&nbsp;&nbsp;return (&nbsp;(param) + prior(param)) } &nbsp;MCMC 现在，实际上是Metropolis-Hastings算法。该算法最常见的应用之一（如本例所示）是从贝叶斯统计中的后验密度中提取样本。然而，原则上，该算法可用于从任何可积函数中进行采样。因此，该算法的目的是在参数空间中跳转，但是以某种方式使得在某一点上的概率与我们采样的函数成比例（这通常称为目标函数）。在我们的例子中，这是上面定义的后验。 这是通过 从随机参数值开始 根据称为提议函数的某个概率密度，选择接近旧值的新参数值 以概率p（新）/ p（旧）跳到这个新点，其中p是目标函数，p&gt; 1表示跳跃 考虑为什么会起作用很有趣，但目前我可以向你保证 - 当我们运行这个算法时，它访问的参数的分布会收敛到目标分布p。那么，让我们在R中得到这个： ######## Metropolis algorithm ################ &nbsp; proposalfunction &lt;- function(param){ &nbsp;&nbsp;&nbsp;&nbsp;return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3))) } &nbsp; run_metropolis_MCMC &lt;- function(startvalue, iterations){ &nbsp; &nbsp; &nbsp;&nbsp;for (i in 1:iterations){ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (runif(1) &lt; probab){ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = proposal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}else{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = chain[i,] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;return(chain) } &nbsp; &nbsp;chain = run_metropolis_MCMC(startvalue, 10000) &nbsp; burnIn = 5000 acceptance = 1-mean(duplicated(chain[-(1:burnIn),])) 再次，使用后验的对数可能在开始时有点混乱，特别是当您查看计算接受概率的行时（probab = exp（后验（建议） - 后验（链[i，]）） ）。要理解我们为什么这样做，请注意p1 / p2 = exp [log（p1）-log（p2）]。 算法的第一步可能受初始值的偏差，因此通常被丢弃用于进一步分析 。要看的一个有趣的输出是接受率： 接受标准拒绝提案的频率是多少？接受率可以受提议函数的影响：通常，提案越接近，接受率越大。然而，非常高的接受率通常是无益的：这意味着算法“停留”在同一点 。可以证明，20％到30％的接受率对于典型应用来说是最佳的 。 &nbsp; ### Summary: ####################### &nbsp; par(mfrow = c(2,3)) hist( [-(1:burnIn),1],nclass=30, , main=&quot;Posterior of a&quot;, xlab=&quot;True value = red line&quot; ) abline(v = mean(chain[-(1:burnIn),1])) &nbsp; &nbsp; # for comparison: summary(lm(y~x)) 生成的图应该类似于下图。您可以看到我们或多或少地检索了用于创建数据的原始参数，并且您还看到我们获得了一个围绕最高后验值的特定区域，这些区域也有一些数据支持，这是贝叶斯相当于置信度的间隔。 图：上排显示斜率（a）的后验估计，截距（b）和误差的标准偏差（sd）。下一行显示马尔可夫链参数值。 &nbsp; 还有问题吗？请在下面留言！ &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/06/13/795477.html","headline":"R语言实现MCMC中的Metropolis–Hastings算法与吉布斯采样","dateModified":"2019-06-13T00:00:00+08:00","datePublished":"2019-06-13T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/06/13/795477.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>R语言实现MCMC中的Metropolis–Hastings算法与吉布斯采样</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h3 style="margin-left:0px;"><span style="color:#404040;">&nbsp;原文：</span><a href="http://tecdat.cn/?p=3772" rel="nofollow" data-token="a11f914ab996846b6216636227282155">http://tecdat.cn/?p=3772</a></h3> 
  <p style="margin-left:0px;">&nbsp;</p> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>创建测试数据</strong></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">作为第一步，我们创建一些测试数据，用于拟合我们的模型。让我们假设预测变量和响应变量之间存在线性关系，因此我们采用线性模型并添加一些噪声。</span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;">我将x值平衡在零附近以“去相关”斜率和截距。结果应该看起来像右边的</span><br><br> &nbsp;</p> 
  <pre class="has">
<code>trueA &lt;- 5

trueB &lt;- 0

trueSd &lt;- 10

sampleSize &lt;- 31

&nbsp;

# create independent x-values

x &lt;- (-(sampleSize-1)/2):((sampleSize-1)/2)

# create dependent values according to ax + b + N(0,sd)

y &lt;-&nbsp; trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)

&nbsp;

plot(x,y, main="Test Data")</code></pre> 
  <p style="margin-left:0px;"><span style="color:#404040;">图</span></p> 
  <p><span style="color:#404040;"><a href="https://theoreticalecology.files.wordpress.com/2010/09/testdata4.png" rel="nofollow" data-token="2f92bf5086845e8da6b1453909090939"><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly90aGVvcmV0aWNhbGVjb2xvZ3kuZmlsZXMud29yZHByZXNzLmNvbS8yMDEwLzA5L3Rlc3RkYXRhNC5wbmc_dz03MDA"></a></span></p> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>定义统计模型</strong></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">下一步是指定统计模型。我们已经知道数据是用x和y之间的线性关系y = a * x + b和带有标准差sd的正常误差模型N（0，sd）创建的，所以让我们使用相同的模型进行拟合，看看如果我们可以检索我们的原始参数值。</span></p> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>从模型中导出似然函数</strong></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">为了估计贝叶斯分析中的参数，我们需要导出我们想要拟合的模型的<a href="http://en.wikipedia.org/wiki/Likelihood_function" rel="nofollow" data-token="f59b856d8948a1ae2ba003766687a998">似然函数</a>。可能性是我们期望观察到的数据以我们所看到的模型的参数为条件发生的概率（密度）。因此，假设我们的线性模型y = b + a * x + N（0，sd）将参数（a，b，sd）作为输入，我们必须返回在此模型下获得上述测试数据的概率（这听起来更复杂，正如你在代码中看到的那样，我们只是计算预测y = b + a * x和观察到的y之间的差异，然后我们必须查找概率密度（使用<a href="http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Normal.html" rel="nofollow" data-token="5a1aca8ab2d0c1817f49c36fb7ebbdd6">dnorm</a>）发生这种偏差。</span></p> 
  <pre class="has">
<code>likelihood &lt;- function(param){

&nbsp;&nbsp;&nbsp;&nbsp;a = param[1]

&nbsp;&nbsp;&nbsp;&nbsp;b = param[2]

&nbsp;&nbsp;&nbsp;&nbsp;sd = param[3]

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;&nbsp;pred = a*x + b

&nbsp; &nbsp; &nbsp;sumll = sum(singlelikelihoods)

&nbsp; &nbsp; &nbsp;(sumll)&nbsp;&nbsp;

}

&nbsp;

&nbsp;slopevalues &lt;- function(x){return(likelihood(c(x, trueB, trueSd)))}</code></pre> 
  <table style="margin-left:0px;">
   <tbody>
    <tr>
     <td style="text-align:left;vertical-align:baseline;"> <p>&nbsp;</p> </td> 
     <td style="text-align:left;vertical-align:baseline;">&nbsp;</td> 
    </tr>
   </tbody>
  </table>
  <p><span style="color:#404040;"><a href="https://theoreticalecology.files.wordpress.com/2013/12/slope.png" rel="nofollow" data-token="7ab50f07d2d4b003f111a7e535047db0"><img alt="斜率参数的对数似然曲线" class="size-medium wp-image-4378" height="300" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181218152712895" width="300"></a></span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;"><span style="color:#999999;">斜率参数的对数似然曲线</span></span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;">作为说明，代码的最后几行绘制了斜率参数a的一系列参数值的似然性。结果应该看起来像右边的情节。</span></p> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>为什么我们使用对数</strong></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">您可能已经注意到我返回似然函数中概率的对数，这也是我对所有数据点的概率求和的原因（乘积的对数等于对数之和）。我们为什么要做这个？你不必这样做，但这是强烈建议的，因为很多小概率乘以的可能性很快就会变得非常小（比如10 ^ -34）。在某些阶段，计算机程序正在进入数字舍入或下溢问题。所以，底线：当你用可能性编程时，总是使用对数！</span></p> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>定义</strong><a href="http://en.wikipedia.org/wiki/Prior_probability" rel="nofollow" data-token="53f7b4140326eeaf6ac8a79a25ee2b91">先验</a></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">作为第二步，与<a href="http://en.wikipedia.org/wiki/Bayesian_statistics" rel="nofollow" data-token="42091bd23bf947297f5a6ef8067209cd">贝叶斯统计中一样</a>，我们必须为每个参数指定<a href="http://en.wikipedia.org/wiki/Prior_probability" rel="nofollow" data-token="53f7b4140326eeaf6ac8a79a25ee2b91">先验分布</a>。为了方便起见，我对所有三个参数使用了均匀分布和正态分布。&nbsp;<em>无信息先验通常是1 / sigma的比例（如果你想了解原因，请看<a href="http://en.wikipedia.org/wiki/Jeffreys_prior#Gaussian_distribution_with_standard_deviation_parameter" rel="nofollow" data-token="e39898bb5bd974c8d9f92cb433b0f989">这里</a>）。当你认真地深入了解贝叶斯统计数据时，这个东西很重要，但我不想让代码在这里更加混乱。</em></span></p> 
  <pre class="has">
<code># Prior distribution

prior &lt;- function(param){

&nbsp;&nbsp;&nbsp;&nbsp;a = param[1]

&nbsp;&nbsp;&nbsp;&nbsp;b = param[2]

&nbsp;&nbsp;&nbsp;&nbsp;sd = param[3]

&nbsp;&nbsp;&nbsp;&nbsp;aprior =&nbsp;&nbsp;(a, min=0, max=10, log = T)

&nbsp;&nbsp;&nbsp;&nbsp;bprior = dnorm(b, sd = 5, log = T)

&nbsp;}</code></pre> 
  <h1 style="margin-left:0px;"><span style="color:#404040;"><strong>&nbsp;</strong></span><span style="color:#404040;"><a href="http://en.wikipedia.org/wiki/Posterior_probability" rel="nofollow" data-token="986985d3a620f4bedba60d383def3b1a">后验</a></span></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">先验和可能性的乘积是MCMC将要处理的实际数量。这个函数被称为<a href="http://en.wikipedia.org/wiki/Posterior_probability" rel="nofollow" data-token="986985d3a620f4bedba60d383def3b1a">后验</a>（或者确切地说，它在被归一化之后称为后验，MCMC将为我们做，但让我们暂时不挑剔）。同样，在这里我们使用总和，因为我们使用对数。</span></p> 
  <pre class="has">
<code>posterior &lt;- function(param){

&nbsp;&nbsp;&nbsp;return (&nbsp;(param) + prior(param))

}</code></pre> 
  <p style="margin-left:0px;"><span style="color:#404040;"><a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2011.01640.x/full#ss12" rel="nofollow" data-token="9f26aa7db5d38e71e867dcee19cb7365"><img alt="" class="aligncenter size-full wp-image-1090" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181218152712913"></a></span></p> 
  <h1 style="margin-left:0px;"><strong style="color:#404040;"><em>&nbsp;</em>MCMC</strong></h1> 
  <p style="margin-left:0px;"><span style="color:#404040;">现在，实际上是<a href="http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" rel="nofollow" data-token="ca5be13d57eefa99e980d94fe54958f9">Metropolis-Hastings算法</a>。该算法最常见的应用之一（如本例所示）是从贝叶斯统计中的后验密度中提取样本。然而，原则上，该算法可用于从任何可积函数中进行采样。因此，该算法的目的是在参数空间中跳转，但是以某种方式使得在某一点上的概率与我们采样的函数成比例（这通常称为目标函数）。在我们的例子中，这是上面定义的后验。</span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;">这是通过</span></p> 
  <ol style="margin-left:3em;">
   <li>从随机参数值开始</li> 
   <li>根据称为提议函数的某个概率密度，选择接近旧值的新参数值</li> 
   <li>以概率p（新）/ p（旧）跳到这个新点，其中p是目标函数，p&gt; 1表示跳跃</li> 
  </ol>
  <p style="margin-left:0px;"><span style="color:#404040;">考虑为什么会起作用很有趣，但目前我可以向你保证 - 当我们运行这个算法时，它访问的参数的分布会收敛到目标分布p。那么，让我们在R中得到这个：</span></p> 
  <pre class="has">
<code>######## Metropolis algorithm ################

&nbsp;

proposalfunction &lt;- function(param){

&nbsp;&nbsp;&nbsp;&nbsp;return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3)))

}

&nbsp;

run_metropolis_MCMC &lt;- function(startvalue, iterations){

&nbsp; &nbsp; &nbsp;&nbsp;for (i in 1:iterations){

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (runif(1) &lt; probab){

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = proposal

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}else{

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain[i+1,] = chain[i,]

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;return(chain)

}

&nbsp;

&nbsp;chain = run_metropolis_MCMC(startvalue, 10000)

&nbsp;

burnIn = 5000

acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))</code></pre> 
  <p style="margin-left:0px;"><span style="color:#404040;">再次，使用后验的对数可能在开始时有点混乱，特别是当您查看计算接受概率的行时（probab = exp（后验（建议） - 后验（链[i，]）） ）。要理解我们为什么这样做，请注意p1 / p2 = exp [log（p1）-log（p2）]。</span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;">算法的第一步可能受初始值的偏差，因此通常被丢弃用于进一步分析 。要看的一个有趣的输出是接受率： 接受标准拒绝提案的频率是多少？接受率可以受提议函数的影响：通常，提案越接近，接受率越大。然而，非常高的接受率通常是无益的：这意味着算法“停留”在同一点 。可以证明，20％到30％的接受率对于典型应用来说是最佳的 。</span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;">&nbsp;</span></p> 
  <pre class="has">
<code>### Summary: #######################

&nbsp;

par(mfrow = c(2,3))

hist( [-(1:burnIn),1],nclass=30, , main="Posterior of a", xlab="True value = red line" )

abline(v = mean(chain[-(1:burnIn),1]))

&nbsp;

&nbsp;

# for comparison:

summary(lm(y~x))</code></pre> 
  <p style="margin-left:0px;"><span style="color:#404040;">生成的图应该类似于下图。您可以看到我们或多或少地检索了用于创建数据的原始参数，并且您还看到我们获得了一个围绕最高后验值的特定区域，这些区域也有一些数据支持，这是贝叶斯相当于置信度的间隔。</span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;"><a href="https://theoreticalecology.files.wordpress.com/2010/09/posterior2.png" rel="nofollow" data-token="2ac69d6b06f6cf103cd246f90c61750a"><img alt="" class="aligncenter size-full wp-image-473" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181218152712931"></a></span></p> 
  <p style="margin-left:0px;"><span style="color:#404040;"><em><strong>图：</strong>上排显示斜率（a）的后验估计，截距（b）和误差的标准偏差（sd）。下一行显示马尔可夫链参数值。</em></span></p> 
  <p style="margin-left:0px;">&nbsp;</p> 
  <p><strong>还有问题吗？请在下面留言！</strong></p> 
  <p style="margin-left:0px;">&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
