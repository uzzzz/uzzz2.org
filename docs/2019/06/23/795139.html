<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Springboot2整合kafka的两种使用方式 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Springboot2整合kafka的两种使用方式" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Springboot2整合kafka kafka docker上安装环境 Springboot2引入kafka 基于注解 基于客户端 kafka是一个分布式消息队列。在项目中应用十分广泛，具有高性能、持久化、多副本备份、横向扩展能力。 kafka 在多台机器上分别部署Kafka，即Kafka集群。每台机器运行的Kafka服务称为broker。 一个Topic主题可以被分为若干个分区(partition)，每个分区在存储层面是append log文件。 分区（Partition ）为Kafka提供了可伸缩性，水平扩展功能。 多副本机制（Partition Replica）提高了kafka的数据可靠性和容灾能力。 图片来源《深入理解kafka核心设计和实践原理》 docker上安装环境 1.安装zookeeper 和 安装kafka 这里使用了wurstmeister/kafka和wurstmeister/zookeeper这两个版本的镜像 2.运行镜像 整个启动过程遇到了8个左右报错，一个个解决，最后运行成功，简单列几个 Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME WARN Session 0x0 for server zookeeper:2181, unexpected error, closing socket java.nio.channels.UnresolvedAddressException could not be established. Broker may not be available Give up sending metadata request since no node is available 总结下最后的启动命令，依此启动zookeeper和kafka docker run --name zk01 -p 2181:2181 --restart always -d zookeeper docker run --name kafka01 -e HOST_IP=localhost -e KAFKA_ADVERTISED_PORT=9092 -e KAFKA_ADVERTISED_HOST_NAME=localhost -e KAFKA_ZOOKEEPER_CONNECT=&quot;192.168.0.111:2181&quot; -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.0.111:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_BROKER_ID=1 -e ZK=zk -p 9092 --link zk01:zk -t wurstmeister/kafka Springboot2引入kafka &lt;!--引入Kafka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; application.properties配置 #kafka配置 spring.kafka.bootstrap-servers=192.168.0.111:9092 #=============== provider ======================= spring.kafka.producer.retries=0 # 每次批量发送消息的数量 spring.kafka.producer.batch-size=16384 spring.kafka.producer.buffer-memory=33554432 # 指定消息key和消息体的编解码方式 spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer #=============== consumer ======================= # 指定默认消费者group id spring.kafka.consumer.group-id=test-consumer-group spring.kafka.consumer.auto-offset-reset=earliest spring.kafka.consumer.enable-auto-commit=true spring.kafka.consumer.auto-commit-interval=100 # 指定消息key和消息体的编解码方式 spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer 基于注解 生产 @Component public class KafkaProducer { private static final String MY_TOPIC = &quot;TOPIC_LIN_LIANG&quot;; @Autowired KafkaTemplate kafkaTemplate; public void produce(){ Message message = new Message(); message.setId(12L); message.setMsg(&quot;hello jack&quot;); message.setTime(new Date()); kafkaTemplate.send(MY_TOPIC,message); } } 消费 @KafkaListener可以接受的参数有： data ： 对于data值的类型其实并没有限定，根据KafkaTemplate所定义的类型来决定。 data为List集合的则是用作批量消费。 ConsumerRecord：具体消费数据类，包含Headers信息、分区信息、时间戳等 Acknowledgment：用作Ack机制的接口 Consumer：消费者类，使用该类我们可以手动提交偏移量、控制消费速率等功能 public void listen1(String data) public void listen2(ConsumerRecord&lt;K,V&gt; data) public void listen3(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment) public void listen4(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) public void listen5(List&lt;String&gt; data) public void listen6(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data) public void listen7(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment) public void listen8(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) 使用示例 @KafkaListener(topics = {MY_TOPIC}) public void consume(String message){ log.info(&quot;receive msg &quot;+ message); } 基于客户端 0.9x版本后的kafka客户端使用java语言编写，本人更倾向于这种开发方式。 在配置中注释了基本意思，具体参考了朱忠华的《深入理解kafka:核心设计和实现原理》，学kafka感觉这一本就够了。 /** * linliang */ @Configuration public class Kafka_Config implements InitializingBean { @Value(&quot;${kafka.broker.list}&quot;) public String brokerList; public static final String topic = &quot;TOPIC_LIN_LIANG&quot;; public final String groupId = &quot;group.01&quot;; public Properties customerConfigs() { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);//自动位移提交 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 100);//自动位移提交间隔时间 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);//消费组失效超时时间 props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;);//位移丢失和位移越界后的恢复起始位置 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); return props; } public Properties producerConfigs() { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 20000000);//20M 消息缓存 //生产者空间不足时，send()被阻塞的时间，默认60s props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 6000); //生产者重试次数 props.put(ProducerConfig.RETRIES_CONFIG, 0); //指定ProducerBatch（消息累加器中BufferPool中的）可复用大小 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //生产者会在ProducerBatch被填满或者等待超过LINGER_MS_CONFIG时发送 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.CLIENT_ID_CONFIG, &quot;producer.client.id.demo&quot;); return props; } @Bean public Producer&lt;Integer, Object&gt; getKafkaProducer() { //KafkaProducer是线程安全的，可以在多个线程中共享单个实例 return new KafkaProducer&lt;Integer, Object&gt;(producerConfigs()); } @Override public void afterPropertiesSet() throws Exception { } } 生产 @Component public class Kafka_Producer { public String topic = Kafka_Config.topic; @Autowired Producer producer; public void producer() throws Exception { ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello, Kafka!&quot;); try { producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (exception == null) { System.out.println(metadata.partition() + &quot;:&quot; + metadata.offset()); } } }); } catch (Exception e) { } } } 消费 @Component public class Kafka_Consumer implements InitializingBean { public String topic = Kafka_Config.topic; @Autowired Kafka_Config kafka_config; @Override public void afterPropertiesSet() throws Exception { //每个线程一个KafkaConsumer实例，且线程数设置成分区数，最大化提高消费能力 int consumerThreadNum = 2;//线程数设置成分区数，最大化提高消费能力 for (int i = 0; i &lt; consumerThreadNum; i++) { new KafkaConsumerThread(kafka_config.customerConfigs(), topic).start(); } } public class KafkaConsumerThread extends Thread { private KafkaConsumer&lt;String, String&gt; kafkaConsumer; public KafkaConsumerThread(Properties props, String topic) { this.kafkaConsumer = new org.apache.kafka.clients.consumer.KafkaConsumer&lt;&gt;(props); this.kafkaConsumer.subscribe(Arrays.asList(topic)); } @Override public void run() { try { while (true) { ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(&quot;message------------ &quot;+record.value()); } } } catch (Exception e) { } finally { kafkaConsumer.close(); } } } } 欢迎关注公众号fbzl95" />
<meta property="og:description" content="Springboot2整合kafka kafka docker上安装环境 Springboot2引入kafka 基于注解 基于客户端 kafka是一个分布式消息队列。在项目中应用十分广泛，具有高性能、持久化、多副本备份、横向扩展能力。 kafka 在多台机器上分别部署Kafka，即Kafka集群。每台机器运行的Kafka服务称为broker。 一个Topic主题可以被分为若干个分区(partition)，每个分区在存储层面是append log文件。 分区（Partition ）为Kafka提供了可伸缩性，水平扩展功能。 多副本机制（Partition Replica）提高了kafka的数据可靠性和容灾能力。 图片来源《深入理解kafka核心设计和实践原理》 docker上安装环境 1.安装zookeeper 和 安装kafka 这里使用了wurstmeister/kafka和wurstmeister/zookeeper这两个版本的镜像 2.运行镜像 整个启动过程遇到了8个左右报错，一个个解决，最后运行成功，简单列几个 Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME WARN Session 0x0 for server zookeeper:2181, unexpected error, closing socket java.nio.channels.UnresolvedAddressException could not be established. Broker may not be available Give up sending metadata request since no node is available 总结下最后的启动命令，依此启动zookeeper和kafka docker run --name zk01 -p 2181:2181 --restart always -d zookeeper docker run --name kafka01 -e HOST_IP=localhost -e KAFKA_ADVERTISED_PORT=9092 -e KAFKA_ADVERTISED_HOST_NAME=localhost -e KAFKA_ZOOKEEPER_CONNECT=&quot;192.168.0.111:2181&quot; -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.0.111:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_BROKER_ID=1 -e ZK=zk -p 9092 --link zk01:zk -t wurstmeister/kafka Springboot2引入kafka &lt;!--引入Kafka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; application.properties配置 #kafka配置 spring.kafka.bootstrap-servers=192.168.0.111:9092 #=============== provider ======================= spring.kafka.producer.retries=0 # 每次批量发送消息的数量 spring.kafka.producer.batch-size=16384 spring.kafka.producer.buffer-memory=33554432 # 指定消息key和消息体的编解码方式 spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer #=============== consumer ======================= # 指定默认消费者group id spring.kafka.consumer.group-id=test-consumer-group spring.kafka.consumer.auto-offset-reset=earliest spring.kafka.consumer.enable-auto-commit=true spring.kafka.consumer.auto-commit-interval=100 # 指定消息key和消息体的编解码方式 spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer 基于注解 生产 @Component public class KafkaProducer { private static final String MY_TOPIC = &quot;TOPIC_LIN_LIANG&quot;; @Autowired KafkaTemplate kafkaTemplate; public void produce(){ Message message = new Message(); message.setId(12L); message.setMsg(&quot;hello jack&quot;); message.setTime(new Date()); kafkaTemplate.send(MY_TOPIC,message); } } 消费 @KafkaListener可以接受的参数有： data ： 对于data值的类型其实并没有限定，根据KafkaTemplate所定义的类型来决定。 data为List集合的则是用作批量消费。 ConsumerRecord：具体消费数据类，包含Headers信息、分区信息、时间戳等 Acknowledgment：用作Ack机制的接口 Consumer：消费者类，使用该类我们可以手动提交偏移量、控制消费速率等功能 public void listen1(String data) public void listen2(ConsumerRecord&lt;K,V&gt; data) public void listen3(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment) public void listen4(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) public void listen5(List&lt;String&gt; data) public void listen6(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data) public void listen7(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment) public void listen8(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) 使用示例 @KafkaListener(topics = {MY_TOPIC}) public void consume(String message){ log.info(&quot;receive msg &quot;+ message); } 基于客户端 0.9x版本后的kafka客户端使用java语言编写，本人更倾向于这种开发方式。 在配置中注释了基本意思，具体参考了朱忠华的《深入理解kafka:核心设计和实现原理》，学kafka感觉这一本就够了。 /** * linliang */ @Configuration public class Kafka_Config implements InitializingBean { @Value(&quot;${kafka.broker.list}&quot;) public String brokerList; public static final String topic = &quot;TOPIC_LIN_LIANG&quot;; public final String groupId = &quot;group.01&quot;; public Properties customerConfigs() { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);//自动位移提交 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 100);//自动位移提交间隔时间 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);//消费组失效超时时间 props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;);//位移丢失和位移越界后的恢复起始位置 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); return props; } public Properties producerConfigs() { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 20000000);//20M 消息缓存 //生产者空间不足时，send()被阻塞的时间，默认60s props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 6000); //生产者重试次数 props.put(ProducerConfig.RETRIES_CONFIG, 0); //指定ProducerBatch（消息累加器中BufferPool中的）可复用大小 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //生产者会在ProducerBatch被填满或者等待超过LINGER_MS_CONFIG时发送 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.CLIENT_ID_CONFIG, &quot;producer.client.id.demo&quot;); return props; } @Bean public Producer&lt;Integer, Object&gt; getKafkaProducer() { //KafkaProducer是线程安全的，可以在多个线程中共享单个实例 return new KafkaProducer&lt;Integer, Object&gt;(producerConfigs()); } @Override public void afterPropertiesSet() throws Exception { } } 生产 @Component public class Kafka_Producer { public String topic = Kafka_Config.topic; @Autowired Producer producer; public void producer() throws Exception { ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello, Kafka!&quot;); try { producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (exception == null) { System.out.println(metadata.partition() + &quot;:&quot; + metadata.offset()); } } }); } catch (Exception e) { } } } 消费 @Component public class Kafka_Consumer implements InitializingBean { public String topic = Kafka_Config.topic; @Autowired Kafka_Config kafka_config; @Override public void afterPropertiesSet() throws Exception { //每个线程一个KafkaConsumer实例，且线程数设置成分区数，最大化提高消费能力 int consumerThreadNum = 2;//线程数设置成分区数，最大化提高消费能力 for (int i = 0; i &lt; consumerThreadNum; i++) { new KafkaConsumerThread(kafka_config.customerConfigs(), topic).start(); } } public class KafkaConsumerThread extends Thread { private KafkaConsumer&lt;String, String&gt; kafkaConsumer; public KafkaConsumerThread(Properties props, String topic) { this.kafkaConsumer = new org.apache.kafka.clients.consumer.KafkaConsumer&lt;&gt;(props); this.kafkaConsumer.subscribe(Arrays.asList(topic)); } @Override public void run() { try { while (true) { ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(&quot;message------------ &quot;+record.value()); } } } catch (Exception e) { } finally { kafkaConsumer.close(); } } } } 欢迎关注公众号fbzl95" />
<link rel="canonical" href="https://uzzz.org/2019/06/23/795139.html" />
<meta property="og:url" content="https://uzzz.org/2019/06/23/795139.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-23T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Springboot2整合kafka kafka docker上安装环境 Springboot2引入kafka 基于注解 基于客户端 kafka是一个分布式消息队列。在项目中应用十分广泛，具有高性能、持久化、多副本备份、横向扩展能力。 kafka 在多台机器上分别部署Kafka，即Kafka集群。每台机器运行的Kafka服务称为broker。 一个Topic主题可以被分为若干个分区(partition)，每个分区在存储层面是append log文件。 分区（Partition ）为Kafka提供了可伸缩性，水平扩展功能。 多副本机制（Partition Replica）提高了kafka的数据可靠性和容灾能力。 图片来源《深入理解kafka核心设计和实践原理》 docker上安装环境 1.安装zookeeper 和 安装kafka 这里使用了wurstmeister/kafka和wurstmeister/zookeeper这两个版本的镜像 2.运行镜像 整个启动过程遇到了8个左右报错，一个个解决，最后运行成功，简单列几个 Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME WARN Session 0x0 for server zookeeper:2181, unexpected error, closing socket java.nio.channels.UnresolvedAddressException could not be established. Broker may not be available Give up sending metadata request since no node is available 总结下最后的启动命令，依此启动zookeeper和kafka docker run --name zk01 -p 2181:2181 --restart always -d zookeeper docker run --name kafka01 -e HOST_IP=localhost -e KAFKA_ADVERTISED_PORT=9092 -e KAFKA_ADVERTISED_HOST_NAME=localhost -e KAFKA_ZOOKEEPER_CONNECT=&quot;192.168.0.111:2181&quot; -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.0.111:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_BROKER_ID=1 -e ZK=zk -p 9092 --link zk01:zk -t wurstmeister/kafka Springboot2引入kafka &lt;!--引入Kafka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; application.properties配置 #kafka配置 spring.kafka.bootstrap-servers=192.168.0.111:9092 #=============== provider ======================= spring.kafka.producer.retries=0 # 每次批量发送消息的数量 spring.kafka.producer.batch-size=16384 spring.kafka.producer.buffer-memory=33554432 # 指定消息key和消息体的编解码方式 spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer #=============== consumer ======================= # 指定默认消费者group id spring.kafka.consumer.group-id=test-consumer-group spring.kafka.consumer.auto-offset-reset=earliest spring.kafka.consumer.enable-auto-commit=true spring.kafka.consumer.auto-commit-interval=100 # 指定消息key和消息体的编解码方式 spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer 基于注解 生产 @Component public class KafkaProducer { private static final String MY_TOPIC = &quot;TOPIC_LIN_LIANG&quot;; @Autowired KafkaTemplate kafkaTemplate; public void produce(){ Message message = new Message(); message.setId(12L); message.setMsg(&quot;hello jack&quot;); message.setTime(new Date()); kafkaTemplate.send(MY_TOPIC,message); } } 消费 @KafkaListener可以接受的参数有： data ： 对于data值的类型其实并没有限定，根据KafkaTemplate所定义的类型来决定。 data为List集合的则是用作批量消费。 ConsumerRecord：具体消费数据类，包含Headers信息、分区信息、时间戳等 Acknowledgment：用作Ack机制的接口 Consumer：消费者类，使用该类我们可以手动提交偏移量、控制消费速率等功能 public void listen1(String data) public void listen2(ConsumerRecord&lt;K,V&gt; data) public void listen3(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment) public void listen4(ConsumerRecord&lt;K,V&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) public void listen5(List&lt;String&gt; data) public void listen6(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data) public void listen7(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment) public void listen8(List&lt;ConsumerRecord&lt;K,V&gt;&gt; data, Acknowledgment acknowledgment, Consumer&lt;K,V&gt; consumer) 使用示例 @KafkaListener(topics = {MY_TOPIC}) public void consume(String message){ log.info(&quot;receive msg &quot;+ message); } 基于客户端 0.9x版本后的kafka客户端使用java语言编写，本人更倾向于这种开发方式。 在配置中注释了基本意思，具体参考了朱忠华的《深入理解kafka:核心设计和实现原理》，学kafka感觉这一本就够了。 /** * linliang */ @Configuration public class Kafka_Config implements InitializingBean { @Value(&quot;${kafka.broker.list}&quot;) public String brokerList; public static final String topic = &quot;TOPIC_LIN_LIANG&quot;; public final String groupId = &quot;group.01&quot;; public Properties customerConfigs() { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);//自动位移提交 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 100);//自动位移提交间隔时间 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);//消费组失效超时时间 props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;);//位移丢失和位移越界后的恢复起始位置 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); return props; } public Properties producerConfigs() { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList); props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 20000000);//20M 消息缓存 //生产者空间不足时，send()被阻塞的时间，默认60s props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 6000); //生产者重试次数 props.put(ProducerConfig.RETRIES_CONFIG, 0); //指定ProducerBatch（消息累加器中BufferPool中的）可复用大小 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //生产者会在ProducerBatch被填满或者等待超过LINGER_MS_CONFIG时发送 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(ProducerConfig.CLIENT_ID_CONFIG, &quot;producer.client.id.demo&quot;); return props; } @Bean public Producer&lt;Integer, Object&gt; getKafkaProducer() { //KafkaProducer是线程安全的，可以在多个线程中共享单个实例 return new KafkaProducer&lt;Integer, Object&gt;(producerConfigs()); } @Override public void afterPropertiesSet() throws Exception { } } 生产 @Component public class Kafka_Producer { public String topic = Kafka_Config.topic; @Autowired Producer producer; public void producer() throws Exception { ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello, Kafka!&quot;); try { producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (exception == null) { System.out.println(metadata.partition() + &quot;:&quot; + metadata.offset()); } } }); } catch (Exception e) { } } } 消费 @Component public class Kafka_Consumer implements InitializingBean { public String topic = Kafka_Config.topic; @Autowired Kafka_Config kafka_config; @Override public void afterPropertiesSet() throws Exception { //每个线程一个KafkaConsumer实例，且线程数设置成分区数，最大化提高消费能力 int consumerThreadNum = 2;//线程数设置成分区数，最大化提高消费能力 for (int i = 0; i &lt; consumerThreadNum; i++) { new KafkaConsumerThread(kafka_config.customerConfigs(), topic).start(); } } public class KafkaConsumerThread extends Thread { private KafkaConsumer&lt;String, String&gt; kafkaConsumer; public KafkaConsumerThread(Properties props, String topic) { this.kafkaConsumer = new org.apache.kafka.clients.consumer.KafkaConsumer&lt;&gt;(props); this.kafkaConsumer.subscribe(Arrays.asList(topic)); } @Override public void run() { try { while (true) { ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(&quot;message------------ &quot;+record.value()); } } } catch (Exception e) { } finally { kafkaConsumer.close(); } } } } 欢迎关注公众号fbzl95","@type":"BlogPosting","url":"https://uzzz.org/2019/06/23/795139.html","headline":"Springboot2整合kafka的两种使用方式","dateModified":"2019-06-23T00:00:00+08:00","datePublished":"2019-06-23T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/06/23/795139.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Springboot2整合kafka的两种使用方式</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p></p>
  <div class="toc">
   <h3>Springboot2整合kafka</h3>
   <ul>
    <ul>
     <li><a href="#kafka_6" rel="nofollow" data-token="0e2f12e7d093d1532ad5eb5a82edf197">kafka</a></li>
     <li><a href="#docker_14" rel="nofollow" data-token="e728b23ca8d06609125362c5b073da0c">docker上安装环境</a></li>
     <li><a href="#Springboot2kafka_36" rel="nofollow" data-token="50968a3d3bf0d2e23cd27f0e18270677">Springboot2引入kafka</a></li>
     <li><a href="#_69" rel="nofollow" data-token="69bd4416fcaf56b30bce5796730b7593">基于注解</a></li>
     <li><a href="#_122" rel="nofollow" data-token="da40c4e93b4aae01b0b789846c4bb629">基于客户端</a></li>
    </ul>
   </ul>
  </div>
  <p></p> 
  <blockquote> 
   <p>kafka是一个分布式消息队列。在项目中应用十分广泛，具有高性能、持久化、多副本备份、横向扩展能力。</p> 
  </blockquote> 
  <hr> 
  <h2><a id="kafka_6"></a>kafka</h2> 
  <ul> 
   <li>在多台机器上分别部署Kafka，即Kafka集群。每台机器运行的Kafka服务称为broker。</li> 
   <li>一个Topic主题可以被分为若干个分区(partition)，每个分区在存储层面是append log文件。</li> 
   <li>分区（Partition ）为Kafka提供了可伸缩性，水平扩展功能。</li> 
   <li>多副本机制（Partition Replica）提高了kafka的数据可靠性和容灾能力。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190623224946793.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ZpY3RveWxpbg==,size_16,color_FFFFFF,t_70" alt="来源《深入理解kafka核心设计和实践原理》"><br> 图片来源《深入理解kafka核心设计和实践原理》</li> 
  </ul> 
  <hr> 
  <h2><a id="docker_14"></a>docker上安装环境</h2> 
  <p>1.安装zookeeper 和 安装kafka</p> 
  <ul> 
   <li>这里使用了wurstmeister/kafka和wurstmeister/zookeeper这两个版本的镜像</li> 
  </ul> 
  <p>2.运行镜像</p> 
  <ul> 
   <li>整个启动过程遇到了8个左右报错，一个个解决，最后运行成功，简单列几个 
    <ul> 
     <li>Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME</li> 
     <li>WARN Session 0x0 for server zookeeper:2181, unexpected error, closing socket</li> 
     <li>java.nio.channels.UnresolvedAddressException</li> 
     <li>could not be established. Broker may not be available</li> 
     <li>Give up sending metadata request since no node is available</li> 
    </ul> </li> 
   <li>总结下最后的启动命令，依此启动zookeeper和kafka</li> 
  </ul> 
  <pre><code class="prism language-java">docker run <span class="token operator">--</span>name zk01 <span class="token operator">-</span>p <span class="token number">2181</span><span class="token operator">:</span><span class="token number">2181</span> <span class="token operator">--</span>restart always <span class="token operator">-</span>d zookeeper
</code></pre> 
  <pre><code class="prism language-java">docker run <span class="token operator">--</span>name kafka01 <span class="token operator">-</span>e HOST_IP<span class="token operator">=</span>localhost <span class="token operator">-</span>e KAFKA_ADVERTISED_PORT<span class="token operator">=</span><span class="token number">9092</span> <span class="token operator">-</span>e  KAFKA_ADVERTISED_HOST_NAME<span class="token operator">=</span>localhost <span class="token operator">-</span>e KAFKA_ZOOKEEPER_CONNECT<span class="token operator">=</span><span class="token string">"192.168.0.111:2181"</span> <span class="token operator">-</span>e KAFKA_ADVERTISED_LISTENERS<span class="token operator">=</span>PLAINTEXT<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token number">192.168</span><span class="token number">.0</span><span class="token number">.111</span><span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">-</span>e KAFKA_ADVERTISED_LISTENERS<span class="token operator">=</span>PLAINTEXT<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>localhost<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">-</span>e KAFKA_BROKER_ID<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span>e ZK<span class="token operator">=</span>zk <span class="token operator">-</span>p <span class="token number">9092</span> <span class="token operator">--</span>link zk01<span class="token operator">:</span>zk <span class="token operator">-</span>t wurstmeister<span class="token operator">/</span>kafka
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190623225901460.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ZpY3RveWxpbg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <hr> 
  <h2><a id="Springboot2kafka_36"></a>Springboot2引入kafka</h2> 
  <pre><code class="prism language-java"> <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span>引入Kafka<span class="token operator">--</span><span class="token operator">&gt;</span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
        <span class="token generics function"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>springframework<span class="token punctuation">.</span>kafka<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
        <span class="token generics function"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>spring<span class="token operator">-</span>kafka<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span> 
</code></pre> 
  <ul> 
   <li>application.properties配置</li> 
  </ul> 
  <pre><code class="prism language-java">
#kafka配置
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>bootstrap<span class="token operator">-</span>servers<span class="token operator">=</span><span class="token number">192.168</span><span class="token number">.0</span><span class="token number">.111</span><span class="token operator">:</span><span class="token number">9092</span>
#<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> provider  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>retries<span class="token operator">=</span><span class="token number">0</span>
# 每次批量发送消息的数量
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>batch<span class="token operator">-</span>size<span class="token operator">=</span><span class="token number">16384</span>
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>buffer<span class="token operator">-</span>memory<span class="token operator">=</span><span class="token number">33554432</span>
# 指定消息key和消息体的编解码方式
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>key<span class="token operator">-</span>serializer<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringSerializer
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>value<span class="token operator">-</span>serializer<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringSerializer
#<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> consumer  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
# 指定默认消费者group id
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>group<span class="token operator">-</span>id<span class="token operator">=</span>test<span class="token operator">-</span>consumer<span class="token operator">-</span>group
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>auto<span class="token operator">-</span>offset<span class="token operator">-</span>reset<span class="token operator">=</span>earliest
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>enable<span class="token operator">-</span>auto<span class="token operator">-</span>commit<span class="token operator">=</span><span class="token boolean">true</span>
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>auto<span class="token operator">-</span>commit<span class="token operator">-</span>interval<span class="token operator">=</span><span class="token number">100</span>
# 指定消息key和消息体的编解码方式
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>key<span class="token operator">-</span>deserializer<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringDeserializer
spring<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>value<span class="token operator">-</span>deserializer<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringDeserializer
</code></pre> 
  <h2><a id="_69"></a>基于注解</h2> 
  <p>生产</p> 
  <pre><code class="prism language-java"><span class="token annotation punctuation">@Component</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KafkaProducer</span> <span class="token punctuation">{</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> String MY_TOPIC <span class="token operator">=</span> <span class="token string">"TOPIC_LIN_LIANG"</span><span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Autowired</span>
    KafkaTemplate kafkaTemplate<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">produce</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        Message message <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Message</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        message<span class="token punctuation">.</span><span class="token function">setId</span><span class="token punctuation">(</span><span class="token number">12</span>L<span class="token punctuation">)</span><span class="token punctuation">;</span>
        message<span class="token punctuation">.</span><span class="token function">setMsg</span><span class="token punctuation">(</span><span class="token string">"hello jack"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        message<span class="token punctuation">.</span><span class="token function">setTime</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>MY_TOPIC<span class="token punctuation">,</span>message<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
  <p>消费<br> @KafkaListener可以接受的参数有：</p> 
  <blockquote> 
   <ul> 
    <li>data ： 对于data值的类型其实并没有限定，根据KafkaTemplate所定义的类型来决定。 data为List集合的则是用作批量消费。</li> 
    <li>ConsumerRecord：具体消费数据类，包含Headers信息、分区信息、时间戳等</li> 
    <li>Acknowledgment：用作Ack机制的接口</li> 
    <li>Consumer：消费者类，使用该类我们可以手动提交偏移量、控制消费速率等功能</li> 
   </ul> 
  </blockquote> 
  <pre><code class="prism language-java">   <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen1</span><span class="token punctuation">(</span>String data<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen2</span><span class="token punctuation">(</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span> data<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen3</span><span class="token punctuation">(</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span> data<span class="token punctuation">,</span> Acknowledgment acknowledgment<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen4</span><span class="token punctuation">(</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span> data<span class="token punctuation">,</span> Acknowledgment acknowledgment<span class="token punctuation">,</span> Consumer<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span> consumer<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen5</span><span class="token punctuation">(</span>List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> data<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen6</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> data<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen7</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> data<span class="token punctuation">,</span> Acknowledgment acknowledgment<span class="token punctuation">)</span> 

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listen8</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> data<span class="token punctuation">,</span> Acknowledgment acknowledgment<span class="token punctuation">,</span> Consumer<span class="token generics function"><span class="token punctuation">&lt;</span>K<span class="token punctuation">,</span>V<span class="token punctuation">&gt;</span></span> consumer<span class="token punctuation">)</span> 
</code></pre> 
  <p>使用示例</p> 
  <pre><code class="prism language-java">   <span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token punctuation">{</span>MY_TOPIC<span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">consume</span><span class="token punctuation">(</span>String message<span class="token punctuation">)</span><span class="token punctuation">{</span>
        log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"receive msg "</span><span class="token operator">+</span> message<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre> 
  <hr> 
  <h2><a id="_122"></a>基于客户端</h2> 
  <p>0.9x版本后的kafka客户端使用java语言编写，本人更倾向于这种开发方式。<br> 在配置中注释了基本意思，具体参考了朱忠华的《深入理解kafka:核心设计和实现原理》，学kafka感觉这一本就够了。</p> 
  <pre><code class="prism language-java"><span class="token comment">/** * linliang */</span>
<span class="token annotation punctuation">@Configuration</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Kafka_Config</span> <span class="token keyword">implements</span> <span class="token class-name">InitializingBean</span> <span class="token punctuation">{</span>

    <span class="token annotation punctuation">@Value</span><span class="token punctuation">(</span><span class="token string">"${kafka.broker.list}"</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> String brokerList<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> String topic <span class="token operator">=</span> <span class="token string">"TOPIC_LIN_LIANG"</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">final</span> String groupId <span class="token operator">=</span> <span class="token string">"group.01"</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> Properties <span class="token function">customerConfigs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> brokerList<span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//自动位移提交</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>AUTO_COMMIT_INTERVAL_MS_CONFIG<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//自动位移提交间隔时间</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>SESSION_TIMEOUT_MS_CONFIG<span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//消费组失效超时时间</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>AUTO_OFFSET_RESET_CONFIG<span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//位移丢失和位移越界后的恢复起始位置</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
                StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
                StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> props<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> Properties <span class="token function">producerConfigs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> brokerList<span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>BUFFER_MEMORY_CONFIG<span class="token punctuation">,</span> <span class="token number">20000000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//20M 消息缓存</span>
        <span class="token comment">//生产者空间不足时，send()被阻塞的时间，默认60s</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>MAX_BLOCK_MS_CONFIG<span class="token punctuation">,</span> <span class="token number">6000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//生产者重试次数</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>RETRIES_CONFIG<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//指定ProducerBatch（消息累加器中BufferPool中的）可复用大小</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>BATCH_SIZE_CONFIG<span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//生产者会在ProducerBatch被填满或者等待超过LINGER_MS_CONFIG时发送</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>LINGER_MS_CONFIG<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>KEY_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
                <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>VALUE_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
                <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>CLIENT_ID_CONFIG<span class="token punctuation">,</span> <span class="token string">"producer.client.id.demo"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> props<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>


    <span class="token annotation punctuation">@Bean</span>
    <span class="token keyword">public</span> Producer<span class="token generics function"><span class="token punctuation">&lt;</span>Integer<span class="token punctuation">,</span> Object<span class="token punctuation">&gt;</span></span> <span class="token function">getKafkaProducer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//KafkaProducer是线程安全的，可以在多个线程中共享单个实例</span>
        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics function"><span class="token punctuation">&lt;</span>Integer<span class="token punctuation">,</span> Object<span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token function">producerConfigs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">afterPropertiesSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
  <p>生产</p> 
  <pre><code class="prism language-java"><span class="token annotation punctuation">@Component</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Kafka_Producer</span>  <span class="token punctuation">{</span>

    <span class="token keyword">public</span> String topic <span class="token operator">=</span> Kafka_Config<span class="token punctuation">.</span>topic<span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Autowired</span>
    Producer producer<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">producer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>

        ProducerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span> record <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">"hello, Kafka!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token annotation punctuation">@Override</span>
                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>metadata<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> metadata<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
  <p>消费</p> 
  <pre><code class="prism language-java"><span class="token annotation punctuation">@Component</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Kafka_Consumer</span> <span class="token keyword">implements</span> <span class="token class-name">InitializingBean</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> String topic <span class="token operator">=</span> Kafka_Config<span class="token punctuation">.</span>topic<span class="token punctuation">;</span>
    <span class="token annotation punctuation">@Autowired</span>
    Kafka_Config kafka_config<span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">afterPropertiesSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>
        <span class="token comment">//每个线程一个KafkaConsumer实例，且线程数设置成分区数，最大化提高消费能力</span>
        <span class="token keyword">int</span> consumerThreadNum <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token comment">//线程数设置成分区数，最大化提高消费能力</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> consumerThreadNum<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">new</span> <span class="token class-name">KafkaConsumerThread</span><span class="token punctuation">(</span>kafka_config<span class="token punctuation">.</span><span class="token function">customerConfigs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> topic<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KafkaConsumerThread</span> <span class="token keyword">extends</span> <span class="token class-name">Thread</span> <span class="token punctuation">{</span>
        <span class="token keyword">private</span> KafkaConsumer<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span> kafkaConsumer<span class="token punctuation">;</span>

        <span class="token keyword">public</span> <span class="token function">KafkaConsumerThread</span><span class="token punctuation">(</span>Properties props<span class="token punctuation">,</span> String topic<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">this</span><span class="token punctuation">.</span>kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">this</span><span class="token punctuation">.</span>kafkaConsumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">try</span> <span class="token punctuation">{</span>
                <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    ConsumerRecords<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span> records <span class="token operator">=</span>
                            kafkaConsumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"message------------ "</span><span class="token operator">+</span>record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
                kafkaConsumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
  <hr> 
  <p>欢迎关注公众号fbzl95</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
