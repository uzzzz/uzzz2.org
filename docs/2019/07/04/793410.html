<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Spring Boot整合Flink | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Spring Boot整合Flink" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="使用spring boot整合flink可以快速的构建起整个应用，将关注点重点放在业务逻辑的实现上。在整合的过程中遇到许多问题，最大的问题是flink流无法访问spring容器中的类，从而导致空指针异常，解决思路是在流中进行spring bean的初始化以获得ApplicationContext，进而使用其getBean方法获取类实例。 软件版本:Spring Boot 2.1.6+Flink1.6.1+JDK1.8 程序主体： @SpringBootApplication public class HadesTmsApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication application = new SpringApplication(HadesTmsApplication.class); application.setBannerMode(Banner.Mode.OFF); application.run(args); } @Override public void run(String... args) { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); FlinkKafkaConsumer010 kafkaConsumer = new FlinkKafkaConsumer010&lt;&gt;(&quot;topic-name&quot;), new SimpleStringSchema(), getProperties()); DataStream&lt;String&gt; dataStream = env.addSource(kafkaConsumer); // 此处省略处理逻辑 dataStream.addSink(new MySink()); } private Properties getProperties() { Properties properties = new Properties(); properties.setProperty(&quot;bootstrap.servers&quot;, bootstrap_servers); properties.setProperty(&quot;zookeeper.connect&quot;, zookeeper_connect); properties.setProperty(&quot;group.id&quot;, group_id); properties.setProperty(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.setProperty(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); return properties; } } 说明一下：因为是非web项目，所以实现CommandLineRunner接口，重写run方法。在里面编写流处理逻辑。 如果在MySink中需要使用spring容器中的类，而MySink是一个普通的类，那么是无法访问到的。会引发空指针异常。可能有人想到了ApplicationContextAware这个接口，实现这个接口获取ApplicationContext，也即是： @Component public class ApplicationContextUtil implements ApplicationContextAware, Serializable { private static final long serialVersionUID = -6454872090519042646L; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { if (ApplicationContextUtil.applicationContext == null) { ApplicationContextUtil.applicationContext = applicationContext; } } public static ApplicationContext getApplicationContext() { return applicationContext; } //通过name获取 Bean. public static Object getBean(String name) { return getApplicationContext().getBean(name); } //通过class获取Bean. public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) { return getApplicationContext().getBean(clazz); } //通过name,以及Clazz返回指定的Bean public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; clazz) { return getApplicationContext().getBean(name, clazz); } } 这种做法实际上在flink流处理中也是不可行的，在我之前的flink文章中 Flink读写系列之-读mysql并写入mysql&nbsp;其中读和写阶段有一个open方法，这个方法专门用于进行初始化的，那么我们可以在这里进行spring bean的初始化。那么MySink改造后即为： @EnableAutoConfiguration @MapperScan(basePackages = {&quot;com.xxx.bigdata.xxx.mapper&quot;}) public class SimpleSink extends RichSinkFunction&lt;String&gt; { TeacherInfoMapper teacherInfoMapper; @Override public void open(Configuration parameters) throws Exception { super.open(parameters); SpringApplication application = new SpringApplication(SimpleSink.class); application.setBannerMode(Banner.Mode.OFF); ApplicationContext context = application.run(new String[]{}); teacherInfoMapper = context.getBean(TeacherInfoMapper.class); } @Override public void close() throws Exception { super.close(); } @Override public void invoke(String value, Context context) throws Exception { List&lt;TeacherInfo&gt; teacherInfoList = teacherInfoMapper.selectByPage(0, 100); teacherInfoList.stream().forEach(teacherInfo -&gt; System.out.println(&quot;teacherinfo:&quot; + teacherInfo.getTeacherId() + &quot;,&quot; + teacherInfo.getTimeBit() + &quot;,&quot; + teacherInfo.getWeek())); } } 在invoke中就可以访问spring容器中的Mapper方法了。 &nbsp;pom如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.xxx.bigdata&lt;/groupId&gt; &lt;artifactId&gt;flink-project&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;flink-project&lt;/name&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;description&gt;My project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;flink.version&gt;1.6.1&lt;/flink.version&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;application.properties&lt;/include&gt; &lt;include&gt;application-${package.environment}.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;mainClass&gt;com.miaoke.bigdata.tms.HadesTmsApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--mybatis plugin to generate mapping file and class--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;${basedir}/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;dev&lt;/package.environment&gt; &lt;/properties&gt; &lt;!--默认环境--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!--预发布环境--&gt; &lt;profile&gt; &lt;id&gt;pre&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pre&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--生产环境--&gt; &lt;profile&gt; &lt;id&gt;pro&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pro&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;/project&gt; 项目打包使用了默认的spring boot插件，配置了skip为true，如果不配置此项，打包后会多一个BOOT-INF目录，运行时会引起ClassNotFoundException等各种异常，比如KafkaStreming问题，甚至需要反转flink的类加载机制，由child-first变为parent-first(修改flink配置文件)等等。 遇到的问题： 1. java.lang.NoSuchMethodError: com.google.gson.GsonBuilder.setLenient()Lcom/google/gson/GsonBuilder &nbsp;GsonBuilder类来自gson-xxx.jar包，而我在自己的项目中执行mvn dependency:tree并没有发现依赖这个包。莫非在flink运行时会使用自己lib库下的gson包，转而去flink的lib库下，发现flink-dist_2.11-1.6.1.jar里包含了gson-xxx包，但是打开这个包一看类中没有setLenient方法，于是在服务器上建立一个commlib，把gson-2.8.0.jar（包含setLenient方法）放进去，然后使用flink run提交时，指定classpath即可。 &nbsp; 2.日志冲突 Caused by: java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/opt/flink-1.6.1/lib/slf4j-log4j12-1.7.7.jar). If you are using WebLogic you will need to add &#39;org.slf4j&#39; to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory 排除springboot中的日志即可： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 3.flink run提交作业到yarn上时，如果需要指定classpath，则需要指定到确定的jar包，指定目录不可行。那么假如所有依赖包已经放置在目录中，拼接的shell可以这么写： lib_classpath=&quot;&quot;; for jar in `ls /home/hadoop/lib` do jar_suffix=${jar##*.} if [ &quot;$jar_suffix&quot; = &quot;jar&quot; ] then jar_path=&quot; --classpath file:///home/hadoop/lib/$jar &quot; lib_classpath=${lib_classpath}${jar_path} else echo &quot;the jar file $jar it not legal jar file,skip appendig&quot; fi done 拼接后的lib_classpath值如下效果： --classpath file:///home/hadoop/lib/accessors-smart-1.2.jar --classpath file:///home/hadoop/lib/akka-actor_2.11-2.4.20.jar 注意：如果jar包放本地文件系统，那么需要每台机器都放一份。" />
<meta property="og:description" content="使用spring boot整合flink可以快速的构建起整个应用，将关注点重点放在业务逻辑的实现上。在整合的过程中遇到许多问题，最大的问题是flink流无法访问spring容器中的类，从而导致空指针异常，解决思路是在流中进行spring bean的初始化以获得ApplicationContext，进而使用其getBean方法获取类实例。 软件版本:Spring Boot 2.1.6+Flink1.6.1+JDK1.8 程序主体： @SpringBootApplication public class HadesTmsApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication application = new SpringApplication(HadesTmsApplication.class); application.setBannerMode(Banner.Mode.OFF); application.run(args); } @Override public void run(String... args) { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); FlinkKafkaConsumer010 kafkaConsumer = new FlinkKafkaConsumer010&lt;&gt;(&quot;topic-name&quot;), new SimpleStringSchema(), getProperties()); DataStream&lt;String&gt; dataStream = env.addSource(kafkaConsumer); // 此处省略处理逻辑 dataStream.addSink(new MySink()); } private Properties getProperties() { Properties properties = new Properties(); properties.setProperty(&quot;bootstrap.servers&quot;, bootstrap_servers); properties.setProperty(&quot;zookeeper.connect&quot;, zookeeper_connect); properties.setProperty(&quot;group.id&quot;, group_id); properties.setProperty(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.setProperty(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); return properties; } } 说明一下：因为是非web项目，所以实现CommandLineRunner接口，重写run方法。在里面编写流处理逻辑。 如果在MySink中需要使用spring容器中的类，而MySink是一个普通的类，那么是无法访问到的。会引发空指针异常。可能有人想到了ApplicationContextAware这个接口，实现这个接口获取ApplicationContext，也即是： @Component public class ApplicationContextUtil implements ApplicationContextAware, Serializable { private static final long serialVersionUID = -6454872090519042646L; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { if (ApplicationContextUtil.applicationContext == null) { ApplicationContextUtil.applicationContext = applicationContext; } } public static ApplicationContext getApplicationContext() { return applicationContext; } //通过name获取 Bean. public static Object getBean(String name) { return getApplicationContext().getBean(name); } //通过class获取Bean. public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) { return getApplicationContext().getBean(clazz); } //通过name,以及Clazz返回指定的Bean public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; clazz) { return getApplicationContext().getBean(name, clazz); } } 这种做法实际上在flink流处理中也是不可行的，在我之前的flink文章中 Flink读写系列之-读mysql并写入mysql&nbsp;其中读和写阶段有一个open方法，这个方法专门用于进行初始化的，那么我们可以在这里进行spring bean的初始化。那么MySink改造后即为： @EnableAutoConfiguration @MapperScan(basePackages = {&quot;com.xxx.bigdata.xxx.mapper&quot;}) public class SimpleSink extends RichSinkFunction&lt;String&gt; { TeacherInfoMapper teacherInfoMapper; @Override public void open(Configuration parameters) throws Exception { super.open(parameters); SpringApplication application = new SpringApplication(SimpleSink.class); application.setBannerMode(Banner.Mode.OFF); ApplicationContext context = application.run(new String[]{}); teacherInfoMapper = context.getBean(TeacherInfoMapper.class); } @Override public void close() throws Exception { super.close(); } @Override public void invoke(String value, Context context) throws Exception { List&lt;TeacherInfo&gt; teacherInfoList = teacherInfoMapper.selectByPage(0, 100); teacherInfoList.stream().forEach(teacherInfo -&gt; System.out.println(&quot;teacherinfo:&quot; + teacherInfo.getTeacherId() + &quot;,&quot; + teacherInfo.getTimeBit() + &quot;,&quot; + teacherInfo.getWeek())); } } 在invoke中就可以访问spring容器中的Mapper方法了。 &nbsp;pom如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.xxx.bigdata&lt;/groupId&gt; &lt;artifactId&gt;flink-project&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;flink-project&lt;/name&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;description&gt;My project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;flink.version&gt;1.6.1&lt;/flink.version&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;application.properties&lt;/include&gt; &lt;include&gt;application-${package.environment}.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;mainClass&gt;com.miaoke.bigdata.tms.HadesTmsApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--mybatis plugin to generate mapping file and class--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;${basedir}/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;dev&lt;/package.environment&gt; &lt;/properties&gt; &lt;!--默认环境--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!--预发布环境--&gt; &lt;profile&gt; &lt;id&gt;pre&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pre&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--生产环境--&gt; &lt;profile&gt; &lt;id&gt;pro&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pro&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;/project&gt; 项目打包使用了默认的spring boot插件，配置了skip为true，如果不配置此项，打包后会多一个BOOT-INF目录，运行时会引起ClassNotFoundException等各种异常，比如KafkaStreming问题，甚至需要反转flink的类加载机制，由child-first变为parent-first(修改flink配置文件)等等。 遇到的问题： 1. java.lang.NoSuchMethodError: com.google.gson.GsonBuilder.setLenient()Lcom/google/gson/GsonBuilder &nbsp;GsonBuilder类来自gson-xxx.jar包，而我在自己的项目中执行mvn dependency:tree并没有发现依赖这个包。莫非在flink运行时会使用自己lib库下的gson包，转而去flink的lib库下，发现flink-dist_2.11-1.6.1.jar里包含了gson-xxx包，但是打开这个包一看类中没有setLenient方法，于是在服务器上建立一个commlib，把gson-2.8.0.jar（包含setLenient方法）放进去，然后使用flink run提交时，指定classpath即可。 &nbsp; 2.日志冲突 Caused by: java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/opt/flink-1.6.1/lib/slf4j-log4j12-1.7.7.jar). If you are using WebLogic you will need to add &#39;org.slf4j&#39; to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory 排除springboot中的日志即可： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 3.flink run提交作业到yarn上时，如果需要指定classpath，则需要指定到确定的jar包，指定目录不可行。那么假如所有依赖包已经放置在目录中，拼接的shell可以这么写： lib_classpath=&quot;&quot;; for jar in `ls /home/hadoop/lib` do jar_suffix=${jar##*.} if [ &quot;$jar_suffix&quot; = &quot;jar&quot; ] then jar_path=&quot; --classpath file:///home/hadoop/lib/$jar &quot; lib_classpath=${lib_classpath}${jar_path} else echo &quot;the jar file $jar it not legal jar file,skip appendig&quot; fi done 拼接后的lib_classpath值如下效果： --classpath file:///home/hadoop/lib/accessors-smart-1.2.jar --classpath file:///home/hadoop/lib/akka-actor_2.11-2.4.20.jar 注意：如果jar包放本地文件系统，那么需要每台机器都放一份。" />
<link rel="canonical" href="https://uzzz.org/2019/07/04/793410.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/04/793410.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"使用spring boot整合flink可以快速的构建起整个应用，将关注点重点放在业务逻辑的实现上。在整合的过程中遇到许多问题，最大的问题是flink流无法访问spring容器中的类，从而导致空指针异常，解决思路是在流中进行spring bean的初始化以获得ApplicationContext，进而使用其getBean方法获取类实例。 软件版本:Spring Boot 2.1.6+Flink1.6.1+JDK1.8 程序主体： @SpringBootApplication public class HadesTmsApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication application = new SpringApplication(HadesTmsApplication.class); application.setBannerMode(Banner.Mode.OFF); application.run(args); } @Override public void run(String... args) { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); FlinkKafkaConsumer010 kafkaConsumer = new FlinkKafkaConsumer010&lt;&gt;(&quot;topic-name&quot;), new SimpleStringSchema(), getProperties()); DataStream&lt;String&gt; dataStream = env.addSource(kafkaConsumer); // 此处省略处理逻辑 dataStream.addSink(new MySink()); } private Properties getProperties() { Properties properties = new Properties(); properties.setProperty(&quot;bootstrap.servers&quot;, bootstrap_servers); properties.setProperty(&quot;zookeeper.connect&quot;, zookeeper_connect); properties.setProperty(&quot;group.id&quot;, group_id); properties.setProperty(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.setProperty(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); return properties; } } 说明一下：因为是非web项目，所以实现CommandLineRunner接口，重写run方法。在里面编写流处理逻辑。 如果在MySink中需要使用spring容器中的类，而MySink是一个普通的类，那么是无法访问到的。会引发空指针异常。可能有人想到了ApplicationContextAware这个接口，实现这个接口获取ApplicationContext，也即是： @Component public class ApplicationContextUtil implements ApplicationContextAware, Serializable { private static final long serialVersionUID = -6454872090519042646L; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { if (ApplicationContextUtil.applicationContext == null) { ApplicationContextUtil.applicationContext = applicationContext; } } public static ApplicationContext getApplicationContext() { return applicationContext; } //通过name获取 Bean. public static Object getBean(String name) { return getApplicationContext().getBean(name); } //通过class获取Bean. public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) { return getApplicationContext().getBean(clazz); } //通过name,以及Clazz返回指定的Bean public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; clazz) { return getApplicationContext().getBean(name, clazz); } } 这种做法实际上在flink流处理中也是不可行的，在我之前的flink文章中 Flink读写系列之-读mysql并写入mysql&nbsp;其中读和写阶段有一个open方法，这个方法专门用于进行初始化的，那么我们可以在这里进行spring bean的初始化。那么MySink改造后即为： @EnableAutoConfiguration @MapperScan(basePackages = {&quot;com.xxx.bigdata.xxx.mapper&quot;}) public class SimpleSink extends RichSinkFunction&lt;String&gt; { TeacherInfoMapper teacherInfoMapper; @Override public void open(Configuration parameters) throws Exception { super.open(parameters); SpringApplication application = new SpringApplication(SimpleSink.class); application.setBannerMode(Banner.Mode.OFF); ApplicationContext context = application.run(new String[]{}); teacherInfoMapper = context.getBean(TeacherInfoMapper.class); } @Override public void close() throws Exception { super.close(); } @Override public void invoke(String value, Context context) throws Exception { List&lt;TeacherInfo&gt; teacherInfoList = teacherInfoMapper.selectByPage(0, 100); teacherInfoList.stream().forEach(teacherInfo -&gt; System.out.println(&quot;teacherinfo:&quot; + teacherInfo.getTeacherId() + &quot;,&quot; + teacherInfo.getTimeBit() + &quot;,&quot; + teacherInfo.getWeek())); } } 在invoke中就可以访问spring容器中的Mapper方法了。 &nbsp;pom如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.xxx.bigdata&lt;/groupId&gt; &lt;artifactId&gt;flink-project&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;flink-project&lt;/name&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;description&gt;My project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;flink.version&gt;1.6.1&lt;/flink.version&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;application.properties&lt;/include&gt; &lt;include&gt;application-${package.environment}.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;mainClass&gt;com.miaoke.bigdata.tms.HadesTmsApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--mybatis plugin to generate mapping file and class--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;${basedir}/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.cloudera&lt;/groupId&gt; &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt; &lt;version&gt;2.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;dev&lt;/package.environment&gt; &lt;/properties&gt; &lt;!--默认环境--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!--预发布环境--&gt; &lt;profile&gt; &lt;id&gt;pre&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pre&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--生产环境--&gt; &lt;profile&gt; &lt;id&gt;pro&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;pro&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;/project&gt; 项目打包使用了默认的spring boot插件，配置了skip为true，如果不配置此项，打包后会多一个BOOT-INF目录，运行时会引起ClassNotFoundException等各种异常，比如KafkaStreming问题，甚至需要反转flink的类加载机制，由child-first变为parent-first(修改flink配置文件)等等。 遇到的问题： 1. java.lang.NoSuchMethodError: com.google.gson.GsonBuilder.setLenient()Lcom/google/gson/GsonBuilder &nbsp;GsonBuilder类来自gson-xxx.jar包，而我在自己的项目中执行mvn dependency:tree并没有发现依赖这个包。莫非在flink运行时会使用自己lib库下的gson包，转而去flink的lib库下，发现flink-dist_2.11-1.6.1.jar里包含了gson-xxx包，但是打开这个包一看类中没有setLenient方法，于是在服务器上建立一个commlib，把gson-2.8.0.jar（包含setLenient方法）放进去，然后使用flink run提交时，指定classpath即可。 &nbsp; 2.日志冲突 Caused by: java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/opt/flink-1.6.1/lib/slf4j-log4j12-1.7.7.jar). If you are using WebLogic you will need to add &#39;org.slf4j&#39; to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory 排除springboot中的日志即可： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 3.flink run提交作业到yarn上时，如果需要指定classpath，则需要指定到确定的jar包，指定目录不可行。那么假如所有依赖包已经放置在目录中，拼接的shell可以这么写： lib_classpath=&quot;&quot;; for jar in `ls /home/hadoop/lib` do jar_suffix=${jar##*.} if [ &quot;$jar_suffix&quot; = &quot;jar&quot; ] then jar_path=&quot; --classpath file:///home/hadoop/lib/$jar &quot; lib_classpath=${lib_classpath}${jar_path} else echo &quot;the jar file $jar it not legal jar file,skip appendig&quot; fi done 拼接后的lib_classpath值如下效果： --classpath file:///home/hadoop/lib/accessors-smart-1.2.jar --classpath file:///home/hadoop/lib/akka-actor_2.11-2.4.20.jar 注意：如果jar包放本地文件系统，那么需要每台机器都放一份。","@type":"BlogPosting","url":"https://uzzz.org/2019/07/04/793410.html","headline":"Spring Boot整合Flink","dateModified":"2019-07-04T00:00:00+08:00","datePublished":"2019-07-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/04/793410.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Spring Boot整合Flink</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>使用spring boot整合flink可以快速的构建起整个应用，将关注点重点放在业务逻辑的实现上。在整合的过程中遇到许多问题，最大的问题是flink流无法访问spring容器中的类，从而导致空指针异常，解决思路是在流中进行spring bean的初始化以获得ApplicationContext，进而使用其getBean方法获取类实例。</p> 
  <p>软件版本:Spring Boot 2.1.6+Flink1.6.1+JDK1.8</p> 
  <p>程序主体：</p> 
  <pre class="has">
<code class="language-java">@SpringBootApplication
public class HadesTmsApplication implements CommandLineRunner {


    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(HadesTmsApplication.class);
        application.setBannerMode(Banner.Mode.OFF);
        application.run(args);
    }

    @Override
    public void run(String... args) {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
FlinkKafkaConsumer010 kafkaConsumer = new FlinkKafkaConsumer010&lt;&gt;("topic-name"), new SimpleStringSchema(), getProperties());
DataStream&lt;String&gt; dataStream = env.addSource(kafkaConsumer);
// 此处省略处理逻辑
dataStream.addSink(new MySink());


    }

private Properties getProperties() {
        Properties properties = new Properties();
        properties.setProperty("bootstrap.servers", bootstrap_servers);
        properties.setProperty("zookeeper.connect", zookeeper_connect);
        properties.setProperty("group.id", group_id);
        properties.setProperty("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.setProperty("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        return properties;
    }
}</code></pre> 
  <p>说明一下：因为是非web项目，所以实现CommandLineRunner接口，重写run方法。在里面编写流处理逻辑。</p> 
  <p>如果在MySink中需要使用spring容器中的类，而MySink是一个普通的类，那么是无法访问到的。会引发空指针异常。可能有人想到了ApplicationContextAware这个接口，实现这个接口获取ApplicationContext，也即是：</p> 
  <pre class="has">
<code class="language-java">@Component
public class ApplicationContextUtil implements ApplicationContextAware, Serializable {
    private static final long serialVersionUID = -6454872090519042646L;
    private static ApplicationContext applicationContext = null;

    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        if (ApplicationContextUtil.applicationContext == null) {
            ApplicationContextUtil.applicationContext = applicationContext;
        }
    }

    public static ApplicationContext getApplicationContext() {
        return applicationContext;
    }

    //通过name获取 Bean.
    public static Object getBean(String name) {
        return getApplicationContext().getBean(name);
    }

    //通过class获取Bean.
    public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) {
        return getApplicationContext().getBean(clazz);
    }

    //通过name,以及Clazz返回指定的Bean
    public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; clazz) {
        return getApplicationContext().getBean(name, clazz);
    }
}</code></pre> 
  <p>这种做法实际上在flink流处理中也是不可行的，在我之前的flink文章中<strong> Flink读写系列之-读mysql并写入mysql&nbsp;</strong>其中读和写阶段有一个open方法，这个方法专门用于进行初始化的，那么我们可以在这里进行spring bean的初始化。那么MySink改造后即为：</p> 
  <pre class="has">
<code class="language-java">@EnableAutoConfiguration
@MapperScan(basePackages = {"com.xxx.bigdata.xxx.mapper"})
public class SimpleSink extends RichSinkFunction&lt;String&gt; {


    TeacherInfoMapper teacherInfoMapper;

    @Override
    public void open(Configuration parameters) throws Exception {
        super.open(parameters);
        SpringApplication application = new SpringApplication(SimpleSink.class);
        application.setBannerMode(Banner.Mode.OFF);
        ApplicationContext context = application.run(new String[]{});
        teacherInfoMapper = context.getBean(TeacherInfoMapper.class);
    }

    @Override
    public void close() throws Exception {
        super.close();
    }

    @Override
    public void invoke(String value, Context context) throws Exception {
        List&lt;TeacherInfo&gt; teacherInfoList = teacherInfoMapper.selectByPage(0, 100);
        teacherInfoList.stream().forEach(teacherInfo -&gt; System.out.println("teacherinfo:" + teacherInfo.getTeacherId() + "," + teacherInfo.getTimeBit() + "," + teacherInfo.getWeek()));
    }
}</code></pre> 
  <p>在invoke中就可以访问spring容器中的Mapper方法了。</p> 
  <p>&nbsp;pom如下：</p> 
  <pre class="has">
<code class="language-java">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.xxx.bigdata&lt;/groupId&gt;
    &lt;artifactId&gt;flink-project&lt;/artifactId&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;name&gt;flink-project&lt;/name&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;
    &lt;description&gt;My project for Spring Boot&lt;/description&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;flink.version&gt;1.6.1&lt;/flink.version&gt;
        &lt;skipTests&gt;true&lt;/skipTests&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
                    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.cloudera&lt;/groupId&gt;
            &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt;
            &lt;version&gt;2.6.4&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.zaxxer&lt;/groupId&gt;
            &lt;artifactId&gt;HikariCP&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;1.3.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
            &lt;version&gt;1.2.47&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt;
        &lt;resources&gt;
            &lt;resource&gt;
                &lt;directory&gt;src/main/resources&lt;/directory&gt;
                &lt;filtering&gt;true&lt;/filtering&gt;
                &lt;includes&gt;
                    &lt;include&gt;application.properties&lt;/include&gt;
                    &lt;include&gt;application-${package.environment}.properties&lt;/include&gt;
                &lt;/includes&gt;
            &lt;/resource&gt;
        &lt;/resources&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                    &lt;mainClass&gt;com.miaoke.bigdata.tms.HadesTmsApplication&lt;/mainClass&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;repackage&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;!--mybatis plugin to generate mapping file and class--&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
                &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;1.3.5&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;configurationFile&gt;${basedir}/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt;
                    &lt;overwrite&gt;true&lt;/overwrite&gt;
                    &lt;verbose&gt;true&lt;/verbose&gt;
                &lt;/configuration&gt;
                &lt;dependencies&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;com.cloudera&lt;/groupId&gt;
                        &lt;artifactId&gt;ImpalaJDBC41&lt;/artifactId&gt;
                        &lt;version&gt;2.6.4&lt;/version&gt;
                    &lt;/dependency&gt;
                &lt;/dependencies&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

    &lt;profiles&gt;
        &lt;!--开发环境--&gt;
        &lt;profile&gt;
            &lt;id&gt;dev&lt;/id&gt;
            &lt;properties&gt;
                &lt;package.environment&gt;dev&lt;/package.environment&gt;
            &lt;/properties&gt;
            &lt;!--默认环境--&gt;
            &lt;activation&gt;
                &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
            &lt;/activation&gt;
        &lt;/profile&gt;
        &lt;!--预发布环境--&gt;
        &lt;profile&gt;
            &lt;id&gt;pre&lt;/id&gt;
            &lt;properties&gt;
                &lt;package.environment&gt;pre&lt;/package.environment&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;
        &lt;!--生产环境--&gt;
        &lt;profile&gt;
            &lt;id&gt;pro&lt;/id&gt;
            &lt;properties&gt;
                &lt;package.environment&gt;pro&lt;/package.environment&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;

&lt;/project&gt;
</code></pre> 
  <p>项目打包使用了默认的spring boot插件，配置了skip为true，如果不配置此项，打包后会多一个BOOT-INF目录，运行时会引起ClassNotFoundException等各种异常，比如KafkaStreming问题，甚至需要反转flink的类加载机制，由child-first变为parent-first(修改flink配置文件)等等。</p> 
  <p>遇到的问题：</p> 
  <pre>
1.  java.lang.NoSuchMethodError: com.google.gson.GsonBuilder.setLenient()Lcom/google/gson/GsonBuilder</pre> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190704212650361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFqeHowMDg=,size_16,color_FFFFFF,t_70">&nbsp;GsonBuilder类来自gson-xxx.jar包，而我在自己的项目中执行mvn dependency:tree并没有发现依赖这个包。莫非在flink运行时会使用自己lib库下的gson包，转而去flink的lib库下，发现flink-dist_2.11-1.6.1.jar里包含了gson-xxx包，但是打开这个包一看类中没有setLenient方法，于是在服务器上建立一个commlib，把gson-2.8.0.jar（包含setLenient方法）放进去，然后使用flink run提交时，指定classpath即可。</p> 
  <p>&nbsp; 2.日志冲突</p> 
  <p><strong>Caused by: java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/opt/flink-1.6.1/lib/slf4j-log4j12-1.7.7.jar). If you are using WebLogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory</strong></p> 
  <p>排除springboot中的日志即可：</p> 
  <pre class="has">
<code class="language-java">&lt;dependency&gt;
       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
       &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
       &lt;exclusions&gt;
             &lt;exclusion&gt;
                 &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
                 &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
             &lt;/exclusion&gt;
       &lt;/exclusions&gt;
&lt;/dependency&gt;</code></pre> 
  <p>3.flink run提交作业到yarn上时，如果需要指定classpath，则需要指定到确定的jar包，指定目录不可行。那么假如所有依赖包已经放置在目录中，拼接的shell可以这么写：</p> 
  <pre class="has">
<code class="language-bash">
lib_classpath="";

for jar in `ls /home/hadoop/lib`
do
  jar_suffix=${jar##*.}
  if [ "$jar_suffix" = "jar" ]
  then
    jar_path=" --classpath file:///home/hadoop/lib/$jar "
    lib_classpath=${lib_classpath}${jar_path}
  else
    echo "the jar file $jar it not legal jar file,skip appendig"
  fi
done</code></pre> 
  <p>拼接后的lib_classpath值如下效果：</p> 
  <pre class="has">
<code class="language-bash">--classpath file:///home/hadoop/lib/accessors-smart-1.2.jar  --classpath file:///home/hadoop/lib/akka-actor_2.11-2.4.20.jar </code></pre> 
  <p>注意：如果jar包放本地文件系统，那么需要每台机器都放一份。</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
