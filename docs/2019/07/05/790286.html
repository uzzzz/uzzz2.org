<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>七月在线机器学习中的数学第二期笔记1 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="七月在线机器学习中的数学第二期笔记1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="这套笔记是跟着七月在线机器学习中的数学第二期的学习而记录的，主要记一下我再学习机器学习的时候一些概念比较模糊的地方，具体课程参考七月算法官网： 七月 数理统计和参数估计部分 一. 概率与数理统计 首先，看一下概率与统计的关注点 1概率论问问题的方式： 已知总体的所有可能性，求某种事件发生的概率，如图所示： 已知小桶中小球的总数和白球和黑球的个数，从小桶中取球，求取出白球或黑球的概率 2 数理统计问问题的方式（相关资料） 已知总体服从某种分布，抽取样本，根据样本估计总体的分布方式，如图： 现在，我们不知道小桶中有多少个小球，我们从小桶中取出一些小球，根据这些小球中白球黑球的数据，估计小桶中黑球白球的分布情况。 3. 概率统计与机器学习之间的关系： 对于一个有监督的训练模型，如下图所示： &nbsp; 对于一个有监督的学习模型，我们已知一些有标签的样本，通过这些样本，构造出一个模型，来估计未被标记的样本，正如有图所示。 机器学习的训练过程，类似于统计的过程，预测过程，类似于计算概率的过程。 其次，在样本中，每个样本都用其自身的特征和对应的标签，假设每一行表示一个样本，如下图： 其中，每一列对应一个分布。标签也是一个分布。因此，可以基于各个分布的特性来苹果模型和样本 总结下概率统计和机器学习的关系 i. 统计估计的是分布，机器学习训练出来的是模型，模型可能包含了很多分布。 ii.训练与预测过程的一个核心评价指标就是模型的误差 iii. 误差本身就可以是概率的形式，与概率紧密相关 iv. 对误差的不同的定义方式就演化成不同损失函数的定义方式。 3. 协方差：(关于期望方差之类的内容，这里不再说明) 定义 Cov(X,Y) = E{[X-E(X)][Y-E(Y)]} =E(XY)-E(X)E(Y) 协方差评价两个随机变量之间的关系,是两个随机变量具有相同方向变化趋势的度量 Cov(X,Y)&gt;0, 则其变化趋势相同 Cov(X,Y)&lt;0, 其变化趋势相反 Cov(X,Y)=0. X与Y不相关 协方差的上界：|Cov(X,Y)| &lt;=两个变量标准差的乘积 4. 独立与不相关： 不相关，是说明X,Y 没有线性关系，即线性不相关，但是他们有没有非线性关系是不能保证的。 5. 贝叶斯公式的思考 P(A|D) = P(D|A)P(A)/P(D) P(A|D):在给定条件D的时候A发生的概率， D为已知的样本， 因此P(A|D）表示给定样本之后，计算分布的参数, 哪组参数取的概率越大，哪组参数就是最有可能被我们估计的那个值。 即： 给定某些样本D,在这些样本中计算结论A1， A2,...An出现的概率，P(Ai|D)。 maxP(Ai|D) = maxP(D|Ai)P(Ai)/P(D) -------&gt; max(P(D|Ai)P(Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//P(D)为常数，样本本身发生的概率 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------&gt; max(P(D|Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//假设在没有任何先验信息的情况下，P(Ai)近似等概率出现 &nbsp;=&gt; maxP(Ai|D) --&gt; maxP(D|Ai) &nbsp; 说明，在样本给定的情况下，求哪个参数的概率最大等价于求哪个参数能够使得样本D出现的概率最大（最大可能发生） 因此，我们不再去求某种数据给定的时候，某个参数的可能值最大，而是求哪个参数能够使这个数据产生的概率最大，这个也是极大似然估计的基本思想。 &nbsp; 转自：https://blog.csdn.net/thystar/article/details/51224733 &nbsp; 参考资料： 七月算法：机器学习中的数学&nbsp;http://edu.duolaimier.cn &nbsp;" />
<meta property="og:description" content="这套笔记是跟着七月在线机器学习中的数学第二期的学习而记录的，主要记一下我再学习机器学习的时候一些概念比较模糊的地方，具体课程参考七月算法官网： 七月 数理统计和参数估计部分 一. 概率与数理统计 首先，看一下概率与统计的关注点 1概率论问问题的方式： 已知总体的所有可能性，求某种事件发生的概率，如图所示： 已知小桶中小球的总数和白球和黑球的个数，从小桶中取球，求取出白球或黑球的概率 2 数理统计问问题的方式（相关资料） 已知总体服从某种分布，抽取样本，根据样本估计总体的分布方式，如图： 现在，我们不知道小桶中有多少个小球，我们从小桶中取出一些小球，根据这些小球中白球黑球的数据，估计小桶中黑球白球的分布情况。 3. 概率统计与机器学习之间的关系： 对于一个有监督的训练模型，如下图所示： &nbsp; 对于一个有监督的学习模型，我们已知一些有标签的样本，通过这些样本，构造出一个模型，来估计未被标记的样本，正如有图所示。 机器学习的训练过程，类似于统计的过程，预测过程，类似于计算概率的过程。 其次，在样本中，每个样本都用其自身的特征和对应的标签，假设每一行表示一个样本，如下图： 其中，每一列对应一个分布。标签也是一个分布。因此，可以基于各个分布的特性来苹果模型和样本 总结下概率统计和机器学习的关系 i. 统计估计的是分布，机器学习训练出来的是模型，模型可能包含了很多分布。 ii.训练与预测过程的一个核心评价指标就是模型的误差 iii. 误差本身就可以是概率的形式，与概率紧密相关 iv. 对误差的不同的定义方式就演化成不同损失函数的定义方式。 3. 协方差：(关于期望方差之类的内容，这里不再说明) 定义 Cov(X,Y) = E{[X-E(X)][Y-E(Y)]} =E(XY)-E(X)E(Y) 协方差评价两个随机变量之间的关系,是两个随机变量具有相同方向变化趋势的度量 Cov(X,Y)&gt;0, 则其变化趋势相同 Cov(X,Y)&lt;0, 其变化趋势相反 Cov(X,Y)=0. X与Y不相关 协方差的上界：|Cov(X,Y)| &lt;=两个变量标准差的乘积 4. 独立与不相关： 不相关，是说明X,Y 没有线性关系，即线性不相关，但是他们有没有非线性关系是不能保证的。 5. 贝叶斯公式的思考 P(A|D) = P(D|A)P(A)/P(D) P(A|D):在给定条件D的时候A发生的概率， D为已知的样本， 因此P(A|D）表示给定样本之后，计算分布的参数, 哪组参数取的概率越大，哪组参数就是最有可能被我们估计的那个值。 即： 给定某些样本D,在这些样本中计算结论A1， A2,...An出现的概率，P(Ai|D)。 maxP(Ai|D) = maxP(D|Ai)P(Ai)/P(D) -------&gt; max(P(D|Ai)P(Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//P(D)为常数，样本本身发生的概率 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------&gt; max(P(D|Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//假设在没有任何先验信息的情况下，P(Ai)近似等概率出现 &nbsp;=&gt; maxP(Ai|D) --&gt; maxP(D|Ai) &nbsp; 说明，在样本给定的情况下，求哪个参数的概率最大等价于求哪个参数能够使得样本D出现的概率最大（最大可能发生） 因此，我们不再去求某种数据给定的时候，某个参数的可能值最大，而是求哪个参数能够使这个数据产生的概率最大，这个也是极大似然估计的基本思想。 &nbsp; 转自：https://blog.csdn.net/thystar/article/details/51224733 &nbsp; 参考资料： 七月算法：机器学习中的数学&nbsp;http://edu.duolaimier.cn &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/07/05/790286.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/05/790286.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"这套笔记是跟着七月在线机器学习中的数学第二期的学习而记录的，主要记一下我再学习机器学习的时候一些概念比较模糊的地方，具体课程参考七月算法官网： 七月 数理统计和参数估计部分 一. 概率与数理统计 首先，看一下概率与统计的关注点 1概率论问问题的方式： 已知总体的所有可能性，求某种事件发生的概率，如图所示： 已知小桶中小球的总数和白球和黑球的个数，从小桶中取球，求取出白球或黑球的概率 2 数理统计问问题的方式（相关资料） 已知总体服从某种分布，抽取样本，根据样本估计总体的分布方式，如图： 现在，我们不知道小桶中有多少个小球，我们从小桶中取出一些小球，根据这些小球中白球黑球的数据，估计小桶中黑球白球的分布情况。 3. 概率统计与机器学习之间的关系： 对于一个有监督的训练模型，如下图所示： &nbsp; 对于一个有监督的学习模型，我们已知一些有标签的样本，通过这些样本，构造出一个模型，来估计未被标记的样本，正如有图所示。 机器学习的训练过程，类似于统计的过程，预测过程，类似于计算概率的过程。 其次，在样本中，每个样本都用其自身的特征和对应的标签，假设每一行表示一个样本，如下图： 其中，每一列对应一个分布。标签也是一个分布。因此，可以基于各个分布的特性来苹果模型和样本 总结下概率统计和机器学习的关系 i. 统计估计的是分布，机器学习训练出来的是模型，模型可能包含了很多分布。 ii.训练与预测过程的一个核心评价指标就是模型的误差 iii. 误差本身就可以是概率的形式，与概率紧密相关 iv. 对误差的不同的定义方式就演化成不同损失函数的定义方式。 3. 协方差：(关于期望方差之类的内容，这里不再说明) 定义 Cov(X,Y) = E{[X-E(X)][Y-E(Y)]} =E(XY)-E(X)E(Y) 协方差评价两个随机变量之间的关系,是两个随机变量具有相同方向变化趋势的度量 Cov(X,Y)&gt;0, 则其变化趋势相同 Cov(X,Y)&lt;0, 其变化趋势相反 Cov(X,Y)=0. X与Y不相关 协方差的上界：|Cov(X,Y)| &lt;=两个变量标准差的乘积 4. 独立与不相关： 不相关，是说明X,Y 没有线性关系，即线性不相关，但是他们有没有非线性关系是不能保证的。 5. 贝叶斯公式的思考 P(A|D) = P(D|A)P(A)/P(D) P(A|D):在给定条件D的时候A发生的概率， D为已知的样本， 因此P(A|D）表示给定样本之后，计算分布的参数, 哪组参数取的概率越大，哪组参数就是最有可能被我们估计的那个值。 即： 给定某些样本D,在这些样本中计算结论A1， A2,...An出现的概率，P(Ai|D)。 maxP(Ai|D) = maxP(D|Ai)P(Ai)/P(D) -------&gt; max(P(D|Ai)P(Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//P(D)为常数，样本本身发生的概率 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------&gt; max(P(D|Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//假设在没有任何先验信息的情况下，P(Ai)近似等概率出现 &nbsp;=&gt; maxP(Ai|D) --&gt; maxP(D|Ai) &nbsp; 说明，在样本给定的情况下，求哪个参数的概率最大等价于求哪个参数能够使得样本D出现的概率最大（最大可能发生） 因此，我们不再去求某种数据给定的时候，某个参数的可能值最大，而是求哪个参数能够使这个数据产生的概率最大，这个也是极大似然估计的基本思想。 &nbsp; 转自：https://blog.csdn.net/thystar/article/details/51224733 &nbsp; 参考资料： 七月算法：机器学习中的数学&nbsp;http://edu.duolaimier.cn &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/07/05/790286.html","headline":"七月在线机器学习中的数学第二期笔记1","dateModified":"2019-07-05T00:00:00+08:00","datePublished":"2019-07-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/05/790286.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>七月在线机器学习中的数学第二期笔记1</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix" data-track-view="{&quot;mod&quot;:&quot;popu_307&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/laokdidiao/article/details/94760771,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_307&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/laokdidiao/article/details/94760771&quot;}"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-cd6c485e8b.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>这套笔记是跟着七月在线机器学习中的数学第二期的学习而记录的，主要记一下我再学习机器学习的时候一些概念比较模糊的地方，具体课程参考七月算法官网：</p> 
  <p><a href="http://www.julyedu.com/" rel="nofollow">七月</a></p> 
  <p>数理统计和参数估计部分</p> 
  <h2>一. 概率与数理统计</h2> 
  <p>首先，看一下概率与统计的关注点</p> 
  <h3>1概率论问问题的方式：</h3> 
  <p>已知总体的所有可能性，求某种事件发生的概率，如图所示：</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20160423094714017?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p> 
  <p>已知小桶中小球的总数和白球和黑球的个数，从小桶中取球，求取出白球或黑球的概率</p> 
  <h3>2 数理统计问问题的方式（<a href="http://edu.duolaimier.cn/forum.php?mod=viewthread&amp;tid=79&amp;extra=page%3D1" rel="nofollow">相关资料</a>）</h3> 
  <p>已知总体服从某种分布，抽取样本，根据样本估计总体的分布方式，如图：</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20160423095552265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p> 
  <p>现在，我们不知道小桶中有多少个小球，我们从小桶中取出一些小球，根据这些小球中白球黑球的数据，估计小桶中黑球白球的分布情况。</p> 
  <h3>3. 概率统计与机器学习之间的关系：</h3> 
  <p>对于一个有监督的训练模型，如下图所示：</p> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20160423102330114?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p> 
  <p>对于一个有监督的学习模型，我们已知一些有标签的样本，通过这些样本，构造出一个模型，来估计未被标记的样本，正如有图所示。</p> 
  <p>机器学习的训练过程，类似于统计的过程，预测过程，类似于计算概率的过程。</p> 
  <p>其次，在样本中，每个样本都用其自身的特征和对应的标签，假设每一行表示一个样本，如下图：</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20160423112444841?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p> 
  <p>其中，每一列对应一个分布。标签也是一个分布。因此，可以基于各个分布的特性来苹果模型和样本</p> 
  <p>总结下概率统计和机器学习的关系</p> 
  <p>i. 统计估计的是分布，机器学习训练出来的是模型，模型可能包含了很多分布。</p> 
  <p>ii.训练与预测过程的一个核心评价指标就是模型的误差</p> 
  <p>iii. 误差本身就可以是概率的形式，与概率紧密相关</p> 
  <p>iv. 对误差的不同的定义方式就演化成不同损失函数的定义方式。</p> 
  <p>3. 协方差：(关于期望方差之类的内容，这里不再说明)</p> 
  <p>定义 Cov(X,Y) = E{[X-E(X)][Y-E(Y)]} =E(XY)-E(X)E(Y)</p> 
  <p>协方差评价两个随机变量之间的关系,是两个随机变量具有相同方向变化趋势的度量</p> 
  <p>Cov(X,Y)&gt;0, 则其变化趋势相同</p> 
  <p>Cov(X,Y)&lt;0, 其变化趋势相反</p> 
  <p>Cov(X,Y)=0. X与Y不相关</p> 
  <p>协方差的上界：|Cov(X,Y)| &lt;=两个变量标准差的乘积</p> 
  <p>4. 独立与不相关：</p> 
  <p>不相关，是说明X,Y 没有线性关系，即线性不相关，但是他们有没有非线性关系是不能保证的。</p> 
  <p>5. 贝叶斯公式的思考</p> 
  <p>P(A|D) = P(D|A)P(A)/P(D)</p> 
  <p>P(A|D):在给定条件D的时候A发生的概率，</p> 
  <p>D为已知的样本，</p> 
  <p>因此P(A|D）表示给定样本之后，计算分布的参数, 哪组参数取的概率越大，哪组参数就是最有可能被我们估计的那个值。</p> 
  <p>即： 给定某些样本D,在这些样本中计算结论A1， A2,...An出现的概率，P(Ai|D)。</p> 
  <p>maxP(Ai|D) = maxP(D|Ai)P(Ai)/P(D) -------&gt; max(P(D|Ai)P(Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//P(D)为常数，样本本身发生的概率</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------&gt; max(P(D|Ai)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//假设在没有任何先验信息的情况下，P(Ai)近似等概率出现</p> 
  <p>&nbsp;=&gt; maxP(Ai|D) --&gt; maxP(D|Ai) &nbsp;</p> 
  <p>说明，在样本给定的情况下，求哪个参数的概率最大等价于求哪个参数能够使得样本D出现的概率最大（最大可能发生）</p> 
  <p>因此，我们不再去求某种数据给定的时候，某个参数的可能值最大，而是求哪个参数能够使这个数据产生的概率最大，这个也是极大似然估计的基本思想。<br> &nbsp;</p> 
  <p>转自：<a href="https://blog.csdn.net/thystar/article/details/51224733" rel="nofollow">https://blog.csdn.net/thystar/article/details/51224733</a></p> 
  <p>&nbsp;</p> 
  <p>参考资料：</p> 
  <p>七月算法：机器学习中的数学&nbsp;<span style="color:#ffffff;">http://edu.duolaimier.cn</span></p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
