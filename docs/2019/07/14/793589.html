<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hive：概述、体系架构、工作流程 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hive：概述、体系架构、工作流程" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 1、Hive概述 1.1、Hive是什么 1.2、数据仓库的特点 1.3、Hive优缺点 1.3.1、优点 1.3.2、缺点 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 1.4.2、更新 1.4.3、索引 1.4.4、数据存储 1.4.5、可扩展性 1.5、Hive与HBase 2、Hive体系架构 3、工作流程 1、Hive概述 1.1、Hive是什么 Hive是由Facebook开源用于解决海量结构化日志的数据统计，是分析数据的框架。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射成一张表，并提供了类SQL查询功能。本质是将HQL转化为MapReduce程序。Hive类似于一个Hadoop的客户端，所以Hive并非集群。 Hive处理的数据存储于HDFS上 Hive分析数据底层实现的是MapReduce 执行程序运行在Yarn上 使用大象的鼻子去采花即数据流大；蜜蜂产蜜即分析结果 1.2、数据仓库的特点 数据仓库是面向主题的、集成的、时变的、非易失的 面向主题的：数据仓库围绕一些主题，如顾客、供应商、产品和销售来组织。数据仓库关注决策者的数据建模与分析，而不是组织机构的日常操作和事务处理。因此，数据仓库排除对于决策支持过程无用的数据，提供特定主题的简明视图。 集成的：通常，构造数据仓库是将多个异构数据源，如关系数据库、一般文件和联机事务记录集成在一起。使用数据清理和数据集成技术确保命名约定、编码结构、属性度量等的一致性。 时变的：数据存储从历史的角度提供信息，数据仓库中的关键结构都隐式或显式地包含时间元素。 非易失的：数据仓库总是物理地分别存放数据，这些数据源于操作环境下的应用数据。由于这种分离，数据仓库不需要事务处理，恢复和并发控制机制。通常，它只需要两种数据访问操作：数据的初始化装入和数据访问。 1.3、Hive优缺点 1.3.1、优点 1）Hive提供了类似于SQL的HQL语言来查询储存在hdfs上的数据 2）Hive可以将大多数的查询转换为MapReduce任务 3）Hive适合数据仓库应用程序，常用于静态数据分析，执行延迟比较高，适合不需要快速响应给出结果的场合 4）Hive的优势在于处理大数据集，因为Hive执行延迟较高 5）Hive支持用户自定义函(UDF)，扩展性好 1.3.2、缺点 1）Hive不支持记录级别的更新、插入或者删除，但用户可以通过查询生成新表或将查询结果导入到文件中 2）Hive查询延时比较严重，因为Hadoop是面向批处理的系统，而MapReduce的启动过程需要消耗一段时间，并且粒度较粗调优比较困难 3）Hive不支持事务，也就是说不支持OLTP(联机事务处理)所需的关键功能ACID。而更接近于OLAP(联机分析技术)，适合离线处理大数据集，虽然还未满足OLAP中OL部分 4）HQL表达能力有限，无法表达迭代式算法，所以在数据挖掘方面不太擅长 5）Hive会自动生成MapReduce作业，通常不够智能化 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 写时模式 传统数据库中采用的是写时模式，表的模式实在数据加载时强制确定的，如果在加载时发现数据不符合模式，则拒绝加载数据。数据在写入数据库时对照模式检查。写时模式有利于提升查询性能，因为数据库可以对列进行索引，并对数据进行压缩。 读时模式 Hive对数据的验证则是在查询时进行的，这有利于大数据集的导入，读时模式使数据的加载非常迅速，数据的加载仅是文件复制或移动。 1.4.2、更新 Hive是针对数据仓库应用设计的，所以数仓的内容是读多写少的。Hive中不建议对数据进行改写，所有数据都是在加载的时候确定好的；而数据库中的数据通常是需要经常进行修改的。 1.4.3、索引 Hive要访问数据中特定数据时，需要全表扫描，因此访问延迟较高。由于MapReduce的引入，Hive可以并行访问数据，在大数据的访问上仍然具有优势。Hive只提供了有限的索引功能，可以为一些字段建立索引，一张表的索引数据存储在另外一张表中。由于数据的访问延迟较高，Hive不适合在线数据查询；数据库在少量的特定条件的数据访问中，索引可以提供较低的延迟。 1.4.4、数据存储 Hive是建立在Hadoop之上的，所有Hive的数据都是存储在hdfs中的，而metastore元数据建议存储在独立的关系型数据库中；数据库则将数据存储在块设备或者本地文件系统中。 1.4.5、可扩展性 由于Hive是建立在Hadoop之上的，因此Hive具有良好的可扩展性；数据库由于ACID语义的严格限制，扩展性十分有限 1.5、Hive与HBase Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。 Hbase hbase是基于Hadoop数据库，是一种NoSQL数据库，用于存储HDFS中结构化和非结构化的数据。数据持久化存储的体现形式是 Hfile，存放于 DataNode 中，被 ResionServer 以 Region 的形式进行管理 HBase 可以实现单表大量数据的存储，同时提供了高效的数据访问速度。延迟较低，接入在线业务使用 适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。 主要解决的是hdfs只能追加的写入方式的不足 Hive Hive是Hadoop数据仓库，主要是让开发人员能够通过SQL来计算和处理HDFS上的结构化数据，本质其实就相当于将 HDFS 中已经存储的文件在 Mysql 中做了一个双射关系，以方便使用 HQL 去管理查询。 适用于离线的批量数据计算，延迟较高 Hive 存储的数据依旧在 DataNode 上，编写的 HQL 语句终将是转换为 MapReduce 代码执行。 2、Hive体系架构 1）用户接口 Client：Hive提供了客户与HDFS之间交互的接口，如Web UI、Hive命令行(CLI)、HD Insight等。 2）元数据 Meta Store：Hive使用了独立的SQL数据库(默认为derby)来存放关于表名、表所属数据库、列/分区字段、表的类型(内部表还是外部表)、等等的元数据 3）驱动器 Driver &nbsp; &nbsp;1、HQL处理引擎 HQL Process Engine 解析器 SQL Parser：将HQL字符串转换成抽象语法树AST，这一步一般由第三方工具完成。解析器对AST语法分析，比如表是否存在、字段是否存在、HQL语句有无语法错误等 编译器 Physical Plan：将AST编译生成逻辑执行计划 优化器 Query Optimizer：对逻辑计划进行优化 &nbsp; &nbsp; 2、执行引擎 Execution Engine：把逻辑计划转换成可以运行的物理计划(MapReduce程序) 4）HDFS或HBase：hdfs或者Hbase是将数据存储到分布式文件系统中的技术 3、工作流程 1、执行查询 Hive的用户接口发送查询指令到数据库驱动程序Driver(如JDBC、ODBC) 2、获取计划 解析器先将用户发送的HQL字符串转换成抽象语法树AST，具体会检查语法和查询计划或查询的需求。然后编译器将AST编译生成逻辑执行计划 3、获取元数据 编译器会根据查询计划向存储元数据的数据库发送请求，要求获取有关元数据&nbsp; 4、发送元数据 元数据所在数据库发送需要使用到相关表的元数据，作为对编译器的响应 5、发送计划 编译器检查需求并由优化器进行优化逻辑计划，然后将计划发送给Driver。到此为止，解析并编译查询的过程已经完成了 6、执行计划 Driver发送执行计划到执行引擎 7、执行任务 执行引擎将逻辑计划翻译成MapReduce任务，再发送任务给JobTracker，JobTracker会将任务分配给TaskTracker。 7.1、元数据操作 与7同时，执行引擎会执行与元数据有关的操作 8、获取结果 执行引擎接受到了来自datanode中TaskTacker的运行结果 9、执行引擎端发送结果 执行引擎将结果发送给Driver 10、Driver端发送结果 Driver将结果发送给用户接口 总结来说：Hive通过用户提供的一系列交互交口，接受到用户的指令，使用Hive自身的Driver，结合元数据将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行返回结果输出到用户接口 &nbsp;" />
<meta property="og:description" content="目录 1、Hive概述 1.1、Hive是什么 1.2、数据仓库的特点 1.3、Hive优缺点 1.3.1、优点 1.3.2、缺点 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 1.4.2、更新 1.4.3、索引 1.4.4、数据存储 1.4.5、可扩展性 1.5、Hive与HBase 2、Hive体系架构 3、工作流程 1、Hive概述 1.1、Hive是什么 Hive是由Facebook开源用于解决海量结构化日志的数据统计，是分析数据的框架。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射成一张表，并提供了类SQL查询功能。本质是将HQL转化为MapReduce程序。Hive类似于一个Hadoop的客户端，所以Hive并非集群。 Hive处理的数据存储于HDFS上 Hive分析数据底层实现的是MapReduce 执行程序运行在Yarn上 使用大象的鼻子去采花即数据流大；蜜蜂产蜜即分析结果 1.2、数据仓库的特点 数据仓库是面向主题的、集成的、时变的、非易失的 面向主题的：数据仓库围绕一些主题，如顾客、供应商、产品和销售来组织。数据仓库关注决策者的数据建模与分析，而不是组织机构的日常操作和事务处理。因此，数据仓库排除对于决策支持过程无用的数据，提供特定主题的简明视图。 集成的：通常，构造数据仓库是将多个异构数据源，如关系数据库、一般文件和联机事务记录集成在一起。使用数据清理和数据集成技术确保命名约定、编码结构、属性度量等的一致性。 时变的：数据存储从历史的角度提供信息，数据仓库中的关键结构都隐式或显式地包含时间元素。 非易失的：数据仓库总是物理地分别存放数据，这些数据源于操作环境下的应用数据。由于这种分离，数据仓库不需要事务处理，恢复和并发控制机制。通常，它只需要两种数据访问操作：数据的初始化装入和数据访问。 1.3、Hive优缺点 1.3.1、优点 1）Hive提供了类似于SQL的HQL语言来查询储存在hdfs上的数据 2）Hive可以将大多数的查询转换为MapReduce任务 3）Hive适合数据仓库应用程序，常用于静态数据分析，执行延迟比较高，适合不需要快速响应给出结果的场合 4）Hive的优势在于处理大数据集，因为Hive执行延迟较高 5）Hive支持用户自定义函(UDF)，扩展性好 1.3.2、缺点 1）Hive不支持记录级别的更新、插入或者删除，但用户可以通过查询生成新表或将查询结果导入到文件中 2）Hive查询延时比较严重，因为Hadoop是面向批处理的系统，而MapReduce的启动过程需要消耗一段时间，并且粒度较粗调优比较困难 3）Hive不支持事务，也就是说不支持OLTP(联机事务处理)所需的关键功能ACID。而更接近于OLAP(联机分析技术)，适合离线处理大数据集，虽然还未满足OLAP中OL部分 4）HQL表达能力有限，无法表达迭代式算法，所以在数据挖掘方面不太擅长 5）Hive会自动生成MapReduce作业，通常不够智能化 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 写时模式 传统数据库中采用的是写时模式，表的模式实在数据加载时强制确定的，如果在加载时发现数据不符合模式，则拒绝加载数据。数据在写入数据库时对照模式检查。写时模式有利于提升查询性能，因为数据库可以对列进行索引，并对数据进行压缩。 读时模式 Hive对数据的验证则是在查询时进行的，这有利于大数据集的导入，读时模式使数据的加载非常迅速，数据的加载仅是文件复制或移动。 1.4.2、更新 Hive是针对数据仓库应用设计的，所以数仓的内容是读多写少的。Hive中不建议对数据进行改写，所有数据都是在加载的时候确定好的；而数据库中的数据通常是需要经常进行修改的。 1.4.3、索引 Hive要访问数据中特定数据时，需要全表扫描，因此访问延迟较高。由于MapReduce的引入，Hive可以并行访问数据，在大数据的访问上仍然具有优势。Hive只提供了有限的索引功能，可以为一些字段建立索引，一张表的索引数据存储在另外一张表中。由于数据的访问延迟较高，Hive不适合在线数据查询；数据库在少量的特定条件的数据访问中，索引可以提供较低的延迟。 1.4.4、数据存储 Hive是建立在Hadoop之上的，所有Hive的数据都是存储在hdfs中的，而metastore元数据建议存储在独立的关系型数据库中；数据库则将数据存储在块设备或者本地文件系统中。 1.4.5、可扩展性 由于Hive是建立在Hadoop之上的，因此Hive具有良好的可扩展性；数据库由于ACID语义的严格限制，扩展性十分有限 1.5、Hive与HBase Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。 Hbase hbase是基于Hadoop数据库，是一种NoSQL数据库，用于存储HDFS中结构化和非结构化的数据。数据持久化存储的体现形式是 Hfile，存放于 DataNode 中，被 ResionServer 以 Region 的形式进行管理 HBase 可以实现单表大量数据的存储，同时提供了高效的数据访问速度。延迟较低，接入在线业务使用 适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。 主要解决的是hdfs只能追加的写入方式的不足 Hive Hive是Hadoop数据仓库，主要是让开发人员能够通过SQL来计算和处理HDFS上的结构化数据，本质其实就相当于将 HDFS 中已经存储的文件在 Mysql 中做了一个双射关系，以方便使用 HQL 去管理查询。 适用于离线的批量数据计算，延迟较高 Hive 存储的数据依旧在 DataNode 上，编写的 HQL 语句终将是转换为 MapReduce 代码执行。 2、Hive体系架构 1）用户接口 Client：Hive提供了客户与HDFS之间交互的接口，如Web UI、Hive命令行(CLI)、HD Insight等。 2）元数据 Meta Store：Hive使用了独立的SQL数据库(默认为derby)来存放关于表名、表所属数据库、列/分区字段、表的类型(内部表还是外部表)、等等的元数据 3）驱动器 Driver &nbsp; &nbsp;1、HQL处理引擎 HQL Process Engine 解析器 SQL Parser：将HQL字符串转换成抽象语法树AST，这一步一般由第三方工具完成。解析器对AST语法分析，比如表是否存在、字段是否存在、HQL语句有无语法错误等 编译器 Physical Plan：将AST编译生成逻辑执行计划 优化器 Query Optimizer：对逻辑计划进行优化 &nbsp; &nbsp; 2、执行引擎 Execution Engine：把逻辑计划转换成可以运行的物理计划(MapReduce程序) 4）HDFS或HBase：hdfs或者Hbase是将数据存储到分布式文件系统中的技术 3、工作流程 1、执行查询 Hive的用户接口发送查询指令到数据库驱动程序Driver(如JDBC、ODBC) 2、获取计划 解析器先将用户发送的HQL字符串转换成抽象语法树AST，具体会检查语法和查询计划或查询的需求。然后编译器将AST编译生成逻辑执行计划 3、获取元数据 编译器会根据查询计划向存储元数据的数据库发送请求，要求获取有关元数据&nbsp; 4、发送元数据 元数据所在数据库发送需要使用到相关表的元数据，作为对编译器的响应 5、发送计划 编译器检查需求并由优化器进行优化逻辑计划，然后将计划发送给Driver。到此为止，解析并编译查询的过程已经完成了 6、执行计划 Driver发送执行计划到执行引擎 7、执行任务 执行引擎将逻辑计划翻译成MapReduce任务，再发送任务给JobTracker，JobTracker会将任务分配给TaskTracker。 7.1、元数据操作 与7同时，执行引擎会执行与元数据有关的操作 8、获取结果 执行引擎接受到了来自datanode中TaskTacker的运行结果 9、执行引擎端发送结果 执行引擎将结果发送给Driver 10、Driver端发送结果 Driver将结果发送给用户接口 总结来说：Hive通过用户提供的一系列交互交口，接受到用户的指令，使用Hive自身的Driver，结合元数据将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行返回结果输出到用户接口 &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/07/14/793589.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/14/793589.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-14T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 1、Hive概述 1.1、Hive是什么 1.2、数据仓库的特点 1.3、Hive优缺点 1.3.1、优点 1.3.2、缺点 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 1.4.2、更新 1.4.3、索引 1.4.4、数据存储 1.4.5、可扩展性 1.5、Hive与HBase 2、Hive体系架构 3、工作流程 1、Hive概述 1.1、Hive是什么 Hive是由Facebook开源用于解决海量结构化日志的数据统计，是分析数据的框架。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射成一张表，并提供了类SQL查询功能。本质是将HQL转化为MapReduce程序。Hive类似于一个Hadoop的客户端，所以Hive并非集群。 Hive处理的数据存储于HDFS上 Hive分析数据底层实现的是MapReduce 执行程序运行在Yarn上 使用大象的鼻子去采花即数据流大；蜜蜂产蜜即分析结果 1.2、数据仓库的特点 数据仓库是面向主题的、集成的、时变的、非易失的 面向主题的：数据仓库围绕一些主题，如顾客、供应商、产品和销售来组织。数据仓库关注决策者的数据建模与分析，而不是组织机构的日常操作和事务处理。因此，数据仓库排除对于决策支持过程无用的数据，提供特定主题的简明视图。 集成的：通常，构造数据仓库是将多个异构数据源，如关系数据库、一般文件和联机事务记录集成在一起。使用数据清理和数据集成技术确保命名约定、编码结构、属性度量等的一致性。 时变的：数据存储从历史的角度提供信息，数据仓库中的关键结构都隐式或显式地包含时间元素。 非易失的：数据仓库总是物理地分别存放数据，这些数据源于操作环境下的应用数据。由于这种分离，数据仓库不需要事务处理，恢复和并发控制机制。通常，它只需要两种数据访问操作：数据的初始化装入和数据访问。 1.3、Hive优缺点 1.3.1、优点 1）Hive提供了类似于SQL的HQL语言来查询储存在hdfs上的数据 2）Hive可以将大多数的查询转换为MapReduce任务 3）Hive适合数据仓库应用程序，常用于静态数据分析，执行延迟比较高，适合不需要快速响应给出结果的场合 4）Hive的优势在于处理大数据集，因为Hive执行延迟较高 5）Hive支持用户自定义函(UDF)，扩展性好 1.3.2、缺点 1）Hive不支持记录级别的更新、插入或者删除，但用户可以通过查询生成新表或将查询结果导入到文件中 2）Hive查询延时比较严重，因为Hadoop是面向批处理的系统，而MapReduce的启动过程需要消耗一段时间，并且粒度较粗调优比较困难 3）Hive不支持事务，也就是说不支持OLTP(联机事务处理)所需的关键功能ACID。而更接近于OLAP(联机分析技术)，适合离线处理大数据集，虽然还未满足OLAP中OL部分 4）HQL表达能力有限，无法表达迭代式算法，所以在数据挖掘方面不太擅长 5）Hive会自动生成MapReduce作业，通常不够智能化 1.4、Hive与传统数据库对比 1.4.1、读时模式与写时模式 写时模式 传统数据库中采用的是写时模式，表的模式实在数据加载时强制确定的，如果在加载时发现数据不符合模式，则拒绝加载数据。数据在写入数据库时对照模式检查。写时模式有利于提升查询性能，因为数据库可以对列进行索引，并对数据进行压缩。 读时模式 Hive对数据的验证则是在查询时进行的，这有利于大数据集的导入，读时模式使数据的加载非常迅速，数据的加载仅是文件复制或移动。 1.4.2、更新 Hive是针对数据仓库应用设计的，所以数仓的内容是读多写少的。Hive中不建议对数据进行改写，所有数据都是在加载的时候确定好的；而数据库中的数据通常是需要经常进行修改的。 1.4.3、索引 Hive要访问数据中特定数据时，需要全表扫描，因此访问延迟较高。由于MapReduce的引入，Hive可以并行访问数据，在大数据的访问上仍然具有优势。Hive只提供了有限的索引功能，可以为一些字段建立索引，一张表的索引数据存储在另外一张表中。由于数据的访问延迟较高，Hive不适合在线数据查询；数据库在少量的特定条件的数据访问中，索引可以提供较低的延迟。 1.4.4、数据存储 Hive是建立在Hadoop之上的，所有Hive的数据都是存储在hdfs中的，而metastore元数据建议存储在独立的关系型数据库中；数据库则将数据存储在块设备或者本地文件系统中。 1.4.5、可扩展性 由于Hive是建立在Hadoop之上的，因此Hive具有良好的可扩展性；数据库由于ACID语义的严格限制，扩展性十分有限 1.5、Hive与HBase Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。 Hbase hbase是基于Hadoop数据库，是一种NoSQL数据库，用于存储HDFS中结构化和非结构化的数据。数据持久化存储的体现形式是 Hfile，存放于 DataNode 中，被 ResionServer 以 Region 的形式进行管理 HBase 可以实现单表大量数据的存储，同时提供了高效的数据访问速度。延迟较低，接入在线业务使用 适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。 主要解决的是hdfs只能追加的写入方式的不足 Hive Hive是Hadoop数据仓库，主要是让开发人员能够通过SQL来计算和处理HDFS上的结构化数据，本质其实就相当于将 HDFS 中已经存储的文件在 Mysql 中做了一个双射关系，以方便使用 HQL 去管理查询。 适用于离线的批量数据计算，延迟较高 Hive 存储的数据依旧在 DataNode 上，编写的 HQL 语句终将是转换为 MapReduce 代码执行。 2、Hive体系架构 1）用户接口 Client：Hive提供了客户与HDFS之间交互的接口，如Web UI、Hive命令行(CLI)、HD Insight等。 2）元数据 Meta Store：Hive使用了独立的SQL数据库(默认为derby)来存放关于表名、表所属数据库、列/分区字段、表的类型(内部表还是外部表)、等等的元数据 3）驱动器 Driver &nbsp; &nbsp;1、HQL处理引擎 HQL Process Engine 解析器 SQL Parser：将HQL字符串转换成抽象语法树AST，这一步一般由第三方工具完成。解析器对AST语法分析，比如表是否存在、字段是否存在、HQL语句有无语法错误等 编译器 Physical Plan：将AST编译生成逻辑执行计划 优化器 Query Optimizer：对逻辑计划进行优化 &nbsp; &nbsp; 2、执行引擎 Execution Engine：把逻辑计划转换成可以运行的物理计划(MapReduce程序) 4）HDFS或HBase：hdfs或者Hbase是将数据存储到分布式文件系统中的技术 3、工作流程 1、执行查询 Hive的用户接口发送查询指令到数据库驱动程序Driver(如JDBC、ODBC) 2、获取计划 解析器先将用户发送的HQL字符串转换成抽象语法树AST，具体会检查语法和查询计划或查询的需求。然后编译器将AST编译生成逻辑执行计划 3、获取元数据 编译器会根据查询计划向存储元数据的数据库发送请求，要求获取有关元数据&nbsp; 4、发送元数据 元数据所在数据库发送需要使用到相关表的元数据，作为对编译器的响应 5、发送计划 编译器检查需求并由优化器进行优化逻辑计划，然后将计划发送给Driver。到此为止，解析并编译查询的过程已经完成了 6、执行计划 Driver发送执行计划到执行引擎 7、执行任务 执行引擎将逻辑计划翻译成MapReduce任务，再发送任务给JobTracker，JobTracker会将任务分配给TaskTracker。 7.1、元数据操作 与7同时，执行引擎会执行与元数据有关的操作 8、获取结果 执行引擎接受到了来自datanode中TaskTacker的运行结果 9、执行引擎端发送结果 执行引擎将结果发送给Driver 10、Driver端发送结果 Driver将结果发送给用户接口 总结来说：Hive通过用户提供的一系列交互交口，接受到用户的指令，使用Hive自身的Driver，结合元数据将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行返回结果输出到用户接口 &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/07/14/793589.html","headline":"Hive：概述、体系架构、工作流程","dateModified":"2019-07-14T00:00:00+08:00","datePublished":"2019-07-14T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/14/793589.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Hive：概述、体系架构、工作流程</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="1%E3%80%81Hive%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#1%E3%80%81Hive%E6%A6%82%E8%BF%B0" rel="nofollow" data-token="3ccd26fc645eb0c2aecab2910c507c39">1、Hive概述</a></p> 
  <p id="1.1%E3%80%81Hive%E6%98%AF%E4%BB%80%E4%B9%88-toc" style="margin-left:40px;"><a href="#1.1%E3%80%81Hive%E6%98%AF%E4%BB%80%E4%B9%88" rel="nofollow" data-token="eb0f9c716ee173bdf04b568acfd380b5">1.1、Hive是什么</a></p> 
  <p id="1.2%E3%80%81%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E7%89%B9%E7%82%B9-toc" style="margin-left:40px;"><a href="#1.2%E3%80%81%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E7%89%B9%E7%82%B9" rel="nofollow" data-token="2cbb9cc1a6aca2ae11b410851154f628">1.2、数据仓库的特点</a></p> 
  <p id="Hive%E4%BC%98%E7%BC%BA%E7%82%B9-toc" style="margin-left:40px;"><a href="#Hive%E4%BC%98%E7%BC%BA%E7%82%B9" rel="nofollow" data-token="1135fb1fde3c4a03ffce39e902a1960f">1.3、Hive优缺点</a></p> 
  <p id="1.3.1%E3%80%81%E4%BC%98%E7%82%B9-toc" style="margin-left:80px;"><a href="#1.3.1%E3%80%81%E4%BC%98%E7%82%B9" rel="nofollow" data-token="26ab7db5787ced95ec7a1de91ea87eca">1.3.1、优点</a></p> 
  <p id="1.3.2%E3%80%81%E7%BC%BA%E7%82%B9-toc" style="margin-left:80px;"><a href="#1.3.2%E3%80%81%E7%BC%BA%E7%82%B9" rel="nofollow" data-token="9cd3af8d15ca36acf093a83c9d134870">1.3.2、缺点</a></p> 
  <p id="Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94-toc" style="margin-left:40px;"><a href="#Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94" rel="nofollow" data-token="39b4898d0e6f7e3506efcff45df4f8dd">1.4、Hive与传统数据库对比</a></p> 
  <p id="%E8%AF%BB%E6%97%B6%E6%A8%A1%E5%BC%8F-toc" style="margin-left:80px;"><a href="#%E8%AF%BB%E6%97%B6%E6%A8%A1%E5%BC%8F" rel="nofollow" data-token="3f197b415473ebbdd71d5c7771d1442e">1.4.1、读时模式与写时模式</a></p> 
  <p id="%E6%9B%B4%E6%96%B0%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%E6%9B%B4%E6%96%B0%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E7%B4%A2%E5%BC%95" rel="nofollow" data-token="c2ab9c070d4989f5543fbbe1ba61be23">1.4.2、更新</a></p> 
  <p id="1.4.3%E3%80%81%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#1.4.3%E3%80%81%E7%B4%A2%E5%BC%95" rel="nofollow" data-token="d1952384ffb69a674b771a90fe551ac5">1.4.3、索引</a></p> 
  <p id="1.4.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8-toc" style="margin-left:80px;"><a href="#1.4.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8" rel="nofollow" data-token="5befd9fb579f2df14d91a2de8c379618">1.4.4、数据存储</a></p> 
  <p id="1.4.5%E3%80%81%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7-toc" style="margin-left:80px;"><a href="#1.4.5%E3%80%81%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7" rel="nofollow" data-token="e03de9eaebab7a99cabac7f3224988d5">1.4.5、可扩展性</a></p> 
  <p id="Hive%E4%B8%8EHBase-toc" style="margin-left:40px;"><a href="#Hive%E4%B8%8EHBase" rel="nofollow" data-token="8037d4b7d4c8fba98d3a17751902f7b8">1.5、Hive与HBase</a></p> 
  <p id="%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84-toc" style="margin-left:0px;"><a href="#%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84" rel="nofollow" data-token="47bbb32f974eb848fb72142f602798c0">2、Hive体系架构</a></p> 
  <p id="%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-toc" style="margin-left:0px;"><a href="#%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B" rel="nofollow" data-token="e0f9becd5ecfb65a775f7e4919e30f35">3、工作流程</a></p> 
  <hr id="hr-toc">
  <h1 id="1%E3%80%81Hive%E6%A6%82%E8%BF%B0">1、Hive概述</h1> 
  <h2 id="1.1%E3%80%81Hive%E6%98%AF%E4%BB%80%E4%B9%88">1.1、Hive是什么</h2> 
  <p>Hive是由Facebook开源用于解决海量结构化日志的数据统计，是分析数据的框架。<br> Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射成一张表，并提供了类SQL查询功能。本质是将HQL转化为MapReduce程序。Hive类似于一个Hadoop的客户端，所以Hive并非集群。</p> 
  <ul>
   <li>Hive处理的数据存储于HDFS上</li> 
   <li>Hive分析数据底层实现的是MapReduce</li> 
   <li>执行程序运行在Yarn上</li> 
  </ul>
  <p><img alt="" class="has" height="108" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716205546425.png" width="142"></p> 
  <p>使用大象的鼻子去采花即数据流大；蜜蜂产蜜即分析结果</p> 
  <h2 id="1.2%E3%80%81%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E7%89%B9%E7%82%B9">1.2、数据仓库的特点</h2> 
  <p>数据仓库是面向主题的、集成的、时变的、非易失的</p> 
  <ul>
   <li>面向主题的：数据仓库围绕一些主题，如顾客、供应商、产品和销售来组织。数据仓库关注决策者的数据建模与分析，而不是组织机构的日常操作和事务处理。因此，数据仓库排除对于决策支持过程无用的数据，提供特定主题的简明视图。</li> 
   <li>集成的：通常，构造数据仓库是将多个异构数据源，如关系数据库、一般文件和联机事务记录集成在一起。使用数据清理和数据集成技术确保命名约定、编码结构、属性度量等的一致性。</li> 
   <li>时变的：数据存储从历史的角度提供信息，数据仓库中的关键结构都隐式或显式地包含时间元素。</li> 
   <li>非易失的：数据仓库总是物理地分别存放数据，这些数据源于操作环境下的应用数据。由于这种分离，数据仓库不需要事务处理，恢复和并发控制机制。通常，它只需要两种数据访问操作：数据的初始化装入和数据访问。</li> 
  </ul>
  <h2 id="Hive%E4%BC%98%E7%BC%BA%E7%82%B9">1.3、Hive优缺点</h2> 
  <h3 id="1.3.1%E3%80%81%E4%BC%98%E7%82%B9">1.3.1、优点</h3> 
  <p>1）Hive提供了类似于SQL的HQL语言来查询储存在hdfs上的数据</p> 
  <p>2）Hive可以将大多数的查询转换为MapReduce任务</p> 
  <p>3）Hive适合数据仓库应用程序，常用于静态数据分析，执行延迟比较高，适合不需要快速响应给出结果的场合</p> 
  <p>4）Hive的优势在于处理大数据集，因为Hive执行延迟较高</p> 
  <p>5）Hive支持用户自定义函(UDF)，扩展性好</p> 
  <h3 id="1.3.2%E3%80%81%E7%BC%BA%E7%82%B9"><strong>1.3.2、缺点</strong></h3> 
  <p>1）Hive不支持记录级别的更新、插入或者删除，但用户可以通过查询生成新表或将查询结果导入到文件中</p> 
  <p>2）Hive查询延时比较严重，因为Hadoop是面向批处理的系统，而MapReduce的启动过程需要消耗一段时间，并且粒度较粗调优比较困难</p> 
  <p>3）Hive不支持事务，也就是说不支持OLTP(联机事务处理)所需的关键功能ACID。而更接近于OLAP(联机分析技术)，适合离线处理大数据集，虽然还未满足OLAP中OL部分</p> 
  <p>4）HQL表达能力有限，无法表达迭代式算法，所以在数据挖掘方面不太擅长</p> 
  <p>5）Hive会自动生成MapReduce作业，通常不够智能化</p> 
  <h2 id="Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94">1.4、Hive与传统数据库对比</h2> 
  <h3 id="%E8%AF%BB%E6%97%B6%E6%A8%A1%E5%BC%8F">1.4.1、读时模式与写时模式</h3> 
  <p><strong>写时模式</strong></p> 
  <p>传统数据库中采用的是写时模式，表的模式实在数据加载时强制确定的，如果在加载时发现数据不符合模式，则拒绝加载数据。数据在写入数据库时对照模式检查。写时模式有利于提升查询性能，因为数据库可以对列进行索引，并对数据进行压缩。</p> 
  <p><strong>读时模式</strong></p> 
  <p>Hive对数据的验证则是在查询时进行的，这有利于大数据集的导入，读时模式使数据的加载非常迅速，数据的加载仅是文件复制或移动。</p> 
  <h3 id="%E6%9B%B4%E6%96%B0%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E7%B4%A2%E5%BC%95">1.4.2、更新</h3> 
  <p>Hive是针对数据仓库应用设计的，所以数仓的内容是读多写少的。Hive中不建议对数据进行改写，所有数据都是在加载的时候确定好的；而数据库中的数据通常是需要经常进行修改的。</p> 
  <h3 id="1.4.3%E3%80%81%E7%B4%A2%E5%BC%95">1.4.3、索引</h3> 
  <p>Hive要访问数据中特定数据时，需要全表扫描，因此访问延迟较高。由于MapReduce的引入，Hive可以并行访问数据，在大数据的访问上仍然具有优势。Hive只提供了有限的索引功能，可以为一些字段建立索引，一张表的索引数据存储在另外一张表中。由于数据的访问延迟较高，Hive不适合在线数据查询；数据库在少量的特定条件的数据访问中，索引可以提供较低的延迟。</p> 
  <h3 id="1.4.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8">1.4.4、数据存储</h3> 
  <p>Hive是建立在Hadoop之上的，所有Hive的数据都是存储在hdfs中的，而metastore元数据建议存储在独立的关系型数据库中；数据库则将数据存储在块设备或者本地文件系统中。</p> 
  <h3 id="1.4.5%E3%80%81%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7">1.4.5、可扩展性</h3> 
  <p>由于Hive是建立在Hadoop之上的，因此Hive具有良好的可扩展性；数据库由于ACID语义的严格限制，扩展性十分有限</p> 
  <h2 id="Hive%E4%B8%8EHBase">1.5、Hive与HBase</h2> 
  <p>Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。</p> 
  <p><strong>Hbase</strong></p> 
  <p>hbase是基于Hadoop数据库，是一种NoSQL数据库，用于存储HDFS中结构化和非结构化的数据。数据持久化存储的体现形式是 Hfile，存放于 DataNode 中，被 ResionServer 以 Region 的形式进行管理</p> 
  <p>HBase 可以实现单表大量数据的存储，同时提供了高效的数据访问速度。延迟较低，接入在线业务使用</p> 
  <p>适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。</p> 
  <p>主要解决的是hdfs只能追加的写入方式的不足</p> 
  <p><strong>Hive</strong></p> 
  <p>Hive是Hadoop数据仓库，主要是让开发人员能够通过SQL来计算和处理HDFS上的结构化数据，本质其实就相当于将 HDFS 中已经存储的文件在 Mysql 中做了一个双射关系，以方便使用 HQL 去管理查询。</p> 
  <p>适用于离线的批量数据计算，延迟较高</p> 
  <p>Hive 存储的数据依旧在 DataNode 上，编写的 HQL 语句终将是转换为 MapReduce 代码执行。</p> 
  <h1 id="%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84">2、Hive体系架构</h1> 
  <p><img alt="" class="has" height="543" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716202501246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9qb2Rqb2QuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="1037"></p> 
  <p>1）用户接口 Client：Hive提供了客户与HDFS之间交互的接口，如Web UI、Hive命令行(CLI)、HD Insight等。</p> 
  <p>2）元数据 Meta Store：Hive使用了独立的SQL数据库(默认为derby)来存放关于表名、表所属数据库、列/分区字段、表的类型(内部表还是外部表)、等等的元数据</p> 
  <p>3）驱动器 Driver</p> 
  <p>&nbsp; &nbsp;1、HQL处理引擎 HQL Process Engine</p> 
  <ul>
   <li>解析器 SQL Parser：将HQL字符串转换成抽象语法树AST，这一步一般由第三方工具完成。解析器对AST语法分析，比如表是否存在、字段是否存在、HQL语句有无语法错误等</li> 
   <li>编译器 Physical Plan：将AST编译生成逻辑执行计划</li> 
   <li>优化器 Query Optimizer：对逻辑计划进行优化</li> 
  </ul>
  <p>&nbsp; &nbsp; 2、执行引擎 Execution Engine：把逻辑计划转换成可以运行的物理计划(MapReduce程序)</p> 
  <p>4）HDFS或HBase：hdfs或者Hbase是将数据存储到分布式文件系统中的技术</p> 
  <h1 id="%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B">3、工作流程</h1> 
  <p><img alt="" class="has" height="669" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190713224932361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9qb2Rqb2QuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" width="975"></p> 
  <p>1、执行查询</p> 
  <ul>
   <li>Hive的用户接口发送查询指令到数据库驱动程序Driver(如JDBC、ODBC)</li> 
  </ul>
  <p>2、获取计划</p> 
  <ul>
   <li>解析器先将用户发送的HQL字符串转换成抽象语法树AST，具体会检查语法和查询计划或查询的需求。然后编译器将AST编译生成逻辑执行计划</li> 
  </ul>
  <p>3、获取元数据</p> 
  <ul>
   <li>编译器会根据查询计划向存储元数据的数据库发送请求，要求获取有关元数据&nbsp;</li> 
  </ul>
  <p>4、发送元数据</p> 
  <ul>
   <li>元数据所在数据库发送需要使用到相关表的元数据，作为对编译器的响应</li> 
  </ul>
  <p>5、发送计划</p> 
  <ul>
   <li>编译器检查需求并由优化器进行优化逻辑计划，然后将计划发送给Driver。到此为止，解析并编译查询的过程已经完成了</li> 
  </ul>
  <p>6、执行计划</p> 
  <ul>
   <li>Driver发送执行计划到执行引擎</li> 
  </ul>
  <p>7、执行任务</p> 
  <ul>
   <li>执行引擎将逻辑计划翻译成MapReduce任务，再发送任务给JobTracker，JobTracker会将任务分配给TaskTracker。</li> 
  </ul>
  <p>7.1、元数据操作</p> 
  <ul>
   <li>与7同时，执行引擎会执行与元数据有关的操作</li> 
  </ul>
  <p>8、获取结果</p> 
  <ul>
   <li>执行引擎接受到了来自datanode中TaskTacker的运行结果</li> 
  </ul>
  <p>9、执行引擎端发送结果</p> 
  <ul>
   <li>执行引擎将结果发送给Driver</li> 
  </ul>
  <p>10、Driver端发送结果</p> 
  <ul>
   <li>Driver将结果发送给用户接口</li> 
  </ul>
  <p>总结来说：Hive通过用户提供的一系列交互交口，接受到用户的指令，使用Hive自身的Driver，结合元数据将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行返回结果输出到用户接口</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
