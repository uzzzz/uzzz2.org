<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Spark源码第四篇——从Executor执行Task开始到结果输出 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Spark源码第四篇——从Executor执行Task开始到结果输出" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="上一篇传送门：https://blog.csdn.net/cw1254332663/article/details/95327497 学习的总结，不对之处请大家及时指正，谢谢啦！ 上回书到，CoarseGrainedSchedulerBackend中的内部类DriverEndpoint把TaskDescription序列化，封装到LaunchTask样例类中。 CoarseGrainedExecutorBackend中有一个方法用于接受消息： override def receive: PartialFunction[Any, Unit] = { // 接收到这个消息才会new一个executor case RegisteredExecutor =&gt; logInfo(&quot;Successfully registered with driver&quot;) try { executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false) } catch { case NonFatal(e) =&gt; exitExecutor(1, &quot;Unable to create executor due to &quot; + e.getMessage, e) } case RegisterExecutorFailed(message) =&gt; exitExecutor(1, &quot;Slave registration failed: &quot; + message) // 在这里我们模式匹配到这里 case LaunchTask(data) =&gt; // 判断Executor是否存在 if (executor == null) { exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;) } else { // 反序列化 val taskDesc = TaskDescription.decode(data.value) logInfo(&quot;Got assigned task &quot; + taskDesc.taskId) // 调用executor的执行方法来执行task executor.launchTask(this, taskDesc) } // 杀死 case KillTask(taskId, _, interruptThread, reason) =&gt; if (executor == null) { exitExecutor(1, &quot;Received KillTask command but executor was null&quot;) } else { executor.killTask(taskId, interruptThread, reason) } case StopExecutor =&gt; stopping.set(true) logInfo(&quot;Driver commanded a shutdown&quot;) self.send(Shutdown) case Shutdown =&gt; stopping.set(true) new Thread(&quot;CoarseGrainedExecutorBackend-stop-executor&quot;) { override def run(): Unit = { executor.stop() } }.start() } 看一下executor.launchTask方法： def launchTask(context: ExecutorBackend, taskDescription: TaskDescription): Unit = { // 把ExecutorBackend和TaskDescription封装到Runnable中 val tr = new TaskRunner(context, taskDescription) // 其中维护着正在运行的task的信息 runningTasks.put(taskDescription.taskId, tr) // 把Runnable放到线程池中去执行 threadPool.execute(tr) } 我们来看看TaskRunner中run方法的逻辑： override def run(): Unit = { /* 这里有一堆的信息获取代码 ...... */ // 获取序列化工具 val ser = env.closureSerializer.newInstance() logInfo(s&quot;Running $taskName (TID $taskId)&quot;) // 向集群调度程序更新状态 execBackend.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER) var taskStart: Long = 0 var taskStartCpu: Long = 0 startGCTime = computeTotalGcTime() try { Executor.taskDeserializationProps.set(taskDescription.properties) // 如果从SparkContext接收到一组新的文件和JAR，将会下载所有缺少的依赖项。 // 并且用类加载器去加载新的jar。 updateDependencies(taskDescription.addedFiles, taskDescription.addedJars) // 反序列化我们的task任务 task = ser.deserialize[Task[Any]]( taskDescription.serializedTask, Thread.currentThread.getContextClassLoader) task.localProperties = taskDescription.properties task.setTaskMemoryManager(taskMemoryManager) // 如果在反序列化此任务之前已将其终止，那么现在就会退出。否则，继续执行任务。 val killReason = reasonIfKilled if (killReason.isDefined) { throw new TaskKilledException(killReason.get) } logDebug(&quot;Task &quot; + taskId + &quot;&#39;s epoch is &quot; + task.epoch) env.mapOutputTracker.updateEpoch(task.epoch) // 运行实际的task，并且测量运行时情况 taskStart = System.currentTimeMillis() taskStartCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L var threwException = true val value = try { // 这里是主要的方法，运行task val res = task.run( taskAttemptId = taskId, attemptNumber = taskDescription.attemptNumber, metricsSystem = env.metricsSystem) threwException = false res } } ...... } 继续跟进task.run()方法中： final def run( taskAttemptId: Long, attemptNumber: Int, metricsSystem: MetricsSystem): T = { SparkEnv.get.blockManager.registerTask(taskAttemptId) //这里初始化了一些类 ...... try { //在这里调用了runTask方法 runTask(context) } ...... } 跟进shuffleMapTask.runTask方法： override def runTask(context: TaskContext): MapStatus = { val threadMXBean = ManagementFactory.getThreadMXBean val deserializeStartTime = System.currentTimeMillis() val deserializeStartCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L val ser = SparkEnv.get.closureSerializer.newInstance() // 使用广播变量反序列化RDD。taskBinary就是Broadcast[Array[Byte]] val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])]( ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader) _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime _executorDeserializeCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime - deserializeStartCpuTime } else 0L var writer: ShuffleWriter[Any, Any] = null try { // 获取shuffleManager， // 有三种shuffleMananger：Hash、Sort（默认）、Tungsten-sort，之后会出篇文章专门讲解。 val manager = SparkEnv.get.shuffleManager // 获取writer对象 writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context) // 这里可以分为两步 // 1. rdd的计算 // 2. 计算结果的存储 writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]]) writer.stop(success = true).get } catch { case e: Exception =&gt; try { if (writer != null) { writer.stop(success = false) } } catch { case e: Exception =&gt; log.debug(&quot;Could not stop writer&quot;, e) } throw e } } 我们先看第一步RDD的计算： final def iterator(split: Partition, context: TaskContext): Iterator[T] = { // 判断本RDD是否已经被持久化过 if (storageLevel != StorageLevel.NONE) { // 获取或计算RDD的一个分区 getOrCompute(split, context) } else { // 计算或读取checkpoint computeOrReadCheckpoint(split, context) } } 其中getOrCompute方法： private[spark] def getOrCompute(partition: Partition, context: TaskContext): Iterator[T] = { // 获取rdd的缓存块id val blockId = RDDBlockId(id, partition.index) var readCachedBlock = true // 如果指定的缓存块存在，则检索该缓存块 // 否则调用提供的“makeIterator”方法来计算该缓存块、保持该缓存块并返回其值。 // 如果缓存块存在，则返回blockresult；如果缓存块不存在，则返回迭代器。 SparkEnv.get.blockManager.getOrElseUpdate(blockId, storageLevel, elementClassTag, () =&gt; { readCachedBlock = false computeOrReadCheckpoint(partition, context) }) match { case Left(blockResult) =&gt; if (readCachedBlock) { val existingMetrics = context.taskMetrics().inputMetrics existingMetrics.incBytesRead(blockResult.bytes) new InterruptibleIterator[T](context, blockResult.data.asInstanceOf[Iterator[T]]) { override def next(): T = { existingMetrics.incRecordsRead(1) delegate.next() } } } else { new InterruptibleIterator(context, blockResult.data.asInstanceOf[Iterator[T]]) } case Right(iter) =&gt; new InterruptibleIterator(context, iter.asInstanceOf[Iterator[T]]) } } computeOrReadCheckpoint方法： private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] = { if (isCheckpointedAndMaterialized) { //调用父RDD的iterator方法 firstParent[T].iterator(split, context) } else { //调用计算逻辑进行计算 compute(split, context) } } 继续跟进compute（非shuffle算子生成的MapPartitionsRDD）方法： override def compute(split: Partition, context: TaskContext): Iterator[U] = // 此处调用父RDD的iterator方法 f(context, split.index, firstParent[T].iterator(split, context)) 而shuffle算子生成的RDD的compute方法： override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = { val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition] // 获取reader对象 val reader = SparkEnv.get.shuffleManager.getReader( dependency.shuffleHandle, shuffledRowPartition.startPreShufflePartitionIndex, shuffledRowPartition.endPreShufflePartitionIndex, context) // 调用read()方法，该方法向BlockManager获取上个rdd生成的中间文件的位置 reader.read().asInstanceOf[Iterator[Product2[Int, InternalRow]]].map(_._2) } 我们再看第二步writer.write(): override def write(records: Iterator[Product2[K, V]]): Unit = { sorter = if (dep.mapSideCombine) { require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;) // ExternalSorter中维护着两个内存结构，如果是聚合类算子如reduceByKey // 在溢出之前先放到Map结构中，在每次写入Map时需要判断大小是否到达一定阈值 // 到达之后溢出到缓冲区并清空该数据结构中的数据 // 缓冲区（默认32K）满了之后落地成文件 // 如果是join类普通的shuffle算子则使用Array结构 new ExternalSorter[K, V, C]( context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer) } else { // 在这种情况下，我们既不向ExternalSorter传递aggregate，也不向ExternalSorter传递sort // 因为我们不用关心key是否在每个分区中排序； // 如果正在运行的操作是sortbykey，那么将在reduce端进行排序。 new ExternalSorter[K, V, V]( context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer) } // 向内存结构（Map或Array）中写入数据，每次写入都需要判断是否要溢出 sorter.insertAll(records) // 在sortShuffleManager中，一个task输出一个文件和一个索引文件 val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId) // 目录中创建一个临时文件 val tmp = Utils.tempFileWith(output) try { val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID) // 将添加到ExternalSorter中的所有数据写入磁盘 val partitionLengths = sorter.writePartitionedFile(blockId, tmp) // 写一个索引文件，每个块的偏移量加上输出文件末尾的最终偏移量。 // 这被用于getBlockData获取数据时确定每个块的位置。 shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp) mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths) } finally { if (tmp.exists() &amp;&amp; !tmp.delete()) { logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;) } } } 这里有点多，以后慢慢的补充......" />
<meta property="og:description" content="上一篇传送门：https://blog.csdn.net/cw1254332663/article/details/95327497 学习的总结，不对之处请大家及时指正，谢谢啦！ 上回书到，CoarseGrainedSchedulerBackend中的内部类DriverEndpoint把TaskDescription序列化，封装到LaunchTask样例类中。 CoarseGrainedExecutorBackend中有一个方法用于接受消息： override def receive: PartialFunction[Any, Unit] = { // 接收到这个消息才会new一个executor case RegisteredExecutor =&gt; logInfo(&quot;Successfully registered with driver&quot;) try { executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false) } catch { case NonFatal(e) =&gt; exitExecutor(1, &quot;Unable to create executor due to &quot; + e.getMessage, e) } case RegisterExecutorFailed(message) =&gt; exitExecutor(1, &quot;Slave registration failed: &quot; + message) // 在这里我们模式匹配到这里 case LaunchTask(data) =&gt; // 判断Executor是否存在 if (executor == null) { exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;) } else { // 反序列化 val taskDesc = TaskDescription.decode(data.value) logInfo(&quot;Got assigned task &quot; + taskDesc.taskId) // 调用executor的执行方法来执行task executor.launchTask(this, taskDesc) } // 杀死 case KillTask(taskId, _, interruptThread, reason) =&gt; if (executor == null) { exitExecutor(1, &quot;Received KillTask command but executor was null&quot;) } else { executor.killTask(taskId, interruptThread, reason) } case StopExecutor =&gt; stopping.set(true) logInfo(&quot;Driver commanded a shutdown&quot;) self.send(Shutdown) case Shutdown =&gt; stopping.set(true) new Thread(&quot;CoarseGrainedExecutorBackend-stop-executor&quot;) { override def run(): Unit = { executor.stop() } }.start() } 看一下executor.launchTask方法： def launchTask(context: ExecutorBackend, taskDescription: TaskDescription): Unit = { // 把ExecutorBackend和TaskDescription封装到Runnable中 val tr = new TaskRunner(context, taskDescription) // 其中维护着正在运行的task的信息 runningTasks.put(taskDescription.taskId, tr) // 把Runnable放到线程池中去执行 threadPool.execute(tr) } 我们来看看TaskRunner中run方法的逻辑： override def run(): Unit = { /* 这里有一堆的信息获取代码 ...... */ // 获取序列化工具 val ser = env.closureSerializer.newInstance() logInfo(s&quot;Running $taskName (TID $taskId)&quot;) // 向集群调度程序更新状态 execBackend.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER) var taskStart: Long = 0 var taskStartCpu: Long = 0 startGCTime = computeTotalGcTime() try { Executor.taskDeserializationProps.set(taskDescription.properties) // 如果从SparkContext接收到一组新的文件和JAR，将会下载所有缺少的依赖项。 // 并且用类加载器去加载新的jar。 updateDependencies(taskDescription.addedFiles, taskDescription.addedJars) // 反序列化我们的task任务 task = ser.deserialize[Task[Any]]( taskDescription.serializedTask, Thread.currentThread.getContextClassLoader) task.localProperties = taskDescription.properties task.setTaskMemoryManager(taskMemoryManager) // 如果在反序列化此任务之前已将其终止，那么现在就会退出。否则，继续执行任务。 val killReason = reasonIfKilled if (killReason.isDefined) { throw new TaskKilledException(killReason.get) } logDebug(&quot;Task &quot; + taskId + &quot;&#39;s epoch is &quot; + task.epoch) env.mapOutputTracker.updateEpoch(task.epoch) // 运行实际的task，并且测量运行时情况 taskStart = System.currentTimeMillis() taskStartCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L var threwException = true val value = try { // 这里是主要的方法，运行task val res = task.run( taskAttemptId = taskId, attemptNumber = taskDescription.attemptNumber, metricsSystem = env.metricsSystem) threwException = false res } } ...... } 继续跟进task.run()方法中： final def run( taskAttemptId: Long, attemptNumber: Int, metricsSystem: MetricsSystem): T = { SparkEnv.get.blockManager.registerTask(taskAttemptId) //这里初始化了一些类 ...... try { //在这里调用了runTask方法 runTask(context) } ...... } 跟进shuffleMapTask.runTask方法： override def runTask(context: TaskContext): MapStatus = { val threadMXBean = ManagementFactory.getThreadMXBean val deserializeStartTime = System.currentTimeMillis() val deserializeStartCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L val ser = SparkEnv.get.closureSerializer.newInstance() // 使用广播变量反序列化RDD。taskBinary就是Broadcast[Array[Byte]] val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])]( ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader) _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime _executorDeserializeCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime - deserializeStartCpuTime } else 0L var writer: ShuffleWriter[Any, Any] = null try { // 获取shuffleManager， // 有三种shuffleMananger：Hash、Sort（默认）、Tungsten-sort，之后会出篇文章专门讲解。 val manager = SparkEnv.get.shuffleManager // 获取writer对象 writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context) // 这里可以分为两步 // 1. rdd的计算 // 2. 计算结果的存储 writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]]) writer.stop(success = true).get } catch { case e: Exception =&gt; try { if (writer != null) { writer.stop(success = false) } } catch { case e: Exception =&gt; log.debug(&quot;Could not stop writer&quot;, e) } throw e } } 我们先看第一步RDD的计算： final def iterator(split: Partition, context: TaskContext): Iterator[T] = { // 判断本RDD是否已经被持久化过 if (storageLevel != StorageLevel.NONE) { // 获取或计算RDD的一个分区 getOrCompute(split, context) } else { // 计算或读取checkpoint computeOrReadCheckpoint(split, context) } } 其中getOrCompute方法： private[spark] def getOrCompute(partition: Partition, context: TaskContext): Iterator[T] = { // 获取rdd的缓存块id val blockId = RDDBlockId(id, partition.index) var readCachedBlock = true // 如果指定的缓存块存在，则检索该缓存块 // 否则调用提供的“makeIterator”方法来计算该缓存块、保持该缓存块并返回其值。 // 如果缓存块存在，则返回blockresult；如果缓存块不存在，则返回迭代器。 SparkEnv.get.blockManager.getOrElseUpdate(blockId, storageLevel, elementClassTag, () =&gt; { readCachedBlock = false computeOrReadCheckpoint(partition, context) }) match { case Left(blockResult) =&gt; if (readCachedBlock) { val existingMetrics = context.taskMetrics().inputMetrics existingMetrics.incBytesRead(blockResult.bytes) new InterruptibleIterator[T](context, blockResult.data.asInstanceOf[Iterator[T]]) { override def next(): T = { existingMetrics.incRecordsRead(1) delegate.next() } } } else { new InterruptibleIterator(context, blockResult.data.asInstanceOf[Iterator[T]]) } case Right(iter) =&gt; new InterruptibleIterator(context, iter.asInstanceOf[Iterator[T]]) } } computeOrReadCheckpoint方法： private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] = { if (isCheckpointedAndMaterialized) { //调用父RDD的iterator方法 firstParent[T].iterator(split, context) } else { //调用计算逻辑进行计算 compute(split, context) } } 继续跟进compute（非shuffle算子生成的MapPartitionsRDD）方法： override def compute(split: Partition, context: TaskContext): Iterator[U] = // 此处调用父RDD的iterator方法 f(context, split.index, firstParent[T].iterator(split, context)) 而shuffle算子生成的RDD的compute方法： override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = { val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition] // 获取reader对象 val reader = SparkEnv.get.shuffleManager.getReader( dependency.shuffleHandle, shuffledRowPartition.startPreShufflePartitionIndex, shuffledRowPartition.endPreShufflePartitionIndex, context) // 调用read()方法，该方法向BlockManager获取上个rdd生成的中间文件的位置 reader.read().asInstanceOf[Iterator[Product2[Int, InternalRow]]].map(_._2) } 我们再看第二步writer.write(): override def write(records: Iterator[Product2[K, V]]): Unit = { sorter = if (dep.mapSideCombine) { require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;) // ExternalSorter中维护着两个内存结构，如果是聚合类算子如reduceByKey // 在溢出之前先放到Map结构中，在每次写入Map时需要判断大小是否到达一定阈值 // 到达之后溢出到缓冲区并清空该数据结构中的数据 // 缓冲区（默认32K）满了之后落地成文件 // 如果是join类普通的shuffle算子则使用Array结构 new ExternalSorter[K, V, C]( context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer) } else { // 在这种情况下，我们既不向ExternalSorter传递aggregate，也不向ExternalSorter传递sort // 因为我们不用关心key是否在每个分区中排序； // 如果正在运行的操作是sortbykey，那么将在reduce端进行排序。 new ExternalSorter[K, V, V]( context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer) } // 向内存结构（Map或Array）中写入数据，每次写入都需要判断是否要溢出 sorter.insertAll(records) // 在sortShuffleManager中，一个task输出一个文件和一个索引文件 val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId) // 目录中创建一个临时文件 val tmp = Utils.tempFileWith(output) try { val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID) // 将添加到ExternalSorter中的所有数据写入磁盘 val partitionLengths = sorter.writePartitionedFile(blockId, tmp) // 写一个索引文件，每个块的偏移量加上输出文件末尾的最终偏移量。 // 这被用于getBlockData获取数据时确定每个块的位置。 shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp) mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths) } finally { if (tmp.exists() &amp;&amp; !tmp.delete()) { logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;) } } } 这里有点多，以后慢慢的补充......" />
<link rel="canonical" href="https://uzzz.org/2019/07/17/794271.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/17/794271.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"上一篇传送门：https://blog.csdn.net/cw1254332663/article/details/95327497 学习的总结，不对之处请大家及时指正，谢谢啦！ 上回书到，CoarseGrainedSchedulerBackend中的内部类DriverEndpoint把TaskDescription序列化，封装到LaunchTask样例类中。 CoarseGrainedExecutorBackend中有一个方法用于接受消息： override def receive: PartialFunction[Any, Unit] = { // 接收到这个消息才会new一个executor case RegisteredExecutor =&gt; logInfo(&quot;Successfully registered with driver&quot;) try { executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false) } catch { case NonFatal(e) =&gt; exitExecutor(1, &quot;Unable to create executor due to &quot; + e.getMessage, e) } case RegisterExecutorFailed(message) =&gt; exitExecutor(1, &quot;Slave registration failed: &quot; + message) // 在这里我们模式匹配到这里 case LaunchTask(data) =&gt; // 判断Executor是否存在 if (executor == null) { exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;) } else { // 反序列化 val taskDesc = TaskDescription.decode(data.value) logInfo(&quot;Got assigned task &quot; + taskDesc.taskId) // 调用executor的执行方法来执行task executor.launchTask(this, taskDesc) } // 杀死 case KillTask(taskId, _, interruptThread, reason) =&gt; if (executor == null) { exitExecutor(1, &quot;Received KillTask command but executor was null&quot;) } else { executor.killTask(taskId, interruptThread, reason) } case StopExecutor =&gt; stopping.set(true) logInfo(&quot;Driver commanded a shutdown&quot;) self.send(Shutdown) case Shutdown =&gt; stopping.set(true) new Thread(&quot;CoarseGrainedExecutorBackend-stop-executor&quot;) { override def run(): Unit = { executor.stop() } }.start() } 看一下executor.launchTask方法： def launchTask(context: ExecutorBackend, taskDescription: TaskDescription): Unit = { // 把ExecutorBackend和TaskDescription封装到Runnable中 val tr = new TaskRunner(context, taskDescription) // 其中维护着正在运行的task的信息 runningTasks.put(taskDescription.taskId, tr) // 把Runnable放到线程池中去执行 threadPool.execute(tr) } 我们来看看TaskRunner中run方法的逻辑： override def run(): Unit = { /* 这里有一堆的信息获取代码 ...... */ // 获取序列化工具 val ser = env.closureSerializer.newInstance() logInfo(s&quot;Running $taskName (TID $taskId)&quot;) // 向集群调度程序更新状态 execBackend.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER) var taskStart: Long = 0 var taskStartCpu: Long = 0 startGCTime = computeTotalGcTime() try { Executor.taskDeserializationProps.set(taskDescription.properties) // 如果从SparkContext接收到一组新的文件和JAR，将会下载所有缺少的依赖项。 // 并且用类加载器去加载新的jar。 updateDependencies(taskDescription.addedFiles, taskDescription.addedJars) // 反序列化我们的task任务 task = ser.deserialize[Task[Any]]( taskDescription.serializedTask, Thread.currentThread.getContextClassLoader) task.localProperties = taskDescription.properties task.setTaskMemoryManager(taskMemoryManager) // 如果在反序列化此任务之前已将其终止，那么现在就会退出。否则，继续执行任务。 val killReason = reasonIfKilled if (killReason.isDefined) { throw new TaskKilledException(killReason.get) } logDebug(&quot;Task &quot; + taskId + &quot;&#39;s epoch is &quot; + task.epoch) env.mapOutputTracker.updateEpoch(task.epoch) // 运行实际的task，并且测量运行时情况 taskStart = System.currentTimeMillis() taskStartCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L var threwException = true val value = try { // 这里是主要的方法，运行task val res = task.run( taskAttemptId = taskId, attemptNumber = taskDescription.attemptNumber, metricsSystem = env.metricsSystem) threwException = false res } } ...... } 继续跟进task.run()方法中： final def run( taskAttemptId: Long, attemptNumber: Int, metricsSystem: MetricsSystem): T = { SparkEnv.get.blockManager.registerTask(taskAttemptId) //这里初始化了一些类 ...... try { //在这里调用了runTask方法 runTask(context) } ...... } 跟进shuffleMapTask.runTask方法： override def runTask(context: TaskContext): MapStatus = { val threadMXBean = ManagementFactory.getThreadMXBean val deserializeStartTime = System.currentTimeMillis() val deserializeStartCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime } else 0L val ser = SparkEnv.get.closureSerializer.newInstance() // 使用广播变量反序列化RDD。taskBinary就是Broadcast[Array[Byte]] val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])]( ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader) _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime _executorDeserializeCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) { threadMXBean.getCurrentThreadCpuTime - deserializeStartCpuTime } else 0L var writer: ShuffleWriter[Any, Any] = null try { // 获取shuffleManager， // 有三种shuffleMananger：Hash、Sort（默认）、Tungsten-sort，之后会出篇文章专门讲解。 val manager = SparkEnv.get.shuffleManager // 获取writer对象 writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context) // 这里可以分为两步 // 1. rdd的计算 // 2. 计算结果的存储 writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]]) writer.stop(success = true).get } catch { case e: Exception =&gt; try { if (writer != null) { writer.stop(success = false) } } catch { case e: Exception =&gt; log.debug(&quot;Could not stop writer&quot;, e) } throw e } } 我们先看第一步RDD的计算： final def iterator(split: Partition, context: TaskContext): Iterator[T] = { // 判断本RDD是否已经被持久化过 if (storageLevel != StorageLevel.NONE) { // 获取或计算RDD的一个分区 getOrCompute(split, context) } else { // 计算或读取checkpoint computeOrReadCheckpoint(split, context) } } 其中getOrCompute方法： private[spark] def getOrCompute(partition: Partition, context: TaskContext): Iterator[T] = { // 获取rdd的缓存块id val blockId = RDDBlockId(id, partition.index) var readCachedBlock = true // 如果指定的缓存块存在，则检索该缓存块 // 否则调用提供的“makeIterator”方法来计算该缓存块、保持该缓存块并返回其值。 // 如果缓存块存在，则返回blockresult；如果缓存块不存在，则返回迭代器。 SparkEnv.get.blockManager.getOrElseUpdate(blockId, storageLevel, elementClassTag, () =&gt; { readCachedBlock = false computeOrReadCheckpoint(partition, context) }) match { case Left(blockResult) =&gt; if (readCachedBlock) { val existingMetrics = context.taskMetrics().inputMetrics existingMetrics.incBytesRead(blockResult.bytes) new InterruptibleIterator[T](context, blockResult.data.asInstanceOf[Iterator[T]]) { override def next(): T = { existingMetrics.incRecordsRead(1) delegate.next() } } } else { new InterruptibleIterator(context, blockResult.data.asInstanceOf[Iterator[T]]) } case Right(iter) =&gt; new InterruptibleIterator(context, iter.asInstanceOf[Iterator[T]]) } } computeOrReadCheckpoint方法： private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] = { if (isCheckpointedAndMaterialized) { //调用父RDD的iterator方法 firstParent[T].iterator(split, context) } else { //调用计算逻辑进行计算 compute(split, context) } } 继续跟进compute（非shuffle算子生成的MapPartitionsRDD）方法： override def compute(split: Partition, context: TaskContext): Iterator[U] = // 此处调用父RDD的iterator方法 f(context, split.index, firstParent[T].iterator(split, context)) 而shuffle算子生成的RDD的compute方法： override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = { val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition] // 获取reader对象 val reader = SparkEnv.get.shuffleManager.getReader( dependency.shuffleHandle, shuffledRowPartition.startPreShufflePartitionIndex, shuffledRowPartition.endPreShufflePartitionIndex, context) // 调用read()方法，该方法向BlockManager获取上个rdd生成的中间文件的位置 reader.read().asInstanceOf[Iterator[Product2[Int, InternalRow]]].map(_._2) } 我们再看第二步writer.write(): override def write(records: Iterator[Product2[K, V]]): Unit = { sorter = if (dep.mapSideCombine) { require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;) // ExternalSorter中维护着两个内存结构，如果是聚合类算子如reduceByKey // 在溢出之前先放到Map结构中，在每次写入Map时需要判断大小是否到达一定阈值 // 到达之后溢出到缓冲区并清空该数据结构中的数据 // 缓冲区（默认32K）满了之后落地成文件 // 如果是join类普通的shuffle算子则使用Array结构 new ExternalSorter[K, V, C]( context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer) } else { // 在这种情况下，我们既不向ExternalSorter传递aggregate，也不向ExternalSorter传递sort // 因为我们不用关心key是否在每个分区中排序； // 如果正在运行的操作是sortbykey，那么将在reduce端进行排序。 new ExternalSorter[K, V, V]( context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer) } // 向内存结构（Map或Array）中写入数据，每次写入都需要判断是否要溢出 sorter.insertAll(records) // 在sortShuffleManager中，一个task输出一个文件和一个索引文件 val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId) // 目录中创建一个临时文件 val tmp = Utils.tempFileWith(output) try { val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID) // 将添加到ExternalSorter中的所有数据写入磁盘 val partitionLengths = sorter.writePartitionedFile(blockId, tmp) // 写一个索引文件，每个块的偏移量加上输出文件末尾的最终偏移量。 // 这被用于getBlockData获取数据时确定每个块的位置。 shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp) mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths) } finally { if (tmp.exists() &amp;&amp; !tmp.delete()) { logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;) } } } 这里有点多，以后慢慢的补充......","@type":"BlogPosting","url":"https://uzzz.org/2019/07/17/794271.html","headline":"Spark源码第四篇——从Executor执行Task开始到结果输出","dateModified":"2019-07-17T00:00:00+08:00","datePublished":"2019-07-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/17/794271.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Spark源码第四篇——从Executor执行Task开始到结果输出</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>上一篇传送门：<a href="https://blog.csdn.net/cw1254332663/article/details/95327497" rel="nofollow" data-token="98285bd50bbfaee667a3cc17fe9aff68">https://blog.csdn.net/cw1254332663/article/details/95327497</a></p> 
  <p>学习的总结，不对之处请大家及时指正，谢谢啦！</p> 
  <p>上回书到，CoarseGrainedSchedulerBackend中的内部类DriverEndpoint把TaskDescription序列化，封装到LaunchTask样例类中。</p> 
  <p>CoarseGrainedExecutorBackend中有一个方法用于接受消息：</p> 
  <pre class="has">
<code>override def receive: PartialFunction[Any, Unit] = {
    // 接收到这个消息才会new一个executor
    case RegisteredExecutor =&gt;
      logInfo("Successfully registered with driver")
      try {
        executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false)
      } catch {
        case NonFatal(e) =&gt;
          exitExecutor(1, "Unable to create executor due to " + e.getMessage, e)
      }

    case RegisterExecutorFailed(message) =&gt;
      exitExecutor(1, "Slave registration failed: " + message)

    // 在这里我们模式匹配到这里
    case LaunchTask(data) =&gt;
      // 判断Executor是否存在
      if (executor == null) {
        exitExecutor(1, "Received LaunchTask command but executor was null")
      } else {
        // 反序列化
        val taskDesc = TaskDescription.decode(data.value)
        logInfo("Got assigned task " + taskDesc.taskId)
        // 调用executor的执行方法来执行task
        executor.launchTask(this, taskDesc)
      }

    // 杀死
    case KillTask(taskId, _, interruptThread, reason) =&gt;
      if (executor == null) {
        exitExecutor(1, "Received KillTask command but executor was null")
      } else {
        executor.killTask(taskId, interruptThread, reason)
      }

    case StopExecutor =&gt;
      stopping.set(true)
      logInfo("Driver commanded a shutdown")
      self.send(Shutdown)

    case Shutdown =&gt;
      stopping.set(true)
      new Thread("CoarseGrainedExecutorBackend-stop-executor") {
        override def run(): Unit = {
          executor.stop()
        }
      }.start()
  }</code></pre> 
  <p>看一下executor.launchTask方法：</p> 
  <pre class="has">
<code>def launchTask(context: ExecutorBackend, taskDescription: TaskDescription): Unit = {
    // 把ExecutorBackend和TaskDescription封装到Runnable中
    val tr = new TaskRunner(context, taskDescription)
    // 其中维护着正在运行的task的信息
    runningTasks.put(taskDescription.taskId, tr)
    // 把Runnable放到线程池中去执行
    threadPool.execute(tr)
  }</code></pre> 
  <p>我们来看看TaskRunner中run方法的逻辑：</p> 
  <pre class="has">
<code class="language-java">override def run(): Unit = {
      /*
       这里有一堆的信息获取代码
           ...... 
       */
      // 获取序列化工具
      val ser = env.closureSerializer.newInstance()
      logInfo(s"Running $taskName (TID $taskId)")
      // 向集群调度程序更新状态
      execBackend.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER)
      var taskStart: Long = 0
      var taskStartCpu: Long = 0
      startGCTime = computeTotalGcTime()
      try {
        Executor.taskDeserializationProps.set(taskDescription.properties)
        // 如果从SparkContext接收到一组新的文件和JAR，将会下载所有缺少的依赖项。
        // 并且用类加载器去加载新的jar。
        updateDependencies(taskDescription.addedFiles, taskDescription.addedJars)
        // 反序列化我们的task任务
        task = ser.deserialize[Task[Any]](
          taskDescription.serializedTask, Thread.currentThread.getContextClassLoader)
        task.localProperties = taskDescription.properties
        task.setTaskMemoryManager(taskMemoryManager)
        // 如果在反序列化此任务之前已将其终止，那么现在就会退出。否则，继续执行任务。
        val killReason = reasonIfKilled
        if (killReason.isDefined) {
          throw new TaskKilledException(killReason.get)
        }
        logDebug("Task " + taskId + "'s epoch is " + task.epoch)
        env.mapOutputTracker.updateEpoch(task.epoch)
        // 运行实际的task，并且测量运行时情况
        taskStart = System.currentTimeMillis()
        taskStartCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) {
          threadMXBean.getCurrentThreadCpuTime
        } else 0L
        var threwException = true
        val value = try {
          // 这里是主要的方法，运行task
          val res = task.run(
            taskAttemptId = taskId,
            attemptNumber = taskDescription.attemptNumber,
            metricsSystem = env.metricsSystem)
          threwException = false
          res
        } 
      }
        ......
    }</code></pre> 
  <p>继续跟进task.run()方法中：</p> 
  <pre class="has">
<code>final def run(
      taskAttemptId: Long,
      attemptNumber: Int,
      metricsSystem: MetricsSystem): T = {
    SparkEnv.get.blockManager.registerTask(taskAttemptId)
   
    //这里初始化了一些类
        ......

    try {
      //在这里调用了runTask方法
      runTask(context)
    } 

    ......
  }</code></pre> 
  <p>跟进shuffleMapTask.runTask方法：</p> 
  <pre class="has">
<code>override def runTask(context: TaskContext): MapStatus = {
    val threadMXBean = ManagementFactory.getThreadMXBean
    val deserializeStartTime = System.currentTimeMillis()
    val deserializeStartCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) {
      threadMXBean.getCurrentThreadCpuTime
    } else 0L
    val ser = SparkEnv.get.closureSerializer.newInstance()
    
    // 使用广播变量反序列化RDD。taskBinary就是Broadcast[Array[Byte]]
    val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])](
      ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
    _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime
    _executorDeserializeCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) {
      threadMXBean.getCurrentThreadCpuTime - deserializeStartCpuTime
    } else 0L

    var writer: ShuffleWriter[Any, Any] = null
    try {
      // 获取shuffleManager，
      // 有三种shuffleMananger：Hash、Sort（默认）、Tungsten-sort，之后会出篇文章专门讲解。
      val manager = SparkEnv.get.shuffleManager
      // 获取writer对象
      writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)
      // 这里可以分为两步
      // 1. rdd的计算
      // 2. 计算结果的存储
      writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]])
      writer.stop(success = true).get
    } catch {
      case e: Exception =&gt;
        try {
          if (writer != null) {
            writer.stop(success = false)
          }
        } catch {
          case e: Exception =&gt;
            log.debug("Could not stop writer", e)
        }
        throw e
    }
  }</code></pre> 
  <p>我们先看第一步RDD的计算：</p> 
  <pre class="has">
<code>final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
    // 判断本RDD是否已经被持久化过
    if (storageLevel != StorageLevel.NONE) {
      // 获取或计算RDD的一个分区
      getOrCompute(split, context)
    } else {
      // 计算或读取checkpoint
      computeOrReadCheckpoint(split, context)
    }
  }</code></pre> 
  <p>其中getOrCompute方法：</p> 
  <pre class="has">
<code>private[spark] def getOrCompute(partition: Partition, context: TaskContext): Iterator[T] = {
    // 获取rdd的缓存块id
    val blockId = RDDBlockId(id, partition.index)
    var readCachedBlock = true
    // 如果指定的缓存块存在，则检索该缓存块
    // 否则调用提供的“makeIterator”方法来计算该缓存块、保持该缓存块并返回其值。
    // 如果缓存块存在，则返回blockresult；如果缓存块不存在，则返回迭代器。
    SparkEnv.get.blockManager.getOrElseUpdate(blockId, storageLevel, elementClassTag, () =&gt; {
      readCachedBlock = false
      computeOrReadCheckpoint(partition, context)
    }) match {
      case Left(blockResult) =&gt;
        if (readCachedBlock) {
          val existingMetrics = context.taskMetrics().inputMetrics
          existingMetrics.incBytesRead(blockResult.bytes)
          new InterruptibleIterator[T](context, blockResult.data.asInstanceOf[Iterator[T]]) {
            override def next(): T = {
              existingMetrics.incRecordsRead(1)
              delegate.next()
            }
          }
        } else {
          new InterruptibleIterator(context, blockResult.data.asInstanceOf[Iterator[T]])
        }
      case Right(iter) =&gt;
        new InterruptibleIterator(context, iter.asInstanceOf[Iterator[T]])
    }
  }</code></pre> 
  <p>computeOrReadCheckpoint方法：</p> 
  <pre class="has">
<code>private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =
  {
    if (isCheckpointedAndMaterialized) {
      //调用父RDD的iterator方法
      firstParent[T].iterator(split, context)
    } else {
      //调用计算逻辑进行计算
      compute(split, context)
    }
  }</code></pre> 
  <p>继续跟进compute（非shuffle算子生成的MapPartitionsRDD）方法：</p> 
  <pre class="has">
<code>override def compute(split: Partition, context: TaskContext): Iterator[U] =
    // 此处调用父RDD的iterator方法
    f(context, split.index, firstParent[T].iterator(split, context))</code></pre> 
  <p>而shuffle算子生成的RDD的compute方法：</p> 
  <pre class="has">
<code>override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = {
    val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition]
    // 获取reader对象
    val reader =
      SparkEnv.get.shuffleManager.getReader(
        dependency.shuffleHandle,
        shuffledRowPartition.startPreShufflePartitionIndex,
        shuffledRowPartition.endPreShufflePartitionIndex,
        context)
    // 调用read()方法，该方法向BlockManager获取上个rdd生成的中间文件的位置
    reader.read().asInstanceOf[Iterator[Product2[Int, InternalRow]]].map(_._2)
  }</code></pre> 
  <p>我们再看第二步writer.write():</p> 
  <pre class="has">
<code>override def write(records: Iterator[Product2[K, V]]): Unit = {
    sorter = if (dep.mapSideCombine) {
      require(dep.aggregator.isDefined, "Map-side combine without Aggregator specified!")
      // ExternalSorter中维护着两个内存结构，如果是聚合类算子如reduceByKey
      // 在溢出之前先放到Map结构中，在每次写入Map时需要判断大小是否到达一定阈值
      // 到达之后溢出到缓冲区并清空该数据结构中的数据
      // 缓冲区（默认32K）满了之后落地成文件
      // 如果是join类普通的shuffle算子则使用Array结构
      new ExternalSorter[K, V, C](
        context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer)
    } else {
      // 在这种情况下，我们既不向ExternalSorter传递aggregate，也不向ExternalSorter传递sort
      // 因为我们不用关心key是否在每个分区中排序；
      // 如果正在运行的操作是sortbykey，那么将在reduce端进行排序。
      new ExternalSorter[K, V, V](
        context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer)
    }
    // 向内存结构（Map或Array）中写入数据，每次写入都需要判断是否要溢出
    sorter.insertAll(records)

    // 在sortShuffleManager中，一个task输出一个文件和一个索引文件
    val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)
    // 目录中创建一个临时文件
    val tmp = Utils.tempFileWith(output)
    try {
      val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID)
      // 将添加到ExternalSorter中的所有数据写入磁盘
      val partitionLengths = sorter.writePartitionedFile(blockId, tmp)
      // 写一个索引文件，每个块的偏移量加上输出文件末尾的最终偏移量。
      // 这被用于getBlockData获取数据时确定每个块的位置。
      shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp)
      mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths)
    } finally {
      if (tmp.exists() &amp;&amp; !tmp.delete()) {
        logError(s"Error while deleting temp file ${tmp.getAbsolutePath}")
      }
    }
  }</code></pre> 
  <p>这里有点多，以后慢慢的补充......</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
