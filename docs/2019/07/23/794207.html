<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大数据运维–生产环境处理问题汇总（持续更新中…….） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="大数据运维–生产环境处理问题汇总（持续更新中…….）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="2019.07.23 需求：现有的filebeat中新增数据源和部署新的filebeat服务器 处理过程： 1、 增加数据源 Filebeat安装目录 C:\Program Files\filebeat1\filebeat C:\Program Files\filebeat2\filebeat 编辑filebeat.yml 新增配置 input_type: log paths: - D:\DataServer\ExactEarth\OriginalData* document_type: AIS_20_ExactAis scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 2、 重新部署filebeat 这是从原来服务器上面拷贝过来的程序 Filebeat安装目录 C:\Program Files\filebeat1 C:\Program Files\filebeat2 注册服务 在Powershell直接脚本时会出现：无法加载文件 ******.ps1，因为在此系统中禁止执行脚本。 管理员身份运行powershell，执行 set-ExecutionPolicy RemoteSigned 编辑install-service-filebeat.ps1 ，修改服务名称为filebeat1或者filebeat2 New-Service -name filebeat1 displayName filebeat1 管理员身份运行powershell，执行 cd ‘C:\Program Files\filebeat1’ (这里路径有空格需要单引号)，再执行 ./ install-service-filebeat.ps1 ，服务注册完成 编辑配置文件filebeat.yml Filebeat输入源配置 input_type: log paths: d:\SpirePrediction\server\DataLogs* document_type: AIS_9_Spire_ANJI scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h filebeat输出到kafka配置 output.kafka: #The Logstash hosts hosts: [“xxx.xxx.xxx.xxx:9092”] enabled: true codec.format: string: ‘%{[message]}’ topic: ‘%{[type]}’ required_acks: 1 max_messages_bytes: 1000000 bulk_max_size: 10240 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 3、将powershell的配置改回默认， set-ExecutionPolicy Restricted 3、 这里还有一个linecount程序的配置，这是一个公司自己的程序，不做详细说明，这个程序的作用是把filebeat数据源里的每一个文件进行行数统计，然后发到kafka，主要用来对比kafka接收数据是否正常，配置如下： 2019.07.23 需求：内外网大数据平台的kafka增加新的数据源 处理过程： 1、 查看kafka现有的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka –list 外网命令 kafka-topics --zookeeper master3:2181 –list ps：内网是Apache原生版本，没有配置环境变量，外网是cdh，自动配置 2、 创建新的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 外网命令 kafka-topics --zookeeper master3:2181 --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 3、 因为数据源接错需要清空topic的数据，选择删除再重建 内网命令 vi /usr/local/kafka/config/server.properties，编辑这个配置文件确认以下内容 #A comma seperated list of directories under which to store log files log.dirs=/usr/local/kafka_data #删除topic(server.properties中设置delete.topic.enable=true否则只是标记删除) delete.topic.enable=true #关闭自动创建topic auto.create.topics.enable=false /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper host5:2188/kafka --topic AIS_20_ExactAis 外网命令 CDH管理界面，群集-kafka-配置 搜索删除topic（启用）和自动创建topic（禁用） kafka-topics --delete --zookeeper maser3:2181 --topic AIS_20_ExactAis ps：这次操作来看，删除topic并不难，直接这两条命令就可以完成（可能是因为没有消费者，如果有需要先停掉），所以我并没有遇到删除不掉需要使用zookeeper客户端删除的情况 4、 无法正常删除topic，则需要对kafka在zookeeer的存储信息进行删除 进入zookeeper客户端删掉对应topic ./zkCli.sh -server master1:2181 找到topic目录 ls /brokers/topics 删掉对应topic rmr /brokers/topics/topic-name 如果topic 是被标记为 marked for deletion，则通过命令 ls /admin/delete_topics，找到要删除的topic，然后执行命令： 找到目录 ls /admin/delete_topics 删除目录 rmr /admin/delete_topics/【topic name】 找到目录 ls /config/topics 删掉对应topic rmr /config/topics/topic-name 5、 添加完成后使用第一步的命令查看新的topic是否添加成功，CDH版本可以通过kafka—图标查看 6、 检查是否有数据进来 内网命令 /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper host10:2188/kafka --topic AIS_9_Spire_ANJI 外网命令kafka-console-consumer --zookeeper master3:2181 --topic AIS_9_Spire_ANJI 2019.07.15 公司内部大数据环境，集群里的任意节点执行了 hdfs dfsadmin -report 命令，发现有一个节点处于 Dead datanodes (1) 状态，Last contact: Mon Jun 24 16:40:00 CST 2019 。 处理过程： 1、联系之前的工程师确认是否为有计划的退出，结果不是。 2、根据HDFS特性，这么长时间的不在线状态，应该已经完成了副本拷贝的工作，所以不用考虑数据问题，不用着急处理。 3、登录这个问题节点，执行hadoop-daemon.sh start datanode 命令，状态并没有恢复。 4、查看hadoop-root-datanode-xxx.log，发现在启动的时候加载 /sdb 这个目录不成功 5、linux系统执行 df -h 显示正常 6、cd /sdb1 执行ls命令提示 Input/output error 7、cd / 目录执行 ll 命令，发现 sdb1 目录信息不正常，显示了很多？？？？？？？？？？ 8、umount之后，在mount 报错 mount: /dev/sdb1: can’t read superblock 9、xfs文件系统所以用xfs_repair 修复，不成功具体提示信息忘记了 10、fdisk -l 看不到相关的磁盘信息，可以从 /dev 看到 11、cat /proc/partitions 可以看到相关信息 12、备份修改 /usr/local/hadoop/etc/hadoop/hdfs-site.xml, dfs.datanode.data.dir file:/dfs,file:/sdd,file:/sdc 去掉file:/sdb 13、执行hadoop-daemon.sh start datanode 命令，查看日志没有报错，但是状态也没有会（这里需要一段时间扫描剩余磁盘的数据，上报给namenode） 14、过一段时间 执行了 hdfs-dfsadmin -report，状态恢复（这时候就等着整个集群慢慢验证数据，多余的副本数量被删除，想要快的话可以自己修改上报参数来缩短时间） Dead datanodes (1): Name: 192.168.1.170:50010 (xxx) Hostname: Decommission Status : Normal Configured Capacity: 23952530427904 (21.78 TB) DFS Used: 7689460762544 (6.99 TB) Non DFS Used: 592783763536 (552.07 GB) DFS Remaining: 15668718210960 (14.25 TB) DFS Used%: 32.10% DFS Remaining%: 65.42% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 0 Last contact: Mon Jun 24 16:40:00 CST 2019 Name: 192.168.1.170:50010 (xxx) Hostname: xxx Decommission Status : Normal Configured Capacity: 17954062262272 (16.33 TB) DFS Used: 6108392244325 (5.56 TB) Non DFS Used: 603698887579 (562.24 GB) DFS Remaining: 11241853299200 (10.22 TB) DFS Used%: 34.02% DFS Remaining%: 62.61% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 4 Last contact: Mon Jul 15 16:04:30 CST 2019" />
<meta property="og:description" content="2019.07.23 需求：现有的filebeat中新增数据源和部署新的filebeat服务器 处理过程： 1、 增加数据源 Filebeat安装目录 C:\Program Files\filebeat1\filebeat C:\Program Files\filebeat2\filebeat 编辑filebeat.yml 新增配置 input_type: log paths: - D:\DataServer\ExactEarth\OriginalData* document_type: AIS_20_ExactAis scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 2、 重新部署filebeat 这是从原来服务器上面拷贝过来的程序 Filebeat安装目录 C:\Program Files\filebeat1 C:\Program Files\filebeat2 注册服务 在Powershell直接脚本时会出现：无法加载文件 ******.ps1，因为在此系统中禁止执行脚本。 管理员身份运行powershell，执行 set-ExecutionPolicy RemoteSigned 编辑install-service-filebeat.ps1 ，修改服务名称为filebeat1或者filebeat2 New-Service -name filebeat1 displayName filebeat1 管理员身份运行powershell，执行 cd ‘C:\Program Files\filebeat1’ (这里路径有空格需要单引号)，再执行 ./ install-service-filebeat.ps1 ，服务注册完成 编辑配置文件filebeat.yml Filebeat输入源配置 input_type: log paths: d:\SpirePrediction\server\DataLogs* document_type: AIS_9_Spire_ANJI scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h filebeat输出到kafka配置 output.kafka: #The Logstash hosts hosts: [“xxx.xxx.xxx.xxx:9092”] enabled: true codec.format: string: ‘%{[message]}’ topic: ‘%{[type]}’ required_acks: 1 max_messages_bytes: 1000000 bulk_max_size: 10240 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 3、将powershell的配置改回默认， set-ExecutionPolicy Restricted 3、 这里还有一个linecount程序的配置，这是一个公司自己的程序，不做详细说明，这个程序的作用是把filebeat数据源里的每一个文件进行行数统计，然后发到kafka，主要用来对比kafka接收数据是否正常，配置如下： 2019.07.23 需求：内外网大数据平台的kafka增加新的数据源 处理过程： 1、 查看kafka现有的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka –list 外网命令 kafka-topics --zookeeper master3:2181 –list ps：内网是Apache原生版本，没有配置环境变量，外网是cdh，自动配置 2、 创建新的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 外网命令 kafka-topics --zookeeper master3:2181 --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 3、 因为数据源接错需要清空topic的数据，选择删除再重建 内网命令 vi /usr/local/kafka/config/server.properties，编辑这个配置文件确认以下内容 #A comma seperated list of directories under which to store log files log.dirs=/usr/local/kafka_data #删除topic(server.properties中设置delete.topic.enable=true否则只是标记删除) delete.topic.enable=true #关闭自动创建topic auto.create.topics.enable=false /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper host5:2188/kafka --topic AIS_20_ExactAis 外网命令 CDH管理界面，群集-kafka-配置 搜索删除topic（启用）和自动创建topic（禁用） kafka-topics --delete --zookeeper maser3:2181 --topic AIS_20_ExactAis ps：这次操作来看，删除topic并不难，直接这两条命令就可以完成（可能是因为没有消费者，如果有需要先停掉），所以我并没有遇到删除不掉需要使用zookeeper客户端删除的情况 4、 无法正常删除topic，则需要对kafka在zookeeer的存储信息进行删除 进入zookeeper客户端删掉对应topic ./zkCli.sh -server master1:2181 找到topic目录 ls /brokers/topics 删掉对应topic rmr /brokers/topics/topic-name 如果topic 是被标记为 marked for deletion，则通过命令 ls /admin/delete_topics，找到要删除的topic，然后执行命令： 找到目录 ls /admin/delete_topics 删除目录 rmr /admin/delete_topics/【topic name】 找到目录 ls /config/topics 删掉对应topic rmr /config/topics/topic-name 5、 添加完成后使用第一步的命令查看新的topic是否添加成功，CDH版本可以通过kafka—图标查看 6、 检查是否有数据进来 内网命令 /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper host10:2188/kafka --topic AIS_9_Spire_ANJI 外网命令kafka-console-consumer --zookeeper master3:2181 --topic AIS_9_Spire_ANJI 2019.07.15 公司内部大数据环境，集群里的任意节点执行了 hdfs dfsadmin -report 命令，发现有一个节点处于 Dead datanodes (1) 状态，Last contact: Mon Jun 24 16:40:00 CST 2019 。 处理过程： 1、联系之前的工程师确认是否为有计划的退出，结果不是。 2、根据HDFS特性，这么长时间的不在线状态，应该已经完成了副本拷贝的工作，所以不用考虑数据问题，不用着急处理。 3、登录这个问题节点，执行hadoop-daemon.sh start datanode 命令，状态并没有恢复。 4、查看hadoop-root-datanode-xxx.log，发现在启动的时候加载 /sdb 这个目录不成功 5、linux系统执行 df -h 显示正常 6、cd /sdb1 执行ls命令提示 Input/output error 7、cd / 目录执行 ll 命令，发现 sdb1 目录信息不正常，显示了很多？？？？？？？？？？ 8、umount之后，在mount 报错 mount: /dev/sdb1: can’t read superblock 9、xfs文件系统所以用xfs_repair 修复，不成功具体提示信息忘记了 10、fdisk -l 看不到相关的磁盘信息，可以从 /dev 看到 11、cat /proc/partitions 可以看到相关信息 12、备份修改 /usr/local/hadoop/etc/hadoop/hdfs-site.xml, dfs.datanode.data.dir file:/dfs,file:/sdd,file:/sdc 去掉file:/sdb 13、执行hadoop-daemon.sh start datanode 命令，查看日志没有报错，但是状态也没有会（这里需要一段时间扫描剩余磁盘的数据，上报给namenode） 14、过一段时间 执行了 hdfs-dfsadmin -report，状态恢复（这时候就等着整个集群慢慢验证数据，多余的副本数量被删除，想要快的话可以自己修改上报参数来缩短时间） Dead datanodes (1): Name: 192.168.1.170:50010 (xxx) Hostname: Decommission Status : Normal Configured Capacity: 23952530427904 (21.78 TB) DFS Used: 7689460762544 (6.99 TB) Non DFS Used: 592783763536 (552.07 GB) DFS Remaining: 15668718210960 (14.25 TB) DFS Used%: 32.10% DFS Remaining%: 65.42% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 0 Last contact: Mon Jun 24 16:40:00 CST 2019 Name: 192.168.1.170:50010 (xxx) Hostname: xxx Decommission Status : Normal Configured Capacity: 17954062262272 (16.33 TB) DFS Used: 6108392244325 (5.56 TB) Non DFS Used: 603698887579 (562.24 GB) DFS Remaining: 11241853299200 (10.22 TB) DFS Used%: 34.02% DFS Remaining%: 62.61% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 4 Last contact: Mon Jul 15 16:04:30 CST 2019" />
<link rel="canonical" href="https://uzzz.org/2019/07/23/794207.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/23/794207.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-23T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"2019.07.23 需求：现有的filebeat中新增数据源和部署新的filebeat服务器 处理过程： 1、 增加数据源 Filebeat安装目录 C:\\Program Files\\filebeat1\\filebeat C:\\Program Files\\filebeat2\\filebeat 编辑filebeat.yml 新增配置 input_type: log paths: - D:\\DataServer\\ExactEarth\\OriginalData* document_type: AIS_20_ExactAis scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 2、 重新部署filebeat 这是从原来服务器上面拷贝过来的程序 Filebeat安装目录 C:\\Program Files\\filebeat1 C:\\Program Files\\filebeat2 注册服务 在Powershell直接脚本时会出现：无法加载文件 ******.ps1，因为在此系统中禁止执行脚本。 管理员身份运行powershell，执行 set-ExecutionPolicy RemoteSigned 编辑install-service-filebeat.ps1 ，修改服务名称为filebeat1或者filebeat2 New-Service -name filebeat1 displayName filebeat1 管理员身份运行powershell，执行 cd ‘C:\\Program Files\\filebeat1’ (这里路径有空格需要单引号)，再执行 ./ install-service-filebeat.ps1 ，服务注册完成 编辑配置文件filebeat.yml Filebeat输入源配置 input_type: log paths: d:\\SpirePrediction\\server\\DataLogs* document_type: AIS_9_Spire_ANJI scan_frequency: 100s close_inactive: 5m ignore_older: 2h clean_removed: true close_removed: true clean_inactive: 3h filebeat输出到kafka配置 output.kafka: #The Logstash hosts hosts: [“xxx.xxx.xxx.xxx:9092”] enabled: true codec.format: string: ‘%{[message]}’ topic: ‘%{[type]}’ required_acks: 1 max_messages_bytes: 1000000 bulk_max_size: 10240 在服务管理器重启filebeat ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加 3、将powershell的配置改回默认， set-ExecutionPolicy Restricted 3、 这里还有一个linecount程序的配置，这是一个公司自己的程序，不做详细说明，这个程序的作用是把filebeat数据源里的每一个文件进行行数统计，然后发到kafka，主要用来对比kafka接收数据是否正常，配置如下： 2019.07.23 需求：内外网大数据平台的kafka增加新的数据源 处理过程： 1、 查看kafka现有的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka –list 外网命令 kafka-topics --zookeeper master3:2181 –list ps：内网是Apache原生版本，没有配置环境变量，外网是cdh，自动配置 2、 创建新的topic 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 外网命令 kafka-topics --zookeeper master3:2181 --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1 3、 因为数据源接错需要清空topic的数据，选择删除再重建 内网命令 vi /usr/local/kafka/config/server.properties，编辑这个配置文件确认以下内容 #A comma seperated list of directories under which to store log files log.dirs=/usr/local/kafka_data #删除topic(server.properties中设置delete.topic.enable=true否则只是标记删除) delete.topic.enable=true #关闭自动创建topic auto.create.topics.enable=false /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper host5:2188/kafka --topic AIS_20_ExactAis 外网命令 CDH管理界面，群集-kafka-配置 搜索删除topic（启用）和自动创建topic（禁用） kafka-topics --delete --zookeeper maser3:2181 --topic AIS_20_ExactAis ps：这次操作来看，删除topic并不难，直接这两条命令就可以完成（可能是因为没有消费者，如果有需要先停掉），所以我并没有遇到删除不掉需要使用zookeeper客户端删除的情况 4、 无法正常删除topic，则需要对kafka在zookeeer的存储信息进行删除 进入zookeeper客户端删掉对应topic ./zkCli.sh -server master1:2181 找到topic目录 ls /brokers/topics 删掉对应topic rmr /brokers/topics/topic-name 如果topic 是被标记为 marked for deletion，则通过命令 ls /admin/delete_topics，找到要删除的topic，然后执行命令： 找到目录 ls /admin/delete_topics 删除目录 rmr /admin/delete_topics/【topic name】 找到目录 ls /config/topics 删掉对应topic rmr /config/topics/topic-name 5、 添加完成后使用第一步的命令查看新的topic是否添加成功，CDH版本可以通过kafka—图标查看 6、 检查是否有数据进来 内网命令 /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper host10:2188/kafka --topic AIS_9_Spire_ANJI 外网命令kafka-console-consumer --zookeeper master3:2181 --topic AIS_9_Spire_ANJI 2019.07.15 公司内部大数据环境，集群里的任意节点执行了 hdfs dfsadmin -report 命令，发现有一个节点处于 Dead datanodes (1) 状态，Last contact: Mon Jun 24 16:40:00 CST 2019 。 处理过程： 1、联系之前的工程师确认是否为有计划的退出，结果不是。 2、根据HDFS特性，这么长时间的不在线状态，应该已经完成了副本拷贝的工作，所以不用考虑数据问题，不用着急处理。 3、登录这个问题节点，执行hadoop-daemon.sh start datanode 命令，状态并没有恢复。 4、查看hadoop-root-datanode-xxx.log，发现在启动的时候加载 /sdb 这个目录不成功 5、linux系统执行 df -h 显示正常 6、cd /sdb1 执行ls命令提示 Input/output error 7、cd / 目录执行 ll 命令，发现 sdb1 目录信息不正常，显示了很多？？？？？？？？？？ 8、umount之后，在mount 报错 mount: /dev/sdb1: can’t read superblock 9、xfs文件系统所以用xfs_repair 修复，不成功具体提示信息忘记了 10、fdisk -l 看不到相关的磁盘信息，可以从 /dev 看到 11、cat /proc/partitions 可以看到相关信息 12、备份修改 /usr/local/hadoop/etc/hadoop/hdfs-site.xml, dfs.datanode.data.dir file:/dfs,file:/sdd,file:/sdc 去掉file:/sdb 13、执行hadoop-daemon.sh start datanode 命令，查看日志没有报错，但是状态也没有会（这里需要一段时间扫描剩余磁盘的数据，上报给namenode） 14、过一段时间 执行了 hdfs-dfsadmin -report，状态恢复（这时候就等着整个集群慢慢验证数据，多余的副本数量被删除，想要快的话可以自己修改上报参数来缩短时间） Dead datanodes (1): Name: 192.168.1.170:50010 (xxx) Hostname: Decommission Status : Normal Configured Capacity: 23952530427904 (21.78 TB) DFS Used: 7689460762544 (6.99 TB) Non DFS Used: 592783763536 (552.07 GB) DFS Remaining: 15668718210960 (14.25 TB) DFS Used%: 32.10% DFS Remaining%: 65.42% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 0 Last contact: Mon Jun 24 16:40:00 CST 2019 Name: 192.168.1.170:50010 (xxx) Hostname: xxx Decommission Status : Normal Configured Capacity: 17954062262272 (16.33 TB) DFS Used: 6108392244325 (5.56 TB) Non DFS Used: 603698887579 (562.24 GB) DFS Remaining: 11241853299200 (10.22 TB) DFS Used%: 34.02% DFS Remaining%: 62.61% Configured Cache Capacity: 0 (0 B) Cache Used: 0 (0 B) Cache Remaining: 0 (0 B) Cache Used%: 100.00% Cache Remaining%: 0.00% Xceivers: 4 Last contact: Mon Jul 15 16:04:30 CST 2019","@type":"BlogPosting","url":"https://uzzz.org/2019/07/23/794207.html","headline":"大数据运维–生产环境处理问题汇总（持续更新中…….）","dateModified":"2019-07-23T00:00:00+08:00","datePublished":"2019-07-23T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/23/794207.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>大数据运维--生产环境处理问题汇总（持续更新中.......）</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-tomorrow-night-eighties"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <hr> 
  <p>2019.07.23<br> 需求：现有的filebeat中新增数据源和部署新的filebeat服务器<br> 处理过程：<br> 1、 增加数据源<br> Filebeat安装目录<br> C:\Program Files\filebeat1\filebeat<br> C:\Program Files\filebeat2\filebeat</p> 
  <p>编辑filebeat.yml 新增配置<br> input_type: log<br> paths:<br> - D:\DataServer\ExactEarth\OriginalData*<br> document_type: AIS_20_ExactAis<br> scan_frequency: 100s<br> close_inactive: 5m<br> ignore_older: 2h<br> clean_removed: true<br> close_removed: true<br> clean_inactive: 3h</p> 
  <p>在服务管理器重启filebeat</p> 
  <p>ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加</p> 
  <p>2、 重新部署filebeat<br> 这是从原来服务器上面拷贝过来的程序<br> Filebeat安装目录<br> C:\Program Files\filebeat1<br> C:\Program Files\filebeat2</p> 
  <p>注册服务<br> 在Powershell直接脚本时会出现：无法加载文件 ******.ps1，因为在此系统中禁止执行脚本。<br> 管理员身份运行powershell，执行 set-ExecutionPolicy RemoteSigned</p> 
  <p>编辑install-service-filebeat.ps1 ，修改服务名称为filebeat1或者filebeat2<br> New-Service -name filebeat1 <code>displayName filebeat1</code></p> 
  <p>管理员身份运行powershell，执行 cd ‘C:\Program Files\filebeat1’ (这里路径有空格需要单引号)，再执行 ./ install-service-filebeat.ps1 ，服务注册完成</p> 
  <p>编辑配置文件filebeat.yml</p> 
  <p>Filebeat输入源配置</p> 
  <ul> 
   <li>input_type: log<br> paths: 
    <ul> 
     <li>d:\SpirePrediction\server\DataLogs*<br> document_type: AIS_9_Spire_ANJI<br> scan_frequency: 100s<br> close_inactive: 5m<br> ignore_older: 2h<br> clean_removed: true<br> close_removed: true<br> clean_inactive: 3h</li> 
    </ul> </li> 
  </ul> 
  <p>filebeat输出到kafka配置<br> output.kafka:<br> #The Logstash hosts<br> hosts: [“<a href="http://xxx.xxx.xxx.xxx:9092" rel="nofollow" data-token="8086bc947e6818a251fafbd367957e38">xxx.xxx.xxx.xxx:9092</a>”]<br> enabled: true<br> codec.format:<br> string: ‘%{[message]}’<br> topic: ‘%{[type]}’<br> required_acks: 1<br> max_messages_bytes: 1000000<br> bulk_max_size: 10240</p> 
  <p>在服务管理器重启filebeat</p> 
  <p>ps：公司分为内外网大数据集群，所以有两个filebeat同时运行，分别是filebeat1和filebeat2，添加配置的时候需要两个都添加</p> 
  <p>3、将powershell的配置改回默认，<br> set-ExecutionPolicy Restricted</p> 
  <p>3、 这里还有一个linecount程序的配置，这是一个公司自己的程序，不做详细说明，这个程序的作用是把filebeat数据源里的每一个文件进行行数统计，然后发到kafka，主要用来对比kafka接收数据是否正常，配置如下：</p> 
  <hr> 
  <p>2019.07.23<br> 需求：内外网大数据平台的kafka增加新的数据源<br> 处理过程：<br> 1、 查看kafka现有的topic<br> 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka –list<br> 外网命令 kafka-topics --zookeeper master3:2181 –list<br> ps：内网是Apache原生版本，没有配置环境变量，外网是cdh，自动配置</p> 
  <p>2、 创建新的topic<br> 内网命令 /usr/local/kafka/bin/kafka-topics.sh --zookeeper host5:2188/kafka --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1<br> 外网命令 kafka-topics --zookeeper master3:2181 --create --topic AIS_20_ExactAis --replication-factor 2 --partitions 1</p> 
  <p>3、 因为数据源接错需要清空topic的数据，选择删除再重建<br> 内网命令<br> vi /usr/local/kafka/config/server.properties，编辑这个配置文件确认以下内容</p> 
  <pre><code>#A comma seperated list of directories under which to store log files 
log.dirs=/usr/local/kafka_data

#删除topic(server.properties中设置delete.topic.enable=true否则只是标记删除)
delete.topic.enable=true

#关闭自动创建topic
auto.create.topics.enable=false
</code></pre> 
  <p>/usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper host5:2188/kafka --topic AIS_20_ExactAis</p> 
  <p>外网命令<br> CDH管理界面，群集-kafka-配置 搜索删除topic（启用）和自动创建topic（禁用）<br> kafka-topics --delete --zookeeper maser3:2181 --topic AIS_20_ExactAis</p> 
  <p>ps：这次操作来看，删除topic并不难，直接这两条命令就可以完成（可能是因为没有消费者，如果有需要先停掉），所以我并没有遇到删除不掉需要使用zookeeper客户端删除的情况<br> 4、 无法正常删除topic，则需要对kafka在zookeeer的存储信息进行删除<br> 进入zookeeper客户端删掉对应topic<br> ./zkCli.sh -server master1:2181</p> 
  <p>找到topic目录<br> ls /brokers/topics<br> 删掉对应topic<br> rmr /brokers/topics/topic-name<br> 如果topic 是被标记为 marked for deletion，则通过命令 ls /admin/delete_topics，找到要删除的topic，然后执行命令：<br> 找到目录<br> ls /admin/delete_topics<br> 删除目录<br> rmr /admin/delete_topics/【topic name】</p> 
  <p>找到目录<br> ls /config/topics<br> 删掉对应topic<br> rmr /config/topics/topic-name</p> 
  <p>5、 添加完成后使用第一步的命令查看新的topic是否添加成功，CDH版本可以通过kafka—图标查看<br> 6、 检查是否有数据进来<br> 内网命令 /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper host10:2188/kafka --topic AIS_9_Spire_ANJI<br> 外网命令kafka-console-consumer --zookeeper master3:2181 --topic AIS_9_Spire_ANJI</p> 
  <hr> 
  <p>2019.07.15<br> 公司内部大数据环境，集群里的任意节点执行了 hdfs dfsadmin -report 命令，发现有一个节点处于 Dead datanodes (1) 状态，Last contact: Mon Jun 24 16:40:00 CST 2019 。<br> 处理过程：<br> 1、联系之前的工程师确认是否为有计划的退出，结果不是。<br> 2、根据HDFS特性，这么长时间的不在线状态，应该已经完成了副本拷贝的工作，所以不用考虑数据问题，不用着急处理。<br> 3、登录这个问题节点，<a href="http://xn--hadoop-daemon-hp00au172b.sh" rel="nofollow" data-token="cc1d3d7f519eda9d81403796defe05b4">执行hadoop-daemon.sh</a> start datanode 命令，状态并没有恢复。<br> 4、查看hadoop-root-datanode-xxx.log，发现在启动的时候加载 /sdb 这个目录不成功<br> 5、linux系统执行 df -h 显示正常<br> 6、cd /sdb1 执行ls命令提示 Input/output error<br> 7、cd / 目录执行 ll 命令，发现 sdb1 目录信息不正常，显示了很多？？？？？？？？？？<br> 8、umount之后，在mount 报错 mount: /dev/sdb1: can’t read superblock<br> 9、xfs文件系统所以用xfs_repair 修复，不成功具体提示信息忘记了<br> 10、fdisk -l 看不到相关的磁盘信息，可以从 /dev 看到<br> 11、cat /proc/partitions 可以看到相关信息<br> 12、备份修改 /usr/local/hadoop/etc/hadoop/hdfs-site.xml,<br> <br> dfs.datanode.data.dir<br> file:/dfs,file:/sdd,file:/sdc<br> <br> 去掉file:/sdb<br> 13、<a href="http://xn--hadoop-daemon-hp00au172b.sh" rel="nofollow" data-token="cc1d3d7f519eda9d81403796defe05b4">执行hadoop-daemon.sh</a> start datanode 命令，查看日志没有报错，但是状态也没有会（这里需要一段时间扫描剩余磁盘的数据，上报给namenode）<br> 14、过一段时间 执行了 hdfs-dfsadmin -report，状态恢复（这时候就等着整个集群慢慢验证数据，多余的副本数量被删除，想要快的话可以自己修改上报参数来缩短时间）</p> 
  <p>Dead datanodes (1):</p> 
  <p>Name: 192.168.1.170:50010 (xxx)<br> Hostname:<br> Decommission Status : Normal<br> Configured Capacity: 23952530427904 (21.78 TB)<br> DFS Used: 7689460762544 (6.99 TB)<br> Non DFS Used: 592783763536 (552.07 GB)<br> DFS Remaining: 15668718210960 (14.25 TB)<br> DFS Used%: 32.10%<br> DFS Remaining%: 65.42%<br> Configured Cache Capacity: 0 (0 B)<br> Cache Used: 0 (0 B)<br> Cache Remaining: 0 (0 B)<br> Cache Used%: 100.00%<br> Cache Remaining%: 0.00%<br> Xceivers: 0<br> Last contact: Mon Jun 24 16:40:00 CST 2019</p> 
  <p>Name: 192.168.1.170:50010 (xxx)<br> Hostname: xxx<br> Decommission Status : Normal<br> Configured Capacity: 17954062262272 (16.33 TB)<br> DFS Used: 6108392244325 (5.56 TB)<br> Non DFS Used: 603698887579 (562.24 GB)<br> DFS Remaining: 11241853299200 (10.22 TB)<br> DFS Used%: 34.02%<br> DFS Remaining%: 62.61%<br> Configured Cache Capacity: 0 (0 B)<br> Cache Used: 0 (0 B)<br> Cache Remaining: 0 (0 B)<br> Cache Used%: 100.00%<br> Cache Remaining%: 0.00%<br> Xceivers: 4<br> Last contact: Mon Jul 15 16:04:30 CST 2019</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
