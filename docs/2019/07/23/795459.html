<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>从头开始搭建kubernetes集群+istio服务网格（1）—— 前期准备、安装docker、kubernetes | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="从头开始搭建kubernetes集群+istio服务网格（1）—— 前期准备、安装docker、kubernetes" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="(win10 + virtualbox6.0 + centos7.6.1810 + docker18.09.8 + kubernetes1.15.1 + istio1.2.3) 本文参考网址： https://www.jianshu.com/p/e43f5e848da1 https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ https://www.jianshu.com/p/1aebf568b786 https://blog.csdn.net/donglynn/article/details/47784393 https://blog.csdn.net/MC_CodeGirl/article/details/79998656 https://blog.csdn.net/andriy_dangli/article/details/85062983 https://docs.projectcalico.org/v3.8/getting-started/kubernetes/installation/calico https://www.jianshu.com/p/70efa1b853f5 https://blog.csdn.net/weixin_44723434/article/details/94583457 https://preliminary.istio.io/zh/docs/setup/kubernetes/download/ https://www.cnblogs.com/rickie/p/istio.html https://blog.csdn.net/lwplvx/article/details/79192182 https://blog.csdn.net/qq_36402372/article/details/82991098 https://www.cnblogs.com/assion/p/11326088.html http://www.lampnick.com/php/823 https://blog.csdn.net/ccagy/article/details/83059349 https://www.jianshu.com/p/789bc867feaa https://www.jianshu.com/p/dde56c521078 本系列分为三章，第一章是创建虚拟机、docker、kubernetes等一些基础设施；第二章是在此基础上创建一个三节点的kubernetes集群；第三章是再在之上搭建istio服务网格。 本文参考了大量其他优秀作者的创作（已经在开头列出），自己从零开始，慢慢搭建了istio服务网格，每一步都在文章中详细地列出了。之所以要自己重新从头搭建，一方面是很多CSDN、简书或其他平台的教程都已经离现在（2019.8.14）太过遥远，变得不合时宜，单纯地照着别人的路子走会遇到非常多的坑；另一方面是实践出真知。 由于我也是刚开始学习istio服务网格，才疏学浅，难免有不尽如人意的地方，还请见谅。 1 系统CentOS 下载 官网下载 DVD ISO：标准安装版，一般下载这个就可以了（推荐） Minimal ISO：迷你版，小巧、安装快速、自带的软件少 点进去之后选择阿里云 然后就是正常的下载 2 虚拟机 virtualbox 下载 官网下载 之所以选择virtualbox 而不是vmware，是因为另一个教程上这样做的，所以…，等搭建完熟悉流程后就可以随心所欲啦。 正常下载 3 创建虚拟机 打开安装好的VirtualBox，新建 控制→新建 如下图进行设置 内存至少2G 默认 虚拟硬盘至少20G 创建成功 接下来安装操作系统 点击设置 如图 选择之前下载好的 .iso 文件，正常安装 。 开启虚拟机，安装CentOS。 一些注意选项如下： 如下图正在安装 重启完成安装。 4 将xshell和虚拟机连接起来 接下来进行虚拟机的配置。由于直接在VirtualBox里操作bash是一件非常恶心的事情，我们使用第三方的终端模拟软件来控制虚拟机，本文选择的是xshell，当然其他的也可以。 返回virtualbox的控制界面，点开设置。 由于VirtualBox 默认使用NAT网络转换，宿主机无法直接访问虚拟机，但我们只要简单的在NAT网卡上添加端口转发，即可访问虚拟机。这里，我们通过端口转发暴露虚拟机的SSH端口（22），就可以远程连接到虚拟机。 在设置中，选择“网络”=&gt;“网卡1”&gt;=“高级”&gt;=“端口转发”： 在我们真实的物理机上，可以利用Xshell，通过端口9000连接到虚拟机终端上。打开Xshell，新建一个连接。注意，因为端口是映射到宿主机上的，所以主机地址要填写为127.0.0.1： 打开Xshell如下配置新建会话。 登陆成功（这里折腾了一会） 关闭图形界面 CentOS 7 安装好后，登录时默认启用了很占资源的图形界面，若启动三个虚拟机更会卡的飞起。因此，我们可以通过如下命令切换默认的登录方式： 命令模式 systemctl set-default multi-user.target 图形模式 systemctl set-default graphical.target 这里，强烈建议切换为命令模式，所有的操作都通过Xshell进行足以。注意，上面的命令执行后重启生效。 试了很多次一直失败，如下 然后发现是需要需要进入root，使用su直接进入继续失败。 [centos_master@localhost ~]$ su 密码： su: 鉴定故障 继续查资料，修改成 [centos_master@localhost ~]$ sudo su root 我们信任您已经从系统管理员那里了解了日常注意事项。 总结起来无外乎这三点： #1) 尊重别人的隐私。 #2) 输入前要先考虑(后果和风险)。 #3) 权力越大，责任越大。 [sudo] centos_master 的密码： [root@localhost centos_master]# ^C [root@localhost centos_master]# systemctl set-default multi-user.target Removed symlink /etc/systemd/system/default.target. Created symlink from /etc/systemd/system/default.target to /usr/lib/systemd/system/multi-user.target. [root@localhost centos_master]# 成功！ 重启虚拟机，已经成功从图形界面变成命令模式。 备注：之后基本使用xshell连接虚拟机之后的第一件事就是sudo su root。 4 虚拟机的一些基础配置 4.1 配置yum源 不建议使用CentOS 7自带的yum源，因为安装软件和依赖时会非常慢甚至超时失败。这里，我们使用阿里云的源予以替换，执行如下命令，替换文件/etc/yum.repos.d/CentOS-Base.repo： wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum makecache 4.2 关闭防火墙 防火墙一定要提前关闭，否则在后续安装K8S集群的时候是个trouble maker。执行下面语句关闭，并禁用开机启动： [root@localhost centos_master]# systemctl stop firewalld &amp; systemctl disable firewalld [1] 4223 Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 4.3 关闭Swap 类似ElasticSearch集群，在安装K8S集群时，Linux的Swap内存交换机制是一定要关闭的，否则会因为内存交换而影响性能以及稳定性。这里，我们可以提前进行设置。 临时关闭swap分区, 重启失效： swapoff -a 永久关闭swap分区： sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab 建议永久关闭，之后如下图即为正常： 4 安装docker 安装kubernetes前，必须要先安装Docker。 4.1 添加阿里云的Docker仓库 [root@localhost centos_master]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo [root@localhost centos_master]# yum makecache 4.2 执行以下命令，安装最新版Docker [root@localhost centos_master]# yum install docker-ce -y 4.3 安装成功后，如下图所示 运行docker --version,可以看到安装了截止目前最新的18.09.8版本： [root@localhost centos_master]# docker --version Docker version 18.09.8, build 0dd43dd87f 4.4 启动Docker服务并激活开机启动 [root@localhost centos_master]# systemctl start docker &amp; systemctl enable docker 4.5 验证 [root@localhost centos_master]# docker run hello-world 成功~ 5 安装kubernrtes 建议使用阿里源的仓库，执行以下命令添加kubernetes.repo仓库 [root@localhost centos_master]# cd /etc/yum.repos.d/ [root@localhost yum.repos.d]# vim kubernetes.repo 出现如图 5.1 关闭swap、防火墙（之前已经关闭），可忽视。 5.2 关闭SeLinux 执行 setenforce 0 5.3 安装kubelet、kubeadm、kubectl 执行以下命令 yum install -y kubelet kubeadm kubectl emmmm报错 重新尝试，清一下缓存 yum clean all yum makecache 接着顺手升级一下yum yum -y update 重新安装kubelet、kubeadm、kubectl 成功~ 5.4 判断docker 的cgroup drive和kubelet的cgroup drive是否一样 首先解决这两个警告 vim /etc/sysctl.conf 接着添加如下内容 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 最后执行 sysctl -p 接下来重启虚拟机 警告消失~ 备注：这里有个坑，虽然我们这里cgroup drive两者都是cgroupfs，是一样的。但是！在后面我们需要把这两者都改成systemd。不过现在可以不用管，后面可以再改；也可以直接参考第二章的2.2节跳过这个坑。 正常启动kubelet [root@localhost centos_master]# systemctl enable kubelet &amp;&amp; systemctl start kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. 5.5 列出需要的镜像 使用kubeadm config images list列出我们需要的镜像 [root@localhost centos_master]# kubeadm config images list W0723 18:09:53.292065 5839 version.go:98] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) W0723 18:09:53.292483 5839 version.go:99] falling back to the local client version: v1.15.1 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 得到所有需要的组件，也就是以下七个组件。 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 接着参考下面的这堆代码进行配置（一行一行地输入命令），将下面这张代码里的组件版本号替换成我们的即可，这个地方需要十分小心！！（我们的是1.15.1，而下面的代码段里是1.15.0，所以只是根据下面的代码来参考） （例如，下面第一行我们应该修改为docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.1） 这里下载v1.15.0版本 docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.10.0 docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.15.0 docker pull mirrorgooglecontainers/pause:3.1 docker pull mirrorgooglecontainers/etcd:3.3.10 docker pull coredns/coredns:1.3.1 镜像打标 docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 k8s.gcr.io/kube-apiserver:v1.15.0 docker tag mirrorgooglecontainers/kube-scheduler:v1.15.0 k8s.gcr.io/kube-scheduler:v1.15.0 docker tag mirrorgooglecontainers/kube-controller-manager:v1.15.0 k8s.gcr.io/kube-controller-manager:v1.15.0 docker tag mirrorgooglecontainers/etcd:v1.15.0 k8s.gcr.io/etcd:v1.15.0 docker tag mirrorgooglecontainers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10 docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1 docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1 镜像分发打包 docker save -o k8s-master.tar.gz `docker image ls |grep k8s |awk &#39;{position=$1&quot;:&quot;$2;print $1,position}&#39; |awk &#39;{print $2}&#39;` 导入镜像 [root@master ~]# docker load -i k8s-master.tar.gz Loaded image: k8s.gcr.io/etcd:3.3.10 Loaded image: k8s.gcr.io/pause:3.1 Loaded image: k8s.gcr.io/kube-proxy:v1.15.0 Loaded image: k8s.gcr.io/kube-apiserver:v1.15.0 Loaded image: k8s.gcr.io/kube-controller-manager:v1.15.0 Loaded image: k8s.gcr.io/kube-scheduler:v1.15.0 Loaded image: k8s.gcr.io/coredns:1.3.1 成功~如图 [root@localhost centos_master]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mirrorgooglecontainers/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB k8s.gcr.io/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB k8s.gcr.io/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB k8s.gcr.io/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB mirrorgooglecontainers/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB k8s.gcr.io/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.0 201c7a840312 4 weeks ago 207MB k8s.gcr.io/coredns 1.3.1 eb516548c180 6 months ago 40.3MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.3.1 eb516548c180 6 months ago 40.3MB hello-world latest fce289e99eb9 6 months ago 1.84kB mirrorgooglecontainers/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB k8s.gcr.io/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB mirrorgooglecontainers/pause 3.1 da86e6ba6ca1 19 months ago 742kB k8s.gcr.io/pause 3.1 da86e6ba6ca1 19 months ago 6 复制虚拟机 当Node1的Kubernetes安装完毕后，就需要进行虚拟机的复制了。复制前需要退出虚拟机，我们选择“正常关机”。右键虚拟机点击复制： 注意上述的所有箭头。点击“复制”，稍等几分钟，即可完成复制，一共复制两台。 现在我们就有了三个虚拟机，master、node2、node3。 复制结束后，不要马上启动虚拟机，而先要为每一个虚拟机添加一个网卡，用于节点间的互通访问。如下图所示，连接方式选择“Host-Only”模式： 网卡添加结束后，启动三个虚拟机，查看各个IP。以主节点master为例，运行ip addr 可以看到，网卡enp0s8为新添加的网卡2，IP地址为192.168.56.103。三个节点IP分别为： master：192.168.56.103 Node2：192.168.56.101 Node3：192.168.56.102 三台虚拟机互相ping一下瞅瞅网络连通性。 接着根据之前master连接xshell的步骤，使用xshell连接另外两台虚拟机，只是把主机端口分别改成9023、8081。 网卡添加结束后，即可启动三个虚拟机，我们需要进行一些简单的设置，以主节点Node1为例： 编辑/etc/hostname，将hostname修改为k8s_master 编辑/etc/hosts，追加内容IP k8s_master，其中上IP为网卡2的IP地址，修改后重启生效。另外两个节点修改同理，主机名分别为k8s_node2、k8s_node3。 (这里也折腾了很久，后来发现正确的步骤是用vi打开之后，再点一下i进入编辑模式，编辑好之后，点Esc，接着输入:wq保存退出；另外编辑hostname时用hostnamectl set-hostname 主机名 同样可以） 备注：这里有个坑，主机名中不要有_，在第二章中我折腾了很久才发现这个问题，所以这里可以把主机名直接改为k8s-master、k8s-node2、k8s-node3跳过这个坑。 最后，输入hostname可以看到当前的hostname。 7 小结 目前我们有了三个虚拟机，每个虚拟机上都有docker、kubernetes。下一章我们开始正式创建集群。" />
<meta property="og:description" content="(win10 + virtualbox6.0 + centos7.6.1810 + docker18.09.8 + kubernetes1.15.1 + istio1.2.3) 本文参考网址： https://www.jianshu.com/p/e43f5e848da1 https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ https://www.jianshu.com/p/1aebf568b786 https://blog.csdn.net/donglynn/article/details/47784393 https://blog.csdn.net/MC_CodeGirl/article/details/79998656 https://blog.csdn.net/andriy_dangli/article/details/85062983 https://docs.projectcalico.org/v3.8/getting-started/kubernetes/installation/calico https://www.jianshu.com/p/70efa1b853f5 https://blog.csdn.net/weixin_44723434/article/details/94583457 https://preliminary.istio.io/zh/docs/setup/kubernetes/download/ https://www.cnblogs.com/rickie/p/istio.html https://blog.csdn.net/lwplvx/article/details/79192182 https://blog.csdn.net/qq_36402372/article/details/82991098 https://www.cnblogs.com/assion/p/11326088.html http://www.lampnick.com/php/823 https://blog.csdn.net/ccagy/article/details/83059349 https://www.jianshu.com/p/789bc867feaa https://www.jianshu.com/p/dde56c521078 本系列分为三章，第一章是创建虚拟机、docker、kubernetes等一些基础设施；第二章是在此基础上创建一个三节点的kubernetes集群；第三章是再在之上搭建istio服务网格。 本文参考了大量其他优秀作者的创作（已经在开头列出），自己从零开始，慢慢搭建了istio服务网格，每一步都在文章中详细地列出了。之所以要自己重新从头搭建，一方面是很多CSDN、简书或其他平台的教程都已经离现在（2019.8.14）太过遥远，变得不合时宜，单纯地照着别人的路子走会遇到非常多的坑；另一方面是实践出真知。 由于我也是刚开始学习istio服务网格，才疏学浅，难免有不尽如人意的地方，还请见谅。 1 系统CentOS 下载 官网下载 DVD ISO：标准安装版，一般下载这个就可以了（推荐） Minimal ISO：迷你版，小巧、安装快速、自带的软件少 点进去之后选择阿里云 然后就是正常的下载 2 虚拟机 virtualbox 下载 官网下载 之所以选择virtualbox 而不是vmware，是因为另一个教程上这样做的，所以…，等搭建完熟悉流程后就可以随心所欲啦。 正常下载 3 创建虚拟机 打开安装好的VirtualBox，新建 控制→新建 如下图进行设置 内存至少2G 默认 虚拟硬盘至少20G 创建成功 接下来安装操作系统 点击设置 如图 选择之前下载好的 .iso 文件，正常安装 。 开启虚拟机，安装CentOS。 一些注意选项如下： 如下图正在安装 重启完成安装。 4 将xshell和虚拟机连接起来 接下来进行虚拟机的配置。由于直接在VirtualBox里操作bash是一件非常恶心的事情，我们使用第三方的终端模拟软件来控制虚拟机，本文选择的是xshell，当然其他的也可以。 返回virtualbox的控制界面，点开设置。 由于VirtualBox 默认使用NAT网络转换，宿主机无法直接访问虚拟机，但我们只要简单的在NAT网卡上添加端口转发，即可访问虚拟机。这里，我们通过端口转发暴露虚拟机的SSH端口（22），就可以远程连接到虚拟机。 在设置中，选择“网络”=&gt;“网卡1”&gt;=“高级”&gt;=“端口转发”： 在我们真实的物理机上，可以利用Xshell，通过端口9000连接到虚拟机终端上。打开Xshell，新建一个连接。注意，因为端口是映射到宿主机上的，所以主机地址要填写为127.0.0.1： 打开Xshell如下配置新建会话。 登陆成功（这里折腾了一会） 关闭图形界面 CentOS 7 安装好后，登录时默认启用了很占资源的图形界面，若启动三个虚拟机更会卡的飞起。因此，我们可以通过如下命令切换默认的登录方式： 命令模式 systemctl set-default multi-user.target 图形模式 systemctl set-default graphical.target 这里，强烈建议切换为命令模式，所有的操作都通过Xshell进行足以。注意，上面的命令执行后重启生效。 试了很多次一直失败，如下 然后发现是需要需要进入root，使用su直接进入继续失败。 [centos_master@localhost ~]$ su 密码： su: 鉴定故障 继续查资料，修改成 [centos_master@localhost ~]$ sudo su root 我们信任您已经从系统管理员那里了解了日常注意事项。 总结起来无外乎这三点： #1) 尊重别人的隐私。 #2) 输入前要先考虑(后果和风险)。 #3) 权力越大，责任越大。 [sudo] centos_master 的密码： [root@localhost centos_master]# ^C [root@localhost centos_master]# systemctl set-default multi-user.target Removed symlink /etc/systemd/system/default.target. Created symlink from /etc/systemd/system/default.target to /usr/lib/systemd/system/multi-user.target. [root@localhost centos_master]# 成功！ 重启虚拟机，已经成功从图形界面变成命令模式。 备注：之后基本使用xshell连接虚拟机之后的第一件事就是sudo su root。 4 虚拟机的一些基础配置 4.1 配置yum源 不建议使用CentOS 7自带的yum源，因为安装软件和依赖时会非常慢甚至超时失败。这里，我们使用阿里云的源予以替换，执行如下命令，替换文件/etc/yum.repos.d/CentOS-Base.repo： wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum makecache 4.2 关闭防火墙 防火墙一定要提前关闭，否则在后续安装K8S集群的时候是个trouble maker。执行下面语句关闭，并禁用开机启动： [root@localhost centos_master]# systemctl stop firewalld &amp; systemctl disable firewalld [1] 4223 Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 4.3 关闭Swap 类似ElasticSearch集群，在安装K8S集群时，Linux的Swap内存交换机制是一定要关闭的，否则会因为内存交换而影响性能以及稳定性。这里，我们可以提前进行设置。 临时关闭swap分区, 重启失效： swapoff -a 永久关闭swap分区： sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab 建议永久关闭，之后如下图即为正常： 4 安装docker 安装kubernetes前，必须要先安装Docker。 4.1 添加阿里云的Docker仓库 [root@localhost centos_master]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo [root@localhost centos_master]# yum makecache 4.2 执行以下命令，安装最新版Docker [root@localhost centos_master]# yum install docker-ce -y 4.3 安装成功后，如下图所示 运行docker --version,可以看到安装了截止目前最新的18.09.8版本： [root@localhost centos_master]# docker --version Docker version 18.09.8, build 0dd43dd87f 4.4 启动Docker服务并激活开机启动 [root@localhost centos_master]# systemctl start docker &amp; systemctl enable docker 4.5 验证 [root@localhost centos_master]# docker run hello-world 成功~ 5 安装kubernrtes 建议使用阿里源的仓库，执行以下命令添加kubernetes.repo仓库 [root@localhost centos_master]# cd /etc/yum.repos.d/ [root@localhost yum.repos.d]# vim kubernetes.repo 出现如图 5.1 关闭swap、防火墙（之前已经关闭），可忽视。 5.2 关闭SeLinux 执行 setenforce 0 5.3 安装kubelet、kubeadm、kubectl 执行以下命令 yum install -y kubelet kubeadm kubectl emmmm报错 重新尝试，清一下缓存 yum clean all yum makecache 接着顺手升级一下yum yum -y update 重新安装kubelet、kubeadm、kubectl 成功~ 5.4 判断docker 的cgroup drive和kubelet的cgroup drive是否一样 首先解决这两个警告 vim /etc/sysctl.conf 接着添加如下内容 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 最后执行 sysctl -p 接下来重启虚拟机 警告消失~ 备注：这里有个坑，虽然我们这里cgroup drive两者都是cgroupfs，是一样的。但是！在后面我们需要把这两者都改成systemd。不过现在可以不用管，后面可以再改；也可以直接参考第二章的2.2节跳过这个坑。 正常启动kubelet [root@localhost centos_master]# systemctl enable kubelet &amp;&amp; systemctl start kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. 5.5 列出需要的镜像 使用kubeadm config images list列出我们需要的镜像 [root@localhost centos_master]# kubeadm config images list W0723 18:09:53.292065 5839 version.go:98] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) W0723 18:09:53.292483 5839 version.go:99] falling back to the local client version: v1.15.1 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 得到所有需要的组件，也就是以下七个组件。 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 接着参考下面的这堆代码进行配置（一行一行地输入命令），将下面这张代码里的组件版本号替换成我们的即可，这个地方需要十分小心！！（我们的是1.15.1，而下面的代码段里是1.15.0，所以只是根据下面的代码来参考） （例如，下面第一行我们应该修改为docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.1） 这里下载v1.15.0版本 docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.10.0 docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.15.0 docker pull mirrorgooglecontainers/pause:3.1 docker pull mirrorgooglecontainers/etcd:3.3.10 docker pull coredns/coredns:1.3.1 镜像打标 docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 k8s.gcr.io/kube-apiserver:v1.15.0 docker tag mirrorgooglecontainers/kube-scheduler:v1.15.0 k8s.gcr.io/kube-scheduler:v1.15.0 docker tag mirrorgooglecontainers/kube-controller-manager:v1.15.0 k8s.gcr.io/kube-controller-manager:v1.15.0 docker tag mirrorgooglecontainers/etcd:v1.15.0 k8s.gcr.io/etcd:v1.15.0 docker tag mirrorgooglecontainers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10 docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1 docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1 镜像分发打包 docker save -o k8s-master.tar.gz `docker image ls |grep k8s |awk &#39;{position=$1&quot;:&quot;$2;print $1,position}&#39; |awk &#39;{print $2}&#39;` 导入镜像 [root@master ~]# docker load -i k8s-master.tar.gz Loaded image: k8s.gcr.io/etcd:3.3.10 Loaded image: k8s.gcr.io/pause:3.1 Loaded image: k8s.gcr.io/kube-proxy:v1.15.0 Loaded image: k8s.gcr.io/kube-apiserver:v1.15.0 Loaded image: k8s.gcr.io/kube-controller-manager:v1.15.0 Loaded image: k8s.gcr.io/kube-scheduler:v1.15.0 Loaded image: k8s.gcr.io/coredns:1.3.1 成功~如图 [root@localhost centos_master]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mirrorgooglecontainers/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB k8s.gcr.io/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB k8s.gcr.io/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB k8s.gcr.io/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB mirrorgooglecontainers/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB k8s.gcr.io/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.0 201c7a840312 4 weeks ago 207MB k8s.gcr.io/coredns 1.3.1 eb516548c180 6 months ago 40.3MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.3.1 eb516548c180 6 months ago 40.3MB hello-world latest fce289e99eb9 6 months ago 1.84kB mirrorgooglecontainers/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB k8s.gcr.io/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB mirrorgooglecontainers/pause 3.1 da86e6ba6ca1 19 months ago 742kB k8s.gcr.io/pause 3.1 da86e6ba6ca1 19 months ago 6 复制虚拟机 当Node1的Kubernetes安装完毕后，就需要进行虚拟机的复制了。复制前需要退出虚拟机，我们选择“正常关机”。右键虚拟机点击复制： 注意上述的所有箭头。点击“复制”，稍等几分钟，即可完成复制，一共复制两台。 现在我们就有了三个虚拟机，master、node2、node3。 复制结束后，不要马上启动虚拟机，而先要为每一个虚拟机添加一个网卡，用于节点间的互通访问。如下图所示，连接方式选择“Host-Only”模式： 网卡添加结束后，启动三个虚拟机，查看各个IP。以主节点master为例，运行ip addr 可以看到，网卡enp0s8为新添加的网卡2，IP地址为192.168.56.103。三个节点IP分别为： master：192.168.56.103 Node2：192.168.56.101 Node3：192.168.56.102 三台虚拟机互相ping一下瞅瞅网络连通性。 接着根据之前master连接xshell的步骤，使用xshell连接另外两台虚拟机，只是把主机端口分别改成9023、8081。 网卡添加结束后，即可启动三个虚拟机，我们需要进行一些简单的设置，以主节点Node1为例： 编辑/etc/hostname，将hostname修改为k8s_master 编辑/etc/hosts，追加内容IP k8s_master，其中上IP为网卡2的IP地址，修改后重启生效。另外两个节点修改同理，主机名分别为k8s_node2、k8s_node3。 (这里也折腾了很久，后来发现正确的步骤是用vi打开之后，再点一下i进入编辑模式，编辑好之后，点Esc，接着输入:wq保存退出；另外编辑hostname时用hostnamectl set-hostname 主机名 同样可以） 备注：这里有个坑，主机名中不要有_，在第二章中我折腾了很久才发现这个问题，所以这里可以把主机名直接改为k8s-master、k8s-node2、k8s-node3跳过这个坑。 最后，输入hostname可以看到当前的hostname。 7 小结 目前我们有了三个虚拟机，每个虚拟机上都有docker、kubernetes。下一章我们开始正式创建集群。" />
<link rel="canonical" href="https://uzzz.org/2019/07/23/795459.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/23/795459.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-23T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"(win10 + virtualbox6.0 + centos7.6.1810 + docker18.09.8 + kubernetes1.15.1 + istio1.2.3) 本文参考网址： https://www.jianshu.com/p/e43f5e848da1 https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ https://www.jianshu.com/p/1aebf568b786 https://blog.csdn.net/donglynn/article/details/47784393 https://blog.csdn.net/MC_CodeGirl/article/details/79998656 https://blog.csdn.net/andriy_dangli/article/details/85062983 https://docs.projectcalico.org/v3.8/getting-started/kubernetes/installation/calico https://www.jianshu.com/p/70efa1b853f5 https://blog.csdn.net/weixin_44723434/article/details/94583457 https://preliminary.istio.io/zh/docs/setup/kubernetes/download/ https://www.cnblogs.com/rickie/p/istio.html https://blog.csdn.net/lwplvx/article/details/79192182 https://blog.csdn.net/qq_36402372/article/details/82991098 https://www.cnblogs.com/assion/p/11326088.html http://www.lampnick.com/php/823 https://blog.csdn.net/ccagy/article/details/83059349 https://www.jianshu.com/p/789bc867feaa https://www.jianshu.com/p/dde56c521078 本系列分为三章，第一章是创建虚拟机、docker、kubernetes等一些基础设施；第二章是在此基础上创建一个三节点的kubernetes集群；第三章是再在之上搭建istio服务网格。 本文参考了大量其他优秀作者的创作（已经在开头列出），自己从零开始，慢慢搭建了istio服务网格，每一步都在文章中详细地列出了。之所以要自己重新从头搭建，一方面是很多CSDN、简书或其他平台的教程都已经离现在（2019.8.14）太过遥远，变得不合时宜，单纯地照着别人的路子走会遇到非常多的坑；另一方面是实践出真知。 由于我也是刚开始学习istio服务网格，才疏学浅，难免有不尽如人意的地方，还请见谅。 1 系统CentOS 下载 官网下载 DVD ISO：标准安装版，一般下载这个就可以了（推荐） Minimal ISO：迷你版，小巧、安装快速、自带的软件少 点进去之后选择阿里云 然后就是正常的下载 2 虚拟机 virtualbox 下载 官网下载 之所以选择virtualbox 而不是vmware，是因为另一个教程上这样做的，所以…，等搭建完熟悉流程后就可以随心所欲啦。 正常下载 3 创建虚拟机 打开安装好的VirtualBox，新建 控制→新建 如下图进行设置 内存至少2G 默认 虚拟硬盘至少20G 创建成功 接下来安装操作系统 点击设置 如图 选择之前下载好的 .iso 文件，正常安装 。 开启虚拟机，安装CentOS。 一些注意选项如下： 如下图正在安装 重启完成安装。 4 将xshell和虚拟机连接起来 接下来进行虚拟机的配置。由于直接在VirtualBox里操作bash是一件非常恶心的事情，我们使用第三方的终端模拟软件来控制虚拟机，本文选择的是xshell，当然其他的也可以。 返回virtualbox的控制界面，点开设置。 由于VirtualBox 默认使用NAT网络转换，宿主机无法直接访问虚拟机，但我们只要简单的在NAT网卡上添加端口转发，即可访问虚拟机。这里，我们通过端口转发暴露虚拟机的SSH端口（22），就可以远程连接到虚拟机。 在设置中，选择“网络”=&gt;“网卡1”&gt;=“高级”&gt;=“端口转发”： 在我们真实的物理机上，可以利用Xshell，通过端口9000连接到虚拟机终端上。打开Xshell，新建一个连接。注意，因为端口是映射到宿主机上的，所以主机地址要填写为127.0.0.1： 打开Xshell如下配置新建会话。 登陆成功（这里折腾了一会） 关闭图形界面 CentOS 7 安装好后，登录时默认启用了很占资源的图形界面，若启动三个虚拟机更会卡的飞起。因此，我们可以通过如下命令切换默认的登录方式： 命令模式 systemctl set-default multi-user.target 图形模式 systemctl set-default graphical.target 这里，强烈建议切换为命令模式，所有的操作都通过Xshell进行足以。注意，上面的命令执行后重启生效。 试了很多次一直失败，如下 然后发现是需要需要进入root，使用su直接进入继续失败。 [centos_master@localhost ~]$ su 密码： su: 鉴定故障 继续查资料，修改成 [centos_master@localhost ~]$ sudo su root 我们信任您已经从系统管理员那里了解了日常注意事项。 总结起来无外乎这三点： #1) 尊重别人的隐私。 #2) 输入前要先考虑(后果和风险)。 #3) 权力越大，责任越大。 [sudo] centos_master 的密码： [root@localhost centos_master]# ^C [root@localhost centos_master]# systemctl set-default multi-user.target Removed symlink /etc/systemd/system/default.target. Created symlink from /etc/systemd/system/default.target to /usr/lib/systemd/system/multi-user.target. [root@localhost centos_master]# 成功！ 重启虚拟机，已经成功从图形界面变成命令模式。 备注：之后基本使用xshell连接虚拟机之后的第一件事就是sudo su root。 4 虚拟机的一些基础配置 4.1 配置yum源 不建议使用CentOS 7自带的yum源，因为安装软件和依赖时会非常慢甚至超时失败。这里，我们使用阿里云的源予以替换，执行如下命令，替换文件/etc/yum.repos.d/CentOS-Base.repo： wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum makecache 4.2 关闭防火墙 防火墙一定要提前关闭，否则在后续安装K8S集群的时候是个trouble maker。执行下面语句关闭，并禁用开机启动： [root@localhost centos_master]# systemctl stop firewalld &amp; systemctl disable firewalld [1] 4223 Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. 4.3 关闭Swap 类似ElasticSearch集群，在安装K8S集群时，Linux的Swap内存交换机制是一定要关闭的，否则会因为内存交换而影响性能以及稳定性。这里，我们可以提前进行设置。 临时关闭swap分区, 重启失效： swapoff -a 永久关闭swap分区： sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab 建议永久关闭，之后如下图即为正常： 4 安装docker 安装kubernetes前，必须要先安装Docker。 4.1 添加阿里云的Docker仓库 [root@localhost centos_master]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo [root@localhost centos_master]# yum makecache 4.2 执行以下命令，安装最新版Docker [root@localhost centos_master]# yum install docker-ce -y 4.3 安装成功后，如下图所示 运行docker --version,可以看到安装了截止目前最新的18.09.8版本： [root@localhost centos_master]# docker --version Docker version 18.09.8, build 0dd43dd87f 4.4 启动Docker服务并激活开机启动 [root@localhost centos_master]# systemctl start docker &amp; systemctl enable docker 4.5 验证 [root@localhost centos_master]# docker run hello-world 成功~ 5 安装kubernrtes 建议使用阿里源的仓库，执行以下命令添加kubernetes.repo仓库 [root@localhost centos_master]# cd /etc/yum.repos.d/ [root@localhost yum.repos.d]# vim kubernetes.repo 出现如图 5.1 关闭swap、防火墙（之前已经关闭），可忽视。 5.2 关闭SeLinux 执行 setenforce 0 5.3 安装kubelet、kubeadm、kubectl 执行以下命令 yum install -y kubelet kubeadm kubectl emmmm报错 重新尝试，清一下缓存 yum clean all yum makecache 接着顺手升级一下yum yum -y update 重新安装kubelet、kubeadm、kubectl 成功~ 5.4 判断docker 的cgroup drive和kubelet的cgroup drive是否一样 首先解决这两个警告 vim /etc/sysctl.conf 接着添加如下内容 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 最后执行 sysctl -p 接下来重启虚拟机 警告消失~ 备注：这里有个坑，虽然我们这里cgroup drive两者都是cgroupfs，是一样的。但是！在后面我们需要把这两者都改成systemd。不过现在可以不用管，后面可以再改；也可以直接参考第二章的2.2节跳过这个坑。 正常启动kubelet [root@localhost centos_master]# systemctl enable kubelet &amp;&amp; systemctl start kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. 5.5 列出需要的镜像 使用kubeadm config images list列出我们需要的镜像 [root@localhost centos_master]# kubeadm config images list W0723 18:09:53.292065 5839 version.go:98] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) W0723 18:09:53.292483 5839 version.go:99] falling back to the local client version: v1.15.1 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 得到所有需要的组件，也就是以下七个组件。 k8s.gcr.io/kube-apiserver:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1 k8s.gcr.io/kube-proxy:v1.15.1 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1 接着参考下面的这堆代码进行配置（一行一行地输入命令），将下面这张代码里的组件版本号替换成我们的即可，这个地方需要十分小心！！（我们的是1.15.1，而下面的代码段里是1.15.0，所以只是根据下面的代码来参考） （例如，下面第一行我们应该修改为docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.1） 这里下载v1.15.0版本 docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.15.0 docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.10.0 docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.15.0 docker pull mirrorgooglecontainers/pause:3.1 docker pull mirrorgooglecontainers/etcd:3.3.10 docker pull coredns/coredns:1.3.1 镜像打标 docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 k8s.gcr.io/kube-apiserver:v1.15.0 docker tag mirrorgooglecontainers/kube-scheduler:v1.15.0 k8s.gcr.io/kube-scheduler:v1.15.0 docker tag mirrorgooglecontainers/kube-controller-manager:v1.15.0 k8s.gcr.io/kube-controller-manager:v1.15.0 docker tag mirrorgooglecontainers/etcd:v1.15.0 k8s.gcr.io/etcd:v1.15.0 docker tag mirrorgooglecontainers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10 docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1 docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1 镜像分发打包 docker save -o k8s-master.tar.gz `docker image ls |grep k8s |awk &#39;{position=$1&quot;:&quot;$2;print $1,position}&#39; |awk &#39;{print $2}&#39;` 导入镜像 [root@master ~]# docker load -i k8s-master.tar.gz Loaded image: k8s.gcr.io/etcd:3.3.10 Loaded image: k8s.gcr.io/pause:3.1 Loaded image: k8s.gcr.io/kube-proxy:v1.15.0 Loaded image: k8s.gcr.io/kube-apiserver:v1.15.0 Loaded image: k8s.gcr.io/kube-controller-manager:v1.15.0 Loaded image: k8s.gcr.io/kube-scheduler:v1.15.0 Loaded image: k8s.gcr.io/coredns:1.3.1 成功~如图 [root@localhost centos_master]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mirrorgooglecontainers/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB k8s.gcr.io/kube-controller-manager v1.15.1 d75082f1d121 5 days ago 159MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB k8s.gcr.io/kube-apiserver v1.15.1 68c3eb07bfc3 5 days ago 207MB mirrorgooglecontainers/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB k8s.gcr.io/kube-proxy v1.15.1 89a062da739d 5 days ago 82.4MB mirrorgooglecontainers/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB k8s.gcr.io/kube-scheduler v1.15.1 b0b3c4c404da 5 days ago 81.1MB mirrorgooglecontainers/kube-apiserver-amd64 v1.15.0 201c7a840312 4 weeks ago 207MB k8s.gcr.io/coredns 1.3.1 eb516548c180 6 months ago 40.3MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.3.1 eb516548c180 6 months ago 40.3MB hello-world latest fce289e99eb9 6 months ago 1.84kB mirrorgooglecontainers/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB k8s.gcr.io/etcd 3.3.10 2c4adeb21b4f 7 months ago 258MB mirrorgooglecontainers/pause 3.1 da86e6ba6ca1 19 months ago 742kB k8s.gcr.io/pause 3.1 da86e6ba6ca1 19 months ago 6 复制虚拟机 当Node1的Kubernetes安装完毕后，就需要进行虚拟机的复制了。复制前需要退出虚拟机，我们选择“正常关机”。右键虚拟机点击复制： 注意上述的所有箭头。点击“复制”，稍等几分钟，即可完成复制，一共复制两台。 现在我们就有了三个虚拟机，master、node2、node3。 复制结束后，不要马上启动虚拟机，而先要为每一个虚拟机添加一个网卡，用于节点间的互通访问。如下图所示，连接方式选择“Host-Only”模式： 网卡添加结束后，启动三个虚拟机，查看各个IP。以主节点master为例，运行ip addr 可以看到，网卡enp0s8为新添加的网卡2，IP地址为192.168.56.103。三个节点IP分别为： master：192.168.56.103 Node2：192.168.56.101 Node3：192.168.56.102 三台虚拟机互相ping一下瞅瞅网络连通性。 接着根据之前master连接xshell的步骤，使用xshell连接另外两台虚拟机，只是把主机端口分别改成9023、8081。 网卡添加结束后，即可启动三个虚拟机，我们需要进行一些简单的设置，以主节点Node1为例： 编辑/etc/hostname，将hostname修改为k8s_master 编辑/etc/hosts，追加内容IP k8s_master，其中上IP为网卡2的IP地址，修改后重启生效。另外两个节点修改同理，主机名分别为k8s_node2、k8s_node3。 (这里也折腾了很久，后来发现正确的步骤是用vi打开之后，再点一下i进入编辑模式，编辑好之后，点Esc，接着输入:wq保存退出；另外编辑hostname时用hostnamectl set-hostname 主机名 同样可以） 备注：这里有个坑，主机名中不要有_，在第二章中我折腾了很久才发现这个问题，所以这里可以把主机名直接改为k8s-master、k8s-node2、k8s-node3跳过这个坑。 最后，输入hostname可以看到当前的hostname。 7 小结 目前我们有了三个虚拟机，每个虚拟机上都有docker、kubernetes。下一章我们开始正式创建集群。","@type":"BlogPosting","url":"https://uzzz.org/2019/07/23/795459.html","headline":"从头开始搭建kubernetes集群+istio服务网格（1）—— 前期准备、安装docker、kubernetes","dateModified":"2019-07-23T00:00:00+08:00","datePublished":"2019-07-23T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/23/795459.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>从头开始搭建kubernetes集群+istio服务网格（1）—— 前期准备、安装docker、kubernetes</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h1><a id="win10__virtualbox60___centos761810__docker18098__kubernetes1151__istio123_1"></a>(win10 + virtualbox6.0 + centos7.6.1810 + docker18.09.8 + kubernetes1.15.1 + istio1.2.3)</h1> 
  <p>本文参考网址：<br> https://www.jianshu.com/p/e43f5e848da1<br> https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/<br> https://www.jianshu.com/p/1aebf568b786<br> https://blog.csdn.net/donglynn/article/details/47784393<br> https://blog.csdn.net/MC_CodeGirl/article/details/79998656<br> https://blog.csdn.net/andriy_dangli/article/details/85062983<br> https://docs.projectcalico.org/v3.8/getting-started/kubernetes/installation/calico<br> https://www.jianshu.com/p/70efa1b853f5<br> https://blog.csdn.net/weixin_44723434/article/details/94583457<br> https://preliminary.istio.io/zh/docs/setup/kubernetes/download/<br> https://www.cnblogs.com/rickie/p/istio.html<br> https://blog.csdn.net/lwplvx/article/details/79192182<br> https://blog.csdn.net/qq_36402372/article/details/82991098<br> https://www.cnblogs.com/assion/p/11326088.html<br> http://www.lampnick.com/php/823<br> https://blog.csdn.net/ccagy/article/details/83059349<br> https://www.jianshu.com/p/789bc867feaa<br> https://www.jianshu.com/p/dde56c521078</p> 
  <blockquote> 
   <p>本系列分为三章，第一章是创建虚拟机、docker、kubernetes等一些基础设施；<a href="https://blog.csdn.net/weixin_42711936/article/details/97041456" rel="nofollow" data-token="60c4d02dfa007dc32261c9f8b982430a">第二章</a>是在此基础上创建一个三节点的kubernetes集群；<a href="https://blog.csdn.net/weixin_42711936/article/details/99311796" rel="nofollow" data-token="6bcf6d7c939b46f4e4a7f1d839278dbd">第三章</a>是再在之上搭建istio服务网格。<br> 本文参考了大量其他优秀作者的创作（已经在开头列出），自己从零开始，慢慢搭建了istio服务网格，每一步都在文章中详细地列出了。之所以要自己重新从头搭建，一方面是很多CSDN、简书或其他平台的教程都已经离现在（2019.8.14）太过遥远，变得不合时宜，单纯地照着别人的路子走会遇到非常多的坑；另一方面是实践出真知。<br> 由于我也是刚开始学习istio服务网格，才疏学浅，难免有不尽如人意的地方，还请见谅。</p> 
  </blockquote> 
  <h2><a id="1_CentOS__28"></a>1 系统CentOS 下载</h2> 
  <p><a href="https://www.centos.org/download/" rel="nofollow" data-token="ef31cc20b53281216bd7d29872efaa36">官网下载</a><br> DVD ISO：标准安装版，一般下载这个就可以了（推荐）<br> Minimal ISO：迷你版，小巧、安装快速、自带的软件少<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722204256663.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="DVD ISO：标准安装版，一般下载这个就可以了（推荐）Everything ISO：对完整版安装盘的软件进行补充，集成所有软件。（包含CentOS7的一套完整的软件包，可以用来安装系统或者填充本地镜像）Minimal ISO：迷你版，小巧、安装快速、自带的软件少"><br> 点进去之后选择阿里云<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722205519934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">然后就是正常的下载</p> 
  <h2><a id="2__virtualbox__39"></a>2 虚拟机 virtualbox 下载</h2> 
  <p><a href="https://www.virtualbox.org/" rel="nofollow" data-token="6d9fc05fc201b85a1f089e34430a1500">官网下载</a><br> 之所以选择virtualbox 而不是vmware，是因为另一个教程上这样做的，所以…，等搭建完熟悉流程后就可以随心所欲啦。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722210230550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">正常下载<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722210459999.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="3__44"></a>3 创建虚拟机</h2> 
  <p>打开安装好的VirtualBox，新建<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722214833988.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">控制→新建<br> 如下图进行设置<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215327580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">内存至少2G<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/201907222154539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">默认<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215528849.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215604392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215629233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">虚拟硬盘至少20G<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215746711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">创建成功<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722215838398.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">接下来安装操作系统<br> 点击设置<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722220020982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">如图</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722221013854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">选择之前下载好的 <code>.iso</code> 文件，正常安装 。<br> 开启虚拟机，安装CentOS。<br> 一些注意选项如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722222115213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">如下图正在安装<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722222347710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">重启完成安装。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723091350554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="4_xshell_62"></a>4 将xshell和虚拟机连接起来</h2> 
  <p>接下来进行虚拟机的配置。由于直接在VirtualBox里操作bash是一件非常恶心的事情，我们使用第三方的终端模拟软件来控制虚拟机，本文选择的是xshell，当然其他的也可以。<br> 返回virtualbox的控制界面，点开设置。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723092708936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p>由于VirtualBox<br> 默认使用NAT网络转换，宿主机无法直接访问虚拟机，但我们只要简单的在NAT网卡上添加端口转发，即可访问虚拟机。这里，我们通过端口转发暴露虚拟机的SSH端口（22），就可以远程连接到虚拟机。<br> 在设置中，选择“网络”=&gt;“网卡1”&gt;=“高级”&gt;=“端口转发”：</p> 
  </blockquote> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723092855612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p>在我们真实的物理机上，可以利用Xshell，通过端口9000连接到虚拟机终端上。打开Xshell，新建一个连接。注意，因为端口是映射到宿主机上的，所以主机地址要填写为127.0.0.1：</p> 
  </blockquote> 
  <p>打开Xshell如下配置新建会话。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723093533851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">登陆成功（这里折腾了一会）<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723094546231.png" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p>关闭图形界面 CentOS 7<br> 安装好后，登录时默认启用了很占资源的图形界面，若启动三个虚拟机更会卡的飞起。因此，我们可以通过如下命令切换默认的登录方式：</p> 
   <p>命令模式 systemctl set-default multi-user.target</p> 
   <p>图形模式 systemctl set-default graphical.target<br> 这里，强烈建议切换为命令模式，所有的操作都通过Xshell进行足以。注意，上面的命令执行后重启生效。</p> 
  </blockquote> 
  <p>试了很多次一直失败，如下<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723095312148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">然后发现是需要需要进入root，使用su直接进入继续失败。</p> 
  <pre><code>[centos_master@localhost ~]$ su
密码：
su: 鉴定故障
</code></pre> 
  <p>继续查资料，修改成</p> 
  <pre><code>[centos_master@localhost ~]$ sudo su root

我们信任您已经从系统管理员那里了解了日常注意事项。
总结起来无外乎这三点：

    #1) 尊重别人的隐私。
    #2) 输入前要先考虑(后果和风险)。
    #3) 权力越大，责任越大。

[sudo] centos_master 的密码：
[root@localhost centos_master]# ^C
[root@localhost centos_master]# systemctl set-default multi-user.target
Removed symlink /etc/systemd/system/default.target.
Created symlink from /etc/systemd/system/default.target to /usr/lib/systemd/system/multi-user.target.
[root@localhost centos_master]# 

</code></pre> 
  <p>成功！<br> 重启虚拟机，已经成功从图形界面变成命令模式。</p> 
  <blockquote> 
   <p>备注：之后基本使用xshell连接虚拟机之后的第一件事就是<code>sudo su root</code>。</p> 
  </blockquote> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723100644901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="4__123"></a>4 虚拟机的一些基础配置</h2> 
  <h3><a id="41_yum_124"></a>4.1 配置yum源</h3> 
  <p>不建议使用CentOS 7自带的yum源，因为安装软件和依赖时会非常慢甚至超时失败。这里，我们使用阿里云的源予以替换，执行如下命令，替换文件/etc/yum.repos.d/CentOS-Base.repo：</p> 
  <pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 
yum makecache
</code></pre> 
  <h3><a id="42__132"></a>4.2 关闭防火墙</h3> 
  <p>防火墙一定要提前关闭，否则在后续安装K8S集群的时候是个trouble maker。执行下面语句关闭，并禁用开机启动：</p> 
  <pre><code>[root@localhost centos_master]# systemctl stop firewalld &amp; systemctl disable firewalld
[1] 4223
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
</code></pre> 
  <h3><a id="43_Swap_142"></a>4.3 关闭Swap</h3> 
  <p>类似ElasticSearch集群，在安装K8S集群时，Linux的Swap内存交换机制是一定要关闭的，否则会因为内存交换而影响性能以及稳定性。这里，我们可以提前进行设置。</p> 
  <p>临时关闭swap分区, 重启失效：</p> 
  <pre><code>swapoff -a
</code></pre> 
  <p>永久关闭swap分区：</p> 
  <pre><code>sed -ri 's/.*swap.*/#&amp;/' /etc/fstab
</code></pre> 
  <p>建议永久关闭，之后如下图即为正常：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723101815465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="4_docker_155"></a>4 安装docker</h2> 
  <p>安装kubernetes前，必须要先安装Docker。</p> 
  <h3><a id="41_Docker_158"></a>4.1 添加阿里云的Docker仓库</h3> 
  <pre><code>[root@localhost centos_master]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@localhost centos_master]# yum makecache
</code></pre> 
  <h3><a id="42_Docker_163"></a>4.2 执行以下命令，安装最新版Docker</h3> 
  <pre><code>[root@localhost centos_master]# yum install docker-ce -y
</code></pre> 
  <h3><a id="43__169"></a>4.3 安装成功后，如下图所示</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723102507146.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>运行<code>docker --version</code>,可以看到安装了截止目前最新的18.09.8版本：</p> 
  <pre><code>[root@localhost centos_master]# docker --version
Docker version 18.09.8, build 0dd43dd87f
</code></pre> 
  <h3><a id="44_Docker_178"></a>4.4 启动Docker服务并激活开机启动</h3> 
  <pre><code>[root@localhost centos_master]# systemctl start docker &amp; systemctl enable docker
</code></pre> 
  <h3><a id="45__183"></a>4.5 验证</h3> 
  <pre><code>[root@localhost centos_master]# docker run hello-world
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723102840766.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">成功~</p> 
  <h2><a id="5_kubernrtes_190"></a>5 安装kubernrtes</h2> 
  <p>建议使用阿里源的仓库，执行以下命令添加kubernetes.repo仓库</p> 
  <pre><code>[root@localhost centos_master]# cd /etc/yum.repos.d/
[root@localhost yum.repos.d]# vim kubernetes.repo
</code></pre> 
  <p>出现如图<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723104319748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h3><a id="51_swap_199"></a>5.1 关闭swap、防火墙（之前已经关闭），可忽视。</h3> 
  <h3><a id="52_SeLinux_200"></a>5.2 关闭SeLinux</h3> 
  <p>执行</p> 
  <pre><code>setenforce 0
</code></pre> 
  <h3><a id="53_kubeletkubeadmkubectl_206"></a>5.3 安装kubelet、kubeadm、kubectl</h3> 
  <p>执行以下命令</p> 
  <pre><code>yum install -y kubelet kubeadm kubectl
</code></pre> 
  <p>emmmm报错<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723104940799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">重新尝试，清一下缓存</p> 
  <pre><code>yum clean all
yum makecache
</code></pre> 
  <p>接着顺手升级一下yum</p> 
  <pre><code>yum -y update
</code></pre> 
  <p>重新安装kubelet、kubeadm、kubectl<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723110828327.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">成功~</p> 
  <h3><a id="54_docker_cgroup_drivekubeletcgroup_drive_230"></a>5.4 判断docker 的cgroup drive和kubelet的cgroup drive是否一样</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723111111395.png" alt="在这里插入图片描述">首先解决这两个警告</p> 
  <pre><code>vim /etc/sysctl.conf
</code></pre> 
  <p>接着添加如下内容</p> 
  <pre><code>net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
</code></pre> 
  <p>最后执行</p> 
  <pre><code>sysctl -p
</code></pre> 
  <p>接下来重启虚拟机<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723164155172.png" alt="在这里插入图片描述">警告消失~<br> <em><strong>备注：这里有个坑，虽然我们这里cgroup drive两者都是<code>cgroupfs</code>，是一样的。但是！在后面我们需要把这两者都改成<code>systemd</code>。不过现在可以不用管，后面可以再改；也可以直接参考第二章的2.2节跳过这个坑。</strong></em></p> 
  <p>正常启动kubelet</p> 
  <pre><code>[root@localhost centos_master]# systemctl enable kubelet &amp;&amp; systemctl start kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.

</code></pre> 
  <h3><a id="55__257"></a>5.5 列出需要的镜像</h3> 
  <p>使用<code>kubeadm config images list</code>列出我们需要的镜像</p> 
  <pre><code>[root@localhost centos_master]# kubeadm config images list
W0723 18:09:53.292065    5839 version.go:98] could not fetch a Kubernetes version from the internet: unable to get URL "https://dl.k8s.io/release/stable-1.txt": Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
W0723 18:09:53.292483    5839 version.go:99] falling back to the local client version: v1.15.1
k8s.gcr.io/kube-apiserver:v1.15.1
k8s.gcr.io/kube-controller-manager:v1.15.1
k8s.gcr.io/kube-scheduler:v1.15.1
k8s.gcr.io/kube-proxy:v1.15.1
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1
</code></pre> 
  <p>得到所有需要的组件，也就是以下七个组件。<br> k8s.gcr.io/kube-apiserver:v1.15.1<br> k8s.gcr.io/kube-controller-manager:v1.15.1<br> k8s.gcr.io/kube-scheduler:v1.15.1<br> k8s.gcr.io/kube-proxy:v1.15.1<br> k8s.gcr.io/pause:3.1<br> k8s.gcr.io/etcd:3.3.10<br> k8s.gcr.io/coredns:1.3.1<br> 接着<strong>参考</strong>下面的这堆代码进行配置（一行一行地输入命令），<strong>将下面这张代码里的组件版本号替换成我们的即可</strong>，这个地方需要十分小心！！（我们的是1.15.1，而下面的代码段里是1.15.0，所以只是根据下面的代码来参考）<br> （例如，下面第一行我们应该修改为<code>docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.1</code>）</p> 
  <pre><code>这里下载v1.15.0版本   
docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0
docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.15.0
docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.10.0
docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.15.0
docker pull mirrorgooglecontainers/pause:3.1
docker pull mirrorgooglecontainers/etcd:3.3.10
docker pull coredns/coredns:1.3.1

镜像打标
docker tag  mirrorgooglecontainers/kube-apiserver-amd64:v1.15.0 k8s.gcr.io/kube-apiserver:v1.15.0
docker tag  mirrorgooglecontainers/kube-scheduler:v1.15.0 k8s.gcr.io/kube-scheduler:v1.15.0
docker tag  mirrorgooglecontainers/kube-controller-manager:v1.15.0 k8s.gcr.io/kube-controller-manager:v1.15.0
docker tag  mirrorgooglecontainers/etcd:v1.15.0 k8s.gcr.io/etcd:v1.15.0
docker tag  mirrorgooglecontainers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10
docker tag  mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1
docker tag  coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1

镜像分发打包
docker save -o k8s-master.tar.gz  `docker image ls |grep k8s |awk '{position=$1":"$2;print $1,position}' |awk '{print $2}'`

导入镜像
[root@master ~]# docker load -i k8s-master.tar.gz 
Loaded image: k8s.gcr.io/etcd:3.3.10
Loaded image: k8s.gcr.io/pause:3.1
Loaded image: k8s.gcr.io/kube-proxy:v1.15.0
Loaded image: k8s.gcr.io/kube-apiserver:v1.15.0
Loaded image: k8s.gcr.io/kube-controller-manager:v1.15.0
Loaded image: k8s.gcr.io/kube-scheduler:v1.15.0
Loaded image: k8s.gcr.io/coredns:1.3.1
</code></pre> 
  <p>成功~如图</p> 
  <pre><code>[root@localhost centos_master]# docker images
REPOSITORY                                                    TAG                 IMAGE ID            CREATED             SIZE
mirrorgooglecontainers/kube-controller-manager                v1.15.1             d75082f1d121        5 days ago          159MB
k8s.gcr.io/kube-controller-manager                            v1.15.1             d75082f1d121        5 days ago          159MB
mirrorgooglecontainers/kube-apiserver-amd64                   v1.15.1             68c3eb07bfc3        5 days ago          207MB
mirrorgooglecontainers/kube-apiserver                         v1.15.1             68c3eb07bfc3        5 days ago          207MB
k8s.gcr.io/kube-apiserver                                     v1.15.1             68c3eb07bfc3        5 days ago          207MB
mirrorgooglecontainers/kube-proxy                             v1.15.1             89a062da739d        5 days ago          82.4MB
k8s.gcr.io/kube-proxy                                         v1.15.1             89a062da739d        5 days ago          82.4MB
mirrorgooglecontainers/kube-scheduler                         v1.15.1             b0b3c4c404da        5 days ago          81.1MB
k8s.gcr.io/kube-scheduler                                     v1.15.1             b0b3c4c404da        5 days ago          81.1MB
mirrorgooglecontainers/kube-apiserver-amd64                   v1.15.0             201c7a840312        4 weeks ago         207MB
k8s.gcr.io/coredns                                            1.3.1               eb516548c180        6 months ago        40.3MB
registry.cn-hangzhou.aliyuncs.com/google_containers/coredns   1.3.1               eb516548c180        6 months ago        40.3MB
hello-world                                                   latest              fce289e99eb9        6 months ago        1.84kB
mirrorgooglecontainers/etcd                                   3.3.10              2c4adeb21b4f        7 months ago        258MB
k8s.gcr.io/etcd                                               3.3.10              2c4adeb21b4f        7 months ago        258MB
mirrorgooglecontainers/pause                                  3.1                 da86e6ba6ca1        19 months ago       742kB
k8s.gcr.io/pause                                              3.1                 da86e6ba6ca1        19 months ago 

</code></pre> 
  <h2><a id="6__341"></a>6 复制虚拟机</h2> 
  <p>当Node1的Kubernetes安装完毕后，就需要进行虚拟机的复制了。复制前需要退出虚拟机，我们选择“正常关机”。右键虚拟机点击复制：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723200137596.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>注意上述的所有箭头。点击“复制”，稍等几分钟，即可完成复制，一共复制两台。<br> 现在我们就有了三个虚拟机，master、node2、node3。<br> 复制结束后，不要马上启动虚拟机，而先要为每一个虚拟机添加一个网卡，用于节点间的互通访问。如下图所示，连接方式选择“Host-Only”模式：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723200655855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 网卡添加结束后，启动三个虚拟机，查看各个IP。以主节点master为例，运行ip addr<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190723201805847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjcxMTkzNg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">可以看到，网卡enp0s8为新添加的网卡2，IP地址为192.168.56.103。三个节点IP分别为：</p> 
  <pre><code>master：192.168.56.103
Node2：192.168.56.101
Node3：192.168.56.102
</code></pre> 
  <p>三台虚拟机互相ping一下瞅瞅网络连通性。<br> 接着根据之前master连接xshell的步骤，使用xshell连接另外两台虚拟机，只是把主机端口分别改成9023、8081。</p> 
  <blockquote> 
   <p>网卡添加结束后，即可启动三个虚拟机，我们需要进行一些简单的设置，以主节点Node1为例：</p> 
   <p>编辑/etc/hostname，将hostname修改为k8s_master</p> 
   <p>编辑/etc/hosts，追加内容<code>IP k8s_master</code>，其中上IP为网卡2的IP地址，修改后重启生效。另外两个节点修改同理，主机名分别为k8s_node2、k8s_node3。</p> 
  </blockquote> 
  <p>(这里也折腾了很久，后来发现正确的步骤是用<code>vi</code>打开之后，再点一下<code>i</code>进入编辑模式，编辑好之后，点Esc，接着输入<code>:wq</code>保存退出；另外编辑hostname时用<code>hostnamectl set-hostname 主机名</code> 同样可以）<br> <em><strong>备注：这里有个坑，主机名中不要有_，在第二章中我折腾了很久才发现这个问题，所以这里可以把主机名直接改为k8s-master、k8s-node2、k8s-node3跳过这个坑。</strong></em><br> 最后，输入<code>hostname</code>可以看到当前的hostname。</p> 
  <h2><a id="7__369"></a>7 小结</h2> 
  <p>目前我们有了三个虚拟机，每个虚拟机上都有docker、kubernetes。<a href="https://blog.csdn.net/weixin_42711936/article/details/97041456" rel="nofollow" data-token="60c4d02dfa007dc32261c9f8b982430a">下一章</a>我们开始正式创建集群。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
