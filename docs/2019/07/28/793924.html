<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大数据学习笔记之azkaban（一）：azkaban | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="大数据学习笔记之azkaban（一）：azkaban" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="文章目录 一 概述 1.1为什么需要工作流调度系统 1.2 常见工作流调度系统 1.3 各种调度工具特性对比 1.4 Azkaban与Oozie对比 二 Azkaban介绍 三 Azkaban安装部署 3.1 安装前准备 3.2安装azkaban 3.2 创建SSL配置 3.3 时间同步配置 3.4 配置文件 3.4.1 Web服务器配置 3.4.2 执行服务器配置 3.4 启动web服务器 3.5 启动执行服务器 四 Azkaban实战 4.1Command类型之单一job案例 4.2Command类型之多job工作流案例 4.3HDFS操作任务 4.4HIVE脚本任务 一 概述 1.1为什么需要工作流调度系统 1）一个完整的数据分析系统通常都是由大量任务单元组成： shell脚本程序，java程序，mapreduce程序、hive脚本等 2）各任务单元之间存在时间先后及前后依赖关系 3）为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行； 例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示： （1）通过Hadoop先将原始数据同步到HDFS上； （2）借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中； （3）需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表； （4）将明细数据进行复杂的统计分析，得到结果报表信息； （5）需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。 1.2 常见工作流调度系统 1）简单的任务调度：直接使用linux的crontab来定义； 2）复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如ooize、azkaban、 Cascading、Hamake等 1.3 各种调度工具特性对比 下面的表格对上述四种hadoop工作流调度器的关键特性进行了比较，尽管这些工作流调度器能够解决的需求场景基本一致，但在设计理念，目标用户，应用场景等方面还是存在显著的区别，在做技术选型的时候，可以提供参考 特性 Hamake Oozie Azkaban Cascading 工作流描述语言 XML XML (xPDL based) text file with key/value pairs Java API 依赖机制 data-driven explicit explicit explicit 是否要web容器 No Yes Yes No 进度跟踪 console/log messages web page web page Java API Hadoop job调度支持 no yes yes yes 运行模式 command line utility daemon daemon API Pig支持 yes yes yes yes 事件通知 no no no yes 需要安装 no yes yes no 支持的hadoop版本 0.18+ 0.20+ currently unknown 0.18+ 重试支持 no workflownode evel yes yes 运行任意命令 yes yes yes yes Amazon EMR支持 yes no currently unknown yes 1.4 Azkaban与Oozie对比 对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象。 详情如下： 1）功能 两者均可以调度mapreduce，pig，java，脚本工作流任务 两者均可以定时执行工作流任务 2）工作流定义 Azkaban使用Properties文件定义工作流 Oozie使用XML文件定义工作流 3）工作流传参 Azkaban支持直接传参，例如 i n p u t O o z i e 支 持 参 数 和 E L 表 达 式 ， 例 如 {input} Oozie支持参数和EL表达式，例如 inputOozie支持参数和EL表达式，例如{fs:dirSize(myInputDir)} 4）定时执行 Azkaban的定时执行任务是基于时间的 Oozie的定时执行任务基于时间和输入数据 5）资源管理 Azkaban有较严格的权限控制，如用户对工作流进行读/写/执行等操作 Oozie暂无严格的权限控制 6）工作流执行 Azkaban有两种运行模式，分别是solo server mode(executor server和web server部署在同一台节点)和multi server mode(executor server和web server可以部署在不同节点) Oozie作为工作流服务器运行，支持多用户和多工作流 7）工作流管理 Azkaban支持浏览器以及ajax方式操作工作流 Oozie支持命令行、HTTP REST、Java API、浏览器操作工作流 二 Azkaban介绍 Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。 它有如下功能特点： 1）Web用户界面 2）方便上传工作流 3）方便设置任务之间的关系 4）调度工作流 5）认证/授权(权限的工作) 6）能够杀死并重新启动工作流 7）模块化和可插拔的插件机制 8）项目工作区 9）工作流和任务的日志记录和审计 下载地址:http://azkaban.github.io/downloads.html 三 Azkaban安装部署 3.1 安装前准备 1）将Azkaban Web服务器、Azkaban执行服务器和MySQL拷贝到hadoop102虚拟机/opt/software目录下 azkaban-web-server-2.5.0.tar.gz azkaban-executor-server-2.5.0.tar.gz azkaban-sql-script-2.5.0.tar.gz mysql-libs.zip 2）目前azkaban只支持 mysql，需安装mysql服务器，本文档中默认已安装好mysql服务器，并建立了 root用户，密码 root。 3.2安装azkaban 1）在/opt/module/目录下创建azkaban目录 [atguigu@hadoop102 module]$ mkdir azkaban 2）解压azkaban-web-server-2.5.0.tar.gz、azkaban-executor-server-2.5.0.tar.gz、azkaban-sql-script-2.5.0.tar.gz到/opt/module/azkaban目录下 [atguigu@hadoop102 software]$ tar -zxvf azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban/ 3）对解压后的文件重新命名 [atguigu@hadoop102 azkaban]$ mv azkaban-web-2.5.0/ server [atguigu@hadoop102 azkaban]$ mv azkaban-executor-2.5.0/ executor 4）azkaban脚本导入 进入mysql，创建azkaban数据库，并将解压的脚本导入到azkaban数据库。 [atguigu@hadoop102 azkaban]$ mysql -uroot -p000000 mysql&gt; create database azkaban; mysql&gt; use azkaban; mysql&gt; source /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql 3.2 创建SSL配置 参考地址: http://docs.codehaus.org/display/JETTY/How+to+configure+SSL 1）生成 keystore的密码及相应信息 [atguigu@hadoop102 hadoop-2.7.2]$ keytool -keystore keystore -alias jetty -genkey -keyalg RSA 输入keystore密码： 再次输入新密码: 您的名字与姓氏是什么？ [Unknown]： 您的组织单位名称是什么？ [Unknown]： 您的组织名称是什么？ [Unknown]： 您所在的城市或区域名称是什么？ [Unknown]： 您所在的州或省份名称是什么？ [Unknown]： 该单位的两字母国家代码是什么 [Unknown]： CN CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？ [否]： y 输入的主密码 （如果和 keystore 密码相同，按回车）： 再次输入新密码: 2）将keystore 考贝到 azkaban web服务器根目录中 [atguigu@hadoop102 hadoop-2.7.2]$ mv keystore /opt/module/azkaban/server/ 3.3 时间同步配置 先配置好服务器节点上的时区 1）如果在/usr/share/zoneinfo/这个目录下不存在时区配置文件Asia/Shanghai，就要用 tzselect 生成。 [atguigu@hadoop102 Asia]$ tzselect Please identify a location so that time zone rules can be set correctly. Please select a continent or ocean. Africa Americas Antarctica Arctic Ocean Asia Atlantic Ocean Australia Europe Indian Ocean Pacific Ocean none - I want to specify the time zone using the Posix TZ format. #? 5 Please select a country. Afghanistan 18) Israel 35) Palestine Armenia 19) Japan 36) Philippines Azerbaijan 20) Jordan 37) Qatar Bahrain 21) Kazakhstan 38) Russia Bangladesh 22) Korea (North) 39) Saudi Arabia Bhutan 23) Korea (South) 40) Singapore Brunei 24) Kuwait 41) Sri Lanka Cambodia 25) Kyrgyzstan 42) Syria China 26) Laos 43) Taiwan Cyprus 27) Lebanon 44) Tajikistan East Timor 28) Macau 45) Thailand Georgia 29) Malaysia 46) Turkmenistan Hong Kong 30) Mongolia 47) United Arab Emirates India 31) Myanmar (Burma) 48) Uzbekistan Indonesia 32) Nepal 49) Vietnam Iran 33) Oman 50) Yemen Iraq 34) Pakistan #? 9 Please select one of the following time zone regions. Beijing Time Xinjiang Time #? 1 The following information has been given: China Beijing Time Therefore TZ=‘Asia/Shanghai’ will be used. Local time is now: Wed Jun 14 09:16:46 CST 2017. Universal Time is now: Wed Jun 14 01:16:46 UTC 2017. Is the above information OK? Yes No #?1 2）拷贝该时区文件，覆盖系统本地时区配置 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 3）集群时间同步 sudo date -s ‘2017-06-14 09:23:45’ hwclock -w 3.4 配置文件 3.4.1 Web服务器配置 1）进入azkaban web服务器安装目录 conf目录，打开azkaban.properties文件 [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/server/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban Personalization Settings azkaban.name=Test #服务器UI名称,用于服务器上方显示的名字 azkaban.label=My Local Azkaban #描述 azkaban.color=#FF3601 #UI颜色 azkaban.default.servlet.path=/index # web.resource.dir=web/ #默认根web目录 default.timezone.id=Asia/Shanghai #默认时区,已改为亚洲/上海 默认为美国 #Azkaban UserManager class user.manager.class=azkaban.user.XmlUserManager #用户权限管理默认类 user.manager.xml.file=conf/azkaban-users.xml #用户配置,具体配置参加下文 #Loader for projects executor.global.properties=conf/global.properties # global配置文件所在位置 azkaban.project.dir=projects # database.type=mysql #数据库类型 mysql.port=3306 #端口号 mysql.host=hadoop102 #数据库连接IP mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #Velocity dev mode velocity.dev.mode=false #Jetty服务器属性. jetty.maxThreads=25 #最大线程数 jetty.ssl.port=8443 #Jetty SSL端口 jetty.port=8081 #Jetty端口 jetty.keystore=keystore #SSL文件名 jetty.password=000000 #SSL文件密码 jetty.keypassword=000000 #Jetty主密码 与 keystore文件相同 jetty.truststore=keystore #SSL文件名 jetty.trustpassword=000000 # SSL文件密码 #执行服务器属性 executor.port=12321 #执行服务器端口 #邮件设置 mail.sender=xxxxxxxx@163.com #发送邮箱 mail.host=smtp.163.com #发送邮箱smtp地址 mail.user=xxxxxxxx #发送邮件时显示的名称 mail.password=********** #邮箱密码 job.failure.email=xxxxxxxx@163.com #任务失败时发送邮件的地址 job.success.email=xxxxxxxx@163.com #任务成功时发送邮件的地址 lockdown.create.projects=false # cache.directory=cache #缓存目录 2）web服务器用户配置 在azkaban web服务器安装目录 conf目录，按照如下配置修改azkaban-users.xml 文件，增加管理员用户。 3.4.2 执行服务器配置 1）进入执行服务器安装目录conf，打开azkaban.properties [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/executor/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban default.timezone.id=Asia/Shanghai #时区 #Azkaban JobTypes 插件配置 azkaban.jobtype.plugin.dir=plugins/jobtypes #jobtype 插件所在位置 #Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects #数据库设置 database.type=mysql #数据库类型(目前只支持mysql) mysql.port=3306 #数据库端口号 mysql.host=192.168.20.200 #数据库IP地址 mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #执行服务器配置 executor.maxThreads=50 #最大线程数 executor.port=12321 #端口号(如修改,请与web服务中一致) executor.flow.threads=30 #线程数 3.4 启动web服务器 在azkaban web服务器目录下执行启动命令 [atguigu@hadoop102 server]$ pwd /opt/module/azkaban/server [atguigu@hadoop102 server]$ bin/azkaban-web-start.sh bin/azkaban-web-start.sh 3.5 启动执行服务器 在执行服务器目录下执行启动命令 [atguigu@hadoop102 executor]$ pwd /opt/module/azkaban/executor [atguigu@hadoop102 executor]$ bin/azkaban-executor-start.sh 启动完成后，在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443，即可访问azkaban服务了。在登录中输入刚才新的户用名及密码，点击 login。 四 Azkaban实战 Azkaba内置的任务类型支持command、java 4.1Command类型之单一job案例 1）创建job描述文件 vi command.job #command.job type=command command=echo ‘hello’ 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 首先创建project 上传zip包 4）启动执行该job 4.2Command类型之多job工作流案例 1）创建有依赖关系的多个job描述 第一个job：foo.job #foo.job type=command command=echo foo 第二个job：bar.job依赖foo.job #bar.job type=command dependencies=foo command=echo bar 2）将所有job资源文件打到一个zip包中 3）创建工程 3）在azkaban的web管理界面创建工程并上传zip包 4）启动工作流flow 5）查看结果 4.3HDFS操作任务 1）创建job描述文件 #fs.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop fs -mkdir /azkaban 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 4）启动执行该job 5）查看结果 4.4 MapReduce任务 Mr任务依然可以使用command的job类型来执行 1）创建job描述文件，及mr程序jar包（示例中直接使用hadoop自带的example jar） #mrwc.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wordcount/input /wordcount/output 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job 4.4HIVE脚本任务 1）创建job描述文件和hive脚本 （1）Hive脚本： test.sql use default; drop table aztest; create table aztest(id int,name string) row format delimited fields terminated by ‘,’; load data inpath ‘/aztest/hiveinput’ into table aztest; create table azres as select * from aztest; insert overwrite directory ‘/aztest/hiveoutput’ select count(1) from aztest; （2）Job描述文件：hivef.job #hivef.job type=command command=/opt/module/hive/bin/hive -f ‘test.sql’ 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job" />
<meta property="og:description" content="文章目录 一 概述 1.1为什么需要工作流调度系统 1.2 常见工作流调度系统 1.3 各种调度工具特性对比 1.4 Azkaban与Oozie对比 二 Azkaban介绍 三 Azkaban安装部署 3.1 安装前准备 3.2安装azkaban 3.2 创建SSL配置 3.3 时间同步配置 3.4 配置文件 3.4.1 Web服务器配置 3.4.2 执行服务器配置 3.4 启动web服务器 3.5 启动执行服务器 四 Azkaban实战 4.1Command类型之单一job案例 4.2Command类型之多job工作流案例 4.3HDFS操作任务 4.4HIVE脚本任务 一 概述 1.1为什么需要工作流调度系统 1）一个完整的数据分析系统通常都是由大量任务单元组成： shell脚本程序，java程序，mapreduce程序、hive脚本等 2）各任务单元之间存在时间先后及前后依赖关系 3）为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行； 例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示： （1）通过Hadoop先将原始数据同步到HDFS上； （2）借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中； （3）需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表； （4）将明细数据进行复杂的统计分析，得到结果报表信息； （5）需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。 1.2 常见工作流调度系统 1）简单的任务调度：直接使用linux的crontab来定义； 2）复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如ooize、azkaban、 Cascading、Hamake等 1.3 各种调度工具特性对比 下面的表格对上述四种hadoop工作流调度器的关键特性进行了比较，尽管这些工作流调度器能够解决的需求场景基本一致，但在设计理念，目标用户，应用场景等方面还是存在显著的区别，在做技术选型的时候，可以提供参考 特性 Hamake Oozie Azkaban Cascading 工作流描述语言 XML XML (xPDL based) text file with key/value pairs Java API 依赖机制 data-driven explicit explicit explicit 是否要web容器 No Yes Yes No 进度跟踪 console/log messages web page web page Java API Hadoop job调度支持 no yes yes yes 运行模式 command line utility daemon daemon API Pig支持 yes yes yes yes 事件通知 no no no yes 需要安装 no yes yes no 支持的hadoop版本 0.18+ 0.20+ currently unknown 0.18+ 重试支持 no workflownode evel yes yes 运行任意命令 yes yes yes yes Amazon EMR支持 yes no currently unknown yes 1.4 Azkaban与Oozie对比 对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象。 详情如下： 1）功能 两者均可以调度mapreduce，pig，java，脚本工作流任务 两者均可以定时执行工作流任务 2）工作流定义 Azkaban使用Properties文件定义工作流 Oozie使用XML文件定义工作流 3）工作流传参 Azkaban支持直接传参，例如 i n p u t O o z i e 支 持 参 数 和 E L 表 达 式 ， 例 如 {input} Oozie支持参数和EL表达式，例如 inputOozie支持参数和EL表达式，例如{fs:dirSize(myInputDir)} 4）定时执行 Azkaban的定时执行任务是基于时间的 Oozie的定时执行任务基于时间和输入数据 5）资源管理 Azkaban有较严格的权限控制，如用户对工作流进行读/写/执行等操作 Oozie暂无严格的权限控制 6）工作流执行 Azkaban有两种运行模式，分别是solo server mode(executor server和web server部署在同一台节点)和multi server mode(executor server和web server可以部署在不同节点) Oozie作为工作流服务器运行，支持多用户和多工作流 7）工作流管理 Azkaban支持浏览器以及ajax方式操作工作流 Oozie支持命令行、HTTP REST、Java API、浏览器操作工作流 二 Azkaban介绍 Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。 它有如下功能特点： 1）Web用户界面 2）方便上传工作流 3）方便设置任务之间的关系 4）调度工作流 5）认证/授权(权限的工作) 6）能够杀死并重新启动工作流 7）模块化和可插拔的插件机制 8）项目工作区 9）工作流和任务的日志记录和审计 下载地址:http://azkaban.github.io/downloads.html 三 Azkaban安装部署 3.1 安装前准备 1）将Azkaban Web服务器、Azkaban执行服务器和MySQL拷贝到hadoop102虚拟机/opt/software目录下 azkaban-web-server-2.5.0.tar.gz azkaban-executor-server-2.5.0.tar.gz azkaban-sql-script-2.5.0.tar.gz mysql-libs.zip 2）目前azkaban只支持 mysql，需安装mysql服务器，本文档中默认已安装好mysql服务器，并建立了 root用户，密码 root。 3.2安装azkaban 1）在/opt/module/目录下创建azkaban目录 [atguigu@hadoop102 module]$ mkdir azkaban 2）解压azkaban-web-server-2.5.0.tar.gz、azkaban-executor-server-2.5.0.tar.gz、azkaban-sql-script-2.5.0.tar.gz到/opt/module/azkaban目录下 [atguigu@hadoop102 software]$ tar -zxvf azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban/ 3）对解压后的文件重新命名 [atguigu@hadoop102 azkaban]$ mv azkaban-web-2.5.0/ server [atguigu@hadoop102 azkaban]$ mv azkaban-executor-2.5.0/ executor 4）azkaban脚本导入 进入mysql，创建azkaban数据库，并将解压的脚本导入到azkaban数据库。 [atguigu@hadoop102 azkaban]$ mysql -uroot -p000000 mysql&gt; create database azkaban; mysql&gt; use azkaban; mysql&gt; source /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql 3.2 创建SSL配置 参考地址: http://docs.codehaus.org/display/JETTY/How+to+configure+SSL 1）生成 keystore的密码及相应信息 [atguigu@hadoop102 hadoop-2.7.2]$ keytool -keystore keystore -alias jetty -genkey -keyalg RSA 输入keystore密码： 再次输入新密码: 您的名字与姓氏是什么？ [Unknown]： 您的组织单位名称是什么？ [Unknown]： 您的组织名称是什么？ [Unknown]： 您所在的城市或区域名称是什么？ [Unknown]： 您所在的州或省份名称是什么？ [Unknown]： 该单位的两字母国家代码是什么 [Unknown]： CN CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？ [否]： y 输入的主密码 （如果和 keystore 密码相同，按回车）： 再次输入新密码: 2）将keystore 考贝到 azkaban web服务器根目录中 [atguigu@hadoop102 hadoop-2.7.2]$ mv keystore /opt/module/azkaban/server/ 3.3 时间同步配置 先配置好服务器节点上的时区 1）如果在/usr/share/zoneinfo/这个目录下不存在时区配置文件Asia/Shanghai，就要用 tzselect 生成。 [atguigu@hadoop102 Asia]$ tzselect Please identify a location so that time zone rules can be set correctly. Please select a continent or ocean. Africa Americas Antarctica Arctic Ocean Asia Atlantic Ocean Australia Europe Indian Ocean Pacific Ocean none - I want to specify the time zone using the Posix TZ format. #? 5 Please select a country. Afghanistan 18) Israel 35) Palestine Armenia 19) Japan 36) Philippines Azerbaijan 20) Jordan 37) Qatar Bahrain 21) Kazakhstan 38) Russia Bangladesh 22) Korea (North) 39) Saudi Arabia Bhutan 23) Korea (South) 40) Singapore Brunei 24) Kuwait 41) Sri Lanka Cambodia 25) Kyrgyzstan 42) Syria China 26) Laos 43) Taiwan Cyprus 27) Lebanon 44) Tajikistan East Timor 28) Macau 45) Thailand Georgia 29) Malaysia 46) Turkmenistan Hong Kong 30) Mongolia 47) United Arab Emirates India 31) Myanmar (Burma) 48) Uzbekistan Indonesia 32) Nepal 49) Vietnam Iran 33) Oman 50) Yemen Iraq 34) Pakistan #? 9 Please select one of the following time zone regions. Beijing Time Xinjiang Time #? 1 The following information has been given: China Beijing Time Therefore TZ=‘Asia/Shanghai’ will be used. Local time is now: Wed Jun 14 09:16:46 CST 2017. Universal Time is now: Wed Jun 14 01:16:46 UTC 2017. Is the above information OK? Yes No #?1 2）拷贝该时区文件，覆盖系统本地时区配置 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 3）集群时间同步 sudo date -s ‘2017-06-14 09:23:45’ hwclock -w 3.4 配置文件 3.4.1 Web服务器配置 1）进入azkaban web服务器安装目录 conf目录，打开azkaban.properties文件 [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/server/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban Personalization Settings azkaban.name=Test #服务器UI名称,用于服务器上方显示的名字 azkaban.label=My Local Azkaban #描述 azkaban.color=#FF3601 #UI颜色 azkaban.default.servlet.path=/index # web.resource.dir=web/ #默认根web目录 default.timezone.id=Asia/Shanghai #默认时区,已改为亚洲/上海 默认为美国 #Azkaban UserManager class user.manager.class=azkaban.user.XmlUserManager #用户权限管理默认类 user.manager.xml.file=conf/azkaban-users.xml #用户配置,具体配置参加下文 #Loader for projects executor.global.properties=conf/global.properties # global配置文件所在位置 azkaban.project.dir=projects # database.type=mysql #数据库类型 mysql.port=3306 #端口号 mysql.host=hadoop102 #数据库连接IP mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #Velocity dev mode velocity.dev.mode=false #Jetty服务器属性. jetty.maxThreads=25 #最大线程数 jetty.ssl.port=8443 #Jetty SSL端口 jetty.port=8081 #Jetty端口 jetty.keystore=keystore #SSL文件名 jetty.password=000000 #SSL文件密码 jetty.keypassword=000000 #Jetty主密码 与 keystore文件相同 jetty.truststore=keystore #SSL文件名 jetty.trustpassword=000000 # SSL文件密码 #执行服务器属性 executor.port=12321 #执行服务器端口 #邮件设置 mail.sender=xxxxxxxx@163.com #发送邮箱 mail.host=smtp.163.com #发送邮箱smtp地址 mail.user=xxxxxxxx #发送邮件时显示的名称 mail.password=********** #邮箱密码 job.failure.email=xxxxxxxx@163.com #任务失败时发送邮件的地址 job.success.email=xxxxxxxx@163.com #任务成功时发送邮件的地址 lockdown.create.projects=false # cache.directory=cache #缓存目录 2）web服务器用户配置 在azkaban web服务器安装目录 conf目录，按照如下配置修改azkaban-users.xml 文件，增加管理员用户。 3.4.2 执行服务器配置 1）进入执行服务器安装目录conf，打开azkaban.properties [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/executor/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban default.timezone.id=Asia/Shanghai #时区 #Azkaban JobTypes 插件配置 azkaban.jobtype.plugin.dir=plugins/jobtypes #jobtype 插件所在位置 #Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects #数据库设置 database.type=mysql #数据库类型(目前只支持mysql) mysql.port=3306 #数据库端口号 mysql.host=192.168.20.200 #数据库IP地址 mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #执行服务器配置 executor.maxThreads=50 #最大线程数 executor.port=12321 #端口号(如修改,请与web服务中一致) executor.flow.threads=30 #线程数 3.4 启动web服务器 在azkaban web服务器目录下执行启动命令 [atguigu@hadoop102 server]$ pwd /opt/module/azkaban/server [atguigu@hadoop102 server]$ bin/azkaban-web-start.sh bin/azkaban-web-start.sh 3.5 启动执行服务器 在执行服务器目录下执行启动命令 [atguigu@hadoop102 executor]$ pwd /opt/module/azkaban/executor [atguigu@hadoop102 executor]$ bin/azkaban-executor-start.sh 启动完成后，在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443，即可访问azkaban服务了。在登录中输入刚才新的户用名及密码，点击 login。 四 Azkaban实战 Azkaba内置的任务类型支持command、java 4.1Command类型之单一job案例 1）创建job描述文件 vi command.job #command.job type=command command=echo ‘hello’ 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 首先创建project 上传zip包 4）启动执行该job 4.2Command类型之多job工作流案例 1）创建有依赖关系的多个job描述 第一个job：foo.job #foo.job type=command command=echo foo 第二个job：bar.job依赖foo.job #bar.job type=command dependencies=foo command=echo bar 2）将所有job资源文件打到一个zip包中 3）创建工程 3）在azkaban的web管理界面创建工程并上传zip包 4）启动工作流flow 5）查看结果 4.3HDFS操作任务 1）创建job描述文件 #fs.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop fs -mkdir /azkaban 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 4）启动执行该job 5）查看结果 4.4 MapReduce任务 Mr任务依然可以使用command的job类型来执行 1）创建job描述文件，及mr程序jar包（示例中直接使用hadoop自带的example jar） #mrwc.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wordcount/input /wordcount/output 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job 4.4HIVE脚本任务 1）创建job描述文件和hive脚本 （1）Hive脚本： test.sql use default; drop table aztest; create table aztest(id int,name string) row format delimited fields terminated by ‘,’; load data inpath ‘/aztest/hiveinput’ into table aztest; create table azres as select * from aztest; insert overwrite directory ‘/aztest/hiveoutput’ select count(1) from aztest; （2）Job描述文件：hivef.job #hivef.job type=command command=/opt/module/hive/bin/hive -f ‘test.sql’ 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job" />
<link rel="canonical" href="https://uzzz.org/2019/07/28/793924.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/28/793924.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-28T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"文章目录 一 概述 1.1为什么需要工作流调度系统 1.2 常见工作流调度系统 1.3 各种调度工具特性对比 1.4 Azkaban与Oozie对比 二 Azkaban介绍 三 Azkaban安装部署 3.1 安装前准备 3.2安装azkaban 3.2 创建SSL配置 3.3 时间同步配置 3.4 配置文件 3.4.1 Web服务器配置 3.4.2 执行服务器配置 3.4 启动web服务器 3.5 启动执行服务器 四 Azkaban实战 4.1Command类型之单一job案例 4.2Command类型之多job工作流案例 4.3HDFS操作任务 4.4HIVE脚本任务 一 概述 1.1为什么需要工作流调度系统 1）一个完整的数据分析系统通常都是由大量任务单元组成： shell脚本程序，java程序，mapreduce程序、hive脚本等 2）各任务单元之间存在时间先后及前后依赖关系 3）为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行； 例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示： （1）通过Hadoop先将原始数据同步到HDFS上； （2）借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中； （3）需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表； （4）将明细数据进行复杂的统计分析，得到结果报表信息； （5）需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。 1.2 常见工作流调度系统 1）简单的任务调度：直接使用linux的crontab来定义； 2）复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如ooize、azkaban、 Cascading、Hamake等 1.3 各种调度工具特性对比 下面的表格对上述四种hadoop工作流调度器的关键特性进行了比较，尽管这些工作流调度器能够解决的需求场景基本一致，但在设计理念，目标用户，应用场景等方面还是存在显著的区别，在做技术选型的时候，可以提供参考 特性 Hamake Oozie Azkaban Cascading 工作流描述语言 XML XML (xPDL based) text file with key/value pairs Java API 依赖机制 data-driven explicit explicit explicit 是否要web容器 No Yes Yes No 进度跟踪 console/log messages web page web page Java API Hadoop job调度支持 no yes yes yes 运行模式 command line utility daemon daemon API Pig支持 yes yes yes yes 事件通知 no no no yes 需要安装 no yes yes no 支持的hadoop版本 0.18+ 0.20+ currently unknown 0.18+ 重试支持 no workflownode evel yes yes 运行任意命令 yes yes yes yes Amazon EMR支持 yes no currently unknown yes 1.4 Azkaban与Oozie对比 对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象。 详情如下： 1）功能 两者均可以调度mapreduce，pig，java，脚本工作流任务 两者均可以定时执行工作流任务 2）工作流定义 Azkaban使用Properties文件定义工作流 Oozie使用XML文件定义工作流 3）工作流传参 Azkaban支持直接传参，例如 i n p u t O o z i e 支 持 参 数 和 E L 表 达 式 ， 例 如 {input} Oozie支持参数和EL表达式，例如 inputOozie支持参数和EL表达式，例如{fs:dirSize(myInputDir)} 4）定时执行 Azkaban的定时执行任务是基于时间的 Oozie的定时执行任务基于时间和输入数据 5）资源管理 Azkaban有较严格的权限控制，如用户对工作流进行读/写/执行等操作 Oozie暂无严格的权限控制 6）工作流执行 Azkaban有两种运行模式，分别是solo server mode(executor server和web server部署在同一台节点)和multi server mode(executor server和web server可以部署在不同节点) Oozie作为工作流服务器运行，支持多用户和多工作流 7）工作流管理 Azkaban支持浏览器以及ajax方式操作工作流 Oozie支持命令行、HTTP REST、Java API、浏览器操作工作流 二 Azkaban介绍 Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。 它有如下功能特点： 1）Web用户界面 2）方便上传工作流 3）方便设置任务之间的关系 4）调度工作流 5）认证/授权(权限的工作) 6）能够杀死并重新启动工作流 7）模块化和可插拔的插件机制 8）项目工作区 9）工作流和任务的日志记录和审计 下载地址:http://azkaban.github.io/downloads.html 三 Azkaban安装部署 3.1 安装前准备 1）将Azkaban Web服务器、Azkaban执行服务器和MySQL拷贝到hadoop102虚拟机/opt/software目录下 azkaban-web-server-2.5.0.tar.gz azkaban-executor-server-2.5.0.tar.gz azkaban-sql-script-2.5.0.tar.gz mysql-libs.zip 2）目前azkaban只支持 mysql，需安装mysql服务器，本文档中默认已安装好mysql服务器，并建立了 root用户，密码 root。 3.2安装azkaban 1）在/opt/module/目录下创建azkaban目录 [atguigu@hadoop102 module]$ mkdir azkaban 2）解压azkaban-web-server-2.5.0.tar.gz、azkaban-executor-server-2.5.0.tar.gz、azkaban-sql-script-2.5.0.tar.gz到/opt/module/azkaban目录下 [atguigu@hadoop102 software]$ tar -zxvf azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban/ [atguigu@hadoop102 software]$ tar -zxvf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban/ 3）对解压后的文件重新命名 [atguigu@hadoop102 azkaban]$ mv azkaban-web-2.5.0/ server [atguigu@hadoop102 azkaban]$ mv azkaban-executor-2.5.0/ executor 4）azkaban脚本导入 进入mysql，创建azkaban数据库，并将解压的脚本导入到azkaban数据库。 [atguigu@hadoop102 azkaban]$ mysql -uroot -p000000 mysql&gt; create database azkaban; mysql&gt; use azkaban; mysql&gt; source /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql 3.2 创建SSL配置 参考地址: http://docs.codehaus.org/display/JETTY/How+to+configure+SSL 1）生成 keystore的密码及相应信息 [atguigu@hadoop102 hadoop-2.7.2]$ keytool -keystore keystore -alias jetty -genkey -keyalg RSA 输入keystore密码： 再次输入新密码: 您的名字与姓氏是什么？ [Unknown]： 您的组织单位名称是什么？ [Unknown]： 您的组织名称是什么？ [Unknown]： 您所在的城市或区域名称是什么？ [Unknown]： 您所在的州或省份名称是什么？ [Unknown]： 该单位的两字母国家代码是什么 [Unknown]： CN CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？ [否]： y 输入的主密码 （如果和 keystore 密码相同，按回车）： 再次输入新密码: 2）将keystore 考贝到 azkaban web服务器根目录中 [atguigu@hadoop102 hadoop-2.7.2]$ mv keystore /opt/module/azkaban/server/ 3.3 时间同步配置 先配置好服务器节点上的时区 1）如果在/usr/share/zoneinfo/这个目录下不存在时区配置文件Asia/Shanghai，就要用 tzselect 生成。 [atguigu@hadoop102 Asia]$ tzselect Please identify a location so that time zone rules can be set correctly. Please select a continent or ocean. Africa Americas Antarctica Arctic Ocean Asia Atlantic Ocean Australia Europe Indian Ocean Pacific Ocean none - I want to specify the time zone using the Posix TZ format. #? 5 Please select a country. Afghanistan 18) Israel 35) Palestine Armenia 19) Japan 36) Philippines Azerbaijan 20) Jordan 37) Qatar Bahrain 21) Kazakhstan 38) Russia Bangladesh 22) Korea (North) 39) Saudi Arabia Bhutan 23) Korea (South) 40) Singapore Brunei 24) Kuwait 41) Sri Lanka Cambodia 25) Kyrgyzstan 42) Syria China 26) Laos 43) Taiwan Cyprus 27) Lebanon 44) Tajikistan East Timor 28) Macau 45) Thailand Georgia 29) Malaysia 46) Turkmenistan Hong Kong 30) Mongolia 47) United Arab Emirates India 31) Myanmar (Burma) 48) Uzbekistan Indonesia 32) Nepal 49) Vietnam Iran 33) Oman 50) Yemen Iraq 34) Pakistan #? 9 Please select one of the following time zone regions. Beijing Time Xinjiang Time #? 1 The following information has been given: China Beijing Time Therefore TZ=‘Asia/Shanghai’ will be used. Local time is now: Wed Jun 14 09:16:46 CST 2017. Universal Time is now: Wed Jun 14 01:16:46 UTC 2017. Is the above information OK? Yes No #?1 2）拷贝该时区文件，覆盖系统本地时区配置 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 3）集群时间同步 sudo date -s ‘2017-06-14 09:23:45’ hwclock -w 3.4 配置文件 3.4.1 Web服务器配置 1）进入azkaban web服务器安装目录 conf目录，打开azkaban.properties文件 [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/server/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban Personalization Settings azkaban.name=Test #服务器UI名称,用于服务器上方显示的名字 azkaban.label=My Local Azkaban #描述 azkaban.color=#FF3601 #UI颜色 azkaban.default.servlet.path=/index # web.resource.dir=web/ #默认根web目录 default.timezone.id=Asia/Shanghai #默认时区,已改为亚洲/上海 默认为美国 #Azkaban UserManager class user.manager.class=azkaban.user.XmlUserManager #用户权限管理默认类 user.manager.xml.file=conf/azkaban-users.xml #用户配置,具体配置参加下文 #Loader for projects executor.global.properties=conf/global.properties # global配置文件所在位置 azkaban.project.dir=projects # database.type=mysql #数据库类型 mysql.port=3306 #端口号 mysql.host=hadoop102 #数据库连接IP mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #Velocity dev mode velocity.dev.mode=false #Jetty服务器属性. jetty.maxThreads=25 #最大线程数 jetty.ssl.port=8443 #Jetty SSL端口 jetty.port=8081 #Jetty端口 jetty.keystore=keystore #SSL文件名 jetty.password=000000 #SSL文件密码 jetty.keypassword=000000 #Jetty主密码 与 keystore文件相同 jetty.truststore=keystore #SSL文件名 jetty.trustpassword=000000 # SSL文件密码 #执行服务器属性 executor.port=12321 #执行服务器端口 #邮件设置 mail.sender=xxxxxxxx@163.com #发送邮箱 mail.host=smtp.163.com #发送邮箱smtp地址 mail.user=xxxxxxxx #发送邮件时显示的名称 mail.password=********** #邮箱密码 job.failure.email=xxxxxxxx@163.com #任务失败时发送邮件的地址 job.success.email=xxxxxxxx@163.com #任务成功时发送邮件的地址 lockdown.create.projects=false # cache.directory=cache #缓存目录 2）web服务器用户配置 在azkaban web服务器安装目录 conf目录，按照如下配置修改azkaban-users.xml 文件，增加管理员用户。 3.4.2 执行服务器配置 1）进入执行服务器安装目录conf，打开azkaban.properties [atguigu@hadoop102 conf]$ pwd /opt/module/azkaban/executor/conf [atguigu@hadoop102 conf]$ vi azkaban.properties 2）按照如下配置修改azkaban.properties文件。 #Azkaban default.timezone.id=Asia/Shanghai #时区 #Azkaban JobTypes 插件配置 azkaban.jobtype.plugin.dir=plugins/jobtypes #jobtype 插件所在位置 #Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects #数据库设置 database.type=mysql #数据库类型(目前只支持mysql) mysql.port=3306 #数据库端口号 mysql.host=192.168.20.200 #数据库IP地址 mysql.database=azkaban #数据库实例名 mysql.user=root #数据库用户名 mysql.password=000000 #数据库密码 mysql.numconnections=100 #最大连接数 #执行服务器配置 executor.maxThreads=50 #最大线程数 executor.port=12321 #端口号(如修改,请与web服务中一致) executor.flow.threads=30 #线程数 3.4 启动web服务器 在azkaban web服务器目录下执行启动命令 [atguigu@hadoop102 server]$ pwd /opt/module/azkaban/server [atguigu@hadoop102 server]$ bin/azkaban-web-start.sh bin/azkaban-web-start.sh 3.5 启动执行服务器 在执行服务器目录下执行启动命令 [atguigu@hadoop102 executor]$ pwd /opt/module/azkaban/executor [atguigu@hadoop102 executor]$ bin/azkaban-executor-start.sh 启动完成后，在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443，即可访问azkaban服务了。在登录中输入刚才新的户用名及密码，点击 login。 四 Azkaban实战 Azkaba内置的任务类型支持command、java 4.1Command类型之单一job案例 1）创建job描述文件 vi command.job #command.job type=command command=echo ‘hello’ 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 首先创建project 上传zip包 4）启动执行该job 4.2Command类型之多job工作流案例 1）创建有依赖关系的多个job描述 第一个job：foo.job #foo.job type=command command=echo foo 第二个job：bar.job依赖foo.job #bar.job type=command dependencies=foo command=echo bar 2）将所有job资源文件打到一个zip包中 3）创建工程 3）在azkaban的web管理界面创建工程并上传zip包 4）启动工作流flow 5）查看结果 4.3HDFS操作任务 1）创建job描述文件 #fs.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop fs -mkdir /azkaban 2）将job资源文件打包成zip文件 3）通过azkaban的web管理平台创建project并上传job压缩包 4）启动执行该job 5）查看结果 4.4 MapReduce任务 Mr任务依然可以使用command的job类型来执行 1）创建job描述文件，及mr程序jar包（示例中直接使用hadoop自带的example jar） #mrwc.job type=command command=/opt/module/hadoop-2.7.2/bin/hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wordcount/input /wordcount/output 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job 4.4HIVE脚本任务 1）创建job描述文件和hive脚本 （1）Hive脚本： test.sql use default; drop table aztest; create table aztest(id int,name string) row format delimited fields terminated by ‘,’; load data inpath ‘/aztest/hiveinput’ into table aztest; create table azres as select * from aztest; insert overwrite directory ‘/aztest/hiveoutput’ select count(1) from aztest; （2）Job描述文件：hivef.job #hivef.job type=command command=/opt/module/hive/bin/hive -f ‘test.sql’ 2）将所有job资源文件打到一个zip包中 3）在azkaban的web管理界面创建工程并上传zip包 4）启动job","@type":"BlogPosting","url":"https://uzzz.org/2019/07/28/793924.html","headline":"大数据学习笔记之azkaban（一）：azkaban","dateModified":"2019-07-28T00:00:00+08:00","datePublished":"2019-07-28T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/28/793924.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>大数据学习笔记之azkaban（一）：azkaban</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-light"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p></p>
  <div class="toc">
   <h3>文章目录</h3>
   <ul>
    <li><a href="#__1" rel="nofollow" data-token="cf277e3b1d62c12c027f3edefb79b3ed">一 概述</a></li>
    <ul>
     <li><a href="#11_2" rel="nofollow" data-token="22af7aed08ef25d201b55a7118403559">1.1为什么需要工作流调度系统</a></li>
     <li><a href="#12__14" rel="nofollow" data-token="0d507a8736c794e4e61766cf3f7d9b74">1.2 常见工作流调度系统</a></li>
     <li><a href="#13__18" rel="nofollow" data-token="ff5bc9411806cc9e58020f4fc75c6118">1.3 各种调度工具特性对比</a></li>
     <li><a href="#14_AzkabanOozie_36" rel="nofollow" data-token="a7caa78613365d9086e987cdbc12cdec">1.4 Azkaban与Oozie对比</a></li>
    </ul>
    <li><a href="#_Azkaban_60" rel="nofollow" data-token="9c598b9b1859ff614d05b18abe964673">二 Azkaban介绍</a></li>
    <li><a href="#_Azkaban_73" rel="nofollow" data-token="55d3c9e7758c103a1de57f8d6553148d">三 Azkaban安装部署</a></li>
    <ul>
     <li><a href="#31__74" rel="nofollow" data-token="8e32522385e79704dfc29c902ed2d40f">3.1 安装前准备</a></li>
     <li><a href="#32azkaban_82" rel="nofollow" data-token="fb0e8c43d53bd1b9a762fef4f89a7c57">3.2安装azkaban</a></li>
     <li><a href="#32_SSL_98" rel="nofollow" data-token="66768e304788042058f0876f922bef59">3.2 创建SSL配置</a></li>
     <li><a href="#33__125" rel="nofollow" data-token="956c0994e41318702b1ad567690d9da4">3.3 时间同步配置</a></li>
     <li><a href="#34__181" rel="nofollow" data-token="31fd891ab2ef859666f7f134a14df732">3.4 配置文件</a></li>
     <ul>
      <li><a href="#341_Web_182" rel="nofollow" data-token="9a5986ec01f4b48b5348cd73a2a6b1b6">3.4.1 Web服务器配置</a></li>
      <li><a href="#342__245" rel="nofollow" data-token="60eb38b5c2e44a90fa2a9b07e7ef15b8">3.4.2 执行服务器配置</a></li>
     </ul>
     <li><a href="#34_web_275" rel="nofollow" data-token="86f9799cf7443862ff522b01be6131df">3.4 启动web服务器</a></li>
     <li><a href="#35__281" rel="nofollow" data-token="72e2b892062a07069652f00a88b73af3">3.5 启动执行服务器</a></li>
    </ul>
    <li><a href="#_Azkaban_290" rel="nofollow" data-token="8473a6df3afefca546c6a6208531afb2">四 Azkaban实战</a></li>
    <ul>
     <li><a href="#41Commandjob_292" rel="nofollow" data-token="bc738bc71a52a20af0f8ee3e29540ce6">4.1Command类型之单一job案例</a></li>
     <li><a href="#42Commandjob_306" rel="nofollow" data-token="a5319bd3cebd05b50bd153a28e26e881">4.2Command类型之多job工作流案例</a></li>
     <li><a href="#43HDFS_331" rel="nofollow" data-token="32af375f0a0766c4efadd673bcbdaf31">4.3HDFS操作任务</a></li>
     <li><a href="#44HIVE_351" rel="nofollow" data-token="600f8ef2bdc5dc0ac25deac13e95e449">4.4HIVE脚本任务</a></li>
    </ul>
   </ul>
  </div>
  <p></p> 
  <h1><a id="__1"></a>一 概述</h1> 
  <h2><a id="11_2"></a>1.1为什么需要工作流调度系统</h2> 
  <p>1）一个完整的数据分析系统通常都是由大量任务单元组成：<br> shell脚本程序，java程序，mapreduce程序、hive脚本等<br> 2）各任务单元之间存在时间先后及前后依赖关系<br> 3）为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行；<br> 例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：<br> （1）通过Hadoop先将原始数据同步到HDFS上；<br> （2）借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中；<br> （3）需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；<br> （4）将明细数据进行复杂的统计分析，得到结果报表信息；<br> （5）需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230434187.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="12__14"></a>1.2 常见工作流调度系统</h2> 
  <p>1）简单的任务调度：直接使用linux的crontab来定义；<br> 2）复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如ooize、azkaban、 Cascading、Hamake等</p> 
  <h2><a id="13__18"></a>1.3 各种调度工具特性对比</h2> 
  <p>下面的表格对上述四种hadoop工作流调度器的关键特性进行了比较，尽管这些工作流调度器能够解决的需求场景基本一致，但在设计理念，目标用户，应用场景等方面还是存在显著的区别，在做技术选型的时候，可以提供参考</p> 
  <table> 
   <thead> 
    <tr> 
     <th>特性</th> 
     <th>Hamake</th> 
     <th>Oozie</th> 
     <th>Azkaban</th> 
     <th>Cascading</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>工作流描述语言</td> 
     <td>XML</td> 
     <td>XML (xPDL based)</td> 
     <td>text file with key/value pairs</td> 
     <td>Java API</td> 
    </tr> 
    <tr> 
     <td>依赖机制</td> 
     <td>data-driven</td> 
     <td>explicit</td> 
     <td>explicit</td> 
     <td>explicit</td> 
    </tr> 
    <tr> 
     <td>是否要web容器</td> 
     <td>No</td> 
     <td>Yes</td> 
     <td>Yes</td> 
     <td>No</td> 
    </tr> 
    <tr> 
     <td>进度跟踪</td> 
     <td>console/log messages</td> 
     <td>web page</td> 
     <td>web page</td> 
     <td>Java API</td> 
    </tr> 
    <tr> 
     <td>Hadoop job调度支持</td> 
     <td>no</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>yes</td> 
    </tr> 
    <tr> 
     <td>运行模式</td> 
     <td>command line utility</td> 
     <td>daemon</td> 
     <td>daemon</td> 
     <td>API</td> 
    </tr> 
    <tr> 
     <td>Pig支持</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>yes</td> 
    </tr> 
    <tr> 
     <td>事件通知</td> 
     <td>no</td> 
     <td>no</td> 
     <td>no</td> 
     <td>yes</td> 
    </tr> 
    <tr> 
     <td>需要安装</td> 
     <td>no</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>no</td> 
    </tr> 
    <tr> 
     <td>支持的hadoop版本</td> 
     <td>0.18+</td> 
     <td>0.20+</td> 
     <td>currently unknown</td> 
     <td>0.18+</td> 
    </tr> 
    <tr> 
     <td>重试支持</td> 
     <td>no</td> 
     <td>workflownode evel</td> 
     <td>yes</td> 
     <td>yes</td> 
    </tr> 
    <tr> 
     <td>运行任意命令</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>yes</td> 
     <td>yes</td> 
    </tr> 
    <tr> 
     <td>Amazon EMR支持</td> 
     <td>yes</td> 
     <td>no</td> 
     <td>currently unknown</td> 
     <td>yes</td> 
    </tr> 
   </tbody> 
  </table>
  <h2><a id="14_AzkabanOozie_36"></a>1.4 Azkaban与Oozie对比</h2> 
  <p>对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象。<br> 详情如下：<br> 1）功能<br> 两者均可以调度mapreduce，pig，java，脚本工作流任务<br> 两者均可以定时执行工作流任务<br> 2）工作流定义<br> Azkaban使用Properties文件定义工作流<br> Oozie使用XML文件定义工作流<br> 3）工作流传参<br> Azkaban支持直接传参，例如<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mrow>
          <mi>
           i
          </mi>
          <mi>
           n
          </mi>
          <mi>
           p
          </mi>
          <mi>
           u
          </mi>
          <mi>
           t
          </mi>
         </mrow>
         <mi>
          O
         </mi>
         <mi>
          o
         </mi>
         <mi>
          z
         </mi>
         <mi>
          i
         </mi>
         <mi>
          e
         </mi>
         <mi mathvariant="normal">
          支
         </mi>
         <mi mathvariant="normal">
          持
         </mi>
         <mi mathvariant="normal">
          参
         </mi>
         <mi mathvariant="normal">
          数
         </mi>
         <mi mathvariant="normal">
          和
         </mi>
         <mi>
          E
         </mi>
         <mi>
          L
         </mi>
         <mi mathvariant="normal">
          表
         </mi>
         <mi mathvariant="normal">
          达
         </mi>
         <mi mathvariant="normal">
          式
         </mi>
         <mi mathvariant="normal">
          ，
         </mi>
         <mi mathvariant="normal">
          例
         </mi>
         <mi mathvariant="normal">
          如
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         {input} Oozie支持参数和EL表达式，例如
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span></span><span class="mord mathit" style="margin-right: 0.02778em;">O</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right: 0.04398em;">z</span><span class="mord mathit">i</span><span class="mord mathit">e</span><span class="mord cjk_fallback">支</span><span class="mord cjk_fallback">持</span><span class="mord cjk_fallback">参</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">和</span><span class="mord mathit" style="margin-right: 0.05764em;">E</span><span class="mord mathit">L</span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">达</span><span class="mord cjk_fallback">式</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">例</span><span class="mord cjk_fallback">如</span></span></span></span></span>{fs:dirSize(myInputDir)}<br> 4）定时执行<br> Azkaban的定时执行任务是基于时间的<br> Oozie的定时执行任务基于时间和输入数据<br> 5）资源管理<br> Azkaban有较严格的权限控制，如用户对工作流进行读/写/执行等操作<br> Oozie暂无严格的权限控制<br> 6）工作流执行<br> Azkaban有两种运行模式，分别是solo server mode(executor server和web server部署在同一台节点)和multi server mode(executor server和web server可以部署在不同节点)<br> Oozie作为工作流服务器运行，支持多用户和多工作流<br> 7）工作流管理<br> Azkaban支持浏览器以及ajax方式操作工作流<br> Oozie支持命令行、HTTP REST、Java API、浏览器操作工作流</p> 
  <h1><a id="_Azkaban_60"></a>二 Azkaban介绍</h1> 
  <p>Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。<br> 它有如下功能特点：<br> 1）Web用户界面<br> 2）方便上传工作流<br> 3）方便设置任务之间的关系<br> 4）调度工作流<br> 5）认证/授权(权限的工作)<br> 6）能够杀死并重新启动工作流<br> 7）模块化和可插拔的插件机制<br> 8）项目工作区<br> 9）工作流和任务的日志记录和审计<br> 下载地址:<a href="http://azkaban.github.io/downloads.html" rel="nofollow" data-token="140ce15407d54df78768ba03b78cecc0">http://azkaban.github.io/downloads.html</a></p> 
  <h1><a id="_Azkaban_73"></a>三 Azkaban安装部署</h1> 
  <h2><a id="31__74"></a>3.1 安装前准备</h2> 
  <p>1）将Azkaban Web服务器、Azkaban执行服务器和MySQL拷贝到hadoop102虚拟机/opt/software目录下<br> azkaban-web-server-2.5.0.tar.gz<br> azkaban-executor-server-2.5.0.tar.gz<br> azkaban-sql-script-2.5.0.tar.gz<br> mysql-libs.zip<br> 2）目前azkaban只支持 mysql，需安装mysql服务器，本文档中默认已安装好mysql服务器，并建立了 root用户，密码 root。</p> 
  <h2><a id="32azkaban_82"></a>3.2安装azkaban</h2> 
  <p>1）在/opt/module/目录下创建azkaban目录<br> [atguigu@hadoop102 module]$ mkdir azkaban<br> 2）解压azkaban-web-server-2.5.0.tar.gz、azkaban-executor-server-2.5.0.tar.gz、azkaban-sql-script-2.5.0.tar.gz到/opt/module/azkaban目录下<br> [atguigu@hadoop102 software]$ tar -zxvf azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban/<br> [atguigu@hadoop102 software]$ tar -zxvf azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban/<br> [atguigu@hadoop102 software]$ tar -zxvf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban/<br> 3）对解压后的文件重新命名<br> [atguigu@hadoop102 azkaban]$ mv azkaban-web-2.5.0/ server<br> [atguigu@hadoop102 azkaban]$ mv azkaban-executor-2.5.0/ executor<br> 4）azkaban脚本导入<br> 进入mysql，创建azkaban数据库，并将解压的脚本导入到azkaban数据库。<br> [atguigu@hadoop102 azkaban]$ mysql -uroot -p000000<br> mysql&gt; create database azkaban;<br> mysql&gt; use azkaban;<br> mysql&gt; source /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql</p> 
  <h2><a id="32_SSL_98"></a>3.2 创建SSL配置</h2> 
  <p>参考地址: <a href="http://docs.codehaus.org/display/JETTY/How+to+configure+SSL" rel="nofollow" data-token="54200762f15c0733edc1c01cc9bdc46c">http://docs.codehaus.org/display/JETTY/How+to+configure+SSL</a><br> 1）生成 keystore的密码及相应信息<br> [atguigu@hadoop102 hadoop-2.7.2]$ keytool -keystore keystore -alias jetty -genkey -keyalg RSA</p> 
  <p>输入keystore密码：<br> 再次输入新密码:<br> 您的名字与姓氏是什么？<br> [Unknown]：<br> 您的组织单位名称是什么？<br> [Unknown]：<br> 您的组织名称是什么？<br> [Unknown]：<br> 您所在的城市或区域名称是什么？<br> [Unknown]：<br> 您所在的州或省份名称是什么？<br> [Unknown]：<br> 该单位的两字母国家代码是什么<br> [Unknown]： CN<br> CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？<br> [否]： y</p> 
  <p>输入的主密码<br> （如果和 keystore 密码相同，按回车）：<br> 再次输入新密码:<br> 2）将keystore 考贝到 azkaban web服务器根目录中<br> [atguigu@hadoop102 hadoop-2.7.2]$ mv keystore /opt/module/azkaban/server/</p> 
  <h2><a id="33__125"></a>3.3 时间同步配置</h2> 
  <p>先配置好服务器节点上的时区<br> 1）如果在/usr/share/zoneinfo/这个目录下不存在时区配置文件Asia/Shanghai，就要用 tzselect 生成。<br> [atguigu@hadoop102 Asia]$ tzselect<br> Please identify a location so that time zone rules can be set correctly.<br> Please select a continent or ocean.</p> 
  <ol> 
   <li>Africa</li> 
   <li>Americas</li> 
   <li>Antarctica</li> 
   <li>Arctic Ocean</li> 
   <li>Asia</li> 
   <li>Atlantic Ocean</li> 
   <li>Australia</li> 
   <li>Europe</li> 
   <li>Indian Ocean</li> 
   <li>Pacific Ocean</li> 
   <li>none - I want to specify the time zone using the Posix TZ format.<br> #? 5<br> Please select a country.</li> 
   <li>Afghanistan 18) Israel 35) Palestine</li> 
   <li>Armenia 19) Japan 36) Philippines</li> 
   <li>Azerbaijan 20) Jordan 37) Qatar</li> 
   <li>Bahrain 21) Kazakhstan 38) Russia</li> 
   <li>Bangladesh 22) Korea (North) 39) Saudi Arabia</li> 
   <li>Bhutan 23) Korea (South) 40) Singapore</li> 
   <li>Brunei 24) Kuwait 41) Sri Lanka</li> 
   <li>Cambodia 25) Kyrgyzstan 42) Syria</li> 
   <li>China 26) Laos 43) Taiwan</li> 
   <li>Cyprus 27) Lebanon 44) Tajikistan</li> 
   <li>East Timor 28) Macau 45) Thailand</li> 
   <li>Georgia 29) Malaysia 46) Turkmenistan</li> 
   <li>Hong Kong 30) Mongolia 47) United Arab Emirates</li> 
   <li>India 31) Myanmar (Burma) 48) Uzbekistan</li> 
   <li>Indonesia 32) Nepal 49) Vietnam</li> 
   <li>Iran 33) Oman 50) Yemen</li> 
   <li>Iraq 34) Pakistan<br> #? 9<br> Please select one of the following time zone regions.</li> 
   <li>Beijing Time</li> 
   <li>Xinjiang Time<br> #? 1<br> The following information has been given:<br> China<br> Beijing Time<br> Therefore TZ=‘Asia/Shanghai’ will be used.<br> Local time is now: Wed Jun 14 09:16:46 CST 2017.<br> Universal Time is now: Wed Jun 14 01:16:46 UTC 2017.<br> Is the above information OK?</li> 
   <li>Yes</li> 
   <li>No<br> #?1<br> 2）拷贝该时区文件，覆盖系统本地时区配置<br> cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime<br> 3）集群时间同步<br> sudo date -s ‘2017-06-14 09:23:45’<br> hwclock -w</li> 
  </ol> 
  <h2><a id="34__181"></a>3.4 配置文件</h2> 
  <h3><a id="341_Web_182"></a>3.4.1 Web服务器配置</h3> 
  <p>1）进入azkaban web服务器安装目录 conf目录，打开azkaban.properties文件<br> [atguigu@hadoop102 conf]$ pwd<br> /opt/module/azkaban/server/conf<br> [atguigu@hadoop102 conf]$ vi azkaban.properties<br> 2）按照如下配置修改azkaban.properties文件。<br> #Azkaban Personalization Settings<br> azkaban.name=Test #服务器UI名称,用于服务器上方显示的名字<br> azkaban.label=My Local Azkaban #描述<br> azkaban.color=#FF3601 #UI颜色<br> azkaban.default.servlet.path=/index #<br> web.resource.dir=web/ #默认根web目录<br> default.timezone.id=Asia/Shanghai #默认时区,已改为亚洲/上海 默认为美国</p> 
  <p>#Azkaban UserManager class<br> user.manager.class=azkaban.user.XmlUserManager #用户权限管理默认类<br> user.manager.xml.file=conf/azkaban-users.xml #用户配置,具体配置参加下文</p> 
  <p>#Loader for projects<br> executor.global.properties=conf/global.properties # global配置文件所在位置<br> azkaban.project.dir=projects #</p> 
  <p>database.type=mysql #数据库类型<br> mysql.port=3306 #端口号<br> mysql.host=hadoop102 #数据库连接IP<br> mysql.database=azkaban #数据库实例名<br> mysql.user=root #数据库用户名<br> mysql.password=000000 #数据库密码<br> mysql.numconnections=100 #最大连接数</p> 
  <p>#Velocity dev mode<br> velocity.dev.mode=false<br> #Jetty服务器属性.<br> jetty.maxThreads=25 #最大线程数<br> jetty.ssl.port=8443 #Jetty SSL端口<br> jetty.port=8081 #Jetty端口<br> jetty.keystore=keystore #SSL文件名<br> jetty.password=000000 #SSL文件密码<br> jetty.keypassword=000000 #Jetty主密码 与 keystore文件相同<br> jetty.truststore=keystore #SSL文件名<br> jetty.trustpassword=000000 # SSL文件密码</p> 
  <p>#执行服务器属性<br> executor.port=12321 #执行服务器端口</p> 
  <p>#邮件设置<br> <a href="mailto:mail.sender=xxxxxxxx@163.com" rel="nofollow" data-token="fa5464b3e15ecb0ecf22a3040ab0fddc">mail.sender=xxxxxxxx@163.com</a> #发送邮箱<br> <a href="http://mail.host=smtp.163.com" rel="nofollow" data-token="270b9bdee9b1b9118b84a99fac029b87">mail.host=smtp.163.com</a> #发送邮箱smtp地址<br> mail.user=xxxxxxxx #发送邮件时显示的名称<br> mail.password=********** #邮箱密码<br> <a href="mailto:job.failure.email=xxxxxxxx@163.com" rel="nofollow" data-token="bcaadbd16ce6b3ce7c15b8ac9cce622d">job.failure.email=xxxxxxxx@163.com</a> #任务失败时发送邮件的地址<br> <a href="mailto:job.success.email=xxxxxxxx@163.com" rel="nofollow" data-token="8d33fe3af73324de5dac257342a40029">job.success.email=xxxxxxxx@163.com</a> #任务成功时发送邮件的地址<br> lockdown.create.projects=false #<br> cache.directory=cache #缓存目录<br> 2）web服务器用户配置<br> 在azkaban web服务器安装目录 conf目录，按照如下配置修改azkaban-users.xml 文件，增加管理员用户。<br> <br> <br> <br> <br> <br> <br> </p> 
  <h3><a id="342__245"></a>3.4.2 执行服务器配置</h3> 
  <p>1）进入执行服务器安装目录conf，打开azkaban.properties<br> [atguigu@hadoop102 conf]$ pwd<br> /opt/module/azkaban/executor/conf<br> [atguigu@hadoop102 conf]$ vi azkaban.properties<br> 2）按照如下配置修改azkaban.properties文件。<br> #Azkaban<br> default.timezone.id=Asia/Shanghai #时区</p> 
  <p>#Azkaban JobTypes 插件配置<br> azkaban.jobtype.plugin.dir=plugins/jobtypes #jobtype 插件所在位置</p> 
  <p>#Loader for projects<br> executor.global.properties=conf/global.properties<br> azkaban.project.dir=projects</p> 
  <p>#数据库设置<br> database.type=mysql #数据库类型(目前只支持mysql)<br> mysql.port=3306 #数据库端口号<br> mysql.host=192.168.20.200 #数据库IP地址<br> mysql.database=azkaban #数据库实例名<br> mysql.user=root #数据库用户名<br> mysql.password=000000 #数据库密码<br> mysql.numconnections=100 #最大连接数</p> 
  <p>#执行服务器配置<br> executor.maxThreads=50 #最大线程数<br> executor.port=12321 #端口号(如修改,请与web服务中一致)<br> executor.flow.threads=30 #线程数</p> 
  <h2><a id="34_web_275"></a>3.4 启动web服务器</h2> 
  <p>在azkaban web服务器目录下执行启动命令<br> [atguigu@hadoop102 server]$ pwd<br> /opt/module/azkaban/server<br> [atguigu@hadoop102 server]$ bin/azkaban-web-start.sh<br> bin/azkaban-web-start.sh</p> 
  <h2><a id="35__281"></a>3.5 启动执行服务器</h2> 
  <p>在执行服务器目录下执行启动命令<br> [atguigu@hadoop102 executor]$ pwd<br> /opt/module/azkaban/executor<br> [atguigu@hadoop102 executor]$ bin/azkaban-executor-start.sh</p> 
  <p>启动完成后，在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443，即可访问azkaban服务了。在登录中输入刚才新的户用名及密码，点击 login。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230724260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230817628.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h1><a id="_Azkaban_290"></a>四 Azkaban实战</h1> 
  <p>Azkaba内置的任务类型支持command、java</p> 
  <h2><a id="41Commandjob_292"></a>4.1Command类型之单一job案例</h2> 
  <p>1）创建job描述文件<br> vi command.job<br> #command.job<br> type=command<br> command=echo ‘hello’<br> 2）将job资源文件打包成zip文件<br> 3）通过azkaban的web管理平台创建project并上传job压缩包<br> 首先创建project<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230828959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 上传zip包<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230837255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 4）启动执行该job<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230845152.png" alt="在这里插入图片描述"></p> 
  <h2><a id="42Commandjob_306"></a>4.2Command类型之多job工作流案例</h2> 
  <p>1）创建有依赖关系的多个job描述<br> 第一个job：foo.job<br> #foo.job<br> type=command<br> command=echo foo<br> 第二个job：bar.job依赖foo.job<br> #bar.job<br> type=command<br> dependencies=foo<br> command=echo bar<br> 2）将所有job资源文件打到一个zip包中<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230859110.png" alt="在这里插入图片描述"><br> 3）创建工程<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728230959839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 3）在azkaban的web管理界面创建工程并上传zip包<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231027809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 4）启动工作流flow</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231033813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231048809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231057749.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 5）查看结果<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231104447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhdGFpeWFuZ3U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="43HDFS_331"></a>4.3HDFS操作任务</h2> 
  <p>1）创建job描述文件<br> #fs.job<br> type=command<br> command=/opt/module/hadoop-2.7.2/bin/hadoop fs -mkdir /azkaban<br> 2）将job资源文件打包成zip文件<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190728231110897.png" alt="在这里插入图片描述"><br> 3）通过azkaban的web管理平台创建project并上传job压缩包<br> 4）启动执行该job<br> 5）查看结果<br> 4.4 MapReduce任务<br> Mr任务依然可以使用command的job类型来执行<br> 1）创建job描述文件，及mr程序jar包（示例中直接使用hadoop自带的example jar）<br> #mrwc.job<br> type=command<br> command=/opt/module/hadoop-2.7.2/bin/hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wordcount/input /wordcount/output<br> 2）将所有job资源文件打到一个zip包中<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019072823111999.png" alt="在这里插入图片描述"><br> 3）在azkaban的web管理界面创建工程并上传zip包<br> 4）启动job</p> 
  <h2><a id="44HIVE_351"></a>4.4HIVE脚本任务</h2> 
  <p>1）创建job描述文件和hive脚本<br> （1）Hive脚本： test.sql<br> use default;<br> drop table aztest;<br> create table aztest(id int,name string) row format delimited fields terminated by ‘,’;<br> load data inpath ‘/aztest/hiveinput’ into table aztest;<br> create table azres as select * from aztest;<br> insert overwrite directory ‘/aztest/hiveoutput’ select count(1) from aztest;<br> （2）Job描述文件：hivef.job<br> #hivef.job<br> type=command<br> command=/opt/module/hive/bin/hive -f ‘test.sql’<br> 2）将所有job资源文件打到一个zip包中<br> 3）在azkaban的web管理界面创建工程并上传zip包<br> 4）启动job</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
