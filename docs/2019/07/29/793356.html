<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测 &nbsp; &nbsp; &nbsp; 目录 输出结果 设计思路 核心代码 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 输出结果 下边两张图对应查看，可知，数字0有965个是被准确识别到！ &nbsp; 1.10.0 Size of: - Training-set: 55000 - Validation-set: 5000 - Test-set: 10000 Epoch 1/1 128/55000 [..............................] - ETA: 14:24 - loss: 2.3439 - acc: 0.0938 256/55000 [..............................] - ETA: 14:05 - loss: 2.2695 - acc: 0.1016 384/55000 [..............................] - ETA: 13:20 - loss: 2.2176 - acc: 0.1302 512/55000 [..............................] - ETA: 13:30 - loss: 2.1608 - acc: 0.2109 640/55000 [..............................] - ETA: 13:29 - loss: 2.0849 - acc: 0.2500 768/55000 [..............................] - ETA: 13:23 - loss: 2.0309 - acc: 0.2734 896/55000 [..............................] - ETA: 13:30 - loss: 1.9793 - acc: 0.2946 1024/55000 [..............................] - ETA: 13:23 - loss: 1.9105 - acc: 0.3369 1152/55000 [..............................] - ETA: 13:22 - loss: 1.8257 - acc: 0.3776 …… 53760/55000 [============================&gt;.] - ETA: 18s - loss: 0.2106 - acc: 0.9329 53888/55000 [============================&gt;.] - ETA: 16s - loss: 0.2103 - acc: 0.9330 54016/55000 [============================&gt;.] - ETA: 14s - loss: 0.2100 - acc: 0.9331 54144/55000 [============================&gt;.] - ETA: 13s - loss: 0.2096 - acc: 0.9333 54272/55000 [============================&gt;.] - ETA: 11s - loss: 0.2092 - acc: 0.9334 54400/55000 [============================&gt;.] - ETA: 9s - loss: 0.2089 - acc: 0.9335 54528/55000 [============================&gt;.] - ETA: 7s - loss: 0.2086 - acc: 0.9336 54656/55000 [============================&gt;.] - ETA: 5s - loss: 0.2082 - acc: 0.9337 54784/55000 [============================&gt;.] - ETA: 3s - loss: 0.2083 - acc: 0.9337 54912/55000 [============================&gt;.] - ETA: 1s - loss: 0.2082 - acc: 0.9337 55000/55000 [==============================] - 837s 15ms/step - loss: 0.2080 - acc: 0.9338 32/10000 [..............................] - ETA: 21s 160/10000 [..............................] - ETA: 8s 288/10000 [..............................] - ETA: 6s 448/10000 [&gt;.............................] - ETA: 5s 576/10000 [&gt;.............................] - ETA: 5s 736/10000 [=&gt;............................] - ETA: 4s 864/10000 [=&gt;............................] - ETA: 4s 1024/10000 [==&gt;...........................] - ETA: 4s 1152/10000 [==&gt;...........................] - ETA: 4s 1312/10000 [==&gt;...........................] - ETA: 4s 1440/10000 [===&gt;..........................] - ETA: 4s 1600/10000 [===&gt;..........................] - ETA: 3s 1728/10000 [====&gt;.........................] - ETA: 3s …… 3008/10000 [========&gt;.....................] - ETA: 3s 3168/10000 [========&gt;.....................] - ETA: 3s 3296/10000 [========&gt;.....................] - ETA: 3s 3456/10000 [=========&gt;....................] - ETA: 2s …… 5248/10000 [==============&gt;...............] - ETA: 2s 5376/10000 [===============&gt;..............] - ETA: 2s 5536/10000 [===============&gt;..............] - ETA: 2s 5664/10000 [===============&gt;..............] - ETA: 1s 5792/10000 [================&gt;.............] - ETA: 1s …… 7360/10000 [=====================&gt;........] - ETA: 1s 7488/10000 [=====================&gt;........] - ETA: 1s 7648/10000 [=====================&gt;........] - ETA: 1s 7776/10000 [======================&gt;.......] - ETA: 1s 7936/10000 [======================&gt;.......] - ETA: 0s 8064/10000 [=======================&gt;......] - ETA: 0s 8224/10000 [=======================&gt;......] - ETA: 0s …… 9760/10000 [============================&gt;.] - ETA: 0s 9920/10000 [============================&gt;.] - ETA: 0s 10000/10000 [==============================] - 4s 449us/step loss 0.05686537345089018 acc 0.982 acc: 98.20% [[ 965 0 4 0 0 0 4 1 2 4] [ 0 1128 3 0 0 0 0 1 3 0] [ 0 0 1028 0 0 0 0 1 3 0] [ 0 0 10 991 0 2 0 2 3 2] [ 0 0 3 0 967 0 1 1 1 9] [ 2 0 1 7 1 863 5 1 4 8] [ 2 3 0 0 3 2 946 0 2 0] [ 0 1 17 1 1 0 0 987 2 19] [ 2 0 9 2 0 1 0 1 955 4] [ 1 4 3 2 8 0 0 0 1 990]] _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 784) 0 _________________________________________________________________ reshape (Reshape) (None, 28, 28, 1) 0 _________________________________________________________________ layer_conv1 (Conv2D) (None, 28, 28, 16) 416 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 14, 14, 16) 0 _________________________________________________________________ layer_conv2 (Conv2D) (None, 14, 14, 36) 14436 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 7, 7, 36) 0 _________________________________________________________________ flatten (Flatten) (None, 1764) 0 _________________________________________________________________ dense (Dense) (None, 128) 225920 _________________________________________________________________ dense_1 (Dense) (None, 10) 1290 ================================================================= Total params: 242,062 Trainable params: 242,062 Non-trainable params: 0 _________________________________________________________________ (5, 5, 1, 16) (1, 28, 28, 16) &nbsp; 设计思路 &nbsp; &nbsp; &nbsp; 核心代码 后期更新…… path_model = &#39;Functional_model.keras&#39; from tensorflow.python.keras.models import load_model model2_1 = load_model(path_model) model_weights_path = &#39;Functional_model_weights.keras&#39; model2_1.save_weights(model_weights_path ) model2_1.load_weights(model_weights_path, by_name=True ) model2_1.load_weights(model_weights_path) result = model.evaluate(x=data.x_test, y=data.y_test) for name, value in zip(model.metrics_names, result): print(name, value) print(&quot;{0}: {1:.2%}&quot;.format(model.metrics_names[1], result[1])) y_pred = model.predict(x=data.x_test) cls_pred = np.argmax(y_pred, axis=1) plot_example_errors(cls_pred) plot_confusion_matrix(cls_pred) images = data.x_test[0:9] cls_true = data.y_test_cls[0:9] y_pred = model.predict(x=images) cls_pred = np.argmax(y_pred, axis=1) title = &#39;MNIST(Sequential Model): plot predicted example, resl VS predict&#39; plot_images(title, images=images, cls_true=cls_true, cls_pred=cls_pred) &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测 &nbsp; &nbsp; &nbsp; 目录 输出结果 设计思路 核心代码 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 输出结果 下边两张图对应查看，可知，数字0有965个是被准确识别到！ &nbsp; 1.10.0 Size of: - Training-set: 55000 - Validation-set: 5000 - Test-set: 10000 Epoch 1/1 128/55000 [..............................] - ETA: 14:24 - loss: 2.3439 - acc: 0.0938 256/55000 [..............................] - ETA: 14:05 - loss: 2.2695 - acc: 0.1016 384/55000 [..............................] - ETA: 13:20 - loss: 2.2176 - acc: 0.1302 512/55000 [..............................] - ETA: 13:30 - loss: 2.1608 - acc: 0.2109 640/55000 [..............................] - ETA: 13:29 - loss: 2.0849 - acc: 0.2500 768/55000 [..............................] - ETA: 13:23 - loss: 2.0309 - acc: 0.2734 896/55000 [..............................] - ETA: 13:30 - loss: 1.9793 - acc: 0.2946 1024/55000 [..............................] - ETA: 13:23 - loss: 1.9105 - acc: 0.3369 1152/55000 [..............................] - ETA: 13:22 - loss: 1.8257 - acc: 0.3776 …… 53760/55000 [============================&gt;.] - ETA: 18s - loss: 0.2106 - acc: 0.9329 53888/55000 [============================&gt;.] - ETA: 16s - loss: 0.2103 - acc: 0.9330 54016/55000 [============================&gt;.] - ETA: 14s - loss: 0.2100 - acc: 0.9331 54144/55000 [============================&gt;.] - ETA: 13s - loss: 0.2096 - acc: 0.9333 54272/55000 [============================&gt;.] - ETA: 11s - loss: 0.2092 - acc: 0.9334 54400/55000 [============================&gt;.] - ETA: 9s - loss: 0.2089 - acc: 0.9335 54528/55000 [============================&gt;.] - ETA: 7s - loss: 0.2086 - acc: 0.9336 54656/55000 [============================&gt;.] - ETA: 5s - loss: 0.2082 - acc: 0.9337 54784/55000 [============================&gt;.] - ETA: 3s - loss: 0.2083 - acc: 0.9337 54912/55000 [============================&gt;.] - ETA: 1s - loss: 0.2082 - acc: 0.9337 55000/55000 [==============================] - 837s 15ms/step - loss: 0.2080 - acc: 0.9338 32/10000 [..............................] - ETA: 21s 160/10000 [..............................] - ETA: 8s 288/10000 [..............................] - ETA: 6s 448/10000 [&gt;.............................] - ETA: 5s 576/10000 [&gt;.............................] - ETA: 5s 736/10000 [=&gt;............................] - ETA: 4s 864/10000 [=&gt;............................] - ETA: 4s 1024/10000 [==&gt;...........................] - ETA: 4s 1152/10000 [==&gt;...........................] - ETA: 4s 1312/10000 [==&gt;...........................] - ETA: 4s 1440/10000 [===&gt;..........................] - ETA: 4s 1600/10000 [===&gt;..........................] - ETA: 3s 1728/10000 [====&gt;.........................] - ETA: 3s …… 3008/10000 [========&gt;.....................] - ETA: 3s 3168/10000 [========&gt;.....................] - ETA: 3s 3296/10000 [========&gt;.....................] - ETA: 3s 3456/10000 [=========&gt;....................] - ETA: 2s …… 5248/10000 [==============&gt;...............] - ETA: 2s 5376/10000 [===============&gt;..............] - ETA: 2s 5536/10000 [===============&gt;..............] - ETA: 2s 5664/10000 [===============&gt;..............] - ETA: 1s 5792/10000 [================&gt;.............] - ETA: 1s …… 7360/10000 [=====================&gt;........] - ETA: 1s 7488/10000 [=====================&gt;........] - ETA: 1s 7648/10000 [=====================&gt;........] - ETA: 1s 7776/10000 [======================&gt;.......] - ETA: 1s 7936/10000 [======================&gt;.......] - ETA: 0s 8064/10000 [=======================&gt;......] - ETA: 0s 8224/10000 [=======================&gt;......] - ETA: 0s …… 9760/10000 [============================&gt;.] - ETA: 0s 9920/10000 [============================&gt;.] - ETA: 0s 10000/10000 [==============================] - 4s 449us/step loss 0.05686537345089018 acc 0.982 acc: 98.20% [[ 965 0 4 0 0 0 4 1 2 4] [ 0 1128 3 0 0 0 0 1 3 0] [ 0 0 1028 0 0 0 0 1 3 0] [ 0 0 10 991 0 2 0 2 3 2] [ 0 0 3 0 967 0 1 1 1 9] [ 2 0 1 7 1 863 5 1 4 8] [ 2 3 0 0 3 2 946 0 2 0] [ 0 1 17 1 1 0 0 987 2 19] [ 2 0 9 2 0 1 0 1 955 4] [ 1 4 3 2 8 0 0 0 1 990]] _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 784) 0 _________________________________________________________________ reshape (Reshape) (None, 28, 28, 1) 0 _________________________________________________________________ layer_conv1 (Conv2D) (None, 28, 28, 16) 416 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 14, 14, 16) 0 _________________________________________________________________ layer_conv2 (Conv2D) (None, 14, 14, 36) 14436 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 7, 7, 36) 0 _________________________________________________________________ flatten (Flatten) (None, 1764) 0 _________________________________________________________________ dense (Dense) (None, 128) 225920 _________________________________________________________________ dense_1 (Dense) (None, 10) 1290 ================================================================= Total params: 242,062 Trainable params: 242,062 Non-trainable params: 0 _________________________________________________________________ (5, 5, 1, 16) (1, 28, 28, 16) &nbsp; 设计思路 &nbsp; &nbsp; &nbsp; 核心代码 后期更新…… path_model = &#39;Functional_model.keras&#39; from tensorflow.python.keras.models import load_model model2_1 = load_model(path_model) model_weights_path = &#39;Functional_model_weights.keras&#39; model2_1.save_weights(model_weights_path ) model2_1.load_weights(model_weights_path, by_name=True ) model2_1.load_weights(model_weights_path) result = model.evaluate(x=data.x_test, y=data.y_test) for name, value in zip(model.metrics_names, result): print(name, value) print(&quot;{0}: {1:.2%}&quot;.format(model.metrics_names[1], result[1])) y_pred = model.predict(x=data.x_test) cls_pred = np.argmax(y_pred, axis=1) plot_example_errors(cls_pred) plot_confusion_matrix(cls_pred) images = data.x_test[0:9] cls_true = data.y_test_cls[0:9] y_pred = model.predict(x=images) cls_pred = np.argmax(y_pred, axis=1) title = &#39;MNIST(Sequential Model): plot predicted example, resl VS predict&#39; plot_images(title, images=images, cls_true=cls_true, cls_pred=cls_pred) &nbsp; &nbsp; &nbsp; &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/07/29/793356.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/29/793356.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-29T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测 &nbsp; &nbsp; &nbsp; 目录 输出结果 设计思路 核心代码 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 输出结果 下边两张图对应查看，可知，数字0有965个是被准确识别到！ &nbsp; 1.10.0 Size of: - Training-set: 55000 - Validation-set: 5000 - Test-set: 10000 Epoch 1/1 128/55000 [..............................] - ETA: 14:24 - loss: 2.3439 - acc: 0.0938 256/55000 [..............................] - ETA: 14:05 - loss: 2.2695 - acc: 0.1016 384/55000 [..............................] - ETA: 13:20 - loss: 2.2176 - acc: 0.1302 512/55000 [..............................] - ETA: 13:30 - loss: 2.1608 - acc: 0.2109 640/55000 [..............................] - ETA: 13:29 - loss: 2.0849 - acc: 0.2500 768/55000 [..............................] - ETA: 13:23 - loss: 2.0309 - acc: 0.2734 896/55000 [..............................] - ETA: 13:30 - loss: 1.9793 - acc: 0.2946 1024/55000 [..............................] - ETA: 13:23 - loss: 1.9105 - acc: 0.3369 1152/55000 [..............................] - ETA: 13:22 - loss: 1.8257 - acc: 0.3776 …… 53760/55000 [============================&gt;.] - ETA: 18s - loss: 0.2106 - acc: 0.9329 53888/55000 [============================&gt;.] - ETA: 16s - loss: 0.2103 - acc: 0.9330 54016/55000 [============================&gt;.] - ETA: 14s - loss: 0.2100 - acc: 0.9331 54144/55000 [============================&gt;.] - ETA: 13s - loss: 0.2096 - acc: 0.9333 54272/55000 [============================&gt;.] - ETA: 11s - loss: 0.2092 - acc: 0.9334 54400/55000 [============================&gt;.] - ETA: 9s - loss: 0.2089 - acc: 0.9335 54528/55000 [============================&gt;.] - ETA: 7s - loss: 0.2086 - acc: 0.9336 54656/55000 [============================&gt;.] - ETA: 5s - loss: 0.2082 - acc: 0.9337 54784/55000 [============================&gt;.] - ETA: 3s - loss: 0.2083 - acc: 0.9337 54912/55000 [============================&gt;.] - ETA: 1s - loss: 0.2082 - acc: 0.9337 55000/55000 [==============================] - 837s 15ms/step - loss: 0.2080 - acc: 0.9338 32/10000 [..............................] - ETA: 21s 160/10000 [..............................] - ETA: 8s 288/10000 [..............................] - ETA: 6s 448/10000 [&gt;.............................] - ETA: 5s 576/10000 [&gt;.............................] - ETA: 5s 736/10000 [=&gt;............................] - ETA: 4s 864/10000 [=&gt;............................] - ETA: 4s 1024/10000 [==&gt;...........................] - ETA: 4s 1152/10000 [==&gt;...........................] - ETA: 4s 1312/10000 [==&gt;...........................] - ETA: 4s 1440/10000 [===&gt;..........................] - ETA: 4s 1600/10000 [===&gt;..........................] - ETA: 3s 1728/10000 [====&gt;.........................] - ETA: 3s …… 3008/10000 [========&gt;.....................] - ETA: 3s 3168/10000 [========&gt;.....................] - ETA: 3s 3296/10000 [========&gt;.....................] - ETA: 3s 3456/10000 [=========&gt;....................] - ETA: 2s …… 5248/10000 [==============&gt;...............] - ETA: 2s 5376/10000 [===============&gt;..............] - ETA: 2s 5536/10000 [===============&gt;..............] - ETA: 2s 5664/10000 [===============&gt;..............] - ETA: 1s 5792/10000 [================&gt;.............] - ETA: 1s …… 7360/10000 [=====================&gt;........] - ETA: 1s 7488/10000 [=====================&gt;........] - ETA: 1s 7648/10000 [=====================&gt;........] - ETA: 1s 7776/10000 [======================&gt;.......] - ETA: 1s 7936/10000 [======================&gt;.......] - ETA: 0s 8064/10000 [=======================&gt;......] - ETA: 0s 8224/10000 [=======================&gt;......] - ETA: 0s …… 9760/10000 [============================&gt;.] - ETA: 0s 9920/10000 [============================&gt;.] - ETA: 0s 10000/10000 [==============================] - 4s 449us/step loss 0.05686537345089018 acc 0.982 acc: 98.20% [[ 965 0 4 0 0 0 4 1 2 4] [ 0 1128 3 0 0 0 0 1 3 0] [ 0 0 1028 0 0 0 0 1 3 0] [ 0 0 10 991 0 2 0 2 3 2] [ 0 0 3 0 967 0 1 1 1 9] [ 2 0 1 7 1 863 5 1 4 8] [ 2 3 0 0 3 2 946 0 2 0] [ 0 1 17 1 1 0 0 987 2 19] [ 2 0 9 2 0 1 0 1 955 4] [ 1 4 3 2 8 0 0 0 1 990]] _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 784) 0 _________________________________________________________________ reshape (Reshape) (None, 28, 28, 1) 0 _________________________________________________________________ layer_conv1 (Conv2D) (None, 28, 28, 16) 416 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 14, 14, 16) 0 _________________________________________________________________ layer_conv2 (Conv2D) (None, 14, 14, 36) 14436 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 7, 7, 36) 0 _________________________________________________________________ flatten (Flatten) (None, 1764) 0 _________________________________________________________________ dense (Dense) (None, 128) 225920 _________________________________________________________________ dense_1 (Dense) (None, 10) 1290 ================================================================= Total params: 242,062 Trainable params: 242,062 Non-trainable params: 0 _________________________________________________________________ (5, 5, 1, 16) (1, 28, 28, 16) &nbsp; 设计思路 &nbsp; &nbsp; &nbsp; 核心代码 后期更新…… path_model = &#39;Functional_model.keras&#39; from tensorflow.python.keras.models import load_model model2_1 = load_model(path_model) model_weights_path = &#39;Functional_model_weights.keras&#39; model2_1.save_weights(model_weights_path ) model2_1.load_weights(model_weights_path, by_name=True ) model2_1.load_weights(model_weights_path) result = model.evaluate(x=data.x_test, y=data.y_test) for name, value in zip(model.metrics_names, result): print(name, value) print(&quot;{0}: {1:.2%}&quot;.format(model.metrics_names[1], result[1])) y_pred = model.predict(x=data.x_test) cls_pred = np.argmax(y_pred, axis=1) plot_example_errors(cls_pred) plot_confusion_matrix(cls_pred) images = data.x_test[0:9] cls_true = data.y_test_cls[0:9] y_pred = model.predict(x=images) cls_pred = np.argmax(y_pred, axis=1) title = &#39;MNIST(Sequential Model): plot predicted example, resl VS predict&#39; plot_images(title, images=images, cls_true=cls_true, cls_pred=cls_pred) &nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/07/29/793356.html","headline":"DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测","dateModified":"2019-07-29T00:00:00+08:00","datePublished":"2019-07-29T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/29/793356.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>DL之CNN：利用卷积神经网络算法(2→2,基于Keras的API-Functional)利用MNIST(手写数字图片识别)数据集实现多分类预测</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C" rel="nofollow" data-token="9acf343f2127c7b689708f48221aeca7">输出结果</a></p> 
  <p id="%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF-toc" style="margin-left:40px;"><a href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF" rel="nofollow" data-token="0c4c21cf62bf06ba4ade6c7ed4b28105">设计思路</a></p> 
  <p id="%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81" rel="nofollow" data-token="19d23fab2b73d7bbe6c026f781ee872d">核心代码</a></p> 
  <hr id="hr-toc">
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <h2 id="%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C">输出结果</h2> 
  <p><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112921947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="394"><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="357"></p> 
  <p>下边两张图对应查看，可知，数字0有965个是被准确识别到！</p> 
  <p><img alt="" class="has" height="206" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019073015073529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="479"><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="387"><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="412"></p> 
  <p><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730113012734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="406"><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="399"></p> 
  <p><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="328"><img alt="" class="has" height="330" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730112922172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="373"></p> 
  <p>&nbsp;</p> 
  <pre class="has">
<code class="language-python">1.10.0
Size of:
- Training-set:		55000
- Validation-set:	5000
- Test-set:		10000
Epoch 1/1

  128/55000 [..............................] - ETA: 14:24 - loss: 2.3439 - acc: 0.0938
  256/55000 [..............................] - ETA: 14:05 - loss: 2.2695 - acc: 0.1016
  384/55000 [..............................] - ETA: 13:20 - loss: 2.2176 - acc: 0.1302
  512/55000 [..............................] - ETA: 13:30 - loss: 2.1608 - acc: 0.2109
  640/55000 [..............................] - ETA: 13:29 - loss: 2.0849 - acc: 0.2500
  768/55000 [..............................] - ETA: 13:23 - loss: 2.0309 - acc: 0.2734
  896/55000 [..............................] - ETA: 13:30 - loss: 1.9793 - acc: 0.2946
 1024/55000 [..............................] - ETA: 13:23 - loss: 1.9105 - acc: 0.3369
 1152/55000 [..............................] - ETA: 13:22 - loss: 1.8257 - acc: 0.3776
……
53760/55000 [============================&gt;.] - ETA: 18s - loss: 0.2106 - acc: 0.9329
53888/55000 [============================&gt;.] - ETA: 16s - loss: 0.2103 - acc: 0.9330
54016/55000 [============================&gt;.] - ETA: 14s - loss: 0.2100 - acc: 0.9331
54144/55000 [============================&gt;.] - ETA: 13s - loss: 0.2096 - acc: 0.9333
54272/55000 [============================&gt;.] - ETA: 11s - loss: 0.2092 - acc: 0.9334
54400/55000 [============================&gt;.] - ETA: 9s - loss: 0.2089 - acc: 0.9335 
54528/55000 [============================&gt;.] - ETA: 7s - loss: 0.2086 - acc: 0.9336
54656/55000 [============================&gt;.] - ETA: 5s - loss: 0.2082 - acc: 0.9337
54784/55000 [============================&gt;.] - ETA: 3s - loss: 0.2083 - acc: 0.9337
54912/55000 [============================&gt;.] - ETA: 1s - loss: 0.2082 - acc: 0.9337
55000/55000 [==============================] - 837s 15ms/step - loss: 0.2080 - acc: 0.9338

   32/10000 [..............................] - ETA: 21s
  160/10000 [..............................] - ETA: 8s 
  288/10000 [..............................] - ETA: 6s
  448/10000 [&gt;.............................] - ETA: 5s
  576/10000 [&gt;.............................] - ETA: 5s
  736/10000 [=&gt;............................] - ETA: 4s
  864/10000 [=&gt;............................] - ETA: 4s
 1024/10000 [==&gt;...........................] - ETA: 4s
 1152/10000 [==&gt;...........................] - ETA: 4s
 1312/10000 [==&gt;...........................] - ETA: 4s
 1440/10000 [===&gt;..........................] - ETA: 4s
 1600/10000 [===&gt;..........................] - ETA: 3s
 1728/10000 [====&gt;.........................] - ETA: 3s
……
 3008/10000 [========&gt;.....................] - ETA: 3s
 3168/10000 [========&gt;.....................] - ETA: 3s
 3296/10000 [========&gt;.....................] - ETA: 3s
 3456/10000 [=========&gt;....................] - ETA: 2s
……
 5248/10000 [==============&gt;...............] - ETA: 2s
 5376/10000 [===============&gt;..............] - ETA: 2s
 5536/10000 [===============&gt;..............] - ETA: 2s
 5664/10000 [===============&gt;..............] - ETA: 1s
 5792/10000 [================&gt;.............] - ETA: 1s
……
 7360/10000 [=====================&gt;........] - ETA: 1s
 7488/10000 [=====================&gt;........] - ETA: 1s
 7648/10000 [=====================&gt;........] - ETA: 1s
 7776/10000 [======================&gt;.......] - ETA: 1s
 7936/10000 [======================&gt;.......] - ETA: 0s
 8064/10000 [=======================&gt;......] - ETA: 0s
 8224/10000 [=======================&gt;......] - ETA: 0s
……
 9760/10000 [============================&gt;.] - ETA: 0s
 9920/10000 [============================&gt;.] - ETA: 0s
10000/10000 [==============================] - 4s 449us/step
loss 0.05686537345089018
acc 0.982
acc: 98.20%
[[ 965    0    4    0    0    0    4    1    2    4]
 [   0 1128    3    0    0    0    0    1    3    0]
 [   0    0 1028    0    0    0    0    1    3    0]
 [   0    0   10  991    0    2    0    2    3    2]
 [   0    0    3    0  967    0    1    1    1    9]
 [   2    0    1    7    1  863    5    1    4    8]
 [   2    3    0    0    3    2  946    0    2    0]
 [   0    1   17    1    1    0    0  987    2   19]
 [   2    0    9    2    0    1    0    1  955    4]
 [   1    4    3    2    8    0    0    0    1  990]]


_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 784)               0         
_________________________________________________________________
reshape (Reshape)            (None, 28, 28, 1)         0         
_________________________________________________________________
layer_conv1 (Conv2D)         (None, 28, 28, 16)        416       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         
_________________________________________________________________
layer_conv2 (Conv2D)         (None, 14, 14, 36)        14436     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 36)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1764)              0         
_________________________________________________________________
dense (Dense)                (None, 128)               225920    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 242,062
Trainable params: 242,062
Non-trainable params: 0
_________________________________________________________________
(5, 5, 1, 16)
(1, 28, 28, 16)</code></pre> 
  <p>&nbsp;</p> 
  <h2 id="%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF">设计思路</h2> 
  <p><img alt="" class="has" height="1200" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190730151903906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly95dW55YW5pdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" width="890"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <h2 id="%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81">核心代码</h2> 
  <p>后期更新……</p> 
  <pre class="has">
<code class="language-python">path_model = 'Functional_model.keras'  
                  
from tensorflow.python.keras.models import load_model  
model2_1 = load_model(path_model)      

model_weights_path = 'Functional_model_weights.keras'
model2_1.save_weights(model_weights_path )                  
model2_1.load_weights(model_weights_path, by_name=True ) 
model2_1.load_weights(model_weights_path)  


result = model.evaluate(x=data.x_test,
                        y=data.y_test)
  
for name, value in zip(model.metrics_names, result):
    print(name, value)
print("{0}: {1:.2%}".format(model.metrics_names[1], result[1]))


y_pred = model.predict(x=data.x_test) 
cls_pred = np.argmax(y_pred, axis=1)   
plot_example_errors(cls_pred)        
plot_confusion_matrix(cls_pred)     
 
 

images = data.x_test[0:9]                      
cls_true = data.y_test_cls[0:9]                 
y_pred = model.predict(x=images)               
cls_pred = np.argmax(y_pred, axis=1)            
title = 'MNIST(Sequential Model): plot predicted example, resl VS predict'
plot_images(title, images=images,               
            cls_true=cls_true,
            cls_pred=cls_pred)</code></pre> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
