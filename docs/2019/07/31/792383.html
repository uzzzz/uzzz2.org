<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Python(TensorFlow框架)实现手写数字识别系统 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Python(TensorFlow框架)实现手写数字识别系统" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示： 这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。 注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Fri Feb 17 19:50:49 2017 @author: Yonghao Huang &quot;&quot;&quot; #import modules import numpy as np import matplotlib.pyplot as plt import tensorflow as tf import time from datetime import timedelta import math from tensorflow.examples.tutorials.mnist import input_data def new_weights(shape): return tf.Variable(tf.truncated_normal(shape,stddev=0.05)) def new_biases(length): return tf.Variable(tf.constant(0.1,shape=length)) def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;) def max_pool_2x2(inputx): return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;) #import data data = input_data.read_data_sets(&quot;./data&quot;, one_hot=True) # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2 print(&quot;Size of:&quot;) print(&quot;--Training-set:\t\t{}&quot;.format(len(data.train.labels))) print(&quot;--Testing-set:\t\t{}&quot;.format(len(data.test.labels))) print(&quot;--Validation-set:\t\t{}&quot;.format(len(data.validation.labels))) data.test.cls = np.argmax(data.test.labels,axis=1) # show the real test labels: [7 2 1 ..., 4 5 6], 10000values x = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;) x_image = tf.reshape(x,[-1,28,28,1]) y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;) y_true_cls = tf.argmax(y_true,dimension=1) # Conv 1 layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]), &quot;biases&quot;:new_biases([32])} h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;]) h_pool1 = max_pool_2x2(h_conv1) # Conv 2 layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]), &quot;biases&quot;:new_biases([64])} h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;]) h_pool2 = max_pool_2x2(h_conv2) # Full-connected layer 1 fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]), &quot;biases&quot;:new_biases([1024])} h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;]) # Droupout Layer keep_prob = tf.placeholder(&quot;float&quot;) h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) # Full-connected layer 2 fc2_layer = {&quot;weights&quot;:new_weights([1024,10]), &quot;biases&quot;:new_weights([10])} # Predicted class y_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;]) # The output is like [0 0 1 0 0 0 0 0 0 0] y_pred_cls = tf.argmax(y_pred,dimension=1) # Show the real predict number like &#39;2&#39; # cost function to be optimized cross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred)) optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy) # Performance Measures correct_prediction = tf.equal(y_pred_cls,y_true_cls) accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;)) with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) train_batch_size = 50 def optimize(num_iterations): total_iterations=0 start_time = time.time() for i in range(total_iterations,total_iterations+num_iterations): x_batch,y_true_batch = data.train.next_batch(train_batch_size) feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5} feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0} sess.run(optimizer,feed_dict=feed_dict_train_op) # Print status every 100 iterations. if i%100==0: # Calculate the accuracy on the training-set. acc = sess.run(accuracy,feed_dict=feed_dict_train) # Message for printing. msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot; # Print it. print(msg.format(i+1,acc)) # Update the total number of iterations performed total_iterations += num_iterations # Ending time end_time = time.time() # Difference between start and end_times. time_dif = end_time-start_time # Print the time-usage print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif))))) test_batch_size = 256 def print_test_accuracy(): # Number of images in the test-set. num_test = len(data.test.images) cls_pred = np.zeros(shape=num_test,dtype=np.int) i = 0 while i &lt; num_test: # The ending index for the next batch is denoted j. j = min(i+test_batch_size,num_test) # Get the images from the test-set between index i and j images = data.test.images[i:j, :] # Get the associated labels labels = data.test.labels[i:j, :] # Create a feed-dict with these images and labels. feed_dict={x:images,y_true:labels,keep_prob:1.0} # Calculate the predicted class using Tensorflow. cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict) # Set the start-index for the next batch to the # end-index of the current batch i = j cls_true = data.test.cls correct = (cls_true==cls_pred) correct_sum = correct.sum() acc = float(correct_sum) / num_test # Print the accuracy msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot; print(msg.format(acc,correct_sum,num_test)) # Performance after 10000 optimization iterations 运行结果显示：测试集中准确率大概为99.2%。 我还写了一些辅助函数，可以查看部分识别错误的图片， 还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。 系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。 系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ================================== 2018年5月13日更新 以上是基本网络的设计与基本的实现，可满足入门学习。 相关链接: ======================================== 2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K 当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。 最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。 本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， [外链图片转存失败(img-k7xPyAio-1564543116627)(https://i.imgur.com/59M3NlD.png)] 识别效果还可以！ 同样，将卷积卷积层可视化。 [外链图片转存失败(img-tIWWgZB9-1564543116629)(https://i.imgur.com/4awe7NY.png)] 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！ （如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）" />
<meta property="og:description" content="手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示： 这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。 注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Fri Feb 17 19:50:49 2017 @author: Yonghao Huang &quot;&quot;&quot; #import modules import numpy as np import matplotlib.pyplot as plt import tensorflow as tf import time from datetime import timedelta import math from tensorflow.examples.tutorials.mnist import input_data def new_weights(shape): return tf.Variable(tf.truncated_normal(shape,stddev=0.05)) def new_biases(length): return tf.Variable(tf.constant(0.1,shape=length)) def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;) def max_pool_2x2(inputx): return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;) #import data data = input_data.read_data_sets(&quot;./data&quot;, one_hot=True) # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2 print(&quot;Size of:&quot;) print(&quot;--Training-set:\t\t{}&quot;.format(len(data.train.labels))) print(&quot;--Testing-set:\t\t{}&quot;.format(len(data.test.labels))) print(&quot;--Validation-set:\t\t{}&quot;.format(len(data.validation.labels))) data.test.cls = np.argmax(data.test.labels,axis=1) # show the real test labels: [7 2 1 ..., 4 5 6], 10000values x = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;) x_image = tf.reshape(x,[-1,28,28,1]) y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;) y_true_cls = tf.argmax(y_true,dimension=1) # Conv 1 layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]), &quot;biases&quot;:new_biases([32])} h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;]) h_pool1 = max_pool_2x2(h_conv1) # Conv 2 layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]), &quot;biases&quot;:new_biases([64])} h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;]) h_pool2 = max_pool_2x2(h_conv2) # Full-connected layer 1 fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]), &quot;biases&quot;:new_biases([1024])} h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;]) # Droupout Layer keep_prob = tf.placeholder(&quot;float&quot;) h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) # Full-connected layer 2 fc2_layer = {&quot;weights&quot;:new_weights([1024,10]), &quot;biases&quot;:new_weights([10])} # Predicted class y_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;]) # The output is like [0 0 1 0 0 0 0 0 0 0] y_pred_cls = tf.argmax(y_pred,dimension=1) # Show the real predict number like &#39;2&#39; # cost function to be optimized cross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred)) optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy) # Performance Measures correct_prediction = tf.equal(y_pred_cls,y_true_cls) accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;)) with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) train_batch_size = 50 def optimize(num_iterations): total_iterations=0 start_time = time.time() for i in range(total_iterations,total_iterations+num_iterations): x_batch,y_true_batch = data.train.next_batch(train_batch_size) feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5} feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0} sess.run(optimizer,feed_dict=feed_dict_train_op) # Print status every 100 iterations. if i%100==0: # Calculate the accuracy on the training-set. acc = sess.run(accuracy,feed_dict=feed_dict_train) # Message for printing. msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot; # Print it. print(msg.format(i+1,acc)) # Update the total number of iterations performed total_iterations += num_iterations # Ending time end_time = time.time() # Difference between start and end_times. time_dif = end_time-start_time # Print the time-usage print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif))))) test_batch_size = 256 def print_test_accuracy(): # Number of images in the test-set. num_test = len(data.test.images) cls_pred = np.zeros(shape=num_test,dtype=np.int) i = 0 while i &lt; num_test: # The ending index for the next batch is denoted j. j = min(i+test_batch_size,num_test) # Get the images from the test-set between index i and j images = data.test.images[i:j, :] # Get the associated labels labels = data.test.labels[i:j, :] # Create a feed-dict with these images and labels. feed_dict={x:images,y_true:labels,keep_prob:1.0} # Calculate the predicted class using Tensorflow. cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict) # Set the start-index for the next batch to the # end-index of the current batch i = j cls_true = data.test.cls correct = (cls_true==cls_pred) correct_sum = correct.sum() acc = float(correct_sum) / num_test # Print the accuracy msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot; print(msg.format(acc,correct_sum,num_test)) # Performance after 10000 optimization iterations 运行结果显示：测试集中准确率大概为99.2%。 我还写了一些辅助函数，可以查看部分识别错误的图片， 还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。 系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。 系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ================================== 2018年5月13日更新 以上是基本网络的设计与基本的实现，可满足入门学习。 相关链接: ======================================== 2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K 当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。 最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。 本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， [外链图片转存失败(img-k7xPyAio-1564543116627)(https://i.imgur.com/59M3NlD.png)] 识别效果还可以！ 同样，将卷积卷积层可视化。 [外链图片转存失败(img-tIWWgZB9-1564543116629)(https://i.imgur.com/4awe7NY.png)] 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！ （如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792383.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792383.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示： 这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。 注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Fri Feb 17 19:50:49 2017 @author: Yonghao Huang &quot;&quot;&quot; #import modules import numpy as np import matplotlib.pyplot as plt import tensorflow as tf import time from datetime import timedelta import math from tensorflow.examples.tutorials.mnist import input_data def new_weights(shape): return tf.Variable(tf.truncated_normal(shape,stddev=0.05)) def new_biases(length): return tf.Variable(tf.constant(0.1,shape=length)) def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;) def max_pool_2x2(inputx): return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;) #import data data = input_data.read_data_sets(&quot;./data&quot;, one_hot=True) # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2 print(&quot;Size of:&quot;) print(&quot;--Training-set:\\t\\t{}&quot;.format(len(data.train.labels))) print(&quot;--Testing-set:\\t\\t{}&quot;.format(len(data.test.labels))) print(&quot;--Validation-set:\\t\\t{}&quot;.format(len(data.validation.labels))) data.test.cls = np.argmax(data.test.labels,axis=1) # show the real test labels: [7 2 1 ..., 4 5 6], 10000values x = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;) x_image = tf.reshape(x,[-1,28,28,1]) y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;) y_true_cls = tf.argmax(y_true,dimension=1) # Conv 1 layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]), &quot;biases&quot;:new_biases([32])} h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;]) h_pool1 = max_pool_2x2(h_conv1) # Conv 2 layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]), &quot;biases&quot;:new_biases([64])} h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;]) h_pool2 = max_pool_2x2(h_conv2) # Full-connected layer 1 fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]), &quot;biases&quot;:new_biases([1024])} h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;]) # Droupout Layer keep_prob = tf.placeholder(&quot;float&quot;) h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) # Full-connected layer 2 fc2_layer = {&quot;weights&quot;:new_weights([1024,10]), &quot;biases&quot;:new_weights([10])} # Predicted class y_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;]) # The output is like [0 0 1 0 0 0 0 0 0 0] y_pred_cls = tf.argmax(y_pred,dimension=1) # Show the real predict number like &#39;2&#39; # cost function to be optimized cross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred)) optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy) # Performance Measures correct_prediction = tf.equal(y_pred_cls,y_true_cls) accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;)) with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) train_batch_size = 50 def optimize(num_iterations): total_iterations=0 start_time = time.time() for i in range(total_iterations,total_iterations+num_iterations): x_batch,y_true_batch = data.train.next_batch(train_batch_size) feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5} feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0} sess.run(optimizer,feed_dict=feed_dict_train_op) # Print status every 100 iterations. if i%100==0: # Calculate the accuracy on the training-set. acc = sess.run(accuracy,feed_dict=feed_dict_train) # Message for printing. msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot; # Print it. print(msg.format(i+1,acc)) # Update the total number of iterations performed total_iterations += num_iterations # Ending time end_time = time.time() # Difference between start and end_times. time_dif = end_time-start_time # Print the time-usage print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif))))) test_batch_size = 256 def print_test_accuracy(): # Number of images in the test-set. num_test = len(data.test.images) cls_pred = np.zeros(shape=num_test,dtype=np.int) i = 0 while i &lt; num_test: # The ending index for the next batch is denoted j. j = min(i+test_batch_size,num_test) # Get the images from the test-set between index i and j images = data.test.images[i:j, :] # Get the associated labels labels = data.test.labels[i:j, :] # Create a feed-dict with these images and labels. feed_dict={x:images,y_true:labels,keep_prob:1.0} # Calculate the predicted class using Tensorflow. cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict) # Set the start-index for the next batch to the # end-index of the current batch i = j cls_true = data.test.cls correct = (cls_true==cls_pred) correct_sum = correct.sum() acc = float(correct_sum) / num_test # Print the accuracy msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot; print(msg.format(acc,correct_sum,num_test)) # Performance after 10000 optimization iterations 运行结果显示：测试集中准确率大概为99.2%。 我还写了一些辅助函数，可以查看部分识别错误的图片， 还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。 系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。 系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ================================== 2018年5月13日更新 以上是基本网络的设计与基本的实现，可满足入门学习。 相关链接: ======================================== 2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K 当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。 最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。 本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， [外链图片转存失败(img-k7xPyAio-1564543116627)(https://i.imgur.com/59M3NlD.png)] 识别效果还可以！ 同样，将卷积卷积层可视化。 [外链图片转存失败(img-tIWWgZB9-1564543116629)(https://i.imgur.com/4awe7NY.png)] 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！ （如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792383.html","headline":"Python(TensorFlow框架)实现手写数字识别系统","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792383.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Python(TensorFlow框架)实现手写数字识别系统</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="font_face_0"></a><font face="微软雅黑"><strong>手写数字识别算法的设计与实现</strong></font></h2> 
  <p><strong>本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。</strong></p> 
  <hr> 
  <p>项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。</p> 
  <p>设计识别率高的算法，实现快速识别的系统。</p> 
  <h3><a id="1_LeNet5_9"></a><strong>1 LeNet-5模型的介绍</strong></h3> 
  <p>本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205724826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。</p> 
  <p>LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。</p> 
  <p>LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。</p> 
  <p>第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。</p> 
  <p>S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。</p> 
  <p>S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。</p> 
  <p>S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。</p> 
  <p>C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。</p> 
  <p>F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。<br></p> 
  <p>卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。<br></p> 
  <h3><a id="2__32"></a><strong>2 手写数字识别算法模型的构建</strong></h3> 
  <h4><a id="21__33"></a><strong>2.1 各层设计</strong></h4> 
  <p>有了第一节的基础知识，在这基础上，进行完善和改进。</p> 
  <blockquote> 
   <p><strong>输入层设计</strong></p> 
  </blockquote> 
  <p>输入为28×28的矩阵，而不是向量。</p> 
  <blockquote> 
   <p><strong>激活函数的选取</strong></p> 
  </blockquote> 
  <p>Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。</p> 
  <p>ReLU的表达式：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205840158.png" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p><strong>卷积层设计</strong></p> 
  </blockquote> 
  <p>本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。</p> 
  <blockquote> 
   <p><strong>降采样层</strong></p> 
  </blockquote> 
  <p>本文降采样层的pooling方式是max-pooling，大小为2×2。</p> 
  <blockquote> 
   <p><strong>输出层设计</strong></p> 
  </blockquote> 
  <p>输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205913456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h4><a id="22__55"></a><strong>2.2 网络模型的总体结构</strong></h4> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205931959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。</p> 
  <h4><a id="23__58"></a><strong>2.3 编程实现算法</strong></h4> 
  <p>本文使用Python，调用TensorFlow的api完成手写数字识别的算法。<br> 注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。</p> 
  <pre><code>#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Fri Feb 17 19:50:49 2017

@author: Yonghao Huang
"""

#import modules
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import time
from datetime import timedelta
import math
from tensorflow.examples.tutorials.mnist import input_data


def new_weights(shape):
    return tf.Variable(tf.truncated_normal(shape,stddev=0.05))
def new_biases(length):
    return tf.Variable(tf.constant(0.1,shape=length))
def conv2d(x,W):
    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')
def max_pool_2x2(inputx):
    return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

#import data
data = input_data.read_data_sets("./data", one_hot=True)  # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2

print("Size of:")
print("--Training-set:\t\t{}".format(len(data.train.labels)))
print("--Testing-set:\t\t{}".format(len(data.test.labels)))
print("--Validation-set:\t\t{}".format(len(data.validation.labels)))
data.test.cls = np.argmax(data.test.labels,axis=1)   # show the real test labels:  [7 2 1 ..., 4 5 6], 10000values

x = tf.placeholder("float",shape=[None,784],name='x')
x_image = tf.reshape(x,[-1,28,28,1])

y_true = tf.placeholder("float",shape=[None,10],name='y_true')
y_true_cls = tf.argmax(y_true,dimension=1)
# Conv 1
layer_conv1 = {"weights":new_weights([5,5,1,32]),
               "biases":new_biases([32])}
h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1["weights"])+layer_conv1["biases"])
h_pool1 = max_pool_2x2(h_conv1)
# Conv 2
layer_conv2 = {"weights":new_weights([5,5,32,64]),
               "biases":new_biases([64])}
h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2["weights"])+layer_conv2["biases"])
h_pool2 = max_pool_2x2(h_conv2)
# Full-connected layer 1
fc1_layer = {"weights":new_weights([7*7*64,1024]),
            "biases":new_biases([1024])}
h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer["weights"])+fc1_layer["biases"])
# Droupout Layer
keep_prob = tf.placeholder("float")
h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)
# Full-connected layer 2
fc2_layer = {"weights":new_weights([1024,10]),
             "biases":new_weights([10])}
# Predicted class
y_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer["weights"])+fc2_layer["biases"])  # The output is like [0 0 1 0 0 0 0 0 0 0]
y_pred_cls = tf.argmax(y_pred,dimension=1)  # Show the real predict number like '2'
# cost function to be optimized
cross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred))
optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)
# Performance Measures
correct_prediction = tf.equal(y_pred_cls,y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction,"float"))
with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)
    train_batch_size = 50
    def optimize(num_iterations):
        total_iterations=0
        start_time = time.time()
        for i in range(total_iterations,total_iterations+num_iterations):
            x_batch,y_true_batch = data.train.next_batch(train_batch_size)
            feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5}
            feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0}
            sess.run(optimizer,feed_dict=feed_dict_train_op)
            # Print status every 100 iterations.
            if i%100==0:
                # Calculate the accuracy on the training-set.
                acc = sess.run(accuracy,feed_dict=feed_dict_train)
                # Message for printing.
                msg = "Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}"
                # Print it.
                print(msg.format(i+1,acc))
        # Update the total number of iterations performed
        total_iterations += num_iterations
        # Ending time
        end_time = time.time()
        # Difference between start and end_times.
        time_dif = end_time-start_time
        # Print the time-usage
        print("Time usage:"+str(timedelta(seconds=int(round(time_dif)))))
    test_batch_size = 256
    def print_test_accuracy():
        # Number of images in the test-set.
        num_test = len(data.test.images)
        cls_pred = np.zeros(shape=num_test,dtype=np.int)
        i = 0
        while i &lt; num_test:
            # The ending index for the next batch is denoted j.
            j = min(i+test_batch_size,num_test)
            # Get the images from the test-set between index i and j
            images = data.test.images[i:j, :]
            # Get the associated labels
            labels = data.test.labels[i:j, :]
            # Create a feed-dict with these images and labels.
            feed_dict={x:images,y_true:labels,keep_prob:1.0}
            # Calculate the predicted class using Tensorflow.
            cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict)
            # Set the start-index for the next batch to the
            # end-index of the current batch
            i = j
        cls_true = data.test.cls
        correct = (cls_true==cls_pred)
        correct_sum = correct.sum()
        acc = float(correct_sum) / num_test
        # Print the accuracy
        msg = "Accuracy on Test-Set: {0:.1%} ({1}/{2})"
        print(msg.format(acc,correct_sum,num_test))
    # Performance after 10000 optimization iterations
    
    
    
</code></pre> 
  <p>运行结果显示：测试集中准确率大概为99.2%。<br> 我还写了一些辅助函数，可以查看部分识别错误的图片，<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205953982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 还可以查看混淆矩阵，<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210009831.png" alt="在这里插入图片描述"></p> 
  <h4><a id="23__200"></a>2.3 实现手写识别系统</h4> 
  <p>最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210022405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。<br> 系统可进行快速识别，如下图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210051874.png" alt="在这里插入图片描述"></p> 
  <h3><a id="3__206"></a><strong>3 总结</strong></h3> 
  <p>本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。</p> 
  <h3><a id="4__208"></a><strong>4 收获</strong></h3> 
  <p>本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。</p> 
  <p>==================================<br><br> 2018年5月13日更新<br><br> 以上是基本网络的设计与基本的实现，可满足入门学习。</p> 
  <p>相关链接:<br> <br><br> ========================================<br><br> 2018年6月6日更新更新！！</p> 
  <h3><a id="pythonTensorFlow_220"></a>python(TensorFlow)实现手写字符识别</h3> 
  <br> 
  <p>此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。<br> <br></p> 
  <h3><a id="NotMnist_227"></a>NotMnist数据库</h3> 
  <p>这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K<br> 当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。</p> 
  <h3><a id="_231"></a>实战</h3> 
  <p>将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。<br><br> 最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。<br><br> 本文也将训练好的网络模型封装在和上述系统相似的GUI系统中，<br></p> 
  <p>[外链图片转存失败(img-k7xPyAio-1564543116627)(<a href="https://i.imgur.com/59M3NlD.png" rel="nofollow" data-token="5eb0fe7065ba02e5d9b276651b106b76">https://i.imgur.com/59M3NlD.png</a>)]<br><br> 识别效果还可以！<br><br> 同样，将卷积卷积层可视化。<br><br> [外链图片转存失败(img-tIWWgZB9-1564543116629)(<a href="https://i.imgur.com/4awe7NY.png" rel="nofollow" data-token="28d1e371a87e5eb771b44332436c143e">https://i.imgur.com/4awe7NY.png</a>)]<br></p> 
  <h3><a id="_242"></a>结语</h3> 
  <p>TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！<br> （如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，<sup>_</sup>）</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
