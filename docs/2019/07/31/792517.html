<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>TensorflowonSpark 从入门到放弃 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="TensorflowonSpark 从入门到放弃" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="TensorflowonSpark 从入门到放弃 最近因为项目原因，需要在短时间内把之前的代码移植到TensorflowonSpark平台中去，于是开始了愉快的探索之旅。 ##虚拟内存不足 Application application_1536745728661_0003 failed 2 times due to AM Container for appattempt_1536745728661_0003_000002 exited with exitCode: -103 For more detailed output, check application tracking page:http://master:8088/cluster/app/application_1536745728661_0003Then, click on links to logs of each attempt. Diagnostics: Container [pid=46766,containerID=container_1536745728661_0003_02_000001] is running beyond virtual memory limits. Current usage: 315.6 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container. 这里虚拟内存是将物理内存乘以一个比例计算出来的，默认是2.1，所以这里才是2.1G，是在yarn-site.xml 中对这个比例进行修改，如下： &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.&lt;/description&gt; &lt;/property&gt; 我这里给改成了5，不知道是不是有点过分。 使用pyspark中的SparkConf()代替spark-submit中的参数 spark-submit中的参数和SparkConf()中要配置的内容大体上还是一致的，如下是两者的配置： /usr/local/spark/bin/spark-submit --master yarn --deploy-mode client --num-executors 2 --executor-memory 2G --archives hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip --conf spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot; --driver-library-path=&quot;/usr/local/cuda/lib64&quot; mnist_data_setup.py --output mnist/csv --format csv all_conf = [(&#39;spark.deploy.mode&#39;, &#39;client&#39;), (&#39;spark.executor.cores&#39;, &#39;2&#39;), (&#39;spark.executor.memory&#39;, &#39;2G&#39;), (&#39;spark.archives&#39;, &#39;hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip&#39;), (&#39;spark.conf&#39;, &#39;spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot;&#39;), (&#39;spark.driver.library.path&#39;, &#39;/usr/local/cuda/lib64&#39;), (&#39;spark.master&#39;, &#39;yarn&#39;)] conf = SparkConf().setAll(all_conf).setAppName(&#39;mnist_parallelize&#39;) sc = SparkContext(conf=conf) pyspark玩耍步骤 定义好SparkConf，所有关于spark的配置都能在这里面搞定，只不过要注意具体是要配置的参数名称 基于定义好的SparkConf创建SparkContext，sc是整个项目的发动机，有点类似于Tensorflow中的Session 好了，下午的结果出来了，我现在可以用ToS勉强进行训练的操作，晚上要做的就是尽量搞清楚中间的输出到底要怎么去做，然后训练完成之后，要怎么去使用训练好的model，饿死了，吃饭 接下来，就是我下午加晚上要玩命探索的内容，怎么使用sc去驱动一个mainfunc去做我想要做的事情，ps和worker到底是怎么联系起来的 ok，用了三天时间想清楚了一件事情，我似乎并不需要将中间的model保存下来，当然，这是我极度偷懒的想法，后面还是要把spark的所有东西都给摸透（是真的，我尽力吧，如果透了，我就买个新手机） 然后，这里我已经能够使用一个ps和一个worker进行我想要做的事情，能够运行程序，能够获取运行的结果，有图的 这张图是我使用Flask搭建了一个小服务器，获取到的从worker中发来的实验结果 整理下思路 最外层，还是前面那个简陋的Flask 直到获取运行命令，检验网络结构，都是一样的 网络结构没问题，数据也没问题，接下来就用这两天整出来的那个tensorflowonspark程序，使用搭建好的model，用现成的数据进行训练 然后呢，就是航路规划的新界面，就明天，我要搞明白一件事情，怎么给正在运行的程序喂数据，这里应该是有点思路了，或者就按照下面说的来 把训练和使用给分开，这样子来，规划路径的时候肯定是用不到分布式的，训练的时候使用分布式，想办法把worker-index为0的节点上的model给搞下来使用新的model来规划路径 9月15号 周六 把简陋服务器flask和tos结合了一下，上午把keras版本的A3C代码搞定之后再去吃饭 9.18 今天是9月18日 默哀。。。。。。。。。 把亚周发过来的源码看懂" />
<meta property="og:description" content="TensorflowonSpark 从入门到放弃 最近因为项目原因，需要在短时间内把之前的代码移植到TensorflowonSpark平台中去，于是开始了愉快的探索之旅。 ##虚拟内存不足 Application application_1536745728661_0003 failed 2 times due to AM Container for appattempt_1536745728661_0003_000002 exited with exitCode: -103 For more detailed output, check application tracking page:http://master:8088/cluster/app/application_1536745728661_0003Then, click on links to logs of each attempt. Diagnostics: Container [pid=46766,containerID=container_1536745728661_0003_02_000001] is running beyond virtual memory limits. Current usage: 315.6 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container. 这里虚拟内存是将物理内存乘以一个比例计算出来的，默认是2.1，所以这里才是2.1G，是在yarn-site.xml 中对这个比例进行修改，如下： &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.&lt;/description&gt; &lt;/property&gt; 我这里给改成了5，不知道是不是有点过分。 使用pyspark中的SparkConf()代替spark-submit中的参数 spark-submit中的参数和SparkConf()中要配置的内容大体上还是一致的，如下是两者的配置： /usr/local/spark/bin/spark-submit --master yarn --deploy-mode client --num-executors 2 --executor-memory 2G --archives hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip --conf spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot; --driver-library-path=&quot;/usr/local/cuda/lib64&quot; mnist_data_setup.py --output mnist/csv --format csv all_conf = [(&#39;spark.deploy.mode&#39;, &#39;client&#39;), (&#39;spark.executor.cores&#39;, &#39;2&#39;), (&#39;spark.executor.memory&#39;, &#39;2G&#39;), (&#39;spark.archives&#39;, &#39;hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip&#39;), (&#39;spark.conf&#39;, &#39;spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot;&#39;), (&#39;spark.driver.library.path&#39;, &#39;/usr/local/cuda/lib64&#39;), (&#39;spark.master&#39;, &#39;yarn&#39;)] conf = SparkConf().setAll(all_conf).setAppName(&#39;mnist_parallelize&#39;) sc = SparkContext(conf=conf) pyspark玩耍步骤 定义好SparkConf，所有关于spark的配置都能在这里面搞定，只不过要注意具体是要配置的参数名称 基于定义好的SparkConf创建SparkContext，sc是整个项目的发动机，有点类似于Tensorflow中的Session 好了，下午的结果出来了，我现在可以用ToS勉强进行训练的操作，晚上要做的就是尽量搞清楚中间的输出到底要怎么去做，然后训练完成之后，要怎么去使用训练好的model，饿死了，吃饭 接下来，就是我下午加晚上要玩命探索的内容，怎么使用sc去驱动一个mainfunc去做我想要做的事情，ps和worker到底是怎么联系起来的 ok，用了三天时间想清楚了一件事情，我似乎并不需要将中间的model保存下来，当然，这是我极度偷懒的想法，后面还是要把spark的所有东西都给摸透（是真的，我尽力吧，如果透了，我就买个新手机） 然后，这里我已经能够使用一个ps和一个worker进行我想要做的事情，能够运行程序，能够获取运行的结果，有图的 这张图是我使用Flask搭建了一个小服务器，获取到的从worker中发来的实验结果 整理下思路 最外层，还是前面那个简陋的Flask 直到获取运行命令，检验网络结构，都是一样的 网络结构没问题，数据也没问题，接下来就用这两天整出来的那个tensorflowonspark程序，使用搭建好的model，用现成的数据进行训练 然后呢，就是航路规划的新界面，就明天，我要搞明白一件事情，怎么给正在运行的程序喂数据，这里应该是有点思路了，或者就按照下面说的来 把训练和使用给分开，这样子来，规划路径的时候肯定是用不到分布式的，训练的时候使用分布式，想办法把worker-index为0的节点上的model给搞下来使用新的model来规划路径 9月15号 周六 把简陋服务器flask和tos结合了一下，上午把keras版本的A3C代码搞定之后再去吃饭 9.18 今天是9月18日 默哀。。。。。。。。。 把亚周发过来的源码看懂" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792517.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792517.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"TensorflowonSpark 从入门到放弃 最近因为项目原因，需要在短时间内把之前的代码移植到TensorflowonSpark平台中去，于是开始了愉快的探索之旅。 ##虚拟内存不足 Application application_1536745728661_0003 failed 2 times due to AM Container for appattempt_1536745728661_0003_000002 exited with exitCode: -103 For more detailed output, check application tracking page:http://master:8088/cluster/app/application_1536745728661_0003Then, click on links to logs of each attempt. Diagnostics: Container [pid=46766,containerID=container_1536745728661_0003_02_000001] is running beyond virtual memory limits. Current usage: 315.6 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container. 这里虚拟内存是将物理内存乘以一个比例计算出来的，默认是2.1，所以这里才是2.1G，是在yarn-site.xml 中对这个比例进行修改，如下： &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.&lt;/description&gt; &lt;/property&gt; 我这里给改成了5，不知道是不是有点过分。 使用pyspark中的SparkConf()代替spark-submit中的参数 spark-submit中的参数和SparkConf()中要配置的内容大体上还是一致的，如下是两者的配置： /usr/local/spark/bin/spark-submit --master yarn --deploy-mode client --num-executors 2 --executor-memory 2G --archives hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip --conf spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot; --driver-library-path=&quot;/usr/local/cuda/lib64&quot; mnist_data_setup.py --output mnist/csv --format csv all_conf = [(&#39;spark.deploy.mode&#39;, &#39;client&#39;), (&#39;spark.executor.cores&#39;, &#39;2&#39;), (&#39;spark.executor.memory&#39;, &#39;2G&#39;), (&#39;spark.archives&#39;, &#39;hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip&#39;), (&#39;spark.conf&#39;, &#39;spark.executorEnv.LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot;&#39;), (&#39;spark.driver.library.path&#39;, &#39;/usr/local/cuda/lib64&#39;), (&#39;spark.master&#39;, &#39;yarn&#39;)] conf = SparkConf().setAll(all_conf).setAppName(&#39;mnist_parallelize&#39;) sc = SparkContext(conf=conf) pyspark玩耍步骤 定义好SparkConf，所有关于spark的配置都能在这里面搞定，只不过要注意具体是要配置的参数名称 基于定义好的SparkConf创建SparkContext，sc是整个项目的发动机，有点类似于Tensorflow中的Session 好了，下午的结果出来了，我现在可以用ToS勉强进行训练的操作，晚上要做的就是尽量搞清楚中间的输出到底要怎么去做，然后训练完成之后，要怎么去使用训练好的model，饿死了，吃饭 接下来，就是我下午加晚上要玩命探索的内容，怎么使用sc去驱动一个mainfunc去做我想要做的事情，ps和worker到底是怎么联系起来的 ok，用了三天时间想清楚了一件事情，我似乎并不需要将中间的model保存下来，当然，这是我极度偷懒的想法，后面还是要把spark的所有东西都给摸透（是真的，我尽力吧，如果透了，我就买个新手机） 然后，这里我已经能够使用一个ps和一个worker进行我想要做的事情，能够运行程序，能够获取运行的结果，有图的 这张图是我使用Flask搭建了一个小服务器，获取到的从worker中发来的实验结果 整理下思路 最外层，还是前面那个简陋的Flask 直到获取运行命令，检验网络结构，都是一样的 网络结构没问题，数据也没问题，接下来就用这两天整出来的那个tensorflowonspark程序，使用搭建好的model，用现成的数据进行训练 然后呢，就是航路规划的新界面，就明天，我要搞明白一件事情，怎么给正在运行的程序喂数据，这里应该是有点思路了，或者就按照下面说的来 把训练和使用给分开，这样子来，规划路径的时候肯定是用不到分布式的，训练的时候使用分布式，想办法把worker-index为0的节点上的model给搞下来使用新的model来规划路径 9月15号 周六 把简陋服务器flask和tos结合了一下，上午把keras版本的A3C代码搞定之后再去吃饭 9.18 今天是9月18日 默哀。。。。。。。。。 把亚周发过来的源码看懂","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792517.html","headline":"TensorflowonSpark 从入门到放弃","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792517.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>TensorflowonSpark 从入门到放弃</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h1><a id="TensorflowonSpark__0"></a>TensorflowonSpark 从入门到放弃</h1> 
  <p>最近因为项目原因，需要在短时间内把之前的代码移植到TensorflowonSpark平台中去，于是开始了愉快的探索之旅。<br> ##虚拟内存不足</p> 
  <pre><code>Application application_1536745728661_0003 failed 2 times due to AM Container for appattempt_1536745728661_0003_000002 exited with exitCode: -103
For more detailed output, check application tracking page:http://master:8088/cluster/app/application_1536745728661_0003Then, click on links to logs of each attempt.
Diagnostics: Container [pid=46766,containerID=container_1536745728661_0003_02_000001] is running beyond virtual memory limits. Current usage: 315.6 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container.
</code></pre> 
  <p>这里虚拟内存是将物理内存乘以一个比例计算出来的，默认是2.1，所以这里才是2.1G，是在yarn-site.xml 中对这个比例进行修改，如下：</p> 
  <pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
    &lt;value&gt;5&lt;/value&gt;
    &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.&lt;/description&gt;
  &lt;/property&gt;
</code></pre> 
  <p>我这里给改成了5，不知道是不是有点过分。</p> 
  <h2><a id="pysparkSparkConfsparksubmit_20"></a>使用pyspark中的SparkConf()代替spark-submit中的参数</h2> 
  <p>spark-submit中的参数和SparkConf()中要配置的内容大体上还是一致的，如下是两者的配置：</p> 
  <pre><code>/usr/local/spark/bin/spark-submit --master yarn --deploy-mode client --num-executors 2 --executor-memory 2G --archives hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip --conf spark.executorEnv.LD_LIBRARY_PATH="/usr/local/cuda/lib64" --driver-library-path="/usr/local/cuda/lib64" mnist_data_setup.py --output mnist/csv --format csv
</code></pre> 
  <pre><code>all_conf = [('spark.deploy.mode', 'client'), ('spark.executor.cores', '2'), ('spark.executor.memory', '2G'),
                ('spark.archives', 'hdfs:///user/baomi/Python.zip,hdfs:///user/baomi/mnist.zip'),
                ('spark.conf', 'spark.executorEnv.LD_LIBRARY_PATH="/usr/local/cuda/lib64"'),
                ('spark.driver.library.path', '/usr/local/cuda/lib64'),
                ('spark.master', 'yarn')]    
conf = SparkConf().setAll(all_conf).setAppName('mnist_parallelize')
sc = SparkContext(conf=conf)
</code></pre> 
  <h2><a id="pyspark_36"></a>pyspark玩耍步骤</h2> 
  <ul> 
   <li>定义好SparkConf，所有关于spark的配置都能在这里面搞定，只不过要注意具体是要配置的参数名称</li> 
   <li>基于定义好的SparkConf创建SparkContext，sc是整个项目的发动机，有点类似于Tensorflow中的Session</li> 
   <li>好了，下午的结果出来了，我现在可以用ToS勉强进行训练的操作，晚上要做的就是尽量搞清楚中间的输出到底要怎么去做，然后训练完成之后，要怎么去使用训练好的model，饿死了，吃饭</li> 
   <li>接下来，就是我下午加晚上要玩命探索的内容，怎么使用sc去驱动一个mainfunc去做我想要做的事情，ps和worker到底是怎么联系起来的</li> 
   <li>ok，用了三天时间想清楚了一件事情，我似乎并不需要将中间的model保存下来，当然，这是我极度偷懒的想法，后面还是要把spark的所有东西都给摸透（是真的，我尽力吧，如果透了，我就买个新手机）</li> 
   <li>然后，这里我已经能够使用一个ps和一个worker进行我想要做的事情，能够运行程序，能够获取运行的结果，有图的<br> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180914170310246?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Ficm9oYW1iYWJ5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></li> 
   <li>这张图是我使用Flask搭建了一个小服务器，获取到的从worker中发来的实验结果</li> 
  </ul> 
  <h2><a id="_47"></a>整理下思路</h2> 
  <ul> 
   <li> <p>最外层，还是前面那个简陋的Flask</p> </li> 
   <li> <p>直到获取运行命令，检验网络结构，都是一样的</p> </li> 
   <li> <p>网络结构没问题，数据也没问题，接下来就用这两天整出来的那个tensorflowonspark程序，使用搭建好的model，用现成的数据进行训练</p> </li> 
   <li> <p>然后呢，就是航路规划的新界面，就明天，我要搞明白一件事情，怎么给正在运行的程序喂数据，这里应该是有点思路了，或者就按照下面说的来</p> </li> 
   <li> <p>把训练和使用给分开，这样子来，规划路径的时候肯定是用不到分布式的，训练的时候使用分布式，想办法把worker-index为0的节点上的model给搞下来使用新的model来规划路径</p> </li> 
  </ul> 
  <h2><a id="915__57"></a>9月15号 周六</h2> 
  <ul> 
   <li>把简陋服务器flask和tos结合了一下，上午把keras版本的A3C代码搞定之后再去吃饭</li> 
  </ul> 
  <h2><a id="918_60"></a>9.18</h2> 
  <ul> 
   <li>今天是9月18日 默哀。。。。。。。。。</li> 
   <li>把亚周发过来的源码看懂</li> 
  </ul> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
