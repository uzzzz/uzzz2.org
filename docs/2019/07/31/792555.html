<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Apache Spark【从无到有从有到无】【简介】【AS1】简介 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Apache Spark【从无到有从有到无】【简介】【AS1】简介" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 1.简介 2.Spark概述 2.1.安全 2.2.下载 2.3.运行示例和Shell 2.4.在群集上启动 2.5.相关文档 参考：官网&nbsp; &nbsp; 文档（2.4.3） 1.简介 速度 将工作负载运行速度提高100倍。 Apache Spark使用最先进的DAG调度程序，查询优化器和物理执行引擎，实现批处理和流数据的高性能。 &nbsp; 便于使用 使用Java，Scala，Python，R和SQL快速编写应用程序。 Spark提供80多个高级操作员，可以轻松构建并行应用程序。您可以&nbsp;从Scala，Python，R和SQL shell中以交互方式使用它。 &nbsp; 概论 结合SQL，流媒体和复杂的分析。 星火权力库的栈包括&nbsp;SQL和DataFrames，MLlib机器学习，&nbsp;GraphX和星火流。您可以在同一个应用程序中无缝地组合这些库。 &nbsp; 到处运行 Spark运行在Hadoop，Apache Mesos，Kubernetes，独立或云端。它可以访问各种数据源。 您可以使用其独立群集模式，EC2，Hadoop YARN，Mesos或Kubernetes运行Spark&nbsp;。访问HDFS，&nbsp;Alluxio，&nbsp;Apache Cassandra，&nbsp;Apache HBase，Apache Hive以及数百个其他数据源中的数据。 &nbsp; 2.Spark概述 Apache Spark是一种快速通用的集群计算系统。它提供Java，Scala，Python和R中的高级API，以及支持通用执行图的优化引擎。它还支持一组丰富的更高级别的工具，包括&nbsp;Spark SQL&nbsp;用于SQL和结构化数据的处理，MLlib机器学习，GraphX用于图形处理和Spark Streaming。 &nbsp; 2.1.安全 Spark中的安全性默认为OFF。这可能意味着您很容易受到默认攻击。在下载和运行Spark之前，请参阅Spark Security。 &nbsp; 2.2.下载 从项目网站的下载页面获取Spark&nbsp;。本文档适用于Spark版本2.4.3。Spark使用Hadoop的客户端库来实现HDFS（Hadoop分布式文件系统）和YARN（快速、可靠、安全的依赖管理工具）。下载是针对少数流行的Hadoop版本预先打包的。用户还可以通过增加Spark的类路径下载“Hadoop免费”二进制文件并使用任何Hadoop版本运行Spark&nbsp;。Scala和Java用户可以使用Maven坐标在他们的项目中包含Spark，并且将来Python用户也可以从PyPI安装Spark。 如果您想从源代码构建Spark，请访问Building Spark。 Spark在Windows和类UNIX系统（例如Linux，Mac OS）上运行。在一台机器上本地运行很容易 - 您只需要java在系统上安装PATH，或者JAVA_HOME指向Java安装的环境变量。 Spark运行在Java 8 +，Python 2.7 + / 3.4 +和R 3.1+上。对于Scala API，Spark 2.4.3使用Scala 2.12。您需要使用兼容的Scala版本（2.12.x）。 请注意，自Spark 2.2.0起，对2.6.5之前的Java 7，Python 2.6和旧Hadoop版本的支持已被删除。自2.3.0起，对Scala 2.10的支持被删除。自Spark 2.4.1起，对Scala 2.11的支持已被弃用，将在Spark 3.0中删除。 &nbsp; 2.3.运行示例和Shell Spark附带了几个示例程序。Scala，Java，Python和R示例都在&nbsp;examples/src/main目录中。要运行其中一个Java或Scala示例程序，请&nbsp;bin/run-example &lt;class&gt; [params]在顶级Spark目录中使用。（在幕后，这将调用用于启动应用程序的更通用的&nbsp;spark-submit脚本）。例如， ./bin/run-example SparkPi 10 您还可以通过Scala shell的修改版本以交互方式运行Spark。这是学习框架的好方法。 ./bin/spark-shell --master local[2] 该--master选项指定分布式集群的&nbsp;主URL，或者local使用一个线程local[N]在本地运行，或者使用N个线程在本地运行。您应该从使用local测试开始&nbsp;。有关选项的完整列表，请使用该--help选项运行Spark shell&nbsp;。 Spark还提供了一个Python API。要在Python解释器中以交互方式运行Spark，请使用&nbsp;bin/pyspark： ./bin/pyspark --master local[2] Python中也提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/python/pi.py 10 Spark还提供了自1.4以来的实验性R API（仅包括DataFrames API）。要在R解释器中以交互方式运行Spark，请使用bin/sparkR： ./bin/sparkR --master local[2] R中还提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/r/dataframe.R &nbsp; 2.4.在群集上启动 Spark&nbsp;群集模式概述说明了在群集上运行的关键概念。Spark既可以自己运行，也可以通过几个现有的集群管理器运行。它目前提供了几种部署选项： 独立部署模式：在专用群集上部署Spark的最简单方法 Apache Mesos Hadoop YARN Kubernetes &nbsp; 2.5.相关文档 编程指南： 快速入门：Spark API的快速入门;&nbsp;从这里开始！ RDD编程指南：Spark基础知识概述 - RDD（核心但旧API），累加器和广播变量 Spark SQL，Datasets和DataFrames：使用关系查询处理结构化数据（比RDD更新的API） 结构化流：使用关系查询处理结构化数据流（使用数据集和数据框架，比DStreams更新的API） Spark Streaming：使用DStreams处理数据流（旧API） MLlib：应用机器学习算法 GraphX：处理图表 API文档： Spark Scala API（Scaladoc） Spark Java API（Javadoc） Spark Python API（Sphinx） Spark R API（Roxygen2） Spark SQL，内置函数（MkDocs） 部署指南： 群集概述：在群集上运行时概念和组件的概述 提交应用程序：打包和部署应用程序 部署模式： Amazon EC2：允许您在大约5分钟内在EC2上启动集群的脚本 独立部署模式：无需第三方集群管理器即可快速启动独立集群 Mesos：使用Apache Mesos部署私有集群 YARN：在Hadoop NextGen（YARN）之上部署Spark Kubernetes：在Kubernetes上部署Spark 其他文件： 配置：通过其配置系统自定义Spark 监控：跟踪应用程序的行为 调优指南：优化性能和内存使用的最佳实践 作业调度：在Spark应用程序内部和内部调度资源 安全性：Spark安全支持 硬件配置：群集硬件的建议 与其他存储系统集成： 云基础架构 OpenStack Swift 构建Spark：使用Maven系统构建Spark 为Spark做贡献 第三方项目：相关的第三方Spark项目 外部资源： Spark主页 Spark社区资源，包括本地聚会 StackOverflow标签&nbsp;apache-spark 邮件列表：在这里询问有关Spark的问题 AMP Camps：加州大学伯克利分校的一系列训练营，包括有关Spark，Spark Streaming，Mesos等的演讲和练习。视频，&nbsp;幻灯片和练习可在线免费获取。 代码示例：examplesSpark（Scala，&nbsp;Java，&nbsp;Python，&nbsp;R）的子文件夹中也提供了更多内容" />
<meta property="og:description" content="目录 1.简介 2.Spark概述 2.1.安全 2.2.下载 2.3.运行示例和Shell 2.4.在群集上启动 2.5.相关文档 参考：官网&nbsp; &nbsp; 文档（2.4.3） 1.简介 速度 将工作负载运行速度提高100倍。 Apache Spark使用最先进的DAG调度程序，查询优化器和物理执行引擎，实现批处理和流数据的高性能。 &nbsp; 便于使用 使用Java，Scala，Python，R和SQL快速编写应用程序。 Spark提供80多个高级操作员，可以轻松构建并行应用程序。您可以&nbsp;从Scala，Python，R和SQL shell中以交互方式使用它。 &nbsp; 概论 结合SQL，流媒体和复杂的分析。 星火权力库的栈包括&nbsp;SQL和DataFrames，MLlib机器学习，&nbsp;GraphX和星火流。您可以在同一个应用程序中无缝地组合这些库。 &nbsp; 到处运行 Spark运行在Hadoop，Apache Mesos，Kubernetes，独立或云端。它可以访问各种数据源。 您可以使用其独立群集模式，EC2，Hadoop YARN，Mesos或Kubernetes运行Spark&nbsp;。访问HDFS，&nbsp;Alluxio，&nbsp;Apache Cassandra，&nbsp;Apache HBase，Apache Hive以及数百个其他数据源中的数据。 &nbsp; 2.Spark概述 Apache Spark是一种快速通用的集群计算系统。它提供Java，Scala，Python和R中的高级API，以及支持通用执行图的优化引擎。它还支持一组丰富的更高级别的工具，包括&nbsp;Spark SQL&nbsp;用于SQL和结构化数据的处理，MLlib机器学习，GraphX用于图形处理和Spark Streaming。 &nbsp; 2.1.安全 Spark中的安全性默认为OFF。这可能意味着您很容易受到默认攻击。在下载和运行Spark之前，请参阅Spark Security。 &nbsp; 2.2.下载 从项目网站的下载页面获取Spark&nbsp;。本文档适用于Spark版本2.4.3。Spark使用Hadoop的客户端库来实现HDFS（Hadoop分布式文件系统）和YARN（快速、可靠、安全的依赖管理工具）。下载是针对少数流行的Hadoop版本预先打包的。用户还可以通过增加Spark的类路径下载“Hadoop免费”二进制文件并使用任何Hadoop版本运行Spark&nbsp;。Scala和Java用户可以使用Maven坐标在他们的项目中包含Spark，并且将来Python用户也可以从PyPI安装Spark。 如果您想从源代码构建Spark，请访问Building Spark。 Spark在Windows和类UNIX系统（例如Linux，Mac OS）上运行。在一台机器上本地运行很容易 - 您只需要java在系统上安装PATH，或者JAVA_HOME指向Java安装的环境变量。 Spark运行在Java 8 +，Python 2.7 + / 3.4 +和R 3.1+上。对于Scala API，Spark 2.4.3使用Scala 2.12。您需要使用兼容的Scala版本（2.12.x）。 请注意，自Spark 2.2.0起，对2.6.5之前的Java 7，Python 2.6和旧Hadoop版本的支持已被删除。自2.3.0起，对Scala 2.10的支持被删除。自Spark 2.4.1起，对Scala 2.11的支持已被弃用，将在Spark 3.0中删除。 &nbsp; 2.3.运行示例和Shell Spark附带了几个示例程序。Scala，Java，Python和R示例都在&nbsp;examples/src/main目录中。要运行其中一个Java或Scala示例程序，请&nbsp;bin/run-example &lt;class&gt; [params]在顶级Spark目录中使用。（在幕后，这将调用用于启动应用程序的更通用的&nbsp;spark-submit脚本）。例如， ./bin/run-example SparkPi 10 您还可以通过Scala shell的修改版本以交互方式运行Spark。这是学习框架的好方法。 ./bin/spark-shell --master local[2] 该--master选项指定分布式集群的&nbsp;主URL，或者local使用一个线程local[N]在本地运行，或者使用N个线程在本地运行。您应该从使用local测试开始&nbsp;。有关选项的完整列表，请使用该--help选项运行Spark shell&nbsp;。 Spark还提供了一个Python API。要在Python解释器中以交互方式运行Spark，请使用&nbsp;bin/pyspark： ./bin/pyspark --master local[2] Python中也提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/python/pi.py 10 Spark还提供了自1.4以来的实验性R API（仅包括DataFrames API）。要在R解释器中以交互方式运行Spark，请使用bin/sparkR： ./bin/sparkR --master local[2] R中还提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/r/dataframe.R &nbsp; 2.4.在群集上启动 Spark&nbsp;群集模式概述说明了在群集上运行的关键概念。Spark既可以自己运行，也可以通过几个现有的集群管理器运行。它目前提供了几种部署选项： 独立部署模式：在专用群集上部署Spark的最简单方法 Apache Mesos Hadoop YARN Kubernetes &nbsp; 2.5.相关文档 编程指南： 快速入门：Spark API的快速入门;&nbsp;从这里开始！ RDD编程指南：Spark基础知识概述 - RDD（核心但旧API），累加器和广播变量 Spark SQL，Datasets和DataFrames：使用关系查询处理结构化数据（比RDD更新的API） 结构化流：使用关系查询处理结构化数据流（使用数据集和数据框架，比DStreams更新的API） Spark Streaming：使用DStreams处理数据流（旧API） MLlib：应用机器学习算法 GraphX：处理图表 API文档： Spark Scala API（Scaladoc） Spark Java API（Javadoc） Spark Python API（Sphinx） Spark R API（Roxygen2） Spark SQL，内置函数（MkDocs） 部署指南： 群集概述：在群集上运行时概念和组件的概述 提交应用程序：打包和部署应用程序 部署模式： Amazon EC2：允许您在大约5分钟内在EC2上启动集群的脚本 独立部署模式：无需第三方集群管理器即可快速启动独立集群 Mesos：使用Apache Mesos部署私有集群 YARN：在Hadoop NextGen（YARN）之上部署Spark Kubernetes：在Kubernetes上部署Spark 其他文件： 配置：通过其配置系统自定义Spark 监控：跟踪应用程序的行为 调优指南：优化性能和内存使用的最佳实践 作业调度：在Spark应用程序内部和内部调度资源 安全性：Spark安全支持 硬件配置：群集硬件的建议 与其他存储系统集成： 云基础架构 OpenStack Swift 构建Spark：使用Maven系统构建Spark 为Spark做贡献 第三方项目：相关的第三方Spark项目 外部资源： Spark主页 Spark社区资源，包括本地聚会 StackOverflow标签&nbsp;apache-spark 邮件列表：在这里询问有关Spark的问题 AMP Camps：加州大学伯克利分校的一系列训练营，包括有关Spark，Spark Streaming，Mesos等的演讲和练习。视频，&nbsp;幻灯片和练习可在线免费获取。 代码示例：examplesSpark（Scala，&nbsp;Java，&nbsp;Python，&nbsp;R）的子文件夹中也提供了更多内容" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792555.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792555.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 1.简介 2.Spark概述 2.1.安全 2.2.下载 2.3.运行示例和Shell 2.4.在群集上启动 2.5.相关文档 参考：官网&nbsp; &nbsp; 文档（2.4.3） 1.简介 速度 将工作负载运行速度提高100倍。 Apache Spark使用最先进的DAG调度程序，查询优化器和物理执行引擎，实现批处理和流数据的高性能。 &nbsp; 便于使用 使用Java，Scala，Python，R和SQL快速编写应用程序。 Spark提供80多个高级操作员，可以轻松构建并行应用程序。您可以&nbsp;从Scala，Python，R和SQL shell中以交互方式使用它。 &nbsp; 概论 结合SQL，流媒体和复杂的分析。 星火权力库的栈包括&nbsp;SQL和DataFrames，MLlib机器学习，&nbsp;GraphX和星火流。您可以在同一个应用程序中无缝地组合这些库。 &nbsp; 到处运行 Spark运行在Hadoop，Apache Mesos，Kubernetes，独立或云端。它可以访问各种数据源。 您可以使用其独立群集模式，EC2，Hadoop YARN，Mesos或Kubernetes运行Spark&nbsp;。访问HDFS，&nbsp;Alluxio，&nbsp;Apache Cassandra，&nbsp;Apache HBase，Apache Hive以及数百个其他数据源中的数据。 &nbsp; 2.Spark概述 Apache Spark是一种快速通用的集群计算系统。它提供Java，Scala，Python和R中的高级API，以及支持通用执行图的优化引擎。它还支持一组丰富的更高级别的工具，包括&nbsp;Spark SQL&nbsp;用于SQL和结构化数据的处理，MLlib机器学习，GraphX用于图形处理和Spark Streaming。 &nbsp; 2.1.安全 Spark中的安全性默认为OFF。这可能意味着您很容易受到默认攻击。在下载和运行Spark之前，请参阅Spark Security。 &nbsp; 2.2.下载 从项目网站的下载页面获取Spark&nbsp;。本文档适用于Spark版本2.4.3。Spark使用Hadoop的客户端库来实现HDFS（Hadoop分布式文件系统）和YARN（快速、可靠、安全的依赖管理工具）。下载是针对少数流行的Hadoop版本预先打包的。用户还可以通过增加Spark的类路径下载“Hadoop免费”二进制文件并使用任何Hadoop版本运行Spark&nbsp;。Scala和Java用户可以使用Maven坐标在他们的项目中包含Spark，并且将来Python用户也可以从PyPI安装Spark。 如果您想从源代码构建Spark，请访问Building Spark。 Spark在Windows和类UNIX系统（例如Linux，Mac OS）上运行。在一台机器上本地运行很容易 - 您只需要java在系统上安装PATH，或者JAVA_HOME指向Java安装的环境变量。 Spark运行在Java 8 +，Python 2.7 + / 3.4 +和R 3.1+上。对于Scala API，Spark 2.4.3使用Scala 2.12。您需要使用兼容的Scala版本（2.12.x）。 请注意，自Spark 2.2.0起，对2.6.5之前的Java 7，Python 2.6和旧Hadoop版本的支持已被删除。自2.3.0起，对Scala 2.10的支持被删除。自Spark 2.4.1起，对Scala 2.11的支持已被弃用，将在Spark 3.0中删除。 &nbsp; 2.3.运行示例和Shell Spark附带了几个示例程序。Scala，Java，Python和R示例都在&nbsp;examples/src/main目录中。要运行其中一个Java或Scala示例程序，请&nbsp;bin/run-example &lt;class&gt; [params]在顶级Spark目录中使用。（在幕后，这将调用用于启动应用程序的更通用的&nbsp;spark-submit脚本）。例如， ./bin/run-example SparkPi 10 您还可以通过Scala shell的修改版本以交互方式运行Spark。这是学习框架的好方法。 ./bin/spark-shell --master local[2] 该--master选项指定分布式集群的&nbsp;主URL，或者local使用一个线程local[N]在本地运行，或者使用N个线程在本地运行。您应该从使用local测试开始&nbsp;。有关选项的完整列表，请使用该--help选项运行Spark shell&nbsp;。 Spark还提供了一个Python API。要在Python解释器中以交互方式运行Spark，请使用&nbsp;bin/pyspark： ./bin/pyspark --master local[2] Python中也提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/python/pi.py 10 Spark还提供了自1.4以来的实验性R API（仅包括DataFrames API）。要在R解释器中以交互方式运行Spark，请使用bin/sparkR： ./bin/sparkR --master local[2] R中还提供了示例应用程序。例如， ./bin/spark-submit examples/src/main/r/dataframe.R &nbsp; 2.4.在群集上启动 Spark&nbsp;群集模式概述说明了在群集上运行的关键概念。Spark既可以自己运行，也可以通过几个现有的集群管理器运行。它目前提供了几种部署选项： 独立部署模式：在专用群集上部署Spark的最简单方法 Apache Mesos Hadoop YARN Kubernetes &nbsp; 2.5.相关文档 编程指南： 快速入门：Spark API的快速入门;&nbsp;从这里开始！ RDD编程指南：Spark基础知识概述 - RDD（核心但旧API），累加器和广播变量 Spark SQL，Datasets和DataFrames：使用关系查询处理结构化数据（比RDD更新的API） 结构化流：使用关系查询处理结构化数据流（使用数据集和数据框架，比DStreams更新的API） Spark Streaming：使用DStreams处理数据流（旧API） MLlib：应用机器学习算法 GraphX：处理图表 API文档： Spark Scala API（Scaladoc） Spark Java API（Javadoc） Spark Python API（Sphinx） Spark R API（Roxygen2） Spark SQL，内置函数（MkDocs） 部署指南： 群集概述：在群集上运行时概念和组件的概述 提交应用程序：打包和部署应用程序 部署模式： Amazon EC2：允许您在大约5分钟内在EC2上启动集群的脚本 独立部署模式：无需第三方集群管理器即可快速启动独立集群 Mesos：使用Apache Mesos部署私有集群 YARN：在Hadoop NextGen（YARN）之上部署Spark Kubernetes：在Kubernetes上部署Spark 其他文件： 配置：通过其配置系统自定义Spark 监控：跟踪应用程序的行为 调优指南：优化性能和内存使用的最佳实践 作业调度：在Spark应用程序内部和内部调度资源 安全性：Spark安全支持 硬件配置：群集硬件的建议 与其他存储系统集成： 云基础架构 OpenStack Swift 构建Spark：使用Maven系统构建Spark 为Spark做贡献 第三方项目：相关的第三方Spark项目 外部资源： Spark主页 Spark社区资源，包括本地聚会 StackOverflow标签&nbsp;apache-spark 邮件列表：在这里询问有关Spark的问题 AMP Camps：加州大学伯克利分校的一系列训练营，包括有关Spark，Spark Streaming，Mesos等的演讲和练习。视频，&nbsp;幻灯片和练习可在线免费获取。 代码示例：examplesSpark（Scala，&nbsp;Java，&nbsp;Python，&nbsp;R）的子文件夹中也提供了更多内容","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792555.html","headline":"Apache Spark【从无到有从有到无】【简介】【AS1】简介","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792555.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Apache Spark【从无到有从有到无】【简介】【AS1】简介</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="1.%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#1.%E7%AE%80%E4%BB%8B" rel="nofollow" data-token="899253433fecaa83bda31124e048e6da">1.简介</a></p> 
  <p id="2.Spark%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#2.Spark%E6%A6%82%E8%BF%B0" rel="nofollow" data-token="9bc36753785d32b4bbbf3fd1695ce6a1">2.Spark概述</a></p> 
  <p id="2.1.%E5%AE%89%E5%85%A8-toc" style="margin-left:40px;"><a href="#2.1.%E5%AE%89%E5%85%A8" rel="nofollow" data-token="b73d7a0a9e28e3a16773d921b16e9b55">2.1.安全</a></p> 
  <p id="2.2.%E4%B8%8B%E8%BD%BD-toc" style="margin-left:40px;"><a href="#2.2.%E4%B8%8B%E8%BD%BD" rel="nofollow" data-token="d62f0496555dbd729cd12a9aeab01711">2.2.下载</a></p> 
  <p id="running-the-examples-and-shell-toc" style="margin-left:40px;"><a href="#running-the-examples-and-shell" rel="nofollow" data-token="3a18e898052c7bb1fb21550326edb2af">2.3.运行示例和Shell</a></p> 
  <p id="launching-on-a-cluster-toc" style="margin-left:40px;"><a href="#launching-on-a-cluster" rel="nofollow" data-token="dc9ee84afa960035dab136fbe116cf26">2.4.在群集上启动</a></p> 
  <p id="2.5.%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3-toc" style="margin-left:40px;"><a href="#2.5.%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3" rel="nofollow" data-token="4e912c5411e0ec605ba557c27125f8ff">2.5.相关文档</a></p> 
  <hr id="hr-toc">
  <p><strong>参考：<a href="http://spark.apache.org/" rel="nofollow" data-token="98dd5e05ee13641422bc3fdf16604766">官网</a>&nbsp; &nbsp; <a href="http://spark.apache.org/docs/latest/" rel="nofollow" data-token="4ee4734a10a0784c03b6633415249438">文档（2.4.3）</a></strong></p> 
  <h1 id="1.%E7%AE%80%E4%BB%8B">1.简介</h1> 
  <p><strong><span style="color:#317eac;">速度</span></strong></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">将工作负载运行速度提高100倍。</span></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">Apache Spark使用最先进的DAG调度程序，查询优化器和物理执行引擎，实现批处理和流数据的高性能。</span></p> 
  <p style="margin-left:0px;"><img alt="" class="has" height="195" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731091954610.png" width="292"></p> 
  <p>&nbsp;</p> 
  <p><strong><span style="color:#317eac;">便于使用</span></strong></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">使用Java，Scala，Python，R和SQL快速编写应用程序。</span></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">Spark提供80多个高级操作员，可以轻松构建并行应用程序。您可以&nbsp;从Scala，Python，R和SQL shell中以<em>交互</em>方式使用它。</span></p> 
  <p><img alt="" class="has" height="133" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731092005137.png" width="345"></p> 
  <p>&nbsp;</p> 
  <p><strong><span style="color:#317eac;">概论</span></strong></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">结合SQL，流媒体和复杂的分析。</span></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">星火权力库的栈包括&nbsp;<a href="http://spark.apache.org/sql/" rel="nofollow" data-token="6754e16d201a37a40dd1cb33a4e01038">SQL和DataFrames</a>，<a href="http://spark.apache.org/mllib/" rel="nofollow" data-token="c40030f748559f3f300493a88fb533ec">MLlib</a>机器学习，&nbsp;<a href="http://spark.apache.org/graphx/" rel="nofollow" data-token="c0a4710385ef0f227c13157f06e8cb09">GraphX</a>和<a href="http://spark.apache.org/streaming/" rel="nofollow" data-token="5c91db9807b29b1dd015f841f593113f">星火流</a>。您可以在同一个应用程序中无缝地组合这些库。</span></p> 
  <p><img alt="" class="has" height="166" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731092014729.png" width="347"></p> 
  <p>&nbsp;</p> 
  <p><strong><span style="color:#317eac;">到处运行</span></strong></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">Spark运行在Hadoop，Apache Mesos，Kubernetes，独立或云端。它可以访问各种数据源。</span></p> 
  <p style="margin-left:0px;"><span style="color:#555555;">您可以使用其<a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" data-token="f358e63288e912a060073df74ca5d5aa">独立群集模式</a>，<a href="https://github.com/amplab/spark-ec2" rel="nofollow" data-token="688b833433c3ef7a2a95f0b97faba2c5">EC2</a>，<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="nofollow" data-token="54bb039eb169f1771940aeebb2074069">Hadoop YARN</a>，<a href="https://mesos.apache.org/" rel="nofollow" data-token="3288f0616f8d3a6e0ef05c5849111846">Mesos</a>或<a href="https://kubernetes.io/" rel="nofollow" data-token="aa575e2ccb3c3d11cd19ea80a6cb7f6f">Kubernetes</a>运行Spark&nbsp;。访问<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html" rel="nofollow" data-token="c343e639fc61bddca7d53d08e3fa173b">HDFS</a>，&nbsp;<a href="https://www.alluxio.org/" rel="nofollow" data-token="c9f91cb2774ac7b5fd61d0900b27522d">Alluxio</a>，&nbsp;<a href="https://cassandra.apache.org/" rel="nofollow" data-token="5beeaf959121b0d4302ea95b3ae35bc2">Apache Cassandra</a>，&nbsp;<a href="https://hbase.apache.org/" rel="nofollow" data-token="449c58848acd4064bdc6e10f8f11fa00">Apache HBase</a>，<a href="https://hive.apache.org/" rel="nofollow" data-token="6492ca22c59ab81e5aa4f0ecc6b79aeb">Apache Hive</a>以及数百个其他数据源中的数据。</span></p> 
  <p><img alt="" class="has" height="291" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731092030527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1NDk2MjY=,size_16,color_FFFFFF,t_70" width="332"></p> 
  <p>&nbsp;</p> 
  <h1 id="2.Spark%E6%A6%82%E8%BF%B0">2.<strong><span style="color:#1d1f22;">Spark概述</span></strong></h1> 
  <p>Apache Spark是一种快速通用的集群计算系统。它提供Java，Scala，Python和R中的高级API，以及支持通用执行图的优化引擎。它还支持一组丰富的更高级别的工具，包括&nbsp;<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" rel="nofollow" data-token="f8a692808a2e46ef069b4c3df4ad3872">Spark SQL</a>&nbsp;用于SQL和结构化数据的处理，<a href="http://spark.apache.org/docs/latest/ml-guide.html" rel="nofollow" data-token="d2382fb954e1ca5ff9f6fc734fa5b5e0">MLlib</a>机器学习，<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" rel="nofollow" data-token="5d0eb0c8a370fd6630e6858b4de648f4">GraphX</a>用于图形处理和<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="nofollow" data-token="347712cbf6cc3f81943029181db37a2d">Spark Streaming</a>。</p> 
  <p>&nbsp;</p> 
  <h2 id="2.1.%E5%AE%89%E5%85%A8">2.1.<strong><span style="color:#1d1f22;">安全</span></strong></h2> 
  <p>Spark中的安全性默认为OFF。这可能意味着您很容易受到默认攻击。在下载和运行Spark之前，请参阅<a href="http://spark.apache.org/docs/latest/security.html" rel="nofollow" data-token="93e09312b04ab0b0e2cca648fa647030">Spark Security</a>。</p> 
  <p>&nbsp;</p> 
  <h2 id="2.2.%E4%B8%8B%E8%BD%BD">2.2.<strong><span style="color:#1d1f22;">下载</span></strong></h2> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">从项目网站的<a href="https://spark.apache.org/downloads.html" rel="nofollow" data-token="453b30aaffaa60a3ae87c0571127864d">下载页面</a>获取Spark&nbsp;。本文档适用于Spark版本2.4.3。Spark使用Hadoop的客户端库来实现HDFS（</span>Hadoop分布式文件系统<span style="color:#1d1f22;">）和YARN（</span>快速、可靠、安全的依赖管理工具<span style="color:#1d1f22;">）。下载是针对少数流行的Hadoop版本预先打包的。用户还可以<a href="http://spark.apache.org/docs/latest/hadoop-provided.html" rel="nofollow" data-token="038b2ccc14f07d3ca5816db25f2c6caf">通过增加Spark的类路径</a>下载“Hadoop免费”二进制文件并使用任何Hadoop版本运行Spark&nbsp;。Scala和Java用户可以使用Maven坐标在他们的项目中包含Spark，并且将来Python用户也可以从PyPI安装Spark。</span></p> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">如果您想从源代码构建Spark，请访问<a href="http://spark.apache.org/docs/latest/building-spark.html" rel="nofollow" data-token="af5b9ad24eb277ba223c6054d7570263">Building Spark</a>。</span></p> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">Spark在Windows和类UNIX系统（例如Linux，Mac OS）上运行。在一台机器上本地运行很容易 - 您只需要<code>java</code>在系统上安装<code>PATH</code>，或者<code>JAVA_HOME</code>指向Java安装的环境变量。</span></p> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">Spark运行在Java 8 +，Python 2.7 + / 3.4 +和R 3.1+上。对于Scala API，Spark 2.4.3使用Scala 2.12。您需要使用兼容的Scala版本（2.12.x）。</span></p> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">请注意，自Spark 2.2.0起，对2.6.5之前的Java 7，Python 2.6和旧Hadoop版本的支持已被删除。自2.3.0起，对Scala 2.10的支持被删除。自Spark 2.4.1起，对Scala 2.11的支持已被弃用，将在Spark 3.0中删除。</span></p> 
  <p>&nbsp;</p> 
  <h2 id="running-the-examples-and-shell" style="margin-left:0px;"><strong><span style="color:#1d1f22;">2.3.运行示例和Shell</span></strong></h2> 
  <p>Spark附带了几个示例程序。Scala，Java，Python和R示例都在&nbsp;<code>examples/src/main</code>目录中。要运行其中一个Java或Scala示例程序，请&nbsp;<code>bin/run-example &lt;class&gt; [params]</code>在顶级Spark目录中使用。（在幕后，这将调用用于启动应用程序的更通用的&nbsp;<a href="http://spark.apache.org/docs/latest/submitting-applications.html" rel="nofollow"><code>spark-submit</code>脚本</a>）。例如，</p> 
  <pre class="has">
<code>./bin/run-example SparkPi 10</code></pre> 
  <p>您还可以通过Scala shell的修改版本以交互方式运行Spark。这是学习框架的好方法。</p> 
  <pre class="has">
<code>./bin/spark-shell --master local[2]</code></pre> 
  <p>该<code>--master</code>选项指定<a href="http://spark.apache.org/docs/latest/submitting-applications.html#master-urls" rel="nofollow" data-token="7011e1ae3bbcd20064c7d1666d274779">分布式集群</a>的&nbsp;<a href="http://spark.apache.org/docs/latest/submitting-applications.html#master-urls" rel="nofollow" data-token="7011e1ae3bbcd20064c7d1666d274779">主URL</a>，或者<code>local</code>使用一个线程<code>local[N]</code>在本地运行，或者使用N个线程在本地运行。您应该从使用<code>local</code>测试开始&nbsp;。有关选项的完整列表，请使用该<code>--help</code>选项运行Spark shell&nbsp;。</p> 
  <p>Spark还提供了一个Python API。要在Python解释器中以交互方式运行Spark，请使用&nbsp;<code>bin/pyspark</code>：</p> 
  <pre class="has">
<code>./bin/pyspark --master local[2]</code></pre> 
  <p>Python中也提供了示例应用程序。例如，</p> 
  <pre class="has">
<code>./bin/spark-submit examples/src/main/python/pi.py 10</code></pre> 
  <p>Spark还提供了自1.4以来的实验性<a href="http://spark.apache.org/docs/latest/sparkr.html" rel="nofollow" data-token="00c5e268ec39e53ab3990bcb5dc17283">R API</a>（仅包括DataFrames API）。要在R解释器中以交互方式运行Spark，请使用<code>bin/sparkR</code>：</p> 
  <pre class="has">
<code>./bin/sparkR --master local[2]</code></pre> 
  <p>R中还提供了示例应用程序。例如，</p> 
  <pre class="has">
<code>./bin/spark-submit examples/src/main/r/dataframe.R</code></pre> 
  <p style="margin-left:0px;">&nbsp;</p> 
  <h2 id="launching-on-a-cluster" style="margin-left:0px;"><strong><span style="color:#1d1f22;">2.4.在群集上启动</span></strong></h2> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;">Spark&nbsp;<a href="http://spark.apache.org/docs/latest/cluster-overview.html" rel="nofollow" data-token="66e8c88fe4e7d9c04340f9d98bcf7282">群集模式概述</a>说明了在群集上运行的关键概念。Spark既可以自己运行，也可以通过几个现有的集群管理器运行。它目前提供了几种部署选项：</span></p> 
  <ul style="margin-left:25px;">
   <li><a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" data-token="f358e63288e912a060073df74ca5d5aa">独立部署模式</a>：在专用群集上部署Spark的最简单方法</li> 
   <li><a href="http://spark.apache.org/docs/latest/running-on-mesos.html" rel="nofollow" data-token="c7fff24f6892898cc44e59cc3e1f64ce">Apache Mesos</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/running-on-yarn.html" rel="nofollow" data-token="a8be8b1895b19426e9a86acc8527c36f">Hadoop YARN</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="nofollow" data-token="94853902a63b491f1b4698300381e45a">Kubernetes</a></li> 
  </ul>
  <p>&nbsp;</p> 
  <h2 id="2.5.%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3">2.5.相关文档</h2> 
  <p style="margin-left:0px;"><span style="color:#1d1f22;"><strong>编程指南：</strong></span></p> 
  <ul style="margin-left:25px;">
   <li><a href="http://spark.apache.org/docs/latest/quick-start.html" rel="nofollow" data-token="e303965bfa4f01f466dbc97441494326">快速入门</a>：Spark API的快速入门;&nbsp;从这里开始！</li> 
   <li><a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html" rel="nofollow" data-token="2cddf2135c552d275394de14ee6bc900">RDD编程指南</a>：Spark基础知识概述 - RDD（核心但旧API），累加器和广播变量</li> 
   <li><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" rel="nofollow" data-token="f8a692808a2e46ef069b4c3df4ad3872">Spark SQL，Datasets和DataFrames</a>：使用关系查询处理结构化数据（比RDD更新的API）</li> 
   <li><a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="nofollow" data-token="6a08a76c1860bddae8d054b4ff667020">结构化流</a>：使用关系查询处理结构化数据流（使用数据集和数据框架，比DStreams更新的API）</li> 
   <li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="nofollow" data-token="347712cbf6cc3f81943029181db37a2d">Spark Streaming</a>：使用DStreams处理数据流（旧API）</li> 
   <li><a href="http://spark.apache.org/docs/latest/ml-guide.html" rel="nofollow" data-token="d2382fb954e1ca5ff9f6fc734fa5b5e0">MLlib</a>：应用机器学习算法</li> 
   <li><a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" rel="nofollow" data-token="5d0eb0c8a370fd6630e6858b4de648f4">GraphX</a>：处理图表</li> 
  </ul>
  <p style="margin-left:0px;"><span style="color:#1d1f22;"><strong>API文档：</strong></span></p> 
  <ul style="margin-left:25px;">
   <li><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package" rel="nofollow" data-token="127b564dde99d9ae676b6a7978c209b8">Spark Scala API（Scaladoc）</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/api/java/index.html" rel="nofollow" data-token="d8b71d68d66631d9b7b07ce14d53716a">Spark Java API（Javadoc）</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/api/python/index.html" rel="nofollow" data-token="1a1f54f6cf8470df60c5171a8831a186">Spark Python API（Sphinx）</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/api/R/index.html" rel="nofollow" data-token="79486f9750f817c97dfaf76fbc204478">Spark R API（Roxygen2）</a></li> 
   <li><a href="http://spark.apache.org/docs/latest/api/sql/index.html" rel="nofollow" data-token="a05f7f496921f15353261ac7ad1a1be9">Spark SQL，内置函数（MkDocs）</a></li> 
  </ul>
  <p style="margin-left:0px;"><span style="color:#1d1f22;"><strong>部署指南：</strong></span></p> 
  <ul style="margin-left:25px;">
   <li><a href="http://spark.apache.org/docs/latest/cluster-overview.html" rel="nofollow" data-token="66e8c88fe4e7d9c04340f9d98bcf7282">群集概述</a>：在群集上运行时概念和组件的概述</li> 
   <li><a href="http://spark.apache.org/docs/latest/submitting-applications.html" rel="nofollow" data-token="655fb7b314e7626178da0b36e0c2bb14">提交应用程序</a>：打包和部署应用程序</li> 
   <li>部署模式： 
    <ul style="margin-left:25px;">
     <li><a href="https://github.com/amplab/spark-ec2" rel="nofollow" data-token="688b833433c3ef7a2a95f0b97faba2c5">Amazon EC2</a>：允许您在大约5分钟内在EC2上启动集群的脚本</li> 
     <li><a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" data-token="f358e63288e912a060073df74ca5d5aa">独立部署模式</a>：无需第三方集群管理器即可快速启动独立集群</li> 
     <li><a href="http://spark.apache.org/docs/latest/running-on-mesos.html" rel="nofollow" data-token="c7fff24f6892898cc44e59cc3e1f64ce">Mesos</a>：使用<a href="https://mesos.apache.org/" rel="nofollow" data-token="3288f0616f8d3a6e0ef05c5849111846">Apache Mesos</a>部署私有集群</li> 
     <li><a href="http://spark.apache.org/docs/latest/running-on-yarn.html" rel="nofollow" data-token="a8be8b1895b19426e9a86acc8527c36f">YARN</a>：在Hadoop NextGen（YARN）之上部署Spark</li> 
     <li><a href="http://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="nofollow" data-token="94853902a63b491f1b4698300381e45a">Kubernetes</a>：在<a href="http://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="nofollow" data-token="94853902a63b491f1b4698300381e45a">Kubernetes上</a>部署Spark</li> 
    </ul></li> 
  </ul>
  <p style="margin-left:0px;"><span style="color:#1d1f22;"><strong>其他文件：</strong></span></p> 
  <ul style="margin-left:25px;">
   <li><a href="http://spark.apache.org/docs/latest/configuration.html" rel="nofollow" data-token="1f5b5bdbc4868dbf1698175b897c4d06">配置</a>：通过其配置系统自定义Spark</li> 
   <li><a href="http://spark.apache.org/docs/latest/monitoring.html" rel="nofollow" data-token="0e438e8805a4911144517b130ce98280">监控</a>：跟踪应用程序的行为</li> 
   <li><a href="http://spark.apache.org/docs/latest/tuning.html" rel="nofollow" data-token="670d856443943ac142717b37eeae6b06">调优指南</a>：优化性能和内存使用的最佳实践</li> 
   <li><a href="http://spark.apache.org/docs/latest/job-scheduling.html" rel="nofollow" data-token="07f799b327ed2842dac3dcc414723db9">作业调度</a>：在Spark应用程序内部和内部调度资源</li> 
   <li><a href="http://spark.apache.org/docs/latest/security.html" rel="nofollow" data-token="93e09312b04ab0b0e2cca648fa647030">安全性</a>：Spark安全支持</li> 
   <li><a href="http://spark.apache.org/docs/latest/hardware-provisioning.html" rel="nofollow" data-token="21d5fb886c9b60003d012cc445069532">硬件配置</a>：群集硬件的建议</li> 
   <li>与其他存储系统集成： 
    <ul style="margin-left:25px;">
     <li><a href="http://spark.apache.org/docs/latest/cloud-integration.html" rel="nofollow" data-token="37b6e18d792c24d9b13b43cbc5938fca">云基础架构</a></li> 
     <li><a href="http://spark.apache.org/docs/latest/storage-openstack-swift.html" rel="nofollow" data-token="6a9c8bc12558aa9e82eaa7995331a360">OpenStack Swift</a></li> 
    </ul></li> 
   <li><a href="http://spark.apache.org/docs/latest/building-spark.html" rel="nofollow" data-token="af5b9ad24eb277ba223c6054d7570263">构建Spark</a>：使用Maven系统构建Spark</li> 
   <li><a href="https://spark.apache.org/contributing.html" rel="nofollow" data-token="6b54240c18b2e0de830328dfce6f16bf">为Spark做贡献</a></li> 
   <li><a href="https://spark.apache.org/third-party-projects.html" rel="nofollow" data-token="f6597e82a89a411e94a7f11880426bf1">第三方项目</a>：相关的第三方Spark项目</li> 
  </ul>
  <p style="margin-left:0px;"><span style="color:#1d1f22;"><strong>外部资源：</strong></span></p> 
  <ul style="margin-left:25px;">
   <li><a href="https://spark.apache.org/" rel="nofollow" data-token="8972f6335076cf84089203e50ac9d39b">Spark主页</a></li> 
   <li><a href="https://spark.apache.org/community.html" rel="nofollow" data-token="dbdb14486bdf7980d73394322c16ccb5">Spark社区</a>资源，包括本地聚会</li> 
   <li><a href="http://stackoverflow.com/questions/tagged/apache-spark" rel="nofollow" data-token="a583bb9714d3b1e68c7665465282df62">StackOverflow标签&nbsp;<code>apache-spark</code></a></li> 
   <li><a href="https://spark.apache.org/mailing-lists.html" rel="nofollow" data-token="6538357e7b8f0fa76723759d663f9675">邮件列表</a>：在这里询问有关Spark的问题</li> 
   <li><a href="http://ampcamp.berkeley.edu/" rel="nofollow" data-token="0f0e02e5d7d0751398143045763beae6">AMP Camps</a>：加州大学伯克利分校的一系列训练营，包括有关Spark，Spark Streaming，Mesos等的演讲和练习。<a href="http://ampcamp.berkeley.edu/6/" rel="nofollow" data-token="fa7e885b73f05a6c8c43dec0725b707d">视频</a>，&nbsp;<a href="http://ampcamp.berkeley.edu/6/" rel="nofollow" data-token="fa7e885b73f05a6c8c43dec0725b707d">幻灯片</a>和<a href="http://ampcamp.berkeley.edu/6/exercises/" rel="nofollow" data-token="591e9ab84e95dfb1b1752614b5844134">练习</a>可在线免费获取。</li> 
   <li><a href="https://spark.apache.org/examples.html" rel="nofollow" data-token="ec551d5d672dd3a1a54edf76c000b9eb">代码示例</a>：<code>examples</code>Spark（<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples" rel="nofollow" data-token="357ac0f689f2e46f13396173ee0adccf">Scala</a>，&nbsp;<a href="https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples" rel="nofollow" data-token="2ce9ef9540b6e92f0b7df9edcf4675db">Java</a>，&nbsp;<a href="https://github.com/apache/spark/tree/master/examples/src/main/python" rel="nofollow" data-token="98d6455fc4a4d19d1190c02b5a2dbcc3">Python</a>，&nbsp;<a href="https://github.com/apache/spark/tree/master/examples/src/main/r" rel="nofollow">R</a>）的子文件夹中也提供了更多内容</li> 
  </ul> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
