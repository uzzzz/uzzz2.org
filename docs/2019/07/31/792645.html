<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>《Hive实战》梳理 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="《Hive实战》梳理" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ASF是一个支持多种软件开发项目的组织 Hive不是数据库，而是一个友好且为我们熟悉的接口，可以查询存储在HDFS上的底层数据文件 SerDe：序列化、反序列化 HCatlog促进了各种Hadoop组件之间实现模式共享，HCatlog的作用包括： 为多种工具提供一种通用模式环境 允许各种工具通过连接器连接，进而从Hive仓库读取数据和向其写入数据 使用户可以跨工具共享数据 为Hadoop中的数据创建一种关系结构 抽象出数据存储的方式和位置 使模式和存储的更改对用户不可见 HCatlog本质上是数据访问工具与底层文件之间的抽象层 HiveServer1的限制：用户并发性、LDAP安全性集成HiveServer2 架构基于一个ThriftService和任意数量由驱动程序、编译器和执行器组成的会话。MetaStore也是HiveServer2的一个重要组成部分 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 支持Kerberos、自定义身份验证以及通过LDAP身份验证 HiveServer2在Hive1.1引入（HIVE-2935),提供更好的并发性、安全性、远程访问 Tez： &nbsp;&nbsp; &nbsp;避免了代价高昂的混洗过程，因此避免了磁盘IO。在Tez执行引擎的执行计划中，约简器的中间数据将直接传递给下一个简约器 &nbsp;&nbsp; &nbsp;采用了高效的Map端连接 &nbsp;&nbsp; &nbsp;采用了基于代价的优化器，有助于生成更快的执行计划 &nbsp;&nbsp; &nbsp;Tez与ORC文件格式联合使用，查询引擎的执行速度比本机MR快100倍 Tez相关配置： hive.prewarm.enabled &nbsp;= true &nbsp; &nbsp; //Hive创建Tez容器 hive.prewarm.numcontainers &nbsp; &nbsp; //调整Tez专用容器的数量 表的属性（TBLPROPERTIES）： &nbsp;&nbsp; &nbsp;last_modified_user： &nbsp;&nbsp; &nbsp;last_modified_time: &nbsp;&nbsp; &nbsp;immutable:为true时，无法在插入新行 &nbsp;&nbsp; &nbsp;orc.compress: &nbsp;&nbsp; &nbsp;skip.header.line.count:调过底层数据的标题行 用show create table 生成创建表语句 分区最佳实践： 挑选一列作为分区键，其唯一值的个数应在较低值到中间值之间 避免分区小于1GB（越大越好） 当分区数量较多时，调整HiveServer2 和 Hive MetaStore的内存 当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树 当使用Hive流处理插入数据时，如果多个会话向相同分区插入数据，那么会导致锁闭 一旦分区表的模式发生改变，将无法在已有分区上修改数据 如果要将数据并行插入到多个分区，应该将hive.optimize.sort.dynamic.partition设置为true 对于日期列进行高效分区： select * from table A where datestamp in (&#39;2015-01-01&#39;,&#39;2015-02-03&#39;,&#39;2016-01-01&#39;); select * from table A where datestamp like &#39;2015-%&#39;; select * from table A where datestamp like &#39;2015-02-%&#39;; select * from table A where datestamp like &#39;%-%-%5&#39;; select * from table A where datestamp between &#39;2015-01-01&#39; AND &#39;2015-03-01&#39; schema - on - read 添加分区： alter table add partition; alter table xxx partition(xx) rename to partition(yy);&nbsp; 分桶： Hive中的分桶是另一种将数据切分为更小片段的方式 分区键时表中的一个虚拟列，然而在分桶中，每个桶都是一个保存实际数据的文件，这些数据基于一种散列算法进行分割，分桶并不会为当前表添加一个虚拟列 create table xx(xxxxxx) clusted by (xxx) into xx buckets location &#39;xxx&#39; 分桶的最佳实践： 选择唯一值的个数较多的桶键。这样会减小出现倾斜的可能性 采用质数作为桶的编号 如果桶键中的数据是倾斜的，为倾斜的值单独创建桶。可以通过列表分桶来实现 需要连接在一起的表，桶的数目必须相同，或者一个表的桶数是另一个表的桶数的因子 一个CPU只会对一个桶进行写入操作，如果桶的数目很小，集群的利用严重不足 一旦表创建好，桶的数目就不能改变了 桶文件大小至少是1GB 通过设置hive.enforce.bucketing = true 实现强制分桶 对于map端连接，分桶表要比非分桶表的速度更快 ORC：（Parquet不如ORC） ORC文件格式用于减少要从磁盘读取的数据量(基于列)，可以被分割的文件格式，可以分割成多个可并行处理的块。每个数据块被进一步细分为256MB的数据带，这些数据带则用于将列数据存储在一起 create table xxx stored as orc tblproperties(&quot;orc.compress&quot;=&quot;snappy&quot;) as select * from xxx ORC格式相关的配置： orc.compress orc.compress.size orc.stripe.size&nbsp;&nbsp; &nbsp; &nbsp;//每个带的字节数 orc.row.index.stride &nbsp;//索引记录之间的行数 orc.create.index &nbsp; &nbsp; &nbsp;//是否要创建行索引 CBO:&nbsp;&nbsp; &nbsp; Hive的more查询执行引擎一次处理一行，因此在嵌套循环中需要有多层虚拟方法调用，从CPU的视角来看是非常低效的。 矢量化查询执行是一种Hive特性，其目的是按照每批1024行读取数据，并且一次性对整个记录集合应用操作，进而消除那些效率低下的问题。必须使用ORC格式，CBO帮助生成一个最优执行计划，在该计划的执行过程中，从磁盘读取和处理的数据量已经尽可能早地减少，使工作更加高效 set hive.vectorized.execution.enabled = true; 合并表文件： 对于RCFile 或 ORCFile 格式存储的Hive表，可以做如下操作：alter table states concatenate 该命令会将多个数据问价合并成较大的文件 单次MapReduce实现连接： select xxx from table_A join table_B on (table_A.xxx = table_B.xxx) join table_C on (table_C.xxx = tableB.xxx) Apache NiFi： 适用于各种类型的数据装载和摄入场景，提供了对数据传输作业进行设计、控制、管理和监视的无缝体验 Hive对JSON数据的处理 1.使用UDF处理 create table json_table(json string); load data inpath &#39;xxxx&#39; into table json_table; select get_json_object(json_table.json,&#39;$&#39;) from json_table; 2.使用SerDe处理json create table json_serde_table(xxxxxx）row format serde &#39;org.openx.data.jsonserde.JsonSerDe&#39; with SERDEPROPERTIES(&quot;mapping._id&quot; = &quot;id&quot;); load data inpath &#39;xxx&#39; into table json_serde_table; select * from json_serde_table; LLAP 对亚秒级查询需求快速的查询执行和降低整个生态系统内任务的设置成本" />
<meta property="og:description" content="ASF是一个支持多种软件开发项目的组织 Hive不是数据库，而是一个友好且为我们熟悉的接口，可以查询存储在HDFS上的底层数据文件 SerDe：序列化、反序列化 HCatlog促进了各种Hadoop组件之间实现模式共享，HCatlog的作用包括： 为多种工具提供一种通用模式环境 允许各种工具通过连接器连接，进而从Hive仓库读取数据和向其写入数据 使用户可以跨工具共享数据 为Hadoop中的数据创建一种关系结构 抽象出数据存储的方式和位置 使模式和存储的更改对用户不可见 HCatlog本质上是数据访问工具与底层文件之间的抽象层 HiveServer1的限制：用户并发性、LDAP安全性集成HiveServer2 架构基于一个ThriftService和任意数量由驱动程序、编译器和执行器组成的会话。MetaStore也是HiveServer2的一个重要组成部分 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 支持Kerberos、自定义身份验证以及通过LDAP身份验证 HiveServer2在Hive1.1引入（HIVE-2935),提供更好的并发性、安全性、远程访问 Tez： &nbsp;&nbsp; &nbsp;避免了代价高昂的混洗过程，因此避免了磁盘IO。在Tez执行引擎的执行计划中，约简器的中间数据将直接传递给下一个简约器 &nbsp;&nbsp; &nbsp;采用了高效的Map端连接 &nbsp;&nbsp; &nbsp;采用了基于代价的优化器，有助于生成更快的执行计划 &nbsp;&nbsp; &nbsp;Tez与ORC文件格式联合使用，查询引擎的执行速度比本机MR快100倍 Tez相关配置： hive.prewarm.enabled &nbsp;= true &nbsp; &nbsp; //Hive创建Tez容器 hive.prewarm.numcontainers &nbsp; &nbsp; //调整Tez专用容器的数量 表的属性（TBLPROPERTIES）： &nbsp;&nbsp; &nbsp;last_modified_user： &nbsp;&nbsp; &nbsp;last_modified_time: &nbsp;&nbsp; &nbsp;immutable:为true时，无法在插入新行 &nbsp;&nbsp; &nbsp;orc.compress: &nbsp;&nbsp; &nbsp;skip.header.line.count:调过底层数据的标题行 用show create table 生成创建表语句 分区最佳实践： 挑选一列作为分区键，其唯一值的个数应在较低值到中间值之间 避免分区小于1GB（越大越好） 当分区数量较多时，调整HiveServer2 和 Hive MetaStore的内存 当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树 当使用Hive流处理插入数据时，如果多个会话向相同分区插入数据，那么会导致锁闭 一旦分区表的模式发生改变，将无法在已有分区上修改数据 如果要将数据并行插入到多个分区，应该将hive.optimize.sort.dynamic.partition设置为true 对于日期列进行高效分区： select * from table A where datestamp in (&#39;2015-01-01&#39;,&#39;2015-02-03&#39;,&#39;2016-01-01&#39;); select * from table A where datestamp like &#39;2015-%&#39;; select * from table A where datestamp like &#39;2015-02-%&#39;; select * from table A where datestamp like &#39;%-%-%5&#39;; select * from table A where datestamp between &#39;2015-01-01&#39; AND &#39;2015-03-01&#39; schema - on - read 添加分区： alter table add partition; alter table xxx partition(xx) rename to partition(yy);&nbsp; 分桶： Hive中的分桶是另一种将数据切分为更小片段的方式 分区键时表中的一个虚拟列，然而在分桶中，每个桶都是一个保存实际数据的文件，这些数据基于一种散列算法进行分割，分桶并不会为当前表添加一个虚拟列 create table xx(xxxxxx) clusted by (xxx) into xx buckets location &#39;xxx&#39; 分桶的最佳实践： 选择唯一值的个数较多的桶键。这样会减小出现倾斜的可能性 采用质数作为桶的编号 如果桶键中的数据是倾斜的，为倾斜的值单独创建桶。可以通过列表分桶来实现 需要连接在一起的表，桶的数目必须相同，或者一个表的桶数是另一个表的桶数的因子 一个CPU只会对一个桶进行写入操作，如果桶的数目很小，集群的利用严重不足 一旦表创建好，桶的数目就不能改变了 桶文件大小至少是1GB 通过设置hive.enforce.bucketing = true 实现强制分桶 对于map端连接，分桶表要比非分桶表的速度更快 ORC：（Parquet不如ORC） ORC文件格式用于减少要从磁盘读取的数据量(基于列)，可以被分割的文件格式，可以分割成多个可并行处理的块。每个数据块被进一步细分为256MB的数据带，这些数据带则用于将列数据存储在一起 create table xxx stored as orc tblproperties(&quot;orc.compress&quot;=&quot;snappy&quot;) as select * from xxx ORC格式相关的配置： orc.compress orc.compress.size orc.stripe.size&nbsp;&nbsp; &nbsp; &nbsp;//每个带的字节数 orc.row.index.stride &nbsp;//索引记录之间的行数 orc.create.index &nbsp; &nbsp; &nbsp;//是否要创建行索引 CBO:&nbsp;&nbsp; &nbsp; Hive的more查询执行引擎一次处理一行，因此在嵌套循环中需要有多层虚拟方法调用，从CPU的视角来看是非常低效的。 矢量化查询执行是一种Hive特性，其目的是按照每批1024行读取数据，并且一次性对整个记录集合应用操作，进而消除那些效率低下的问题。必须使用ORC格式，CBO帮助生成一个最优执行计划，在该计划的执行过程中，从磁盘读取和处理的数据量已经尽可能早地减少，使工作更加高效 set hive.vectorized.execution.enabled = true; 合并表文件： 对于RCFile 或 ORCFile 格式存储的Hive表，可以做如下操作：alter table states concatenate 该命令会将多个数据问价合并成较大的文件 单次MapReduce实现连接： select xxx from table_A join table_B on (table_A.xxx = table_B.xxx) join table_C on (table_C.xxx = tableB.xxx) Apache NiFi： 适用于各种类型的数据装载和摄入场景，提供了对数据传输作业进行设计、控制、管理和监视的无缝体验 Hive对JSON数据的处理 1.使用UDF处理 create table json_table(json string); load data inpath &#39;xxxx&#39; into table json_table; select get_json_object(json_table.json,&#39;$&#39;) from json_table; 2.使用SerDe处理json create table json_serde_table(xxxxxx）row format serde &#39;org.openx.data.jsonserde.JsonSerDe&#39; with SERDEPROPERTIES(&quot;mapping._id&quot; = &quot;id&quot;); load data inpath &#39;xxx&#39; into table json_serde_table; select * from json_serde_table; LLAP 对亚秒级查询需求快速的查询执行和降低整个生态系统内任务的设置成本" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792645.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792645.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"ASF是一个支持多种软件开发项目的组织 Hive不是数据库，而是一个友好且为我们熟悉的接口，可以查询存储在HDFS上的底层数据文件 SerDe：序列化、反序列化 HCatlog促进了各种Hadoop组件之间实现模式共享，HCatlog的作用包括： 为多种工具提供一种通用模式环境 允许各种工具通过连接器连接，进而从Hive仓库读取数据和向其写入数据 使用户可以跨工具共享数据 为Hadoop中的数据创建一种关系结构 抽象出数据存储的方式和位置 使模式和存储的更改对用户不可见 HCatlog本质上是数据访问工具与底层文件之间的抽象层 HiveServer1的限制：用户并发性、LDAP安全性集成HiveServer2 架构基于一个ThriftService和任意数量由驱动程序、编译器和执行器组成的会话。MetaStore也是HiveServer2的一个重要组成部分 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 支持Kerberos、自定义身份验证以及通过LDAP身份验证 HiveServer2在Hive1.1引入（HIVE-2935),提供更好的并发性、安全性、远程访问 Tez： &nbsp;&nbsp; &nbsp;避免了代价高昂的混洗过程，因此避免了磁盘IO。在Tez执行引擎的执行计划中，约简器的中间数据将直接传递给下一个简约器 &nbsp;&nbsp; &nbsp;采用了高效的Map端连接 &nbsp;&nbsp; &nbsp;采用了基于代价的优化器，有助于生成更快的执行计划 &nbsp;&nbsp; &nbsp;Tez与ORC文件格式联合使用，查询引擎的执行速度比本机MR快100倍 Tez相关配置： hive.prewarm.enabled &nbsp;= true &nbsp; &nbsp; //Hive创建Tez容器 hive.prewarm.numcontainers &nbsp; &nbsp; //调整Tez专用容器的数量 表的属性（TBLPROPERTIES）： &nbsp;&nbsp; &nbsp;last_modified_user： &nbsp;&nbsp; &nbsp;last_modified_time: &nbsp;&nbsp; &nbsp;immutable:为true时，无法在插入新行 &nbsp;&nbsp; &nbsp;orc.compress: &nbsp;&nbsp; &nbsp;skip.header.line.count:调过底层数据的标题行 用show create table 生成创建表语句 分区最佳实践： 挑选一列作为分区键，其唯一值的个数应在较低值到中间值之间 避免分区小于1GB（越大越好） 当分区数量较多时，调整HiveServer2 和 Hive MetaStore的内存 当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树 当使用Hive流处理插入数据时，如果多个会话向相同分区插入数据，那么会导致锁闭 一旦分区表的模式发生改变，将无法在已有分区上修改数据 如果要将数据并行插入到多个分区，应该将hive.optimize.sort.dynamic.partition设置为true 对于日期列进行高效分区： select * from table A where datestamp in (&#39;2015-01-01&#39;,&#39;2015-02-03&#39;,&#39;2016-01-01&#39;); select * from table A where datestamp like &#39;2015-%&#39;; select * from table A where datestamp like &#39;2015-02-%&#39;; select * from table A where datestamp like &#39;%-%-%5&#39;; select * from table A where datestamp between &#39;2015-01-01&#39; AND &#39;2015-03-01&#39; schema - on - read 添加分区： alter table add partition; alter table xxx partition(xx) rename to partition(yy);&nbsp; 分桶： Hive中的分桶是另一种将数据切分为更小片段的方式 分区键时表中的一个虚拟列，然而在分桶中，每个桶都是一个保存实际数据的文件，这些数据基于一种散列算法进行分割，分桶并不会为当前表添加一个虚拟列 create table xx(xxxxxx) clusted by (xxx) into xx buckets location &#39;xxx&#39; 分桶的最佳实践： 选择唯一值的个数较多的桶键。这样会减小出现倾斜的可能性 采用质数作为桶的编号 如果桶键中的数据是倾斜的，为倾斜的值单独创建桶。可以通过列表分桶来实现 需要连接在一起的表，桶的数目必须相同，或者一个表的桶数是另一个表的桶数的因子 一个CPU只会对一个桶进行写入操作，如果桶的数目很小，集群的利用严重不足 一旦表创建好，桶的数目就不能改变了 桶文件大小至少是1GB 通过设置hive.enforce.bucketing = true 实现强制分桶 对于map端连接，分桶表要比非分桶表的速度更快 ORC：（Parquet不如ORC） ORC文件格式用于减少要从磁盘读取的数据量(基于列)，可以被分割的文件格式，可以分割成多个可并行处理的块。每个数据块被进一步细分为256MB的数据带，这些数据带则用于将列数据存储在一起 create table xxx stored as orc tblproperties(&quot;orc.compress&quot;=&quot;snappy&quot;) as select * from xxx ORC格式相关的配置： orc.compress orc.compress.size orc.stripe.size&nbsp;&nbsp; &nbsp; &nbsp;//每个带的字节数 orc.row.index.stride &nbsp;//索引记录之间的行数 orc.create.index &nbsp; &nbsp; &nbsp;//是否要创建行索引 CBO:&nbsp;&nbsp; &nbsp; Hive的more查询执行引擎一次处理一行，因此在嵌套循环中需要有多层虚拟方法调用，从CPU的视角来看是非常低效的。 矢量化查询执行是一种Hive特性，其目的是按照每批1024行读取数据，并且一次性对整个记录集合应用操作，进而消除那些效率低下的问题。必须使用ORC格式，CBO帮助生成一个最优执行计划，在该计划的执行过程中，从磁盘读取和处理的数据量已经尽可能早地减少，使工作更加高效 set hive.vectorized.execution.enabled = true; 合并表文件： 对于RCFile 或 ORCFile 格式存储的Hive表，可以做如下操作：alter table states concatenate 该命令会将多个数据问价合并成较大的文件 单次MapReduce实现连接： select xxx from table_A join table_B on (table_A.xxx = table_B.xxx) join table_C on (table_C.xxx = tableB.xxx) Apache NiFi： 适用于各种类型的数据装载和摄入场景，提供了对数据传输作业进行设计、控制、管理和监视的无缝体验 Hive对JSON数据的处理 1.使用UDF处理 create table json_table(json string); load data inpath &#39;xxxx&#39; into table json_table; select get_json_object(json_table.json,&#39;$&#39;) from json_table; 2.使用SerDe处理json create table json_serde_table(xxxxxx）row format serde &#39;org.openx.data.jsonserde.JsonSerDe&#39; with SERDEPROPERTIES(&quot;mapping._id&quot; = &quot;id&quot;); load data inpath &#39;xxx&#39; into table json_serde_table; select * from json_serde_table; LLAP 对亚秒级查询需求快速的查询执行和降低整个生态系统内任务的设置成本","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792645.html","headline":"《Hive实战》梳理","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792645.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>《Hive实战》梳理</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>ASF是一个支持多种软件开发项目的组织</p> 
  <p>Hive不是数据库，而是一个友好且为我们熟悉的接口，可以查询存储在HDFS上的底层数据文件</p> 
  <p><strong>SerDe：</strong>序列化、反序列化</p> 
  <p><strong>HCatlog促进了各种Hadoop组件之间实现模式共享，HCatlog的作用包括：</strong></p> 
  <ul>
   <li>为多种工具提供一种通用模式环境</li> 
   <li>允许各种工具通过连接器连接，进而从Hive仓库读取数据和向其写入数据</li> 
   <li>使用户可以跨工具共享数据</li> 
   <li>为Hadoop中的数据创建一种关系结构</li> 
   <li>抽象出数据存储的方式和位置</li> 
   <li>使模式和存储的更改对用户不可见</li> 
  </ul>
  <p>HCatlog本质上是数据访问工具与底层文件之间的抽象层</p> 
  <p><strong>HiveServer1的限制：</strong>用户并发性、LDAP安全性集成<br><strong>HiveServer2</strong> 架构基于一个ThriftService和任意数量由驱动程序、编译器和执行器组成的会话。MetaStore也是HiveServer2的一个重要组成部分<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 支持Kerberos、自定义身份验证以及通过LDAP身份验证</p> 
  <p>HiveServer2在Hive1.1引入（HIVE-2935),提供更好的并发性、安全性、远程访问</p> 
  <p><br><strong>Tez：</strong></p> 
  <ul>
   <li>&nbsp;&nbsp; &nbsp;避免了代价高昂的混洗过程，因此避免了磁盘IO。在Tez执行引擎的执行计划中，约简器的中间数据将直接传递给下一个简约器</li> 
   <li>&nbsp;&nbsp; &nbsp;采用了高效的Map端连接</li> 
   <li>&nbsp;&nbsp; &nbsp;采用了基于代价的优化器，有助于生成更快的执行计划</li> 
   <li>&nbsp;&nbsp; &nbsp;Tez与ORC文件格式联合使用，查询引擎的执行速度比本机MR快100倍</li> 
  </ul>
  <p><strong>Tez相关配置：</strong></p> 
  <blockquote> 
   <p>hive.prewarm.enabled &nbsp;= true &nbsp; &nbsp; //Hive创建Tez容器<br> hive.prewarm.numcontainers &nbsp; &nbsp; //调整Tez专用容器的数量</p> 
  </blockquote> 
  <p><br><strong>表的属性（TBLPROPERTIES）：</strong></p> 
  <ul>
   <li>&nbsp;&nbsp; &nbsp;last_modified_user：</li> 
   <li>&nbsp;&nbsp; &nbsp;last_modified_time:</li> 
   <li>&nbsp;&nbsp; &nbsp;immutable:为true时，无法在插入新行</li> 
   <li>&nbsp;&nbsp; &nbsp;orc.compress:</li> 
   <li>&nbsp;&nbsp; &nbsp;skip.header.line.count:调过底层数据的标题行</li> 
  </ul>
  <p>用show create table 生成创建表语句</p> 
  <p><br><strong>分区最佳实践：</strong></p> 
  <ul>
   <li>挑选一列作为分区键，其唯一值的个数应在较低值到中间值之间</li> 
   <li>避免分区小于1GB（越大越好）</li> 
   <li>当分区数量较多时，调整HiveServer2 和 Hive MetaStore的内存</li> 
   <li>当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树</li> 
   <li>当使用Hive流处理插入数据时，如果多个会话向相同分区插入数据，那么会导致锁闭</li> 
   <li>一旦分区表的模式发生改变，将无法在已有分区上修改数据</li> 
   <li>如果要将数据并行插入到多个分区，应该将hive.optimize.sort.dynamic.partition设置为true</li> 
  </ul>
  <p><br><strong>对于日期列进行高效分区：</strong></p> 
  <blockquote> 
   <p>select * from table A where datestamp in ('2015-01-01','2015-02-03','2016-01-01');<br> select * from table A where datestamp like '2015-%';<br> select * from table A where datestamp like '2015-02-%';<br> select * from table A where datestamp like '%-%-%5';<br> select * from table A where datestamp between '2015-01-01' AND '2015-03-01'</p> 
  </blockquote> 
  <p><strong>schema - on - read</strong></p> 
  <p><strong>添加分区：</strong></p> 
  <blockquote> 
   <p>alter table add partition;<br> alter table xxx partition(xx) rename to partition(yy);&nbsp;</p> 
  </blockquote> 
  <p><br><strong>分桶：</strong></p> 
  <ul>
   <li>Hive中的分桶是另一种将数据切分为更小片段的方式</li> 
   <li>分区键时表中的一个虚拟列，然而在分桶中，每个桶都是一个保存实际数据的文件，这些数据基于一种散列算法进行分割，分桶并不会为当前表添加一个虚拟列</li> 
  </ul>
  <blockquote> 
   <p>create table xx(xxxxxx) clusted by (xxx) into xx buckets location 'xxx'</p> 
  </blockquote> 
  <p><strong>分桶的最佳实践：</strong></p> 
  <ul>
   <li>选择唯一值的个数较多的桶键。这样会减小出现倾斜的可能性</li> 
   <li>采用质数作为桶的编号</li> 
   <li>如果桶键中的数据是倾斜的，为倾斜的值单独创建桶。可以通过列表分桶来实现</li> 
   <li>需要连接在一起的表，桶的数目必须相同，或者一个表的桶数是另一个表的桶数的因子</li> 
   <li>一个CPU只会对一个桶进行写入操作，如果桶的数目很小，集群的利用严重不足</li> 
   <li>一旦表创建好，桶的数目就不能改变了</li> 
   <li>桶文件大小至少是1GB</li> 
   <li>通过设置hive.enforce.bucketing = true 实现强制分桶</li> 
   <li>对于map端连接，分桶表要比非分桶表的速度更快</li> 
  </ul>
  <p><strong>ORC：</strong>（Parquet不如ORC）<br> ORC文件格式用于减少要从磁盘读取的数据量(基于列)，可以被分割的文件格式，可以分割成多个可并行处理的块。每个数据块被进一步细分为256MB的数据带，这些数据带则用于将列数据存储在一起</p> 
  <blockquote> 
   <p>create table xxx stored as orc tblproperties("orc.compress"="snappy") as select * from xxx</p> 
  </blockquote> 
  <p><strong>ORC格式相关的配置：</strong></p> 
  <blockquote> 
   <p>orc.compress<br> orc.compress.size<br> orc.stripe.size&nbsp;&nbsp; &nbsp; &nbsp;//每个带的字节数<br> orc.row.index.stride &nbsp;//索引记录之间的行数<br> orc.create.index &nbsp; &nbsp; &nbsp;//是否要创建行索引</p> 
  </blockquote> 
  <p><strong>CBO:&nbsp;&nbsp; &nbsp;</strong><br> Hive的more查询执行引擎一次处理一行，因此在嵌套循环中需要有多层虚拟方法调用，从CPU的视角来看是非常低效的。</p> 
  <p>矢量化查询执行是一种Hive特性，其目的是按照每批1024行读取数据，并且一次性对整个记录集合应用操作，进而消除那些效率低下的问题。必须使用ORC格式，CBO帮助生成一个最优执行计划，在该计划的执行过程中，从磁盘读取和处理的数据量已经尽可能早地减少，使工作更加高效</p> 
  <blockquote> 
   <p>set hive.vectorized.execution.enabled = true;</p> 
  </blockquote> 
  <p><strong>合并表文件：</strong><br> 对于RCFile 或 ORCFile 格式存储的Hive表，可以做如下操作：alter table states concatenate</p> 
  <p>该命令会将多个数据问价合并成较大的文件</p> 
  <p><strong>单次MapReduce实现连接：</strong></p> 
  <blockquote> 
   <p>select xxx from table_A join table_B<br> on (table_A.xxx = table_B.xxx)<br> join table_C<br> on (table_C.xxx = tableB.xxx)</p> 
  </blockquote> 
  <p><br><strong>Apache NiFi：</strong><br> 适用于各种类型的数据装载和摄入场景，提供了对数据传输作业进行设计、控制、管理和监视的无缝体验</p> 
  <p><br><strong>Hive对JSON数据的处理</strong><br> 1.使用UDF处理</p> 
  <blockquote> 
   <p>create table json_table(json string);<br> load data inpath 'xxxx' into table json_table;<br> select get_json_object(json_table.json,'$') from json_table;</p> 
  </blockquote> 
  <p>2.使用SerDe处理json</p> 
  <blockquote> 
   <p>create table json_serde_table(xxxxxx）row format serde 'org.openx.data.jsonserde.JsonSerDe' with SERDEPROPERTIES("mapping._id" = "id");<br> load data inpath 'xxx' into table json_serde_table;<br> select * from json_serde_table;</p> 
  </blockquote> 
  <p><strong>LLAP</strong><br> 对亚秒级查询需求快速的查询执行和降低整个生态系统内任务的设置成本</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
