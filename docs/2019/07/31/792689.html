<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>02.spark-core入门（算子和Spark任务执行流程） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="02.spark-core入门（算子和Spark任务执行流程）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="一、Spark Core概念讲解 Spark Core：内核，也是Spark中最重要的部分。 相当于Mapreduce SparkCore 和 Mapreduce都是进行离线数据分析 SparkCore的核心：RDD（弹性分布式数据集），由分区组成 二、RDD的五大特性 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;1、RDD是由一系列的partition组成的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partition一般有三种方式产生 &nbsp; &nbsp; （1）从Scala集合中创建，通过调用SparkContext#makeRDD或SparkContext#parallelize &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;是可以指定partition 个数的，若指定了具体值，那么partition的个数就等于该值 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于从 Scala集合中转换而来的RDD：默认的partition数为defaultParallelism，该值在不同的部署模式下不同： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Local 模式：本机 cpu cores 的数量 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mesos 模式：8 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Yarn：max(2, 所有 executors 的 cpu cores 个数总和) &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;对于从外部数据加载而来的 RDD：默认的 partition 数为 min(defaultParallelism, 2) &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于执行转换操作而得到的 RDD：视具体操作而定，如 map 得到的 RDD 的 partition 数与 父 RDD 相同; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;union 得到的 RDD的 partition 数为父 RDDs 的 partition 数之和... &nbsp; &nbsp;（2） 加载外部数据来创建 RDD，例如从 HDFS 文件、mysql 数据库读取数据等 &nbsp; &nbsp;（3）由其它 RDD 执行 transform 操作转换而来2、函数是作用在每一个partition（split）上的。 &nbsp; &nbsp; &nbsp; &nbsp; partition 是 RDD 的数据单位，代表了一个分区的数据。但这里千万不要搞错了，partition 是逻辑概念， &nbsp; &nbsp; &nbsp; &nbsp; 是代表了一个分片的数据，而不是包含或持有一个分片的数据。3、RDD之间有一些列的依赖关系。 &nbsp; &nbsp; &nbsp; &nbsp; 如下图，可以看到RDD1产生RDD2；RDD2产生RDD3，即RDD分裂时返回的仍是RDD集， &nbsp; &nbsp; &nbsp; &nbsp; 这样就形成了RDD间的层级依赖4、partitioner是作用在K,V格式的RDD上。 &nbsp; &nbsp; &nbsp; &nbsp; partitioner即分区器，即决定RDD的每一条消息应该分到哪个分区。 &nbsp; &nbsp; &nbsp; &nbsp; 但只有 k, v 类型的RDD才能有partitioner(当然，非 key，value类型的RDD的partitioner为None)。 5、RDD提供一系列最佳的计算位置 &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;spark提供了一种机制，在集群中运行任务时，会把task发送到集群中需要读取存储数据的节点来运行，不会将task随意发送到无关节点，这样减少数据节点间网络传输时间，做到计算移动、而数据不移动，实现了最佳计算位置。 RDD特性理解图： &nbsp; 三、 Spark任务执行流程 1、基于standalone-client模式 （1）spark集群启动，Worker节点向Master节点汇报各自资源，master掌握集群资源 （2）在client提交spark应用程序，此时会再client启动一个Driver进程 （3）Driver向Master请求资源，Master收到请求后，在集群中找到符合要求的节点启动Executor （4）Driver发送task到Worker,Worker上启动的Executor开始执行任务，完成后Driver负责并回收结果 2、基于standalone-cluster模式 standalone-cluster和standalone-client不同的是，client提交任务后，不会再启动Driver，而是Master在集群中找一台节点，即Worker上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 3、基于yarn-client模式 （1）Hadoop集群启动，NodeManager（NM）向ResourceManager（RM）通信，汇报各自资源，RM掌握集群资源 （2）client上提交spark应用，同时启动Driver，client向RM申请资源，启动ApplicationMaster(AM) （3）RM在随机选择集群中的一个NM，来启动AM，AM向RM申请资源启动Executor，RM分配资源给NM启动Executor （4）Executor通知Driver，Driver发送task给Executor，Executor执行完成，返回结果给Driver 4、基于yarn-cluster模式 yarn-cluste和yarn-client不同的是，client提交任务后，不会再启动Driver，而是RM在集群中找一台节点，即NM上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client上没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 术语解释 四、Spark代码流程 （1）创建SparkConf对象 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以设置Applicationname、可以设置运行模式及资源需求。 （2）创建SparkContext对象 （3）&nbsp;基于Spark的上下文创建一个RDD，对RDD进行处理 （4）应用程序中要有Action类算子来触发Transformation类算子执行。 （5）关闭Spark上下文对象SparkContext。 五、算子操作 1、Transformations转换算子 Transformations类算子是一类算子（函数）叫做转换算子，如map,flatMap,reduceByKey等。Transformations算子是延迟执行，也叫懒加载执行。 2、Action行动算子 Action类算子也是一类算子（函数）叫做行动算子，如foreach,collect，count等。Transformations类算子是延迟执行，Action类算子是触发执行。一个application应用程序中有几个Action类算子执行，就有几个job运行。 3、持久化算子 有时候会多次对同一个RDD进行计算，如果每次只是简单地调用行动算子，spark每次都会重新计算RDD及其所有依赖，这在迭代算法中消耗格外大。为了避免多次计算同一个RDD，spark引入了持久化 算子。 （1）cache 默认将RDD的数据持久化到内存中，cache是懒执行。看spark源码可以知道 chche () = persist()=persist(StorageLevel.Memory_Only)，相当于persist的StorageLevel.Memory_Only （2）persist 可以指定持久化的级别，最常用的是MEMORY_ONLY和MEMORY_AND_DISK，persist是懒执行 （3）checkpoint checkpoint将RDD持久化到磁盘，还可以切断RDD之间的依赖关系 执行流程：当RDD的job执行完毕后，会从finalRDD从后往前回溯。当回溯到某一个RDD调用了checkpoint方法，会对当前的RDD做一个标记。Spark框架会自动启动一个新的job，重新计算这个RDD的数据，将数据持久化到指定的存储位置上 优化：对RDD执行checkpoint之前，最好对这个RDD先执行cache，这样新启动的job只需要将内存中的数据拷贝到HDFS上就可以，省去了重新计算这一步 &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="一、Spark Core概念讲解 Spark Core：内核，也是Spark中最重要的部分。 相当于Mapreduce SparkCore 和 Mapreduce都是进行离线数据分析 SparkCore的核心：RDD（弹性分布式数据集），由分区组成 二、RDD的五大特性 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;1、RDD是由一系列的partition组成的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partition一般有三种方式产生 &nbsp; &nbsp; （1）从Scala集合中创建，通过调用SparkContext#makeRDD或SparkContext#parallelize &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;是可以指定partition 个数的，若指定了具体值，那么partition的个数就等于该值 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于从 Scala集合中转换而来的RDD：默认的partition数为defaultParallelism，该值在不同的部署模式下不同： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Local 模式：本机 cpu cores 的数量 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mesos 模式：8 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Yarn：max(2, 所有 executors 的 cpu cores 个数总和) &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;对于从外部数据加载而来的 RDD：默认的 partition 数为 min(defaultParallelism, 2) &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于执行转换操作而得到的 RDD：视具体操作而定，如 map 得到的 RDD 的 partition 数与 父 RDD 相同; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;union 得到的 RDD的 partition 数为父 RDDs 的 partition 数之和... &nbsp; &nbsp;（2） 加载外部数据来创建 RDD，例如从 HDFS 文件、mysql 数据库读取数据等 &nbsp; &nbsp;（3）由其它 RDD 执行 transform 操作转换而来2、函数是作用在每一个partition（split）上的。 &nbsp; &nbsp; &nbsp; &nbsp; partition 是 RDD 的数据单位，代表了一个分区的数据。但这里千万不要搞错了，partition 是逻辑概念， &nbsp; &nbsp; &nbsp; &nbsp; 是代表了一个分片的数据，而不是包含或持有一个分片的数据。3、RDD之间有一些列的依赖关系。 &nbsp; &nbsp; &nbsp; &nbsp; 如下图，可以看到RDD1产生RDD2；RDD2产生RDD3，即RDD分裂时返回的仍是RDD集， &nbsp; &nbsp; &nbsp; &nbsp; 这样就形成了RDD间的层级依赖4、partitioner是作用在K,V格式的RDD上。 &nbsp; &nbsp; &nbsp; &nbsp; partitioner即分区器，即决定RDD的每一条消息应该分到哪个分区。 &nbsp; &nbsp; &nbsp; &nbsp; 但只有 k, v 类型的RDD才能有partitioner(当然，非 key，value类型的RDD的partitioner为None)。 5、RDD提供一系列最佳的计算位置 &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;spark提供了一种机制，在集群中运行任务时，会把task发送到集群中需要读取存储数据的节点来运行，不会将task随意发送到无关节点，这样减少数据节点间网络传输时间，做到计算移动、而数据不移动，实现了最佳计算位置。 RDD特性理解图： &nbsp; 三、 Spark任务执行流程 1、基于standalone-client模式 （1）spark集群启动，Worker节点向Master节点汇报各自资源，master掌握集群资源 （2）在client提交spark应用程序，此时会再client启动一个Driver进程 （3）Driver向Master请求资源，Master收到请求后，在集群中找到符合要求的节点启动Executor （4）Driver发送task到Worker,Worker上启动的Executor开始执行任务，完成后Driver负责并回收结果 2、基于standalone-cluster模式 standalone-cluster和standalone-client不同的是，client提交任务后，不会再启动Driver，而是Master在集群中找一台节点，即Worker上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 3、基于yarn-client模式 （1）Hadoop集群启动，NodeManager（NM）向ResourceManager（RM）通信，汇报各自资源，RM掌握集群资源 （2）client上提交spark应用，同时启动Driver，client向RM申请资源，启动ApplicationMaster(AM) （3）RM在随机选择集群中的一个NM，来启动AM，AM向RM申请资源启动Executor，RM分配资源给NM启动Executor （4）Executor通知Driver，Driver发送task给Executor，Executor执行完成，返回结果给Driver 4、基于yarn-cluster模式 yarn-cluste和yarn-client不同的是，client提交任务后，不会再启动Driver，而是RM在集群中找一台节点，即NM上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client上没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 术语解释 四、Spark代码流程 （1）创建SparkConf对象 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以设置Applicationname、可以设置运行模式及资源需求。 （2）创建SparkContext对象 （3）&nbsp;基于Spark的上下文创建一个RDD，对RDD进行处理 （4）应用程序中要有Action类算子来触发Transformation类算子执行。 （5）关闭Spark上下文对象SparkContext。 五、算子操作 1、Transformations转换算子 Transformations类算子是一类算子（函数）叫做转换算子，如map,flatMap,reduceByKey等。Transformations算子是延迟执行，也叫懒加载执行。 2、Action行动算子 Action类算子也是一类算子（函数）叫做行动算子，如foreach,collect，count等。Transformations类算子是延迟执行，Action类算子是触发执行。一个application应用程序中有几个Action类算子执行，就有几个job运行。 3、持久化算子 有时候会多次对同一个RDD进行计算，如果每次只是简单地调用行动算子，spark每次都会重新计算RDD及其所有依赖，这在迭代算法中消耗格外大。为了避免多次计算同一个RDD，spark引入了持久化 算子。 （1）cache 默认将RDD的数据持久化到内存中，cache是懒执行。看spark源码可以知道 chche () = persist()=persist(StorageLevel.Memory_Only)，相当于persist的StorageLevel.Memory_Only （2）persist 可以指定持久化的级别，最常用的是MEMORY_ONLY和MEMORY_AND_DISK，persist是懒执行 （3）checkpoint checkpoint将RDD持久化到磁盘，还可以切断RDD之间的依赖关系 执行流程：当RDD的job执行完毕后，会从finalRDD从后往前回溯。当回溯到某一个RDD调用了checkpoint方法，会对当前的RDD做一个标记。Spark框架会自动启动一个新的job，重新计算这个RDD的数据，将数据持久化到指定的存储位置上 优化：对RDD执行checkpoint之前，最好对这个RDD先执行cache，这样新启动的job只需要将内存中的数据拷贝到HDFS上就可以，省去了重新计算这一步 &nbsp; &nbsp; &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792689.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792689.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"一、Spark Core概念讲解 Spark Core：内核，也是Spark中最重要的部分。 相当于Mapreduce SparkCore 和 Mapreduce都是进行离线数据分析 SparkCore的核心：RDD（弹性分布式数据集），由分区组成 二、RDD的五大特性 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;1、RDD是由一系列的partition组成的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partition一般有三种方式产生 &nbsp; &nbsp; （1）从Scala集合中创建，通过调用SparkContext#makeRDD或SparkContext#parallelize &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;是可以指定partition 个数的，若指定了具体值，那么partition的个数就等于该值 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于从 Scala集合中转换而来的RDD：默认的partition数为defaultParallelism，该值在不同的部署模式下不同： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Local 模式：本机 cpu cores 的数量 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mesos 模式：8 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Yarn：max(2, 所有 executors 的 cpu cores 个数总和) &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;对于从外部数据加载而来的 RDD：默认的 partition 数为 min(defaultParallelism, 2) &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于执行转换操作而得到的 RDD：视具体操作而定，如 map 得到的 RDD 的 partition 数与 父 RDD 相同; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;union 得到的 RDD的 partition 数为父 RDDs 的 partition 数之和... &nbsp; &nbsp;（2） 加载外部数据来创建 RDD，例如从 HDFS 文件、mysql 数据库读取数据等 &nbsp; &nbsp;（3）由其它 RDD 执行 transform 操作转换而来2、函数是作用在每一个partition（split）上的。 &nbsp; &nbsp; &nbsp; &nbsp; partition 是 RDD 的数据单位，代表了一个分区的数据。但这里千万不要搞错了，partition 是逻辑概念， &nbsp; &nbsp; &nbsp; &nbsp; 是代表了一个分片的数据，而不是包含或持有一个分片的数据。3、RDD之间有一些列的依赖关系。 &nbsp; &nbsp; &nbsp; &nbsp; 如下图，可以看到RDD1产生RDD2；RDD2产生RDD3，即RDD分裂时返回的仍是RDD集， &nbsp; &nbsp; &nbsp; &nbsp; 这样就形成了RDD间的层级依赖4、partitioner是作用在K,V格式的RDD上。 &nbsp; &nbsp; &nbsp; &nbsp; partitioner即分区器，即决定RDD的每一条消息应该分到哪个分区。 &nbsp; &nbsp; &nbsp; &nbsp; 但只有 k, v 类型的RDD才能有partitioner(当然，非 key，value类型的RDD的partitioner为None)。 5、RDD提供一系列最佳的计算位置 &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;spark提供了一种机制，在集群中运行任务时，会把task发送到集群中需要读取存储数据的节点来运行，不会将task随意发送到无关节点，这样减少数据节点间网络传输时间，做到计算移动、而数据不移动，实现了最佳计算位置。 RDD特性理解图： &nbsp; 三、 Spark任务执行流程 1、基于standalone-client模式 （1）spark集群启动，Worker节点向Master节点汇报各自资源，master掌握集群资源 （2）在client提交spark应用程序，此时会再client启动一个Driver进程 （3）Driver向Master请求资源，Master收到请求后，在集群中找到符合要求的节点启动Executor （4）Driver发送task到Worker,Worker上启动的Executor开始执行任务，完成后Driver负责并回收结果 2、基于standalone-cluster模式 standalone-cluster和standalone-client不同的是，client提交任务后，不会再启动Driver，而是Master在集群中找一台节点，即Worker上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 3、基于yarn-client模式 （1）Hadoop集群启动，NodeManager（NM）向ResourceManager（RM）通信，汇报各自资源，RM掌握集群资源 （2）client上提交spark应用，同时启动Driver，client向RM申请资源，启动ApplicationMaster(AM) （3）RM在随机选择集群中的一个NM，来启动AM，AM向RM申请资源启动Executor，RM分配资源给NM启动Executor （4）Executor通知Driver，Driver发送task给Executor，Executor执行完成，返回结果给Driver 4、基于yarn-cluster模式 yarn-cluste和yarn-client不同的是，client提交任务后，不会再启动Driver，而是RM在集群中找一台节点，即NM上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client上没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。 术语解释 四、Spark代码流程 （1）创建SparkConf对象 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以设置Applicationname、可以设置运行模式及资源需求。 （2）创建SparkContext对象 （3）&nbsp;基于Spark的上下文创建一个RDD，对RDD进行处理 （4）应用程序中要有Action类算子来触发Transformation类算子执行。 （5）关闭Spark上下文对象SparkContext。 五、算子操作 1、Transformations转换算子 Transformations类算子是一类算子（函数）叫做转换算子，如map,flatMap,reduceByKey等。Transformations算子是延迟执行，也叫懒加载执行。 2、Action行动算子 Action类算子也是一类算子（函数）叫做行动算子，如foreach,collect，count等。Transformations类算子是延迟执行，Action类算子是触发执行。一个application应用程序中有几个Action类算子执行，就有几个job运行。 3、持久化算子 有时候会多次对同一个RDD进行计算，如果每次只是简单地调用行动算子，spark每次都会重新计算RDD及其所有依赖，这在迭代算法中消耗格外大。为了避免多次计算同一个RDD，spark引入了持久化 算子。 （1）cache 默认将RDD的数据持久化到内存中，cache是懒执行。看spark源码可以知道 chche () = persist()=persist(StorageLevel.Memory_Only)，相当于persist的StorageLevel.Memory_Only （2）persist 可以指定持久化的级别，最常用的是MEMORY_ONLY和MEMORY_AND_DISK，persist是懒执行 （3）checkpoint checkpoint将RDD持久化到磁盘，还可以切断RDD之间的依赖关系 执行流程：当RDD的job执行完毕后，会从finalRDD从后往前回溯。当回溯到某一个RDD调用了checkpoint方法，会对当前的RDD做一个标记。Spark框架会自动启动一个新的job，重新计算这个RDD的数据，将数据持久化到指定的存储位置上 优化：对RDD执行checkpoint之前，最好对这个RDD先执行cache，这样新启动的job只需要将内存中的数据拷贝到HDFS上就可以，省去了重新计算这一步 &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792689.html","headline":"02.spark-core入门（算子和Spark任务执行流程）","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792689.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>02.spark-core入门（算子和Spark任务执行流程）</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-light"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="Spark_Core_0"></a>一、Spark Core概念讲解</h2> 
  <p>Spark Core：内核，也是Spark中最重要的部分。</p> 
  <ul> 
   <li>相当于Mapreduce</li> 
   <li>SparkCore 和 Mapreduce都是进行离线数据分析</li> 
   <li>SparkCore的核心：RDD（弹性分布式数据集），由分区组成</li> 
  </ul> 
  <h3><a></a>二、RDD的五大特性</h3> 
  <p>&nbsp;</p> 
  <p>&nbsp;&nbsp;&nbsp;<strong>&nbsp;1、RDD是由一系列的partition组成的。</strong></p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partition一般有三种方式产生</p> 
  <p>&nbsp; &nbsp; （1）从Scala集合中创建，通过调用SparkContext#makeRDD或SparkContext#parallelize<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;是可以指定partition 个数的，若指定了具体值，那么partition的个数就等于该值<br> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于从 Scala集合中转换而来的RDD：默认的partition数为defaultParallelism，该值在不同的部署模式下不同：<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Local 模式：本机 cpu cores 的数量<br> &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mesos 模式：8<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Yarn：max(2, 所有 executors 的 cpu cores 个数总和)<br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;对于从外部数据加载而来的 RDD：默认的 partition 数为 min(defaultParallelism, 2)<br> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于执行转换操作而得到的 RDD：视具体操作而定，如 map 得到的 RDD 的 partition 数与 父 RDD 相同;<br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;union 得到的 RDD的 partition 数为父 RDDs 的 partition 数之和...<br> &nbsp; &nbsp;（2） 加载外部数据来创建 RDD，例如从 HDFS 文件、mysql 数据库读取数据等<br> &nbsp; &nbsp;（3）由其它 RDD 执行 transform 操作转换而来<br><strong>2、函数是作用在每一个partition（split）上的。</strong><br> &nbsp; &nbsp; &nbsp; &nbsp; partition 是 RDD 的数据单位，代表了一个分区的数据。但这里千万不要搞错了，partition 是逻辑概念，<br> &nbsp; &nbsp; &nbsp; &nbsp; 是代表了一个分片的数据，而不是包含或持有一个分片的数据。<br><strong>3、RDD之间有一些列的依赖关系。</strong><br> &nbsp; &nbsp; &nbsp; &nbsp; 如下图，可以看到RDD1产生RDD2；RDD2产生RDD3，即RDD分裂时返回的仍是RDD集，<br> &nbsp; &nbsp; &nbsp; &nbsp; 这样就形成了RDD间的层级依赖<br><strong>4、partitioner是作用在K,V格式的RDD上。</strong><br> &nbsp; &nbsp; &nbsp; &nbsp; partitioner即分区器，即决定RDD的每一条消息应该分到哪个分区。<br> &nbsp; &nbsp; &nbsp; &nbsp; 但只有 k, v 类型的RDD才能有partitioner(当然，非 key，value类型的RDD的partitioner为None)。</p> 
  <p><strong>5、RDD提供一系列最佳的计算位置</strong><br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;spark提供了一种机制，在集群中运行任务时，会把task发送到集群中需要读取存储数据的节点来运行，不会将task随意发送到无关节点，这样减少数据节点间网络传输时间，做到计算移动、而数据不移动，实现了最佳计算位置。</p> 
  <p>RDD特性理解图：</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180710003331576?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eGxmbHk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p> 
  <p>&nbsp;</p> 
  <h3><a></a>三、 Spark任务执行流程</h3> 
  <p>1、基于standalone-client模式</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180713162559853?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eGxmbHk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="600" height="349"></p> 
  <p>（1）spark集群启动，Worker节点向Master节点汇报各自资源，master掌握集群资源</p> 
  <p>（2）在client提交spark应用程序，此时会再client启动一个Driver进程</p> 
  <p>（3）Driver向Master请求资源，Master收到请求后，在集群中找到符合要求的节点启动Executor</p> 
  <p>（4）Driver发送task到Worker,Worker上启动的Executor开始执行任务，完成后Driver负责并回收结果</p> 
  <p>2、基于standalone-cluster模式</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180713164834738?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eGxmbHk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="600" height="364"></p> 
  <p>standalone-cluster和standalone-client不同的是，client提交任务后，不会再启动Driver，而是Master在集群中找一台节点，即Worker上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。</p> 
  <p>3、基于yarn-client模式</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180713170423807?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eGxmbHk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="600" height="363"></p> 
  <p>（1）Hadoop集群启动，NodeManager（NM）向ResourceManager（RM）通信，汇报各自资源，RM掌握集群资源</p> 
  <p>（2）client上提交spark应用，同时启动Driver，client向RM申请资源，启动ApplicationMaster(AM)</p> 
  <p>（3）RM在随机选择集群中的一个NM，来启动AM，AM向RM申请资源启动Executor，RM分配资源给NM启动Executor</p> 
  <p>（4）Executor通知Driver，Driver发送task给Executor，Executor执行完成，返回结果给Driver</p> 
  <p>4、基于yarn-cluster模式</p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180713170620411?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eGxmbHk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="600" height="374"></p> 
  <p>yarn-cluste和yarn-client不同的是，client提交任务后，不会再启动Driver，而是RM在集群中找一台节点，即NM上启动Driver，把Driver分散在集群节点中运行，这样避免了client上提交多个任务而引起的网络流量激增问题。client上没有Driver 进程，也看不到task执行情况，以及接收不到输出结果。</p> 
  <h4><a id="_82"></a>术语解释</h4> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731092715168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MzU2ODQw,size_16,color_FFFFFF,t_70" alt="术语解释"></p> 
  <h3><a></a>四、Spark代码流程</h3> 
  <p>（1）创建SparkConf对象</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以设置Applicationname、可以设置运行模式及资源需求。</p> 
  <p>（2）创建SparkContext对象</p> 
  <p>（3）&nbsp;基于Spark的上下文创建一个RDD，对RDD进行处理</p> 
  <p>（4）应用程序中要有Action类算子来触发Transformation类算子执行。</p> 
  <p>（5）关闭Spark上下文对象SparkContext。</p> 
  <h3><a></a>五、算子操作</h3> 
  <p>1、Transformations转换算子</p> 
  <p>Transformations类算子是一类算子（函数）叫做转换算子，如map,flatMap,reduceByKey等。Transformations算子是延迟执行，也叫懒加载执行。</p> 
  <p>2、Action行动算子</p> 
  <p>Action类算子也是一类算子（函数）叫做行动算子，如foreach,collect，count等。Transformations类算子是延迟执行，Action类算子是触发执行。一个application应用程序中有几个Action类算子执行，就有几个job运行。</p> 
  <p>3、持久化算子</p> 
  <p>有时候会多次对同一个RDD进行计算，如果每次只是简单地调用行动算子，spark每次都会重新计算RDD及其所有依赖，这在迭代算法中消耗格外大。为了避免多次计算同一个RDD，spark引入了持久化 算子。</p> 
  <p>（1）cache</p> 
  <p>默认将RDD的数据持久化到内存中，cache是懒执行。看spark源码可以知道</p> 
  <p>chche () = persist()=persist(StorageLevel.Memory_Only)，相当于persist的StorageLevel.Memory_Only</p> 
  <p>（2）persist</p> 
  <p>可以指定持久化的级别，最常用的是MEMORY_ONLY和MEMORY_AND_DISK，persist是懒执行</p> 
  <p>（3）checkpoint</p> 
  <p>checkpoint将RDD持久化到磁盘，还可以切断RDD之间的依赖关系</p> 
  <p>执行流程：当RDD的job执行完毕后，会从finalRDD从后往前回溯。当回溯到某一个RDD调用了checkpoint方法，会对当前的RDD做一个标记。Spark框架会自动启动一个新的job，重新计算这个RDD的数据，将数据持久化到指定的存储位置上</p> 
  <p>优化：对RDD执行checkpoint之前，最好对这个RDD先执行cache，这样新启动的job只需要将内存中的数据拷贝到HDFS上就可以，省去了重新计算这一步</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
