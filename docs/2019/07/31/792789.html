<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>spring boot中kafka教程 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="spring boot中kafka教程" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="参考了很多教程，最后精选了几篇，通俗易懂的 &nbsp; kafkaTemplate包装生产者工厂，生产者工厂包含具体的send发送senderProps参数，往topic里发， ConcurrentKafkaListenerContainerFactory监听器包装消费者工厂，消费者工厂包含具体的consumer消费consumerProps参数，从topic里消费，该topic要和生产者的一致。 public ProducerRecord(String topic, K key, V value) { this(topic, (Integer)null, (Long)null, key, value, (Iterable)null); } public class KafkaConsumer { @KafkaListener(topics = &quot;topic&quot;) &nbsp; 编写第一个Demo 实现顺序 &nbsp; &nbsp;1,连接kafka服务器的配置 &nbsp; &nbsp; 2,kafka-customer:消费者配置 &nbsp; &nbsp; 3,kafka-provider:提供者配置 &nbsp; &nbsp; 4,KfkaUtils:根据topic发送消息 &nbsp; &nbsp; 5,消费者根据topic处理消息 创建消费者和生产者的Map配置 根据Map配置创建对应的消费者工厂(consumerFactory)和生产者工厂(producerFactory) 根据consumerFactory创建监听器的监听器工厂 根据producerFactory创建KafkaTemplate(Kafka操作类) 创建监听容器 一、精文章 先给你们瞄一眼项目结构，记得把Kafka 启动... &nbsp; 项目结构 创建KafkaConfiguration配置类 都是一些配置参数，具体的作用也在代码中写明了，值得注意的是，KafkaTemplate的类型为&lt;Integer,String&gt;，我们可以找kafkaTemplate的send方法，有多个重载方法，其中有个方法如下，key和data参数都为泛型，这其实就是对应着KafkaTemplate&lt;Integer,String&gt;。那具体有什么用呢，还记得我们的Topic中可以包含多个Partition(分区)吗，那我们如果不想手动指定发送到哪个分区，我们则可以利用key去实现。这里我们的key是Integer类型，template会根据 key 路由到对应的partition中，如果key存在对应的partitionID则发送到该partition中，否则由算法选择发送到哪个partition。 public ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, V data) { ProducerRecord&lt;K, V&gt; producerRecord = new ProducerRecord(topic, key, data); return this.doSend(producerRecord); } @Configuration @EnableKafka public class KafkaConfiguration { //ConcurrentKafkaListenerContainerFactory为创建Kafka监听器的工程类，这里只配置了消费者 @Bean public ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; kafkaListenerContainerFactory() { ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); return factory; } //根据consumerProps填写的参数创建消费者工厂 @Bean public ConsumerFactory&lt;Integer, String&gt; consumerFactory() { return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); } //根据senderProps填写的参数创建生产者工厂 @Bean public ProducerFactory&lt;Integer, String&gt; producerFactory() { return new DefaultKafkaProducerFactory&lt;&gt;(senderProps()); } //kafkaTemplate实现了Kafka发送接收等功能 @Bean public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { KafkaTemplate template = new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); return template; } //消费者配置参数 private Map&lt;String, Object&gt; consumerProps() { Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //GroupID props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;bootKafka&quot;); //是否自动提交 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true); //自动提交的频率 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); //Session超时设置 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); //键的反序列化方式 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); //值的反序列化方式 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); return props; } //生产者配置 private Map&lt;String, Object&gt; senderProps (){ Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //重试，0为不启用重试机制 props.put(ProducerConfig.RETRIES_CONFIG, 1); //控制批处理大小，单位为字节 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //批量发送，延迟为1毫秒，启用该功能能有效减少生产者发送消息次数，从而提高并发量 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); //生产者可以使用的总内存字节来缓冲等待发送到服务器的记录 props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024000); //键的序列化方式 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); //值的序列化方式 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; } } &nbsp; 创建DemoListener消费者 这里的消费者其实就是一个监听类，指定监听名为topic.quick.demo的Topic，consumerID为demo。 @Component public class DemoListener { private static final Logger log= LoggerFactory.getLogger(DemoListener.class); //声明consumerID为demo，监听topicName为topic.quick.demo的Topic @KafkaListener(id = &quot;demo&quot;, topics = &quot;topic.quick.demo&quot;) public void listen(String msgData) { log.info(&quot;demo receive : &quot;+msgData); } } &nbsp; 创建测试类 这里的send方法第一参数为TopicName，第二个参数则是发送的数据 @SpringBootTest @RunWith(SpringRunner.class) public class DemoTest { @Autowired private KafkaTemplate kafkaTemplate; @Test public void testDemo() throws InterruptedException { kafkaTemplate.send(&quot;topic.quick.demo&quot;, &quot;this is my first demo&quot;); //休眠5秒，为了使监听器有足够的时间监听到topic的数据 Thread.sleep(5000); } } 接下来直接运行这个测试方法，我们可以看到日志中输出了我们发送的消息，这就代表我们成功的消费了测试方法中发送的消息。 2018-09-06 17:26:20.850 INFO 6232 --- [ demo-0-C-1] com.viu.kafka.listen.DemoListener : demo receive : this is my first demo &nbsp; 启动项目 看清楚了是启动项目，不是测试类,我们来观察一下控制台的输出日志 首先这个是KafkaConsumer的配置信息，每个消费者都会输出该配置信息，配置太多就不做讲解了 2018-09-06 17:40:15.258 INFO 9944 --- [ main] o.a.k.clients.consumer.ConsumerConfig : ConsumerConfig values: auto.commit.interval.ms = 100 auto.offset.reset = latest bootstrap.servers = [localhost:9092] check.crcs = true client.id = connections.max.idle.ms = 540000 enable.auto.commit = true exclude.internal.topics = true fetch.max.bytes = 52428800 fetch.max.wait.ms = 500 fetch.min.bytes = 1 group.id = demo heartbeat.interval.ms = 3000 interceptor.classes = null internal.leave.group.on.close = true isolation.level = read_uncommitted key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer max.partition.fetch.bytes = 1048576 max.poll.interval.ms = 300000 max.poll.records = 500 metadata.max.age.ms = 300000 metric.reporters = [] metrics.num.samples = 2 metrics.recording.level = INFO metrics.sample.window.ms = 30000 partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor] receive.buffer.bytes = 65536 reconnect.backoff.max.ms = 1000 reconnect.backoff.ms = 50 request.timeout.ms = 305000 retry.backoff.ms = 100 sasl.jaas.config = null sasl.kerberos.kinit.cmd = /usr/bin/kinit sasl.kerberos.min.time.before.relogin = 60000 sasl.kerberos.service.name = null sasl.kerberos.ticket.renew.jitter = 0.05 sasl.kerberos.ticket.renew.window.factor = 0.8 sasl.mechanism = GSSAPI security.protocol = PLAINTEXT send.buffer.bytes = 131072 session.timeout.ms = 15000 ssl.cipher.suites = null ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1] ssl.endpoint.identification.algorithm = null ssl.key.password = null ssl.keymanager.algorithm = SunX509 ssl.keystore.location = null ssl.keystore.password = null ssl.keystore.type = JKS ssl.protocol = TLS ssl.provider = null ssl.secure.random.implementation = null ssl.trustmanager.algorithm = PKIX ssl.truststore.location = null ssl.truststore.password = null ssl.truststore.type = JKS value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka version : 1.0.2 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka commitId : 2a121f7b1d402825 这些日志就代表我们成功的创建了Consumer，由于没有做并发配置，所以现在为单个消费者模式，系统会做一个分配Partition的操作，也就是将某个Partition指定给某个消费者消费。 这里有个地方需要注意一下， 看到日志中有输出[Consumer clientId=consumer-1, groupId=demo]，我们之前在监听中@KafkaListener注解中配置的id=demo，怎么就变成了groupId=demo，这是因为@KafkaListener注解如果没有指定groupId这个属性的值，则会默认把id作为groupId。 2018-09-06 17:40:15.287 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Discovered group coordinator admin-PC:9092 (id: 2147483647 rack: null) 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Revoking previously assigned partitions [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.s.k.l.KafkaMessageListenerContainer : partitions revoked: [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] (Re-)joining group 2018-09-06 17:40:15.301 INFO 9944 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#39;&#39; 2018-09-06 17:40:15.302 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Successfully joined group with generation 33 2018-09-06 17:40:15.303 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Setting newly assigned partitions [topic.quick.demo-0] &nbsp; &nbsp; 结束 SpringBoot2.0已经提供了Kafka的自动配置，可以在application.properties文件中配置，我觉得更方便 &nbsp; 二、精文章 &nbsp; 提前启动zk，kafka，并且创建一个Topic [root@Basic kafka_2.11-1.1.0]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic&nbsp; 1 确保你的kafka能够访问，如果访问不了，需要打开外网访问。 config/server.properties advertised.listeners=PLAINTEXT://192.168.239.128:9092 1 Maven 依赖 &lt;dependency&gt; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &nbsp; &nbsp; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; 二、项目结构 为了更加体现实际开发需求，一般生产者都是在调用某些接口的服务处理完逻辑之后然后往kafka里面扔数据，然后有一个消费者不停的监控这个Topic，然后处理数据，所以这里把生产者作为一个接口，消费者放到kafka这个目录下，注意@Component注解，不然扫描不到@KafkaListener 三、具体实现代码 SpringBoot配置文件 application.yml spring: &nbsp; kafka: &nbsp; &nbsp; bootstrap-servers: 192.168.239.128:9092 &nbsp; &nbsp; producer: &nbsp; &nbsp; &nbsp; key-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; &nbsp; value-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; consumer: &nbsp; &nbsp; &nbsp; group-id: test &nbsp; &nbsp; &nbsp; enable-auto-commit: true &nbsp; &nbsp; &nbsp; auto-commit-interval: 1000 &nbsp; &nbsp; &nbsp; key-deserializer: org.apache.kafka.common.serialization.StringDeserializer &nbsp; &nbsp; &nbsp; value-deserializer: org.apache.kafka.common.serialization.StringDeserializer 生产者 package cn.saytime.web; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.kafka.core.KafkaTemplate; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** &nbsp;* 测试kafka生产者 &nbsp;*/ @RestController @RequestMapping(&quot;kafka&quot;) public class TestKafkaProducerController { &nbsp; &nbsp; @Autowired &nbsp; &nbsp; private KafkaTemplate&lt;String, String&gt; kafkaTemplate; &nbsp; &nbsp; @RequestMapping(&quot;send&quot;) &nbsp; &nbsp; public String send(String msg){ &nbsp; &nbsp; &nbsp; &nbsp; kafkaTemplate.send(&quot;test_topic&quot;, msg); &nbsp; &nbsp; &nbsp; &nbsp; return &quot;success&quot;; &nbsp; &nbsp; } } 消费者 这里的消费者会监听这个主题，有消息就会执行，不需要进行while(true) package cn.saytime.kafka; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; /** &nbsp;* kafka消费者测试 &nbsp;*/ @Component public class TestConsumer { &nbsp; &nbsp; @KafkaListener(topics = &quot;test_topic&quot;) &nbsp; &nbsp; public void listen (ConsumerRecord&lt;?, ?&gt; record) throws Exception { &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf(&quot;topic = %s, offset = %d, value = %s \n&quot;, record.topic(), record.offset(), record.value()); &nbsp; &nbsp; } } 项目启动类 package cn.saytime; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class TestApplication{ &nbsp; &nbsp; public static void main(String[] args) { &nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(TestApplication.class, args); &nbsp; &nbsp; } } 四、测试 运行项目，执行：http://localhost:8080/kafka/send?msg=hello 控制台输出： topic = test_topic, offset = 19, value = hello&nbsp; 1 为了体现消费者不止执行一次就结束，再调用一次接口：&nbsp; http://localhost:8080/kafka/send?msg=kafkatopic = test_topic, offset = 20, value = kafka&nbsp; 1 所以可以看到这里消费者实际上是不停的poll Topic数据的。 ---------------------&nbsp; 三、精文章 1.&nbsp; Apache Kafka是一个分布式流平台 1.1&nbsp; 流平台有三个关键功能： 发布和订阅流记录，类似于一个消息队列或企业消息系统 以一种容错的持久方式存储记录流 在流记录生成的时候就处理它们 1.2&nbsp; Kafka通常用于两大类应用： 构建实时流数据管道，在系统或应用程序之间可靠地获取数据 构建对数据流进行转换或输出的实时流媒体应用程序 1.3&nbsp; 有几个特别重要的概念： Kafka is run as a cluster on one or more servers that can span multiple datacenters. The Kafka cluster stores streams of records in categories called topics. Each record consists of a key, a value, and a timestamp. 　　Kafka作为集群运行在一个或多个可以跨多个数据中心的服务器上 　　从这句话表达了三个意思： Kafka是以集群方式运行的 集群中可以只有一台服务器，也有可能有多台服务器。也就是说，一台服务器也是一个集群，多台服务器也可以组成一个集群 这些服务器可以跨多个数据中心 　　Kafka集群按分类存储流记录，这个分类叫做主题 　　这句话表达了以下几个信息： 流记录是分类存储的，也就说记录是归类的 我们称这种分类为主题 简单地来讲，记录是按主题划分归类存储的 　　每个记录由一个键、一个值和一个时间戳组成 1.4&nbsp; Kafka有四个核心API： Producer API&nbsp;：允许应用发布一条流记录到一个或多个主题 Consumer API&nbsp;：允许应用订阅一个或多个主题，并处理流记录 Streams API&nbsp;：允许应用作为一个流处理器，从一个或多个主题那里消费输入流，并将输出流输出到一个或多个输出主题，从而有效地讲输入流转换为输出流 Connector API&nbsp;：允许将主题连接到已经存在的应用或者数据系统，以构建并允许可重用的生产者或消费者。例如，一个关系型数据库的连接器可能捕获到一张表的每一次变更 （画外音：我理解这四个核心API其实就是：发布、订阅、转换处理、从第三方采集数据。） 在Kafka中，客户端和服务器之间的通信是使用简单的、高性能的、与语言无关的TCP协议完成的。 2.&nbsp;&nbsp;Topics and Logs（主题和日志） 一个topic是一个分类，或者说是记录被发布的时候的一个名字（画外音：可以理解为记录要被发到哪儿去）。 在Kafka中，topic总是有多个订阅者，因此，一个topic可能有0个，1个或多个订阅该数据的消费者。 对于每个主题，Kafka集群维护一个分区日志，如下图所示： 每个分区都是一个有序的、不可变的记录序列，而且记录会不断的被追加，一条记录就是一个结构化的提交日志（a structured commit log）。 分区中的每条记录都被分配了一个连续的id号，这个id号被叫做offset（偏移量），这个偏移量唯一的标识出分区中的每条记录。（PS：如果把分区比作数据库表的话，那么偏移量就是主键） Kafka集群持久化所有已发布的记录，无论它们有没有被消费，记录被保留的时间是可以配置的。例如，如果保留策略被设置为两天，那么在记录发布后的两天内，可以使用它，之后将其丢弃以释放空间。在对数据大小方面，Kafka的性能是高效的，恒定常量级的，因此长时间存储数据不是问题。 事实上，唯一维护在每个消费者上的元数据是消费者在日志中的位置或者叫偏移量。偏移量是由消费者控制的：通常消费者在读取记录的时候会线性的增加它的偏移量，但是，事实上，由于位置（偏移量）是由消费者控制的，所有它可以按任意它喜欢的顺序消费记录。例如：一个消费者可以重置到一个较旧的偏移量来重新处理之前已经处理过的数据，或者跳转到最近的记录并从“现在”开始消费。 这种特性意味着消费者非常廉价————他们可以来来去去的消息而不会对集群或者其它消费者造成太大影响。 日志中的分区有几个用途。首先，它们允许日志的规模超出单个服务器的大小。每个独立分区都必须与宿主的服务器相匹配，但一个主题可能有多个分区，所以它可以处理任意数量的数据。第二，它们作为并行的单位——稍后再进一步。 （ 画外音：简单地来说，日志分区的作用有两个：一、日志的规模不再受限于单个服务器；二、分区意味着可以并行。 什么意思呢？主题建立在集群之上，每个主题维护了一个分区日志，顾名思义，日志是分区的；每个分区所在的服务器的资源（比如：CPU、内存、带宽、磁盘等）是有限的，如果不分区（可以理解为等同于只有一个）的话，必然受限于这个分区所在的服务器，那么多个分区的话就不一样了，就突破了这种限制，服务器可以随便加，分区也可以随便加。 ） 3.&nbsp;&nbsp;Distribution（分布） 日志的分区分布在集群中的服务器上，每个服务器处理数据，并且分区请求是共享的。每个分区被复制到多个服务器上以实现容错，到底复制到多少个服务器上是可以配置的。 Each partition is replicated across a configurable number of servers for fault tolerance. 每个分区都有一个服务器充当“leader”角色，并且有0个或者多个服务器作为“followers”。leader处理对这个分区的所有读和写请求，而followers被动的从leader那里复制数据。如果leader失败，followers中的其中一个会自动变成新的leader。每个服务器充当一些分区的“leader”的同时也是其它分区的“follower”，因此在整个集群中负载是均衡的。 也就是说，每个服务器既是“leader”也是“follower”。我们知道一个主题可能有多个分区，一个分区可能在一个服务器上也可能跨多个服务器，然而这并不以为着一台服务器上只有一个分区，是可能有多个分区的。每个分区中有一个服务器充当“leader”，其余是“follower”。leader负责处理这个它作为leader所负责的分区的所有读写请求，而该分区中的follow只是被动复制leader的数据。这个有点儿像HDFS中的副本机制。例如：分区-1有服务器A和B组成，A是leader，B是follower，有请求要往分区-1中写数据的时候就由A处理，然后A把刚才写的数据同步给B，这样的话正常请求相当于A和B的数据是一样的，都有分区-1的全部数据，如果A宕机了，B成为leader，接替A继续处理对分区-1的读写请求。 需要注意的是，分区是一个虚拟的概念，是一个逻辑单元。 4.&nbsp;&nbsp;Producers（生产者） 生产者发布数据到它们选择的主题中。生产者负责选择将记录投递到哪个主题的哪个分区中。要做这件事情，可以简单地用循环方式以到达负载均衡，或者根据一些语义分区函数（比如：基于记录中的某些key） 5.&nbsp;&nbsp;Consumers（消费者） 消费者用一个消费者组名来标识它们自己（PS：相当于给自己贴一个标签，标签的名字是组名，以表明自己属于哪个组），并且每一条发布到主题中的记录只会投递给每个订阅的消费者组中的其中一个消费者实例。消费者实例可能是单独的进程或者在单独的机器上。 如果所有的消费者实例都使用相同的消费者组，那么记录将会在这些消费者之间有效的负载均衡。 如果所有的消费者实例都使用不同的消费者组，那么每条记录将会广播给所有的消费者进程。 上图中其实那个Kafka Cluster换成Topic会更准确一些 一个Kafka集群有2个服务器，4个分区（P0-P3），有两个消费者组。组A中有2个消费者实例，组B中有4个消费者实例。 通常我们会发现，主题不会有太多的消费者组，每个消费者组是一个“逻辑订阅者”（以消费者组的名义订阅主题，而非以消费者实例的名义去订阅）。每个组由许多消费者实例组成，以实现可扩展性和容错。这仍然是发布/订阅，只不过订阅者是一个消费者群体，而非单个进程。 在Kafka中，这种消费方式是通过用日志中的分区除以使用者实例来实现的，这样可以保证在任意时刻每个消费者都是排它的消费，即“公平共享”。Kafka协议动态的处理维护组中的成员。如果有心的实例加入到组中，它们将从组中的其它成员那里接管一些分区；如果组中有一个实例死了，那么它的分区将会被分给其它实例。 （画外音：什么意思呢？举个例子，在上面的图中，4个分区，组A有2个消费者，组B有4个消费者，那么对A来讲组中的每个消费者负责4/2=2个分区，对组B来说组中的每个消费者负责4/4=1个分区，而且同一时间消息只能被组中的一个实例消费。如果组中的成员数量有变化，则重新分配。） Kafka只提供分区下的记录的总的顺序，而不提供主题下不同分区的总的顺序。每个分区结合按key划分数据的能力排序对大多数应用来说是足够的。然而，如果你需要主题下总的记录顺序，你可以只使用一个分区，这样做的做的话就意味着每个消费者组中只能有一个消费者实例。 6.&nbsp; 保证 在一个高级别的Kafka给出下列保证： 被一个生产者发送到指定主题分区的消息将会按照它们被发送的顺序追加到分区中。也就是说，如果记录M1和M2是被同一个生产者发送到同一个分区的，而且M1是先发送的，M2是后发送的，那么在分区中M1的偏移量一定比M2小，并且M1出现在日志中的位置更靠前。 一个消费者看到记录的顺序和它们在日志中存储的顺序是一样的。 对于一个副本因子是N的主题，我们可以容忍最多N-1个服务器失败，而不会丢失已经提交给日志的任何记录。 7.&nbsp; Spring Kafka Spring提供了一个“模板”作为发送消息的高级抽象。它也通过使用@KafkaListener注释和“监听器容器”提供对消息驱动POJOs的支持。这些库促进了依赖注入和声明式的使用。 7.1&nbsp; 纯Java方式 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.clients.producer.ProducerConfig; 6 import org.apache.kafka.common.serialization.IntegerDeserializer; 7 import org.apache.kafka.common.serialization.IntegerSerializer; 8 import org.apache.kafka.common.serialization.StringDeserializer; 9 import org.apache.kafka.common.serialization.StringSerializer; 10 import org.springframework.kafka.core.*; 11 import org.springframework.kafka.listener.KafkaMessageListenerContainer; 12 import org.springframework.kafka.listener.MessageListener; 13 import org.springframework.kafka.listener.config.ContainerProperties; 14 15 import java.util.HashMap; 16 import java.util.Map; 17 18 public class PureJavaDemo { 19 20 /** 21 * 生产者配置 22 */ 23 private static Map&lt;String, Object&gt; senderProps() { 24 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 25 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 26 props.put(ProducerConfig.RETRIES_CONFIG, 0); 27 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); 28 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 29 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 30 return props; 31 } 32 33 /** 34 * 消费者配置 35 */ 36 private static Map&lt;String, Object&gt; consumerProps() { 37 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 38 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 39 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hello&quot;); 40 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 41 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); 42 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); 43 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 44 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 45 return props; 46 } 47 48 /** 49 * 发送模板配置 50 */ 51 private static KafkaTemplate&lt;Integer, String&gt; createTemplate() { 52 Map&lt;String, Object&gt; senderProps = senderProps(); 53 ProducerFactory&lt;Integer, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(senderProps); 54 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = new KafkaTemplate&lt;&gt;(producerFactory); 55 return kafkaTemplate; 56 } 57 58 /** 59 * 消息监听器容器配置 60 */ 61 private static KafkaMessageListenerContainer&lt;Integer, String&gt; createContainer() { 62 Map&lt;String, Object&gt; consumerProps = consumerProps(); 63 ConsumerFactory&lt;Integer, String&gt; consumerFactory = new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps); 64 ContainerProperties containerProperties = new ContainerProperties(&quot;test&quot;); 65 KafkaMessageListenerContainer&lt;Integer, String&gt; container = new KafkaMessageListenerContainer&lt;&gt;(consumerFactory, containerProperties); 66 return container; 67 } 68 69 70 public static void main(String[] args) throws InterruptedException { 71 String topic1 = &quot;test&quot;; // 主题 72 73 KafkaMessageListenerContainer container = createContainer(); 74 ContainerProperties containerProperties = container.getContainerProperties(); 75 containerProperties.setMessageListener(new MessageListener&lt;Integer, String&gt;() { 76 @Override 77 public void onMessage(ConsumerRecord&lt;Integer, String&gt; record) { 78 System.out.println(&quot;Received: &quot; + record); 79 } 80 }); 81 container.setBeanName(&quot;testAuto&quot;); 82 83 container.start(); 84 85 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = createTemplate(); 86 kafkaTemplate.setDefaultTopic(topic1); 87 88 kafkaTemplate.sendDefault(0, &quot;foo&quot;); 89 kafkaTemplate.sendDefault(2, &quot;bar&quot;); 90 kafkaTemplate.sendDefault(0, &quot;baz&quot;); 91 kafkaTemplate.sendDefault(2, &quot;qux&quot;); 92 93 kafkaTemplate.flush(); 94 container.stop(); 95 96 System.out.println(&quot;结束&quot;); 97 } 98 99 } 运行结果： Received: ConsumerRecord(topic = test, partition = 0, offset = 67, CreateTime = 1533300970788, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = foo) Received: ConsumerRecord(topic = test, partition = 0, offset = 68, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = bar) Received: ConsumerRecord(topic = test, partition = 0, offset = 69, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = baz) Received: ConsumerRecord(topic = test, partition = 0, offset = 70, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = qux) 7.2&nbsp; 更简单一点儿，用SpringBoot 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.beans.factory.annotation.Autowired; 5 import org.springframework.boot.CommandLineRunner; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.annotation.KafkaListener; 9 import org.springframework.kafka.core.KafkaTemplate; 10 11 @Configuration 12 public class JavaConfigurationDemo { 13 14 @KafkaListener(topics = &quot;test&quot;) 15 public void listen(ConsumerRecord&lt;String, String&gt; record) { 16 System.out.println(&quot;收到消息: &quot; + record); 17 } 18 19 @Bean 20 public CommandLineRunner commandLineRunner() { 21 return new MyRunner(); 22 } 23 24 class MyRunner implements CommandLineRunner { 25 26 @Autowired 27 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 28 29 @Override 30 public void run(String... args) throws Exception { 31 kafkaTemplate.send(&quot;test&quot;, &quot;foo1&quot;); 32 kafkaTemplate.send(&quot;test&quot;, &quot;foo2&quot;); 33 kafkaTemplate.send(&quot;test&quot;, &quot;foo3&quot;); 34 kafkaTemplate.send(&quot;test&quot;, &quot;foo4&quot;); 35 } 36 } 37 } application.properties配置 spring.kafka.bootstrap-servers=192.168.101.5:9092 spring.kafka.consumer.group-id=world 8.&nbsp; 生产者 1 package com.cjs.example.send; 2 3 import org.apache.kafka.clients.producer.ProducerConfig; 4 import org.apache.kafka.common.serialization.IntegerSerializer; 5 import org.apache.kafka.common.serialization.StringSerializer; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.core.DefaultKafkaProducerFactory; 9 import org.springframework.kafka.core.KafkaTemplate; 10 import org.springframework.kafka.core.ProducerFactory; 11 12 import java.util.HashMap; 13 import java.util.Map; 14 15 @Configuration 16 public class Config { 17 18 public Map&lt;String, Object&gt; producerConfigs() { 19 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 20 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 21 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 22 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 23 return props; 24 } 25 26 public ProducerFactory&lt;Integer, String&gt; producerFactory() { 27 return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs()); 28 } 29 30 @Bean 31 public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { 32 return new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); 33 } 34 35 } 1 package com.cjs.example.send; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.boot.CommandLineRunner; 5 import org.springframework.kafka.core.KafkaTemplate; 6 import org.springframework.kafka.support.SendResult; 7 import org.springframework.stereotype.Component; 8 import org.springframework.util.concurrent.ListenableFuture; 9 import org.springframework.util.concurrent.ListenableFutureCallback; 10 11 @Component 12 public class MyCommandLineRunner implements CommandLineRunner { 13 14 @Autowired 15 private KafkaTemplate&lt;Integer, String&gt; kafkaTemplate; 16 17 public void sendTo(Integer key, String value) { 18 ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; listenableFuture = kafkaTemplate.send(&quot;test&quot;, key, value); 19 listenableFuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() { 20 @Override 21 public void onFailure(Throwable throwable) { 22 System.out.println(&quot;发送失败啦&quot;); 23 throwable.printStackTrace(); 24 } 25 26 @Override 27 public void onSuccess(SendResult&lt;Integer, String&gt; sendResult) { 28 System.out.println(&quot;发送成功，&quot; + sendResult); 29 } 30 }); 31 } 32 33 @Override 34 public void run(String... args) throws Exception { 35 sendTo(1, &quot;aaa&quot;); 36 sendTo(2, &quot;bbb&quot;); 37 sendTo(3, &quot;ccc&quot;); 38 } 39 40 41 } 运行结果： 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=1, value=aaa, timestamp=null), recordMetadata=test-0@37] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=2, value=bbb, timestamp=null), recordMetadata=test-0@38] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=3, value=ccc, timestamp=null), recordMetadata=test-0@39] 9.&nbsp; 消费者@KafkaListener 1 package com.cjs.example.receive; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.common.serialization.IntegerDeserializer; 6 import org.apache.kafka.common.serialization.StringDeserializer; 7 import org.springframework.context.annotation.Bean; 8 import org.springframework.context.annotation.Configuration; 9 import org.springframework.kafka.annotation.KafkaListener; 10 import org.springframework.kafka.annotation.TopicPartition; 11 import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory; 12 import org.springframework.kafka.config.KafkaListenerContainerFactory; 13 import org.springframework.kafka.core.ConsumerFactory; 14 import org.springframework.kafka.core.DefaultKafkaConsumerFactory; 15 import org.springframework.kafka.listener.AbstractMessageListenerContainer; 16 import org.springframework.kafka.listener.ConcurrentMessageListenerContainer; 17 import org.springframework.kafka.listener.config.ContainerProperties; 18 import org.springframework.kafka.support.Acknowledgment; 19 import org.springframework.kafka.support.KafkaHeaders; 20 import org.springframework.messaging.handler.annotation.Header; 21 import org.springframework.messaging.handler.annotation.Payload; 22 23 import java.util.HashMap; 24 import java.util.List; 25 import java.util.Map; 26 27 @Configuration 28 public class Config2 { 29 30 @Bean 31 public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaListenerContainerFactory() { 32 ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); 33 factory.setConsumerFactory(consumerFactory()); 34 factory.setConcurrency(3); 35 ContainerProperties containerProperties = factory.getContainerProperties(); 36 containerProperties.setPollTimeout(2000); 37 // containerProperties.setAckMode(AbstractMessageListenerContainer.AckMode.MANUAL_IMMEDIATE); 38 return factory; 39 } 40 41 private ConsumerFactory&lt;Integer,String&gt; consumerFactory() { 42 return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); 43 } 44 45 private Map&lt;String, Object&gt; consumerProps() { 46 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 47 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 48 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hahaha&quot;); 49 // props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 50 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 51 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 52 return props; 53 } 54 55 56 @KafkaListener(topics = &quot;test&quot;) 57 public void listen(String data) { 58 System.out.println(&quot;listen 收到: &quot; + data); 59 } 60 61 62 @KafkaListener(topics = &quot;test&quot;, containerFactory = &quot;kafkaListenerContainerFactory&quot;) 63 public void listen2(String data, Acknowledgment ack) { 64 System.out.println(&quot;listen2 收到: &quot; + data); 65 ack.acknowledge(); 66 } 67 68 @KafkaListener(topicPartitions = {@TopicPartition(topic = &quot;test&quot;, partitions = &quot;0&quot;)}) 69 public void listen3(ConsumerRecord&lt;?, ?&gt; record) { 70 System.out.println(&quot;listen3 收到: &quot; + record.value()); 71 } 72 73 74 @KafkaListener(id = &quot;xyz&quot;, topics = &quot;test&quot;) 75 public void listen4(@Payload String foo, 76 @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) Integer key, 77 @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition, 78 @Header(KafkaHeaders.RECEIVED_TOPIC) String topic, 79 @Header(KafkaHeaders.OFFSET) List&lt;Long&gt; offsets) { 80 System.out.println(&quot;listen4 收到: &quot;); 81 System.out.println(foo); 82 System.out.println(key); 83 System.out.println(partition); 84 System.out.println(topic); 85 System.out.println(offsets); 86 } 87 88 } 9.1&nbsp; Committing Offsets 如果enable.auto.commit设置为true，那么kafka将自动提交offset。如果设置为false，则支持下列AckMode（确认模式）。 消费者poll()方法将返回一个或多个ConsumerRecords RECORD ：处理完记录以后，当监听器返回时，提交offset BATCH&nbsp; ：当对poll()返回的所有记录进行处理完以后，提交偏offset TIME&nbsp; &nbsp;：当对poll()返回的所有记录进行处理完以后，只要距离上一次提交已经过了ackTime时间后就提交 COUNT&nbsp; ：当poll()返回的所有记录都被处理时，只要从上次提交以来收到了ackCount条记录，就可以提交 COUNT_TIME ：和TIME以及COUNT类似，只要这两个中有一个为true，则提交 MANUAL ：消息监听器负责调用Acknowledgment.acknowledge()方法，此后和BATCH是一样的 MANUAL_IMMEDIATE ：当监听器调用Acknowledgment.acknowledge()方法后立即提交 10.&nbsp; Spring Boot Kafka 10.1&nbsp; application.properties spring.kafka.bootstrap-servers=192.168.101.5:9092 10.2&nbsp; 发送消息 1 package com.cjs.example; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.kafka.core.KafkaTemplate; 5 import org.springframework.web.bind.annotation.RequestMapping; 6 import org.springframework.web.bind.annotation.RestController; 7 8 import javax.annotation.Resource; 9 10 @RestController 11 @RequestMapping(&quot;/msg&quot;) 12 public class MessageController { 13 14 @Resource 15 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 16 17 @RequestMapping(&quot;/send&quot;) 18 public String send(String topic, String key, String value) { 19 kafkaTemplate.send(topic, key, value); 20 return &quot;ok&quot;; 21 } 22 23 } 10.3&nbsp; 接收消息 1 package com.cjs.example; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.kafka.annotation.KafkaListener; 5 import org.springframework.kafka.annotation.KafkaListeners; 6 import org.springframework.stereotype.Component; 7 8 @Component 9 public class MessageListener { 10 11 /** 12 * 监听订单消息 13 */ 14 @KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;) 15 public void listenToOrder(String data) { 16 System.out.println(&quot;收到订单消息：&quot; + data); 17 } 18 19 /** 20 * 监听会员消息 21 */ 22 @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;) 23 public void listenToMember(ConsumerRecord&lt;String, String&gt; record) { 24 System.out.println(&quot;收到会员消息：&quot; + record); 25 } 26 27 /** 28 * 监听所有消息 29 * 30 * 任意时刻，一条消息只会发给组中的一个消费者 31 * 32 * 消费者组中的成员数量不能超过分区数，这里分区数是1，因此订阅该主题的消费者组成员不能超过1 33 */ 34 // @KafkaListeners({@KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;), 35 // @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;)}) 36 // public void listenToAll(String data) { 37 // System.out.println(&quot;啊啊啊&quot;); 38 // } 39 40 } 11.&nbsp; pom.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.cjs.example&lt;/groupId&gt; &lt;artifactId&gt;cjs-kafka-example&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;cjs-kafka-example&lt;/name&gt; &lt;description&gt;&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 参考：https://www.jianshu.com/p/c9581f695d64 &nbsp; &nbsp;：https://blog.csdn.net/saytime/article/details/79950635&nbsp; &nbsp; &nbsp; &nbsp;https://www.cnblogs.com/cjsblog/p/9416380.html" />
<meta property="og:description" content="参考了很多教程，最后精选了几篇，通俗易懂的 &nbsp; kafkaTemplate包装生产者工厂，生产者工厂包含具体的send发送senderProps参数，往topic里发， ConcurrentKafkaListenerContainerFactory监听器包装消费者工厂，消费者工厂包含具体的consumer消费consumerProps参数，从topic里消费，该topic要和生产者的一致。 public ProducerRecord(String topic, K key, V value) { this(topic, (Integer)null, (Long)null, key, value, (Iterable)null); } public class KafkaConsumer { @KafkaListener(topics = &quot;topic&quot;) &nbsp; 编写第一个Demo 实现顺序 &nbsp; &nbsp;1,连接kafka服务器的配置 &nbsp; &nbsp; 2,kafka-customer:消费者配置 &nbsp; &nbsp; 3,kafka-provider:提供者配置 &nbsp; &nbsp; 4,KfkaUtils:根据topic发送消息 &nbsp; &nbsp; 5,消费者根据topic处理消息 创建消费者和生产者的Map配置 根据Map配置创建对应的消费者工厂(consumerFactory)和生产者工厂(producerFactory) 根据consumerFactory创建监听器的监听器工厂 根据producerFactory创建KafkaTemplate(Kafka操作类) 创建监听容器 一、精文章 先给你们瞄一眼项目结构，记得把Kafka 启动... &nbsp; 项目结构 创建KafkaConfiguration配置类 都是一些配置参数，具体的作用也在代码中写明了，值得注意的是，KafkaTemplate的类型为&lt;Integer,String&gt;，我们可以找kafkaTemplate的send方法，有多个重载方法，其中有个方法如下，key和data参数都为泛型，这其实就是对应着KafkaTemplate&lt;Integer,String&gt;。那具体有什么用呢，还记得我们的Topic中可以包含多个Partition(分区)吗，那我们如果不想手动指定发送到哪个分区，我们则可以利用key去实现。这里我们的key是Integer类型，template会根据 key 路由到对应的partition中，如果key存在对应的partitionID则发送到该partition中，否则由算法选择发送到哪个partition。 public ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, V data) { ProducerRecord&lt;K, V&gt; producerRecord = new ProducerRecord(topic, key, data); return this.doSend(producerRecord); } @Configuration @EnableKafka public class KafkaConfiguration { //ConcurrentKafkaListenerContainerFactory为创建Kafka监听器的工程类，这里只配置了消费者 @Bean public ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; kafkaListenerContainerFactory() { ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); return factory; } //根据consumerProps填写的参数创建消费者工厂 @Bean public ConsumerFactory&lt;Integer, String&gt; consumerFactory() { return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); } //根据senderProps填写的参数创建生产者工厂 @Bean public ProducerFactory&lt;Integer, String&gt; producerFactory() { return new DefaultKafkaProducerFactory&lt;&gt;(senderProps()); } //kafkaTemplate实现了Kafka发送接收等功能 @Bean public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { KafkaTemplate template = new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); return template; } //消费者配置参数 private Map&lt;String, Object&gt; consumerProps() { Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //GroupID props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;bootKafka&quot;); //是否自动提交 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true); //自动提交的频率 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); //Session超时设置 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); //键的反序列化方式 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); //值的反序列化方式 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); return props; } //生产者配置 private Map&lt;String, Object&gt; senderProps (){ Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //重试，0为不启用重试机制 props.put(ProducerConfig.RETRIES_CONFIG, 1); //控制批处理大小，单位为字节 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //批量发送，延迟为1毫秒，启用该功能能有效减少生产者发送消息次数，从而提高并发量 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); //生产者可以使用的总内存字节来缓冲等待发送到服务器的记录 props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024000); //键的序列化方式 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); //值的序列化方式 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; } } &nbsp; 创建DemoListener消费者 这里的消费者其实就是一个监听类，指定监听名为topic.quick.demo的Topic，consumerID为demo。 @Component public class DemoListener { private static final Logger log= LoggerFactory.getLogger(DemoListener.class); //声明consumerID为demo，监听topicName为topic.quick.demo的Topic @KafkaListener(id = &quot;demo&quot;, topics = &quot;topic.quick.demo&quot;) public void listen(String msgData) { log.info(&quot;demo receive : &quot;+msgData); } } &nbsp; 创建测试类 这里的send方法第一参数为TopicName，第二个参数则是发送的数据 @SpringBootTest @RunWith(SpringRunner.class) public class DemoTest { @Autowired private KafkaTemplate kafkaTemplate; @Test public void testDemo() throws InterruptedException { kafkaTemplate.send(&quot;topic.quick.demo&quot;, &quot;this is my first demo&quot;); //休眠5秒，为了使监听器有足够的时间监听到topic的数据 Thread.sleep(5000); } } 接下来直接运行这个测试方法，我们可以看到日志中输出了我们发送的消息，这就代表我们成功的消费了测试方法中发送的消息。 2018-09-06 17:26:20.850 INFO 6232 --- [ demo-0-C-1] com.viu.kafka.listen.DemoListener : demo receive : this is my first demo &nbsp; 启动项目 看清楚了是启动项目，不是测试类,我们来观察一下控制台的输出日志 首先这个是KafkaConsumer的配置信息，每个消费者都会输出该配置信息，配置太多就不做讲解了 2018-09-06 17:40:15.258 INFO 9944 --- [ main] o.a.k.clients.consumer.ConsumerConfig : ConsumerConfig values: auto.commit.interval.ms = 100 auto.offset.reset = latest bootstrap.servers = [localhost:9092] check.crcs = true client.id = connections.max.idle.ms = 540000 enable.auto.commit = true exclude.internal.topics = true fetch.max.bytes = 52428800 fetch.max.wait.ms = 500 fetch.min.bytes = 1 group.id = demo heartbeat.interval.ms = 3000 interceptor.classes = null internal.leave.group.on.close = true isolation.level = read_uncommitted key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer max.partition.fetch.bytes = 1048576 max.poll.interval.ms = 300000 max.poll.records = 500 metadata.max.age.ms = 300000 metric.reporters = [] metrics.num.samples = 2 metrics.recording.level = INFO metrics.sample.window.ms = 30000 partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor] receive.buffer.bytes = 65536 reconnect.backoff.max.ms = 1000 reconnect.backoff.ms = 50 request.timeout.ms = 305000 retry.backoff.ms = 100 sasl.jaas.config = null sasl.kerberos.kinit.cmd = /usr/bin/kinit sasl.kerberos.min.time.before.relogin = 60000 sasl.kerberos.service.name = null sasl.kerberos.ticket.renew.jitter = 0.05 sasl.kerberos.ticket.renew.window.factor = 0.8 sasl.mechanism = GSSAPI security.protocol = PLAINTEXT send.buffer.bytes = 131072 session.timeout.ms = 15000 ssl.cipher.suites = null ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1] ssl.endpoint.identification.algorithm = null ssl.key.password = null ssl.keymanager.algorithm = SunX509 ssl.keystore.location = null ssl.keystore.password = null ssl.keystore.type = JKS ssl.protocol = TLS ssl.provider = null ssl.secure.random.implementation = null ssl.trustmanager.algorithm = PKIX ssl.truststore.location = null ssl.truststore.password = null ssl.truststore.type = JKS value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka version : 1.0.2 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka commitId : 2a121f7b1d402825 这些日志就代表我们成功的创建了Consumer，由于没有做并发配置，所以现在为单个消费者模式，系统会做一个分配Partition的操作，也就是将某个Partition指定给某个消费者消费。 这里有个地方需要注意一下， 看到日志中有输出[Consumer clientId=consumer-1, groupId=demo]，我们之前在监听中@KafkaListener注解中配置的id=demo，怎么就变成了groupId=demo，这是因为@KafkaListener注解如果没有指定groupId这个属性的值，则会默认把id作为groupId。 2018-09-06 17:40:15.287 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Discovered group coordinator admin-PC:9092 (id: 2147483647 rack: null) 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Revoking previously assigned partitions [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.s.k.l.KafkaMessageListenerContainer : partitions revoked: [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] (Re-)joining group 2018-09-06 17:40:15.301 INFO 9944 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#39;&#39; 2018-09-06 17:40:15.302 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Successfully joined group with generation 33 2018-09-06 17:40:15.303 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Setting newly assigned partitions [topic.quick.demo-0] &nbsp; &nbsp; 结束 SpringBoot2.0已经提供了Kafka的自动配置，可以在application.properties文件中配置，我觉得更方便 &nbsp; 二、精文章 &nbsp; 提前启动zk，kafka，并且创建一个Topic [root@Basic kafka_2.11-1.1.0]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic&nbsp; 1 确保你的kafka能够访问，如果访问不了，需要打开外网访问。 config/server.properties advertised.listeners=PLAINTEXT://192.168.239.128:9092 1 Maven 依赖 &lt;dependency&gt; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &nbsp; &nbsp; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; 二、项目结构 为了更加体现实际开发需求，一般生产者都是在调用某些接口的服务处理完逻辑之后然后往kafka里面扔数据，然后有一个消费者不停的监控这个Topic，然后处理数据，所以这里把生产者作为一个接口，消费者放到kafka这个目录下，注意@Component注解，不然扫描不到@KafkaListener 三、具体实现代码 SpringBoot配置文件 application.yml spring: &nbsp; kafka: &nbsp; &nbsp; bootstrap-servers: 192.168.239.128:9092 &nbsp; &nbsp; producer: &nbsp; &nbsp; &nbsp; key-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; &nbsp; value-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; consumer: &nbsp; &nbsp; &nbsp; group-id: test &nbsp; &nbsp; &nbsp; enable-auto-commit: true &nbsp; &nbsp; &nbsp; auto-commit-interval: 1000 &nbsp; &nbsp; &nbsp; key-deserializer: org.apache.kafka.common.serialization.StringDeserializer &nbsp; &nbsp; &nbsp; value-deserializer: org.apache.kafka.common.serialization.StringDeserializer 生产者 package cn.saytime.web; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.kafka.core.KafkaTemplate; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** &nbsp;* 测试kafka生产者 &nbsp;*/ @RestController @RequestMapping(&quot;kafka&quot;) public class TestKafkaProducerController { &nbsp; &nbsp; @Autowired &nbsp; &nbsp; private KafkaTemplate&lt;String, String&gt; kafkaTemplate; &nbsp; &nbsp; @RequestMapping(&quot;send&quot;) &nbsp; &nbsp; public String send(String msg){ &nbsp; &nbsp; &nbsp; &nbsp; kafkaTemplate.send(&quot;test_topic&quot;, msg); &nbsp; &nbsp; &nbsp; &nbsp; return &quot;success&quot;; &nbsp; &nbsp; } } 消费者 这里的消费者会监听这个主题，有消息就会执行，不需要进行while(true) package cn.saytime.kafka; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; /** &nbsp;* kafka消费者测试 &nbsp;*/ @Component public class TestConsumer { &nbsp; &nbsp; @KafkaListener(topics = &quot;test_topic&quot;) &nbsp; &nbsp; public void listen (ConsumerRecord&lt;?, ?&gt; record) throws Exception { &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf(&quot;topic = %s, offset = %d, value = %s \n&quot;, record.topic(), record.offset(), record.value()); &nbsp; &nbsp; } } 项目启动类 package cn.saytime; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class TestApplication{ &nbsp; &nbsp; public static void main(String[] args) { &nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(TestApplication.class, args); &nbsp; &nbsp; } } 四、测试 运行项目，执行：http://localhost:8080/kafka/send?msg=hello 控制台输出： topic = test_topic, offset = 19, value = hello&nbsp; 1 为了体现消费者不止执行一次就结束，再调用一次接口：&nbsp; http://localhost:8080/kafka/send?msg=kafkatopic = test_topic, offset = 20, value = kafka&nbsp; 1 所以可以看到这里消费者实际上是不停的poll Topic数据的。 ---------------------&nbsp; 三、精文章 1.&nbsp; Apache Kafka是一个分布式流平台 1.1&nbsp; 流平台有三个关键功能： 发布和订阅流记录，类似于一个消息队列或企业消息系统 以一种容错的持久方式存储记录流 在流记录生成的时候就处理它们 1.2&nbsp; Kafka通常用于两大类应用： 构建实时流数据管道，在系统或应用程序之间可靠地获取数据 构建对数据流进行转换或输出的实时流媒体应用程序 1.3&nbsp; 有几个特别重要的概念： Kafka is run as a cluster on one or more servers that can span multiple datacenters. The Kafka cluster stores streams of records in categories called topics. Each record consists of a key, a value, and a timestamp. 　　Kafka作为集群运行在一个或多个可以跨多个数据中心的服务器上 　　从这句话表达了三个意思： Kafka是以集群方式运行的 集群中可以只有一台服务器，也有可能有多台服务器。也就是说，一台服务器也是一个集群，多台服务器也可以组成一个集群 这些服务器可以跨多个数据中心 　　Kafka集群按分类存储流记录，这个分类叫做主题 　　这句话表达了以下几个信息： 流记录是分类存储的，也就说记录是归类的 我们称这种分类为主题 简单地来讲，记录是按主题划分归类存储的 　　每个记录由一个键、一个值和一个时间戳组成 1.4&nbsp; Kafka有四个核心API： Producer API&nbsp;：允许应用发布一条流记录到一个或多个主题 Consumer API&nbsp;：允许应用订阅一个或多个主题，并处理流记录 Streams API&nbsp;：允许应用作为一个流处理器，从一个或多个主题那里消费输入流，并将输出流输出到一个或多个输出主题，从而有效地讲输入流转换为输出流 Connector API&nbsp;：允许将主题连接到已经存在的应用或者数据系统，以构建并允许可重用的生产者或消费者。例如，一个关系型数据库的连接器可能捕获到一张表的每一次变更 （画外音：我理解这四个核心API其实就是：发布、订阅、转换处理、从第三方采集数据。） 在Kafka中，客户端和服务器之间的通信是使用简单的、高性能的、与语言无关的TCP协议完成的。 2.&nbsp;&nbsp;Topics and Logs（主题和日志） 一个topic是一个分类，或者说是记录被发布的时候的一个名字（画外音：可以理解为记录要被发到哪儿去）。 在Kafka中，topic总是有多个订阅者，因此，一个topic可能有0个，1个或多个订阅该数据的消费者。 对于每个主题，Kafka集群维护一个分区日志，如下图所示： 每个分区都是一个有序的、不可变的记录序列，而且记录会不断的被追加，一条记录就是一个结构化的提交日志（a structured commit log）。 分区中的每条记录都被分配了一个连续的id号，这个id号被叫做offset（偏移量），这个偏移量唯一的标识出分区中的每条记录。（PS：如果把分区比作数据库表的话，那么偏移量就是主键） Kafka集群持久化所有已发布的记录，无论它们有没有被消费，记录被保留的时间是可以配置的。例如，如果保留策略被设置为两天，那么在记录发布后的两天内，可以使用它，之后将其丢弃以释放空间。在对数据大小方面，Kafka的性能是高效的，恒定常量级的，因此长时间存储数据不是问题。 事实上，唯一维护在每个消费者上的元数据是消费者在日志中的位置或者叫偏移量。偏移量是由消费者控制的：通常消费者在读取记录的时候会线性的增加它的偏移量，但是，事实上，由于位置（偏移量）是由消费者控制的，所有它可以按任意它喜欢的顺序消费记录。例如：一个消费者可以重置到一个较旧的偏移量来重新处理之前已经处理过的数据，或者跳转到最近的记录并从“现在”开始消费。 这种特性意味着消费者非常廉价————他们可以来来去去的消息而不会对集群或者其它消费者造成太大影响。 日志中的分区有几个用途。首先，它们允许日志的规模超出单个服务器的大小。每个独立分区都必须与宿主的服务器相匹配，但一个主题可能有多个分区，所以它可以处理任意数量的数据。第二，它们作为并行的单位——稍后再进一步。 （ 画外音：简单地来说，日志分区的作用有两个：一、日志的规模不再受限于单个服务器；二、分区意味着可以并行。 什么意思呢？主题建立在集群之上，每个主题维护了一个分区日志，顾名思义，日志是分区的；每个分区所在的服务器的资源（比如：CPU、内存、带宽、磁盘等）是有限的，如果不分区（可以理解为等同于只有一个）的话，必然受限于这个分区所在的服务器，那么多个分区的话就不一样了，就突破了这种限制，服务器可以随便加，分区也可以随便加。 ） 3.&nbsp;&nbsp;Distribution（分布） 日志的分区分布在集群中的服务器上，每个服务器处理数据，并且分区请求是共享的。每个分区被复制到多个服务器上以实现容错，到底复制到多少个服务器上是可以配置的。 Each partition is replicated across a configurable number of servers for fault tolerance. 每个分区都有一个服务器充当“leader”角色，并且有0个或者多个服务器作为“followers”。leader处理对这个分区的所有读和写请求，而followers被动的从leader那里复制数据。如果leader失败，followers中的其中一个会自动变成新的leader。每个服务器充当一些分区的“leader”的同时也是其它分区的“follower”，因此在整个集群中负载是均衡的。 也就是说，每个服务器既是“leader”也是“follower”。我们知道一个主题可能有多个分区，一个分区可能在一个服务器上也可能跨多个服务器，然而这并不以为着一台服务器上只有一个分区，是可能有多个分区的。每个分区中有一个服务器充当“leader”，其余是“follower”。leader负责处理这个它作为leader所负责的分区的所有读写请求，而该分区中的follow只是被动复制leader的数据。这个有点儿像HDFS中的副本机制。例如：分区-1有服务器A和B组成，A是leader，B是follower，有请求要往分区-1中写数据的时候就由A处理，然后A把刚才写的数据同步给B，这样的话正常请求相当于A和B的数据是一样的，都有分区-1的全部数据，如果A宕机了，B成为leader，接替A继续处理对分区-1的读写请求。 需要注意的是，分区是一个虚拟的概念，是一个逻辑单元。 4.&nbsp;&nbsp;Producers（生产者） 生产者发布数据到它们选择的主题中。生产者负责选择将记录投递到哪个主题的哪个分区中。要做这件事情，可以简单地用循环方式以到达负载均衡，或者根据一些语义分区函数（比如：基于记录中的某些key） 5.&nbsp;&nbsp;Consumers（消费者） 消费者用一个消费者组名来标识它们自己（PS：相当于给自己贴一个标签，标签的名字是组名，以表明自己属于哪个组），并且每一条发布到主题中的记录只会投递给每个订阅的消费者组中的其中一个消费者实例。消费者实例可能是单独的进程或者在单独的机器上。 如果所有的消费者实例都使用相同的消费者组，那么记录将会在这些消费者之间有效的负载均衡。 如果所有的消费者实例都使用不同的消费者组，那么每条记录将会广播给所有的消费者进程。 上图中其实那个Kafka Cluster换成Topic会更准确一些 一个Kafka集群有2个服务器，4个分区（P0-P3），有两个消费者组。组A中有2个消费者实例，组B中有4个消费者实例。 通常我们会发现，主题不会有太多的消费者组，每个消费者组是一个“逻辑订阅者”（以消费者组的名义订阅主题，而非以消费者实例的名义去订阅）。每个组由许多消费者实例组成，以实现可扩展性和容错。这仍然是发布/订阅，只不过订阅者是一个消费者群体，而非单个进程。 在Kafka中，这种消费方式是通过用日志中的分区除以使用者实例来实现的，这样可以保证在任意时刻每个消费者都是排它的消费，即“公平共享”。Kafka协议动态的处理维护组中的成员。如果有心的实例加入到组中，它们将从组中的其它成员那里接管一些分区；如果组中有一个实例死了，那么它的分区将会被分给其它实例。 （画外音：什么意思呢？举个例子，在上面的图中，4个分区，组A有2个消费者，组B有4个消费者，那么对A来讲组中的每个消费者负责4/2=2个分区，对组B来说组中的每个消费者负责4/4=1个分区，而且同一时间消息只能被组中的一个实例消费。如果组中的成员数量有变化，则重新分配。） Kafka只提供分区下的记录的总的顺序，而不提供主题下不同分区的总的顺序。每个分区结合按key划分数据的能力排序对大多数应用来说是足够的。然而，如果你需要主题下总的记录顺序，你可以只使用一个分区，这样做的做的话就意味着每个消费者组中只能有一个消费者实例。 6.&nbsp; 保证 在一个高级别的Kafka给出下列保证： 被一个生产者发送到指定主题分区的消息将会按照它们被发送的顺序追加到分区中。也就是说，如果记录M1和M2是被同一个生产者发送到同一个分区的，而且M1是先发送的，M2是后发送的，那么在分区中M1的偏移量一定比M2小，并且M1出现在日志中的位置更靠前。 一个消费者看到记录的顺序和它们在日志中存储的顺序是一样的。 对于一个副本因子是N的主题，我们可以容忍最多N-1个服务器失败，而不会丢失已经提交给日志的任何记录。 7.&nbsp; Spring Kafka Spring提供了一个“模板”作为发送消息的高级抽象。它也通过使用@KafkaListener注释和“监听器容器”提供对消息驱动POJOs的支持。这些库促进了依赖注入和声明式的使用。 7.1&nbsp; 纯Java方式 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.clients.producer.ProducerConfig; 6 import org.apache.kafka.common.serialization.IntegerDeserializer; 7 import org.apache.kafka.common.serialization.IntegerSerializer; 8 import org.apache.kafka.common.serialization.StringDeserializer; 9 import org.apache.kafka.common.serialization.StringSerializer; 10 import org.springframework.kafka.core.*; 11 import org.springframework.kafka.listener.KafkaMessageListenerContainer; 12 import org.springframework.kafka.listener.MessageListener; 13 import org.springframework.kafka.listener.config.ContainerProperties; 14 15 import java.util.HashMap; 16 import java.util.Map; 17 18 public class PureJavaDemo { 19 20 /** 21 * 生产者配置 22 */ 23 private static Map&lt;String, Object&gt; senderProps() { 24 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 25 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 26 props.put(ProducerConfig.RETRIES_CONFIG, 0); 27 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); 28 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 29 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 30 return props; 31 } 32 33 /** 34 * 消费者配置 35 */ 36 private static Map&lt;String, Object&gt; consumerProps() { 37 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 38 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 39 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hello&quot;); 40 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 41 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); 42 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); 43 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 44 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 45 return props; 46 } 47 48 /** 49 * 发送模板配置 50 */ 51 private static KafkaTemplate&lt;Integer, String&gt; createTemplate() { 52 Map&lt;String, Object&gt; senderProps = senderProps(); 53 ProducerFactory&lt;Integer, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(senderProps); 54 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = new KafkaTemplate&lt;&gt;(producerFactory); 55 return kafkaTemplate; 56 } 57 58 /** 59 * 消息监听器容器配置 60 */ 61 private static KafkaMessageListenerContainer&lt;Integer, String&gt; createContainer() { 62 Map&lt;String, Object&gt; consumerProps = consumerProps(); 63 ConsumerFactory&lt;Integer, String&gt; consumerFactory = new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps); 64 ContainerProperties containerProperties = new ContainerProperties(&quot;test&quot;); 65 KafkaMessageListenerContainer&lt;Integer, String&gt; container = new KafkaMessageListenerContainer&lt;&gt;(consumerFactory, containerProperties); 66 return container; 67 } 68 69 70 public static void main(String[] args) throws InterruptedException { 71 String topic1 = &quot;test&quot;; // 主题 72 73 KafkaMessageListenerContainer container = createContainer(); 74 ContainerProperties containerProperties = container.getContainerProperties(); 75 containerProperties.setMessageListener(new MessageListener&lt;Integer, String&gt;() { 76 @Override 77 public void onMessage(ConsumerRecord&lt;Integer, String&gt; record) { 78 System.out.println(&quot;Received: &quot; + record); 79 } 80 }); 81 container.setBeanName(&quot;testAuto&quot;); 82 83 container.start(); 84 85 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = createTemplate(); 86 kafkaTemplate.setDefaultTopic(topic1); 87 88 kafkaTemplate.sendDefault(0, &quot;foo&quot;); 89 kafkaTemplate.sendDefault(2, &quot;bar&quot;); 90 kafkaTemplate.sendDefault(0, &quot;baz&quot;); 91 kafkaTemplate.sendDefault(2, &quot;qux&quot;); 92 93 kafkaTemplate.flush(); 94 container.stop(); 95 96 System.out.println(&quot;结束&quot;); 97 } 98 99 } 运行结果： Received: ConsumerRecord(topic = test, partition = 0, offset = 67, CreateTime = 1533300970788, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = foo) Received: ConsumerRecord(topic = test, partition = 0, offset = 68, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = bar) Received: ConsumerRecord(topic = test, partition = 0, offset = 69, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = baz) Received: ConsumerRecord(topic = test, partition = 0, offset = 70, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = qux) 7.2&nbsp; 更简单一点儿，用SpringBoot 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.beans.factory.annotation.Autowired; 5 import org.springframework.boot.CommandLineRunner; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.annotation.KafkaListener; 9 import org.springframework.kafka.core.KafkaTemplate; 10 11 @Configuration 12 public class JavaConfigurationDemo { 13 14 @KafkaListener(topics = &quot;test&quot;) 15 public void listen(ConsumerRecord&lt;String, String&gt; record) { 16 System.out.println(&quot;收到消息: &quot; + record); 17 } 18 19 @Bean 20 public CommandLineRunner commandLineRunner() { 21 return new MyRunner(); 22 } 23 24 class MyRunner implements CommandLineRunner { 25 26 @Autowired 27 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 28 29 @Override 30 public void run(String... args) throws Exception { 31 kafkaTemplate.send(&quot;test&quot;, &quot;foo1&quot;); 32 kafkaTemplate.send(&quot;test&quot;, &quot;foo2&quot;); 33 kafkaTemplate.send(&quot;test&quot;, &quot;foo3&quot;); 34 kafkaTemplate.send(&quot;test&quot;, &quot;foo4&quot;); 35 } 36 } 37 } application.properties配置 spring.kafka.bootstrap-servers=192.168.101.5:9092 spring.kafka.consumer.group-id=world 8.&nbsp; 生产者 1 package com.cjs.example.send; 2 3 import org.apache.kafka.clients.producer.ProducerConfig; 4 import org.apache.kafka.common.serialization.IntegerSerializer; 5 import org.apache.kafka.common.serialization.StringSerializer; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.core.DefaultKafkaProducerFactory; 9 import org.springframework.kafka.core.KafkaTemplate; 10 import org.springframework.kafka.core.ProducerFactory; 11 12 import java.util.HashMap; 13 import java.util.Map; 14 15 @Configuration 16 public class Config { 17 18 public Map&lt;String, Object&gt; producerConfigs() { 19 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 20 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 21 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 22 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 23 return props; 24 } 25 26 public ProducerFactory&lt;Integer, String&gt; producerFactory() { 27 return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs()); 28 } 29 30 @Bean 31 public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { 32 return new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); 33 } 34 35 } 1 package com.cjs.example.send; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.boot.CommandLineRunner; 5 import org.springframework.kafka.core.KafkaTemplate; 6 import org.springframework.kafka.support.SendResult; 7 import org.springframework.stereotype.Component; 8 import org.springframework.util.concurrent.ListenableFuture; 9 import org.springframework.util.concurrent.ListenableFutureCallback; 10 11 @Component 12 public class MyCommandLineRunner implements CommandLineRunner { 13 14 @Autowired 15 private KafkaTemplate&lt;Integer, String&gt; kafkaTemplate; 16 17 public void sendTo(Integer key, String value) { 18 ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; listenableFuture = kafkaTemplate.send(&quot;test&quot;, key, value); 19 listenableFuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() { 20 @Override 21 public void onFailure(Throwable throwable) { 22 System.out.println(&quot;发送失败啦&quot;); 23 throwable.printStackTrace(); 24 } 25 26 @Override 27 public void onSuccess(SendResult&lt;Integer, String&gt; sendResult) { 28 System.out.println(&quot;发送成功，&quot; + sendResult); 29 } 30 }); 31 } 32 33 @Override 34 public void run(String... args) throws Exception { 35 sendTo(1, &quot;aaa&quot;); 36 sendTo(2, &quot;bbb&quot;); 37 sendTo(3, &quot;ccc&quot;); 38 } 39 40 41 } 运行结果： 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=1, value=aaa, timestamp=null), recordMetadata=test-0@37] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=2, value=bbb, timestamp=null), recordMetadata=test-0@38] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=3, value=ccc, timestamp=null), recordMetadata=test-0@39] 9.&nbsp; 消费者@KafkaListener 1 package com.cjs.example.receive; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.common.serialization.IntegerDeserializer; 6 import org.apache.kafka.common.serialization.StringDeserializer; 7 import org.springframework.context.annotation.Bean; 8 import org.springframework.context.annotation.Configuration; 9 import org.springframework.kafka.annotation.KafkaListener; 10 import org.springframework.kafka.annotation.TopicPartition; 11 import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory; 12 import org.springframework.kafka.config.KafkaListenerContainerFactory; 13 import org.springframework.kafka.core.ConsumerFactory; 14 import org.springframework.kafka.core.DefaultKafkaConsumerFactory; 15 import org.springframework.kafka.listener.AbstractMessageListenerContainer; 16 import org.springframework.kafka.listener.ConcurrentMessageListenerContainer; 17 import org.springframework.kafka.listener.config.ContainerProperties; 18 import org.springframework.kafka.support.Acknowledgment; 19 import org.springframework.kafka.support.KafkaHeaders; 20 import org.springframework.messaging.handler.annotation.Header; 21 import org.springframework.messaging.handler.annotation.Payload; 22 23 import java.util.HashMap; 24 import java.util.List; 25 import java.util.Map; 26 27 @Configuration 28 public class Config2 { 29 30 @Bean 31 public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaListenerContainerFactory() { 32 ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); 33 factory.setConsumerFactory(consumerFactory()); 34 factory.setConcurrency(3); 35 ContainerProperties containerProperties = factory.getContainerProperties(); 36 containerProperties.setPollTimeout(2000); 37 // containerProperties.setAckMode(AbstractMessageListenerContainer.AckMode.MANUAL_IMMEDIATE); 38 return factory; 39 } 40 41 private ConsumerFactory&lt;Integer,String&gt; consumerFactory() { 42 return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); 43 } 44 45 private Map&lt;String, Object&gt; consumerProps() { 46 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 47 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 48 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hahaha&quot;); 49 // props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 50 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 51 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 52 return props; 53 } 54 55 56 @KafkaListener(topics = &quot;test&quot;) 57 public void listen(String data) { 58 System.out.println(&quot;listen 收到: &quot; + data); 59 } 60 61 62 @KafkaListener(topics = &quot;test&quot;, containerFactory = &quot;kafkaListenerContainerFactory&quot;) 63 public void listen2(String data, Acknowledgment ack) { 64 System.out.println(&quot;listen2 收到: &quot; + data); 65 ack.acknowledge(); 66 } 67 68 @KafkaListener(topicPartitions = {@TopicPartition(topic = &quot;test&quot;, partitions = &quot;0&quot;)}) 69 public void listen3(ConsumerRecord&lt;?, ?&gt; record) { 70 System.out.println(&quot;listen3 收到: &quot; + record.value()); 71 } 72 73 74 @KafkaListener(id = &quot;xyz&quot;, topics = &quot;test&quot;) 75 public void listen4(@Payload String foo, 76 @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) Integer key, 77 @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition, 78 @Header(KafkaHeaders.RECEIVED_TOPIC) String topic, 79 @Header(KafkaHeaders.OFFSET) List&lt;Long&gt; offsets) { 80 System.out.println(&quot;listen4 收到: &quot;); 81 System.out.println(foo); 82 System.out.println(key); 83 System.out.println(partition); 84 System.out.println(topic); 85 System.out.println(offsets); 86 } 87 88 } 9.1&nbsp; Committing Offsets 如果enable.auto.commit设置为true，那么kafka将自动提交offset。如果设置为false，则支持下列AckMode（确认模式）。 消费者poll()方法将返回一个或多个ConsumerRecords RECORD ：处理完记录以后，当监听器返回时，提交offset BATCH&nbsp; ：当对poll()返回的所有记录进行处理完以后，提交偏offset TIME&nbsp; &nbsp;：当对poll()返回的所有记录进行处理完以后，只要距离上一次提交已经过了ackTime时间后就提交 COUNT&nbsp; ：当poll()返回的所有记录都被处理时，只要从上次提交以来收到了ackCount条记录，就可以提交 COUNT_TIME ：和TIME以及COUNT类似，只要这两个中有一个为true，则提交 MANUAL ：消息监听器负责调用Acknowledgment.acknowledge()方法，此后和BATCH是一样的 MANUAL_IMMEDIATE ：当监听器调用Acknowledgment.acknowledge()方法后立即提交 10.&nbsp; Spring Boot Kafka 10.1&nbsp; application.properties spring.kafka.bootstrap-servers=192.168.101.5:9092 10.2&nbsp; 发送消息 1 package com.cjs.example; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.kafka.core.KafkaTemplate; 5 import org.springframework.web.bind.annotation.RequestMapping; 6 import org.springframework.web.bind.annotation.RestController; 7 8 import javax.annotation.Resource; 9 10 @RestController 11 @RequestMapping(&quot;/msg&quot;) 12 public class MessageController { 13 14 @Resource 15 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 16 17 @RequestMapping(&quot;/send&quot;) 18 public String send(String topic, String key, String value) { 19 kafkaTemplate.send(topic, key, value); 20 return &quot;ok&quot;; 21 } 22 23 } 10.3&nbsp; 接收消息 1 package com.cjs.example; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.kafka.annotation.KafkaListener; 5 import org.springframework.kafka.annotation.KafkaListeners; 6 import org.springframework.stereotype.Component; 7 8 @Component 9 public class MessageListener { 10 11 /** 12 * 监听订单消息 13 */ 14 @KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;) 15 public void listenToOrder(String data) { 16 System.out.println(&quot;收到订单消息：&quot; + data); 17 } 18 19 /** 20 * 监听会员消息 21 */ 22 @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;) 23 public void listenToMember(ConsumerRecord&lt;String, String&gt; record) { 24 System.out.println(&quot;收到会员消息：&quot; + record); 25 } 26 27 /** 28 * 监听所有消息 29 * 30 * 任意时刻，一条消息只会发给组中的一个消费者 31 * 32 * 消费者组中的成员数量不能超过分区数，这里分区数是1，因此订阅该主题的消费者组成员不能超过1 33 */ 34 // @KafkaListeners({@KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;), 35 // @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;)}) 36 // public void listenToAll(String data) { 37 // System.out.println(&quot;啊啊啊&quot;); 38 // } 39 40 } 11.&nbsp; pom.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.cjs.example&lt;/groupId&gt; &lt;artifactId&gt;cjs-kafka-example&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;cjs-kafka-example&lt;/name&gt; &lt;description&gt;&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 参考：https://www.jianshu.com/p/c9581f695d64 &nbsp; &nbsp;：https://blog.csdn.net/saytime/article/details/79950635&nbsp; &nbsp; &nbsp; &nbsp;https://www.cnblogs.com/cjsblog/p/9416380.html" />
<link rel="canonical" href="https://uzzz.org/2019/07/31/792789.html" />
<meta property="og:url" content="https://uzzz.org/2019/07/31/792789.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"参考了很多教程，最后精选了几篇，通俗易懂的 &nbsp; kafkaTemplate包装生产者工厂，生产者工厂包含具体的send发送senderProps参数，往topic里发， ConcurrentKafkaListenerContainerFactory监听器包装消费者工厂，消费者工厂包含具体的consumer消费consumerProps参数，从topic里消费，该topic要和生产者的一致。 public ProducerRecord(String topic, K key, V value) { this(topic, (Integer)null, (Long)null, key, value, (Iterable)null); } public class KafkaConsumer { @KafkaListener(topics = &quot;topic&quot;) &nbsp; 编写第一个Demo 实现顺序 &nbsp; &nbsp;1,连接kafka服务器的配置 &nbsp; &nbsp; 2,kafka-customer:消费者配置 &nbsp; &nbsp; 3,kafka-provider:提供者配置 &nbsp; &nbsp; 4,KfkaUtils:根据topic发送消息 &nbsp; &nbsp; 5,消费者根据topic处理消息 创建消费者和生产者的Map配置 根据Map配置创建对应的消费者工厂(consumerFactory)和生产者工厂(producerFactory) 根据consumerFactory创建监听器的监听器工厂 根据producerFactory创建KafkaTemplate(Kafka操作类) 创建监听容器 一、精文章 先给你们瞄一眼项目结构，记得把Kafka 启动... &nbsp; 项目结构 创建KafkaConfiguration配置类 都是一些配置参数，具体的作用也在代码中写明了，值得注意的是，KafkaTemplate的类型为&lt;Integer,String&gt;，我们可以找kafkaTemplate的send方法，有多个重载方法，其中有个方法如下，key和data参数都为泛型，这其实就是对应着KafkaTemplate&lt;Integer,String&gt;。那具体有什么用呢，还记得我们的Topic中可以包含多个Partition(分区)吗，那我们如果不想手动指定发送到哪个分区，我们则可以利用key去实现。这里我们的key是Integer类型，template会根据 key 路由到对应的partition中，如果key存在对应的partitionID则发送到该partition中，否则由算法选择发送到哪个partition。 public ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, V data) { ProducerRecord&lt;K, V&gt; producerRecord = new ProducerRecord(topic, key, data); return this.doSend(producerRecord); } @Configuration @EnableKafka public class KafkaConfiguration { //ConcurrentKafkaListenerContainerFactory为创建Kafka监听器的工程类，这里只配置了消费者 @Bean public ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; kafkaListenerContainerFactory() { ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); return factory; } //根据consumerProps填写的参数创建消费者工厂 @Bean public ConsumerFactory&lt;Integer, String&gt; consumerFactory() { return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); } //根据senderProps填写的参数创建生产者工厂 @Bean public ProducerFactory&lt;Integer, String&gt; producerFactory() { return new DefaultKafkaProducerFactory&lt;&gt;(senderProps()); } //kafkaTemplate实现了Kafka发送接收等功能 @Bean public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { KafkaTemplate template = new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); return template; } //消费者配置参数 private Map&lt;String, Object&gt; consumerProps() { Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //GroupID props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;bootKafka&quot;); //是否自动提交 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true); //自动提交的频率 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); //Session超时设置 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); //键的反序列化方式 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); //值的反序列化方式 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); return props; } //生产者配置 private Map&lt;String, Object&gt; senderProps (){ Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); //连接地址 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); //重试，0为不启用重试机制 props.put(ProducerConfig.RETRIES_CONFIG, 1); //控制批处理大小，单位为字节 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); //批量发送，延迟为1毫秒，启用该功能能有效减少生产者发送消息次数，从而提高并发量 props.put(ProducerConfig.LINGER_MS_CONFIG, 1); //生产者可以使用的总内存字节来缓冲等待发送到服务器的记录 props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024000); //键的序列化方式 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); //值的序列化方式 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; } } &nbsp; 创建DemoListener消费者 这里的消费者其实就是一个监听类，指定监听名为topic.quick.demo的Topic，consumerID为demo。 @Component public class DemoListener { private static final Logger log= LoggerFactory.getLogger(DemoListener.class); //声明consumerID为demo，监听topicName为topic.quick.demo的Topic @KafkaListener(id = &quot;demo&quot;, topics = &quot;topic.quick.demo&quot;) public void listen(String msgData) { log.info(&quot;demo receive : &quot;+msgData); } } &nbsp; 创建测试类 这里的send方法第一参数为TopicName，第二个参数则是发送的数据 @SpringBootTest @RunWith(SpringRunner.class) public class DemoTest { @Autowired private KafkaTemplate kafkaTemplate; @Test public void testDemo() throws InterruptedException { kafkaTemplate.send(&quot;topic.quick.demo&quot;, &quot;this is my first demo&quot;); //休眠5秒，为了使监听器有足够的时间监听到topic的数据 Thread.sleep(5000); } } 接下来直接运行这个测试方法，我们可以看到日志中输出了我们发送的消息，这就代表我们成功的消费了测试方法中发送的消息。 2018-09-06 17:26:20.850 INFO 6232 --- [ demo-0-C-1] com.viu.kafka.listen.DemoListener : demo receive : this is my first demo &nbsp; 启动项目 看清楚了是启动项目，不是测试类,我们来观察一下控制台的输出日志 首先这个是KafkaConsumer的配置信息，每个消费者都会输出该配置信息，配置太多就不做讲解了 2018-09-06 17:40:15.258 INFO 9944 --- [ main] o.a.k.clients.consumer.ConsumerConfig : ConsumerConfig values: auto.commit.interval.ms = 100 auto.offset.reset = latest bootstrap.servers = [localhost:9092] check.crcs = true client.id = connections.max.idle.ms = 540000 enable.auto.commit = true exclude.internal.topics = true fetch.max.bytes = 52428800 fetch.max.wait.ms = 500 fetch.min.bytes = 1 group.id = demo heartbeat.interval.ms = 3000 interceptor.classes = null internal.leave.group.on.close = true isolation.level = read_uncommitted key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer max.partition.fetch.bytes = 1048576 max.poll.interval.ms = 300000 max.poll.records = 500 metadata.max.age.ms = 300000 metric.reporters = [] metrics.num.samples = 2 metrics.recording.level = INFO metrics.sample.window.ms = 30000 partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor] receive.buffer.bytes = 65536 reconnect.backoff.max.ms = 1000 reconnect.backoff.ms = 50 request.timeout.ms = 305000 retry.backoff.ms = 100 sasl.jaas.config = null sasl.kerberos.kinit.cmd = /usr/bin/kinit sasl.kerberos.min.time.before.relogin = 60000 sasl.kerberos.service.name = null sasl.kerberos.ticket.renew.jitter = 0.05 sasl.kerberos.ticket.renew.window.factor = 0.8 sasl.mechanism = GSSAPI security.protocol = PLAINTEXT send.buffer.bytes = 131072 session.timeout.ms = 15000 ssl.cipher.suites = null ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1] ssl.endpoint.identification.algorithm = null ssl.key.password = null ssl.keymanager.algorithm = SunX509 ssl.keystore.location = null ssl.keystore.password = null ssl.keystore.type = JKS ssl.protocol = TLS ssl.provider = null ssl.secure.random.implementation = null ssl.trustmanager.algorithm = PKIX ssl.truststore.location = null ssl.truststore.password = null ssl.truststore.type = JKS value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka version : 1.0.2 2018-09-06 17:40:15.274 INFO 9944 --- [ main] o.a.kafka.common.utils.AppInfoParser : Kafka commitId : 2a121f7b1d402825 这些日志就代表我们成功的创建了Consumer，由于没有做并发配置，所以现在为单个消费者模式，系统会做一个分配Partition的操作，也就是将某个Partition指定给某个消费者消费。 这里有个地方需要注意一下， 看到日志中有输出[Consumer clientId=consumer-1, groupId=demo]，我们之前在监听中@KafkaListener注解中配置的id=demo，怎么就变成了groupId=demo，这是因为@KafkaListener注解如果没有指定groupId这个属性的值，则会默认把id作为groupId。 2018-09-06 17:40:15.287 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Discovered group coordinator admin-PC:9092 (id: 2147483647 rack: null) 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Revoking previously assigned partitions [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.s.k.l.KafkaMessageListenerContainer : partitions revoked: [] 2018-09-06 17:40:15.290 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] (Re-)joining group 2018-09-06 17:40:15.301 INFO 9944 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#39;&#39; 2018-09-06 17:40:15.302 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-1, groupId=demo] Successfully joined group with generation 33 2018-09-06 17:40:15.303 INFO 9944 --- [ demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-1, groupId=demo] Setting newly assigned partitions [topic.quick.demo-0] &nbsp; &nbsp; 结束 SpringBoot2.0已经提供了Kafka的自动配置，可以在application.properties文件中配置，我觉得更方便 &nbsp; 二、精文章 &nbsp; 提前启动zk，kafka，并且创建一个Topic [root@Basic kafka_2.11-1.1.0]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic&nbsp; 1 确保你的kafka能够访问，如果访问不了，需要打开外网访问。 config/server.properties advertised.listeners=PLAINTEXT://192.168.239.128:9092 1 Maven 依赖 &lt;dependency&gt; &nbsp; &nbsp; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &nbsp; &nbsp; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; 二、项目结构 为了更加体现实际开发需求，一般生产者都是在调用某些接口的服务处理完逻辑之后然后往kafka里面扔数据，然后有一个消费者不停的监控这个Topic，然后处理数据，所以这里把生产者作为一个接口，消费者放到kafka这个目录下，注意@Component注解，不然扫描不到@KafkaListener 三、具体实现代码 SpringBoot配置文件 application.yml spring: &nbsp; kafka: &nbsp; &nbsp; bootstrap-servers: 192.168.239.128:9092 &nbsp; &nbsp; producer: &nbsp; &nbsp; &nbsp; key-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; &nbsp; value-serializer: org.apache.kafka.common.serialization.StringSerializer &nbsp; &nbsp; consumer: &nbsp; &nbsp; &nbsp; group-id: test &nbsp; &nbsp; &nbsp; enable-auto-commit: true &nbsp; &nbsp; &nbsp; auto-commit-interval: 1000 &nbsp; &nbsp; &nbsp; key-deserializer: org.apache.kafka.common.serialization.StringDeserializer &nbsp; &nbsp; &nbsp; value-deserializer: org.apache.kafka.common.serialization.StringDeserializer 生产者 package cn.saytime.web; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.kafka.core.KafkaTemplate; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** &nbsp;* 测试kafka生产者 &nbsp;*/ @RestController @RequestMapping(&quot;kafka&quot;) public class TestKafkaProducerController { &nbsp; &nbsp; @Autowired &nbsp; &nbsp; private KafkaTemplate&lt;String, String&gt; kafkaTemplate; &nbsp; &nbsp; @RequestMapping(&quot;send&quot;) &nbsp; &nbsp; public String send(String msg){ &nbsp; &nbsp; &nbsp; &nbsp; kafkaTemplate.send(&quot;test_topic&quot;, msg); &nbsp; &nbsp; &nbsp; &nbsp; return &quot;success&quot;; &nbsp; &nbsp; } } 消费者 这里的消费者会监听这个主题，有消息就会执行，不需要进行while(true) package cn.saytime.kafka; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; /** &nbsp;* kafka消费者测试 &nbsp;*/ @Component public class TestConsumer { &nbsp; &nbsp; @KafkaListener(topics = &quot;test_topic&quot;) &nbsp; &nbsp; public void listen (ConsumerRecord&lt;?, ?&gt; record) throws Exception { &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf(&quot;topic = %s, offset = %d, value = %s \\n&quot;, record.topic(), record.offset(), record.value()); &nbsp; &nbsp; } } 项目启动类 package cn.saytime; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class TestApplication{ &nbsp; &nbsp; public static void main(String[] args) { &nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(TestApplication.class, args); &nbsp; &nbsp; } } 四、测试 运行项目，执行：http://localhost:8080/kafka/send?msg=hello 控制台输出： topic = test_topic, offset = 19, value = hello&nbsp; 1 为了体现消费者不止执行一次就结束，再调用一次接口：&nbsp; http://localhost:8080/kafka/send?msg=kafkatopic = test_topic, offset = 20, value = kafka&nbsp; 1 所以可以看到这里消费者实际上是不停的poll Topic数据的。 ---------------------&nbsp; 三、精文章 1.&nbsp; Apache Kafka是一个分布式流平台 1.1&nbsp; 流平台有三个关键功能： 发布和订阅流记录，类似于一个消息队列或企业消息系统 以一种容错的持久方式存储记录流 在流记录生成的时候就处理它们 1.2&nbsp; Kafka通常用于两大类应用： 构建实时流数据管道，在系统或应用程序之间可靠地获取数据 构建对数据流进行转换或输出的实时流媒体应用程序 1.3&nbsp; 有几个特别重要的概念： Kafka is run as a cluster on one or more servers that can span multiple datacenters. The Kafka cluster stores streams of records in categories called topics. Each record consists of a key, a value, and a timestamp. 　　Kafka作为集群运行在一个或多个可以跨多个数据中心的服务器上 　　从这句话表达了三个意思： Kafka是以集群方式运行的 集群中可以只有一台服务器，也有可能有多台服务器。也就是说，一台服务器也是一个集群，多台服务器也可以组成一个集群 这些服务器可以跨多个数据中心 　　Kafka集群按分类存储流记录，这个分类叫做主题 　　这句话表达了以下几个信息： 流记录是分类存储的，也就说记录是归类的 我们称这种分类为主题 简单地来讲，记录是按主题划分归类存储的 　　每个记录由一个键、一个值和一个时间戳组成 1.4&nbsp; Kafka有四个核心API： Producer API&nbsp;：允许应用发布一条流记录到一个或多个主题 Consumer API&nbsp;：允许应用订阅一个或多个主题，并处理流记录 Streams API&nbsp;：允许应用作为一个流处理器，从一个或多个主题那里消费输入流，并将输出流输出到一个或多个输出主题，从而有效地讲输入流转换为输出流 Connector API&nbsp;：允许将主题连接到已经存在的应用或者数据系统，以构建并允许可重用的生产者或消费者。例如，一个关系型数据库的连接器可能捕获到一张表的每一次变更 （画外音：我理解这四个核心API其实就是：发布、订阅、转换处理、从第三方采集数据。） 在Kafka中，客户端和服务器之间的通信是使用简单的、高性能的、与语言无关的TCP协议完成的。 2.&nbsp;&nbsp;Topics and Logs（主题和日志） 一个topic是一个分类，或者说是记录被发布的时候的一个名字（画外音：可以理解为记录要被发到哪儿去）。 在Kafka中，topic总是有多个订阅者，因此，一个topic可能有0个，1个或多个订阅该数据的消费者。 对于每个主题，Kafka集群维护一个分区日志，如下图所示： 每个分区都是一个有序的、不可变的记录序列，而且记录会不断的被追加，一条记录就是一个结构化的提交日志（a structured commit log）。 分区中的每条记录都被分配了一个连续的id号，这个id号被叫做offset（偏移量），这个偏移量唯一的标识出分区中的每条记录。（PS：如果把分区比作数据库表的话，那么偏移量就是主键） Kafka集群持久化所有已发布的记录，无论它们有没有被消费，记录被保留的时间是可以配置的。例如，如果保留策略被设置为两天，那么在记录发布后的两天内，可以使用它，之后将其丢弃以释放空间。在对数据大小方面，Kafka的性能是高效的，恒定常量级的，因此长时间存储数据不是问题。 事实上，唯一维护在每个消费者上的元数据是消费者在日志中的位置或者叫偏移量。偏移量是由消费者控制的：通常消费者在读取记录的时候会线性的增加它的偏移量，但是，事实上，由于位置（偏移量）是由消费者控制的，所有它可以按任意它喜欢的顺序消费记录。例如：一个消费者可以重置到一个较旧的偏移量来重新处理之前已经处理过的数据，或者跳转到最近的记录并从“现在”开始消费。 这种特性意味着消费者非常廉价————他们可以来来去去的消息而不会对集群或者其它消费者造成太大影响。 日志中的分区有几个用途。首先，它们允许日志的规模超出单个服务器的大小。每个独立分区都必须与宿主的服务器相匹配，但一个主题可能有多个分区，所以它可以处理任意数量的数据。第二，它们作为并行的单位——稍后再进一步。 （ 画外音：简单地来说，日志分区的作用有两个：一、日志的规模不再受限于单个服务器；二、分区意味着可以并行。 什么意思呢？主题建立在集群之上，每个主题维护了一个分区日志，顾名思义，日志是分区的；每个分区所在的服务器的资源（比如：CPU、内存、带宽、磁盘等）是有限的，如果不分区（可以理解为等同于只有一个）的话，必然受限于这个分区所在的服务器，那么多个分区的话就不一样了，就突破了这种限制，服务器可以随便加，分区也可以随便加。 ） 3.&nbsp;&nbsp;Distribution（分布） 日志的分区分布在集群中的服务器上，每个服务器处理数据，并且分区请求是共享的。每个分区被复制到多个服务器上以实现容错，到底复制到多少个服务器上是可以配置的。 Each partition is replicated across a configurable number of servers for fault tolerance. 每个分区都有一个服务器充当“leader”角色，并且有0个或者多个服务器作为“followers”。leader处理对这个分区的所有读和写请求，而followers被动的从leader那里复制数据。如果leader失败，followers中的其中一个会自动变成新的leader。每个服务器充当一些分区的“leader”的同时也是其它分区的“follower”，因此在整个集群中负载是均衡的。 也就是说，每个服务器既是“leader”也是“follower”。我们知道一个主题可能有多个分区，一个分区可能在一个服务器上也可能跨多个服务器，然而这并不以为着一台服务器上只有一个分区，是可能有多个分区的。每个分区中有一个服务器充当“leader”，其余是“follower”。leader负责处理这个它作为leader所负责的分区的所有读写请求，而该分区中的follow只是被动复制leader的数据。这个有点儿像HDFS中的副本机制。例如：分区-1有服务器A和B组成，A是leader，B是follower，有请求要往分区-1中写数据的时候就由A处理，然后A把刚才写的数据同步给B，这样的话正常请求相当于A和B的数据是一样的，都有分区-1的全部数据，如果A宕机了，B成为leader，接替A继续处理对分区-1的读写请求。 需要注意的是，分区是一个虚拟的概念，是一个逻辑单元。 4.&nbsp;&nbsp;Producers（生产者） 生产者发布数据到它们选择的主题中。生产者负责选择将记录投递到哪个主题的哪个分区中。要做这件事情，可以简单地用循环方式以到达负载均衡，或者根据一些语义分区函数（比如：基于记录中的某些key） 5.&nbsp;&nbsp;Consumers（消费者） 消费者用一个消费者组名来标识它们自己（PS：相当于给自己贴一个标签，标签的名字是组名，以表明自己属于哪个组），并且每一条发布到主题中的记录只会投递给每个订阅的消费者组中的其中一个消费者实例。消费者实例可能是单独的进程或者在单独的机器上。 如果所有的消费者实例都使用相同的消费者组，那么记录将会在这些消费者之间有效的负载均衡。 如果所有的消费者实例都使用不同的消费者组，那么每条记录将会广播给所有的消费者进程。 上图中其实那个Kafka Cluster换成Topic会更准确一些 一个Kafka集群有2个服务器，4个分区（P0-P3），有两个消费者组。组A中有2个消费者实例，组B中有4个消费者实例。 通常我们会发现，主题不会有太多的消费者组，每个消费者组是一个“逻辑订阅者”（以消费者组的名义订阅主题，而非以消费者实例的名义去订阅）。每个组由许多消费者实例组成，以实现可扩展性和容错。这仍然是发布/订阅，只不过订阅者是一个消费者群体，而非单个进程。 在Kafka中，这种消费方式是通过用日志中的分区除以使用者实例来实现的，这样可以保证在任意时刻每个消费者都是排它的消费，即“公平共享”。Kafka协议动态的处理维护组中的成员。如果有心的实例加入到组中，它们将从组中的其它成员那里接管一些分区；如果组中有一个实例死了，那么它的分区将会被分给其它实例。 （画外音：什么意思呢？举个例子，在上面的图中，4个分区，组A有2个消费者，组B有4个消费者，那么对A来讲组中的每个消费者负责4/2=2个分区，对组B来说组中的每个消费者负责4/4=1个分区，而且同一时间消息只能被组中的一个实例消费。如果组中的成员数量有变化，则重新分配。） Kafka只提供分区下的记录的总的顺序，而不提供主题下不同分区的总的顺序。每个分区结合按key划分数据的能力排序对大多数应用来说是足够的。然而，如果你需要主题下总的记录顺序，你可以只使用一个分区，这样做的做的话就意味着每个消费者组中只能有一个消费者实例。 6.&nbsp; 保证 在一个高级别的Kafka给出下列保证： 被一个生产者发送到指定主题分区的消息将会按照它们被发送的顺序追加到分区中。也就是说，如果记录M1和M2是被同一个生产者发送到同一个分区的，而且M1是先发送的，M2是后发送的，那么在分区中M1的偏移量一定比M2小，并且M1出现在日志中的位置更靠前。 一个消费者看到记录的顺序和它们在日志中存储的顺序是一样的。 对于一个副本因子是N的主题，我们可以容忍最多N-1个服务器失败，而不会丢失已经提交给日志的任何记录。 7.&nbsp; Spring Kafka Spring提供了一个“模板”作为发送消息的高级抽象。它也通过使用@KafkaListener注释和“监听器容器”提供对消息驱动POJOs的支持。这些库促进了依赖注入和声明式的使用。 7.1&nbsp; 纯Java方式 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.clients.producer.ProducerConfig; 6 import org.apache.kafka.common.serialization.IntegerDeserializer; 7 import org.apache.kafka.common.serialization.IntegerSerializer; 8 import org.apache.kafka.common.serialization.StringDeserializer; 9 import org.apache.kafka.common.serialization.StringSerializer; 10 import org.springframework.kafka.core.*; 11 import org.springframework.kafka.listener.KafkaMessageListenerContainer; 12 import org.springframework.kafka.listener.MessageListener; 13 import org.springframework.kafka.listener.config.ContainerProperties; 14 15 import java.util.HashMap; 16 import java.util.Map; 17 18 public class PureJavaDemo { 19 20 /** 21 * 生产者配置 22 */ 23 private static Map&lt;String, Object&gt; senderProps() { 24 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 25 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 26 props.put(ProducerConfig.RETRIES_CONFIG, 0); 27 props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); 28 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 29 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 30 return props; 31 } 32 33 /** 34 * 消费者配置 35 */ 36 private static Map&lt;String, Object&gt; consumerProps() { 37 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 38 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9093&quot;); 39 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hello&quot;); 40 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 41 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;); 42 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;15000&quot;); 43 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 44 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 45 return props; 46 } 47 48 /** 49 * 发送模板配置 50 */ 51 private static KafkaTemplate&lt;Integer, String&gt; createTemplate() { 52 Map&lt;String, Object&gt; senderProps = senderProps(); 53 ProducerFactory&lt;Integer, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(senderProps); 54 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = new KafkaTemplate&lt;&gt;(producerFactory); 55 return kafkaTemplate; 56 } 57 58 /** 59 * 消息监听器容器配置 60 */ 61 private static KafkaMessageListenerContainer&lt;Integer, String&gt; createContainer() { 62 Map&lt;String, Object&gt; consumerProps = consumerProps(); 63 ConsumerFactory&lt;Integer, String&gt; consumerFactory = new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps); 64 ContainerProperties containerProperties = new ContainerProperties(&quot;test&quot;); 65 KafkaMessageListenerContainer&lt;Integer, String&gt; container = new KafkaMessageListenerContainer&lt;&gt;(consumerFactory, containerProperties); 66 return container; 67 } 68 69 70 public static void main(String[] args) throws InterruptedException { 71 String topic1 = &quot;test&quot;; // 主题 72 73 KafkaMessageListenerContainer container = createContainer(); 74 ContainerProperties containerProperties = container.getContainerProperties(); 75 containerProperties.setMessageListener(new MessageListener&lt;Integer, String&gt;() { 76 @Override 77 public void onMessage(ConsumerRecord&lt;Integer, String&gt; record) { 78 System.out.println(&quot;Received: &quot; + record); 79 } 80 }); 81 container.setBeanName(&quot;testAuto&quot;); 82 83 container.start(); 84 85 KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = createTemplate(); 86 kafkaTemplate.setDefaultTopic(topic1); 87 88 kafkaTemplate.sendDefault(0, &quot;foo&quot;); 89 kafkaTemplate.sendDefault(2, &quot;bar&quot;); 90 kafkaTemplate.sendDefault(0, &quot;baz&quot;); 91 kafkaTemplate.sendDefault(2, &quot;qux&quot;); 92 93 kafkaTemplate.flush(); 94 container.stop(); 95 96 System.out.println(&quot;结束&quot;); 97 } 98 99 } 运行结果： Received: ConsumerRecord(topic = test, partition = 0, offset = 67, CreateTime = 1533300970788, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = foo) Received: ConsumerRecord(topic = test, partition = 0, offset = 68, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = bar) Received: ConsumerRecord(topic = test, partition = 0, offset = 69, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = baz) Received: ConsumerRecord(topic = test, partition = 0, offset = 70, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = qux) 7.2&nbsp; 更简单一点儿，用SpringBoot 1 package com.cjs.example.quickstart; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.beans.factory.annotation.Autowired; 5 import org.springframework.boot.CommandLineRunner; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.annotation.KafkaListener; 9 import org.springframework.kafka.core.KafkaTemplate; 10 11 @Configuration 12 public class JavaConfigurationDemo { 13 14 @KafkaListener(topics = &quot;test&quot;) 15 public void listen(ConsumerRecord&lt;String, String&gt; record) { 16 System.out.println(&quot;收到消息: &quot; + record); 17 } 18 19 @Bean 20 public CommandLineRunner commandLineRunner() { 21 return new MyRunner(); 22 } 23 24 class MyRunner implements CommandLineRunner { 25 26 @Autowired 27 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 28 29 @Override 30 public void run(String... args) throws Exception { 31 kafkaTemplate.send(&quot;test&quot;, &quot;foo1&quot;); 32 kafkaTemplate.send(&quot;test&quot;, &quot;foo2&quot;); 33 kafkaTemplate.send(&quot;test&quot;, &quot;foo3&quot;); 34 kafkaTemplate.send(&quot;test&quot;, &quot;foo4&quot;); 35 } 36 } 37 } application.properties配置 spring.kafka.bootstrap-servers=192.168.101.5:9092 spring.kafka.consumer.group-id=world 8.&nbsp; 生产者 1 package com.cjs.example.send; 2 3 import org.apache.kafka.clients.producer.ProducerConfig; 4 import org.apache.kafka.common.serialization.IntegerSerializer; 5 import org.apache.kafka.common.serialization.StringSerializer; 6 import org.springframework.context.annotation.Bean; 7 import org.springframework.context.annotation.Configuration; 8 import org.springframework.kafka.core.DefaultKafkaProducerFactory; 9 import org.springframework.kafka.core.KafkaTemplate; 10 import org.springframework.kafka.core.ProducerFactory; 11 12 import java.util.HashMap; 13 import java.util.Map; 14 15 @Configuration 16 public class Config { 17 18 public Map&lt;String, Object&gt; producerConfigs() { 19 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 20 props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 21 props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); 22 props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 23 return props; 24 } 25 26 public ProducerFactory&lt;Integer, String&gt; producerFactory() { 27 return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs()); 28 } 29 30 @Bean 31 public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() { 32 return new KafkaTemplate&lt;Integer, String&gt;(producerFactory()); 33 } 34 35 } 1 package com.cjs.example.send; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.boot.CommandLineRunner; 5 import org.springframework.kafka.core.KafkaTemplate; 6 import org.springframework.kafka.support.SendResult; 7 import org.springframework.stereotype.Component; 8 import org.springframework.util.concurrent.ListenableFuture; 9 import org.springframework.util.concurrent.ListenableFutureCallback; 10 11 @Component 12 public class MyCommandLineRunner implements CommandLineRunner { 13 14 @Autowired 15 private KafkaTemplate&lt;Integer, String&gt; kafkaTemplate; 16 17 public void sendTo(Integer key, String value) { 18 ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; listenableFuture = kafkaTemplate.send(&quot;test&quot;, key, value); 19 listenableFuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() { 20 @Override 21 public void onFailure(Throwable throwable) { 22 System.out.println(&quot;发送失败啦&quot;); 23 throwable.printStackTrace(); 24 } 25 26 @Override 27 public void onSuccess(SendResult&lt;Integer, String&gt; sendResult) { 28 System.out.println(&quot;发送成功，&quot; + sendResult); 29 } 30 }); 31 } 32 33 @Override 34 public void run(String... args) throws Exception { 35 sendTo(1, &quot;aaa&quot;); 36 sendTo(2, &quot;bbb&quot;); 37 sendTo(3, &quot;ccc&quot;); 38 } 39 40 41 } 运行结果： 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=1, value=aaa, timestamp=null), recordMetadata=test-0@37] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=2, value=bbb, timestamp=null), recordMetadata=test-0@38] 发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=3, value=ccc, timestamp=null), recordMetadata=test-0@39] 9.&nbsp; 消费者@KafkaListener 1 package com.cjs.example.receive; 2 3 import org.apache.kafka.clients.consumer.ConsumerConfig; 4 import org.apache.kafka.clients.consumer.ConsumerRecord; 5 import org.apache.kafka.common.serialization.IntegerDeserializer; 6 import org.apache.kafka.common.serialization.StringDeserializer; 7 import org.springframework.context.annotation.Bean; 8 import org.springframework.context.annotation.Configuration; 9 import org.springframework.kafka.annotation.KafkaListener; 10 import org.springframework.kafka.annotation.TopicPartition; 11 import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory; 12 import org.springframework.kafka.config.KafkaListenerContainerFactory; 13 import org.springframework.kafka.core.ConsumerFactory; 14 import org.springframework.kafka.core.DefaultKafkaConsumerFactory; 15 import org.springframework.kafka.listener.AbstractMessageListenerContainer; 16 import org.springframework.kafka.listener.ConcurrentMessageListenerContainer; 17 import org.springframework.kafka.listener.config.ContainerProperties; 18 import org.springframework.kafka.support.Acknowledgment; 19 import org.springframework.kafka.support.KafkaHeaders; 20 import org.springframework.messaging.handler.annotation.Header; 21 import org.springframework.messaging.handler.annotation.Payload; 22 23 import java.util.HashMap; 24 import java.util.List; 25 import java.util.Map; 26 27 @Configuration 28 public class Config2 { 29 30 @Bean 31 public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaListenerContainerFactory() { 32 ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); 33 factory.setConsumerFactory(consumerFactory()); 34 factory.setConcurrency(3); 35 ContainerProperties containerProperties = factory.getContainerProperties(); 36 containerProperties.setPollTimeout(2000); 37 // containerProperties.setAckMode(AbstractMessageListenerContainer.AckMode.MANUAL_IMMEDIATE); 38 return factory; 39 } 40 41 private ConsumerFactory&lt;Integer,String&gt; consumerFactory() { 42 return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps()); 43 } 44 45 private Map&lt;String, Object&gt; consumerProps() { 46 Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); 47 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.101.5:9092&quot;); 48 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;hahaha&quot;); 49 // props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); 50 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); 51 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 52 return props; 53 } 54 55 56 @KafkaListener(topics = &quot;test&quot;) 57 public void listen(String data) { 58 System.out.println(&quot;listen 收到: &quot; + data); 59 } 60 61 62 @KafkaListener(topics = &quot;test&quot;, containerFactory = &quot;kafkaListenerContainerFactory&quot;) 63 public void listen2(String data, Acknowledgment ack) { 64 System.out.println(&quot;listen2 收到: &quot; + data); 65 ack.acknowledge(); 66 } 67 68 @KafkaListener(topicPartitions = {@TopicPartition(topic = &quot;test&quot;, partitions = &quot;0&quot;)}) 69 public void listen3(ConsumerRecord&lt;?, ?&gt; record) { 70 System.out.println(&quot;listen3 收到: &quot; + record.value()); 71 } 72 73 74 @KafkaListener(id = &quot;xyz&quot;, topics = &quot;test&quot;) 75 public void listen4(@Payload String foo, 76 @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) Integer key, 77 @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition, 78 @Header(KafkaHeaders.RECEIVED_TOPIC) String topic, 79 @Header(KafkaHeaders.OFFSET) List&lt;Long&gt; offsets) { 80 System.out.println(&quot;listen4 收到: &quot;); 81 System.out.println(foo); 82 System.out.println(key); 83 System.out.println(partition); 84 System.out.println(topic); 85 System.out.println(offsets); 86 } 87 88 } 9.1&nbsp; Committing Offsets 如果enable.auto.commit设置为true，那么kafka将自动提交offset。如果设置为false，则支持下列AckMode（确认模式）。 消费者poll()方法将返回一个或多个ConsumerRecords RECORD ：处理完记录以后，当监听器返回时，提交offset BATCH&nbsp; ：当对poll()返回的所有记录进行处理完以后，提交偏offset TIME&nbsp; &nbsp;：当对poll()返回的所有记录进行处理完以后，只要距离上一次提交已经过了ackTime时间后就提交 COUNT&nbsp; ：当poll()返回的所有记录都被处理时，只要从上次提交以来收到了ackCount条记录，就可以提交 COUNT_TIME ：和TIME以及COUNT类似，只要这两个中有一个为true，则提交 MANUAL ：消息监听器负责调用Acknowledgment.acknowledge()方法，此后和BATCH是一样的 MANUAL_IMMEDIATE ：当监听器调用Acknowledgment.acknowledge()方法后立即提交 10.&nbsp; Spring Boot Kafka 10.1&nbsp; application.properties spring.kafka.bootstrap-servers=192.168.101.5:9092 10.2&nbsp; 发送消息 1 package com.cjs.example; 2 3 import org.springframework.beans.factory.annotation.Autowired; 4 import org.springframework.kafka.core.KafkaTemplate; 5 import org.springframework.web.bind.annotation.RequestMapping; 6 import org.springframework.web.bind.annotation.RestController; 7 8 import javax.annotation.Resource; 9 10 @RestController 11 @RequestMapping(&quot;/msg&quot;) 12 public class MessageController { 13 14 @Resource 15 private KafkaTemplate&lt;String, String&gt; kafkaTemplate; 16 17 @RequestMapping(&quot;/send&quot;) 18 public String send(String topic, String key, String value) { 19 kafkaTemplate.send(topic, key, value); 20 return &quot;ok&quot;; 21 } 22 23 } 10.3&nbsp; 接收消息 1 package com.cjs.example; 2 3 import org.apache.kafka.clients.consumer.ConsumerRecord; 4 import org.springframework.kafka.annotation.KafkaListener; 5 import org.springframework.kafka.annotation.KafkaListeners; 6 import org.springframework.stereotype.Component; 7 8 @Component 9 public class MessageListener { 10 11 /** 12 * 监听订单消息 13 */ 14 @KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;) 15 public void listenToOrder(String data) { 16 System.out.println(&quot;收到订单消息：&quot; + data); 17 } 18 19 /** 20 * 监听会员消息 21 */ 22 @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;) 23 public void listenToMember(ConsumerRecord&lt;String, String&gt; record) { 24 System.out.println(&quot;收到会员消息：&quot; + record); 25 } 26 27 /** 28 * 监听所有消息 29 * 30 * 任意时刻，一条消息只会发给组中的一个消费者 31 * 32 * 消费者组中的成员数量不能超过分区数，这里分区数是1，因此订阅该主题的消费者组成员不能超过1 33 */ 34 // @KafkaListeners({@KafkaListener(topics = &quot;ORDER&quot;, groupId = &quot;OrderGroup&quot;), 35 // @KafkaListener(topics = &quot;MEMBER&quot;, groupId = &quot;MemberGroup&quot;)}) 36 // public void listenToAll(String data) { 37 // System.out.println(&quot;啊啊啊&quot;); 38 // } 39 40 } 11.&nbsp; pom.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.cjs.example&lt;/groupId&gt; &lt;artifactId&gt;cjs-kafka-example&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;cjs-kafka-example&lt;/name&gt; &lt;description&gt;&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 参考：https://www.jianshu.com/p/c9581f695d64 &nbsp; &nbsp;：https://blog.csdn.net/saytime/article/details/79950635&nbsp; &nbsp; &nbsp; &nbsp;https://www.cnblogs.com/cjsblog/p/9416380.html","@type":"BlogPosting","url":"https://uzzz.org/2019/07/31/792789.html","headline":"spring boot中kafka教程","dateModified":"2019-07-31T00:00:00+08:00","datePublished":"2019-07-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/07/31/792789.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>spring boot中kafka教程</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h2><strong>参考了很多教程，最后精选了几篇，通俗易懂的</strong></h2> 
  <p>&nbsp;</p> 
  <p><strong>kafkaTemplate包装生产者工厂，</strong><strong>生产者工厂</strong><strong>包含具体的send发送senderProps参数</strong><strong>，往topic里发，</strong></p> 
  <p><strong>ConcurrentKafkaListenerContainerFactory监听器包装消费者工厂，消费者工厂包含具体的consumer消费consumerProps参数，从topic里消费，该topic要和生产者的一致。</strong></p> 
  <pre>
public ProducerRecord(String topic, K key, V value) {
    this(topic, (Integer)null, (Long)null, key, value, (Iterable)null);
}</pre> 
  <pre>
public class KafkaConsumer {</pre> 
  <pre>
   @KafkaListener(topics = "topic")</pre> 
  <p>&nbsp;</p> 
  <p>编写第一个Demo</p> 
  <p>实现顺序</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;1,连接kafka服务器的配置</p> 
  <p>&nbsp; &nbsp; 2,kafka-customer:消费者配置</p> 
  <p>&nbsp; &nbsp; 3,kafka-provider:提供者配置</p> 
  <p>&nbsp; &nbsp; 4,KfkaUtils:根据topic发送消息</p> 
  <p>&nbsp; &nbsp; 5,消费者根据topic处理消息</p> 
  <ol>
   <li>创建消费者和生产者的Map配置</li> 
   <li>根据Map配置创建对应的消费者工厂(consumerFactory)和生产者工厂(producerFactory)</li> 
   <li>根据consumerFactory创建监听器的监听器工厂</li> 
   <li>根据producerFactory创建KafkaTemplate(Kafka操作类)</li> 
   <li>创建监听容器</li> 
  </ol>
  <h3><strong>一、精文章</strong></h3> 
  <p>先给你们瞄一眼项目结构，记得把Kafka 启动...</p> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81NTUxOTI3LWNlMGQwZjQ0OTg4YWNiZDcucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy81MTcvZm9ybWF0L3dlYnA"></p> 
  <p>项目结构</p> 
  <p>创建KafkaConfiguration配置类</p> 
  <p>都是一些配置参数，具体的作用也在代码中写明了，值得注意的是，KafkaTemplate的类型为&lt;Integer,String&gt;，我们可以找kafkaTemplate的send方法，有多个重载方法，其中有个方法如下，key和data参数都为泛型，这其实就是对应着KafkaTemplate&lt;Integer,String&gt;。那具体有什么用呢，还记得我们的Topic中可以包含多个Partition(分区)吗，那我们如果不想手动指定发送到哪个分区，我们则可以利用key去实现。这里我们的key是Integer类型，template会根据 key 路由到对应的partition中，如果key存在对应的partitionID则发送到该partition中，否则由算法选择发送到哪个partition。</p> 
  <pre class="has">
<code>    public ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, V data) {
        ProducerRecord&lt;K, V&gt; producerRecord = new ProducerRecord(topic, key, data);
        return this.doSend(producerRecord);
    }
</code></pre> 
  <pre class="has">
<code>@Configuration
@EnableKafka
public class KafkaConfiguration {

    //ConcurrentKafkaListenerContainerFactory为创建Kafka监听器的工程类，这里只配置了消费者
    @Bean
    public ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }

    //根据consumerProps填写的参数创建消费者工厂
    @Bean
    public ConsumerFactory&lt;Integer, String&gt; consumerFactory() {
        return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps());
    }

    //根据senderProps填写的参数创建生产者工厂
    @Bean
    public ProducerFactory&lt;Integer, String&gt; producerFactory() {
        return new DefaultKafkaProducerFactory&lt;&gt;(senderProps());
    }

    //kafkaTemplate实现了Kafka发送接收等功能
    @Bean
    public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() {
        KafkaTemplate template = new KafkaTemplate&lt;Integer, String&gt;(producerFactory());
        return template;
    }

    //消费者配置参数
    private Map&lt;String, Object&gt; consumerProps() {
        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
        //连接地址
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        //GroupID
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "bootKafka");
        //是否自动提交
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
        //自动提交的频率
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "100");
        //Session超时设置
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "15000");
        //键的反序列化方式
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class);
        //值的反序列化方式
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        return props;
    }

    //生产者配置
    private Map&lt;String, Object&gt; senderProps (){
        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
        //连接地址
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        //重试，0为不启用重试机制
        props.put(ProducerConfig.RETRIES_CONFIG, 1);
        //控制批处理大小，单位为字节
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        //批量发送，延迟为1毫秒，启用该功能能有效减少生产者发送消息次数，从而提高并发量
        props.put(ProducerConfig.LINGER_MS_CONFIG, 1);
        //生产者可以使用的总内存字节来缓冲等待发送到服务器的记录
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024000);
        //键的序列化方式
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
        //值的序列化方式
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return props;
    }

}

</code></pre> 
  <p>&nbsp;</p> 
  <p>创建DemoListener消费者</p> 
  <p>这里的消费者其实就是一个监听类，指定监听名为topic.quick.demo的Topic，consumerID为demo。</p> 
  <pre class="has">
<code>@Component
public class DemoListener {

    private static final Logger log= LoggerFactory.getLogger(DemoListener.class);

    //声明consumerID为demo，监听topicName为topic.quick.demo的Topic
    @KafkaListener(id = "demo", topics = "topic.quick.demo")
    public void listen(String msgData) {
        log.info("demo receive : "+msgData);
    }
}

</code></pre> 
  <p>&nbsp;</p> 
  <p>创建测试类</p> 
  <p>这里的send方法第一参数为TopicName，第二个参数则是发送的数据</p> 
  <pre class="has">
<code>@SpringBootTest
@RunWith(SpringRunner.class)
public class DemoTest {

    @Autowired
    private KafkaTemplate kafkaTemplate;

    @Test
    public void testDemo() throws InterruptedException {
        kafkaTemplate.send("topic.quick.demo", "this is my first demo");
        //休眠5秒，为了使监听器有足够的时间监听到topic的数据
        Thread.sleep(5000);
    }
}
</code></pre> 
  <p>接下来直接运行这个测试方法，我们可以看到日志中输出了我们发送的消息，这就代表我们成功的消费了测试方法中发送的消息。</p> 
  <pre class="has">
<code>2018-09-06 17:26:20.850  INFO 6232 --- [     demo-0-C-1] com.viu.kafka.listen.DemoListener        : demo receive : this is my first demo
</code></pre> 
  <p>&nbsp;</p> 
  <p>启动项目</p> 
  <p>看清楚了是启动项目，不是测试类,我们来观察一下控制台的输出日志</p> 
  <p>首先这个是KafkaConsumer的配置信息，每个消费者都会输出该配置信息，配置太多就不做讲解了</p> 
  <pre class="has">
<code>2018-09-06 17:40:15.258  INFO 9944 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
    auto.commit.interval.ms = 100
    auto.offset.reset = latest
    bootstrap.servers = [localhost:9092]
    check.crcs = true
    client.id = 
    connections.max.idle.ms = 540000
    enable.auto.commit = true
    exclude.internal.topics = true
    fetch.max.bytes = 52428800
    fetch.max.wait.ms = 500
    fetch.min.bytes = 1
    group.id = demo
    heartbeat.interval.ms = 3000
    interceptor.classes = null
    internal.leave.group.on.close = true
    isolation.level = read_uncommitted
    key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    max.partition.fetch.bytes = 1048576
    max.poll.interval.ms = 300000
    max.poll.records = 500
    metadata.max.age.ms = 300000
    metric.reporters = []
    metrics.num.samples = 2
    metrics.recording.level = INFO
    metrics.sample.window.ms = 30000
    partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
    receive.buffer.bytes = 65536
    reconnect.backoff.max.ms = 1000
    reconnect.backoff.ms = 50
    request.timeout.ms = 305000
    retry.backoff.ms = 100
    sasl.jaas.config = null
    sasl.kerberos.kinit.cmd = /usr/bin/kinit
    sasl.kerberos.min.time.before.relogin = 60000
    sasl.kerberos.service.name = null
    sasl.kerberos.ticket.renew.jitter = 0.05
    sasl.kerberos.ticket.renew.window.factor = 0.8
    sasl.mechanism = GSSAPI
    security.protocol = PLAINTEXT
    send.buffer.bytes = 131072
    session.timeout.ms = 15000
    ssl.cipher.suites = null
    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
    ssl.endpoint.identification.algorithm = null
    ssl.key.password = null
    ssl.keymanager.algorithm = SunX509
    ssl.keystore.location = null
    ssl.keystore.password = null
    ssl.keystore.type = JKS
    ssl.protocol = TLS
    ssl.provider = null
    ssl.secure.random.implementation = null
    ssl.trustmanager.algorithm = PKIX
    ssl.truststore.location = null
    ssl.truststore.password = null
    ssl.truststore.type = JKS
    value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-06 17:40:15.274  INFO 9944 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.0.2
2018-09-06 17:40:15.274  INFO 9944 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 2a121f7b1d402825
</code></pre> 
  <p><br><br> 这些日志就代表我们成功的创建了Consumer，由于没有做并发配置，所以现在为单个消费者模式，系统会做一个分配Partition的操作，也就是将某个Partition指定给某个消费者消费。 这里有个地方需要注意一下，<br> 看到日志中有输出[Consumer clientId=consumer-1, groupId=demo]，我们之前在监听中@KafkaListener注解中配置的id=demo，怎么就变成了groupId=demo，这是因为@KafkaListener注解如果没有指定groupId这个属性的值，则会默认把id作为groupId。</p> 
  <pre class="has">
<code>2018-09-06 17:40:15.287  INFO 9944 --- [     demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-1, groupId=demo] Discovered group coordinator admin-PC:9092 (id: 2147483647 rack: null)
2018-09-06 17:40:15.290  INFO 9944 --- [     demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-1, groupId=demo] Revoking previously assigned partitions []
2018-09-06 17:40:15.290  INFO 9944 --- [     demo-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2018-09-06 17:40:15.290  INFO 9944 --- [     demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-1, groupId=demo] (Re-)joining group
2018-09-06 17:40:15.301  INFO 9944 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2018-09-06 17:40:15.302  INFO 9944 --- [     demo-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-1, groupId=demo] Successfully joined group with generation 33
2018-09-06 17:40:15.303  INFO 9944 --- [     demo-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-1, groupId=demo] Setting newly assigned partitions [topic.quick.demo-0]
</code></pre> 
  <p><br> &nbsp;</p> 
  <hr>
  <p>&nbsp;</p> 
  <p>结束</p> 
  <p>SpringBoot2.0已经提供了Kafka的自动配置，可以在application.properties文件中配置，我觉得更方便</p> 
  <p><br><br> &nbsp;</p> 
  <h1><strong>二、精文章</strong></h1> 
  <p>&nbsp;</p> 
  <p>提前启动zk，kafka，并且创建一个Topic</p> 
  <p>[root@Basic kafka_2.11-1.1.0]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic&nbsp;<br> 1<br> 确保你的kafka能够访问，如果访问不了，需要打开外网访问。<br> config/server.properties</p> 
  <p>advertised.listeners=PLAINTEXT://192.168.239.128:9092<br> 1<br> Maven 依赖<br> &lt;dependency&gt;<br> &nbsp; &nbsp; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;<br> &nbsp; &nbsp; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;<br> &lt;/dependency&gt;<br><br> 二、项目结构<br> 为了更加体现实际开发需求，一般生产者都是在调用某些接口的服务处理完逻辑之后然后往kafka里面扔数据，然后有一个消费者不停的监控这个Topic，然后处理数据，所以这里把生产者作为一个接口，消费者放到kafka这个目录下，注意@Component注解，不然扫描不到@KafkaListener</p> 
  <p>三、具体实现代码<br> SpringBoot配置文件<br> application.yml</p> 
  <p>spring:<br> &nbsp; kafka:<br> &nbsp; &nbsp; bootstrap-servers: 192.168.239.128:9092<br> &nbsp; &nbsp; producer:<br> &nbsp; &nbsp; &nbsp; key-serializer: org.apache.kafka.common.serialization.StringSerializer<br> &nbsp; &nbsp; &nbsp; value-serializer: org.apache.kafka.common.serialization.StringSerializer<br> &nbsp; &nbsp; consumer:<br> &nbsp; &nbsp; &nbsp; group-id: test<br> &nbsp; &nbsp; &nbsp; enable-auto-commit: true<br> &nbsp; &nbsp; &nbsp; auto-commit-interval: 1000<br> &nbsp; &nbsp; &nbsp; key-deserializer: org.apache.kafka.common.serialization.StringDeserializer<br> &nbsp; &nbsp; &nbsp; value-deserializer: org.apache.kafka.common.serialization.StringDeserializer<br><br> 生产者<br> package cn.saytime.web;</p> 
  <p>import org.springframework.beans.factory.annotation.Autowired;<br> import org.springframework.kafka.core.KafkaTemplate;<br> import org.springframework.web.bind.annotation.RequestMapping;<br> import org.springframework.web.bind.annotation.RestController;</p> 
  <p>/**<br> &nbsp;* 测试kafka生产者<br> &nbsp;*/<br> @RestController<br> @RequestMapping("kafka")<br> public class TestKafkaProducerController {</p> 
  <p>&nbsp; &nbsp; @Autowired<br> &nbsp; &nbsp; private KafkaTemplate&lt;String, String&gt; kafkaTemplate;</p> 
  <p>&nbsp; &nbsp; @RequestMapping("send")<br> &nbsp; &nbsp; public String send(String msg){<br> &nbsp; &nbsp; &nbsp; &nbsp; kafkaTemplate.send("test_topic", msg);<br> &nbsp; &nbsp; &nbsp; &nbsp; return "success";<br> &nbsp; &nbsp; }</p> 
  <p>}<br><br> 消费者<br> 这里的消费者会监听这个主题，有消息就会执行，不需要进行while(true)</p> 
  <p>package cn.saytime.kafka;</p> 
  <p>import org.apache.kafka.clients.consumer.ConsumerRecord;<br> import org.springframework.kafka.annotation.KafkaListener;<br> import org.springframework.stereotype.Component;</p> 
  <p>/**<br> &nbsp;* kafka消费者测试<br> &nbsp;*/<br> @Component<br> public class TestConsumer {</p> 
  <p>&nbsp; &nbsp; @KafkaListener(topics = "test_topic")<br> &nbsp; &nbsp; public void listen (ConsumerRecord&lt;?, ?&gt; record) throws Exception {<br> &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("topic = %s, offset = %d, value = %s \n", record.topic(), record.offset(), record.value());<br> &nbsp; &nbsp; }<br> }<br><br> 项目启动类</p> 
  <p>package cn.saytime;</p> 
  <p>import org.springframework.boot.SpringApplication;<br> import org.springframework.boot.autoconfigure.SpringBootApplication;</p> 
  <p>@SpringBootApplication<br> public class TestApplication{</p> 
  <p>&nbsp; &nbsp; public static void main(String[] args) {<br> &nbsp; &nbsp; &nbsp; &nbsp; SpringApplication.run(TestApplication.class, args);<br> &nbsp; &nbsp; }<br> }<br><br> 四、测试<br> 运行项目，执行：http://localhost:8080/kafka/send?msg=hello</p> 
  <p>控制台输出：</p> 
  <p>topic = test_topic, offset = 19, value = hello&nbsp;<br> 1<br> 为了体现消费者不止执行一次就结束，再调用一次接口：&nbsp;<br> http://localhost:8080/kafka/send?msg=kafkatopic = test_topic, offset = 20, value = kafka&nbsp;<br> 1<br> 所以可以看到这里消费者实际上是不停的poll Topic数据的。<br> ---------------------&nbsp;</p> 
  <h1><strong>三、精文章</strong></h1> 
  <p><img alt="" class="has" height="579" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190731112627972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhb3poYW5nOTIz,size_16,color_FFFFFF,t_70" width="708"></p> 
  <p><strong>1.&nbsp; Apache Kafka是一个分布式流平台</strong></p> 
  <p><strong>1.1&nbsp; 流平台有三个关键功能：</strong></p> 
  <ol>
   <li>发布和订阅流记录，类似于一个消息队列或企业消息系统</li> 
   <li>以一种容错的持久方式存储记录流</li> 
   <li>在流记录生成的时候就处理它们</li> 
  </ol>
  <p><strong>1.2&nbsp; Kafka通常用于两大类应用：</strong></p> 
  <ol>
   <li>构建实时流数据管道，在系统或应用程序之间可靠地获取数据</li> 
   <li>构建对数据流进行转换或输出的实时流媒体应用程序</li> 
  </ol>
  <p><strong>1.3&nbsp; 有几个特别重要的概念：</strong></p> 
  <blockquote> 
   <p>Kafka is run as a cluster on one or more servers that can span multiple datacenters.</p> 
   <p>The Kafka cluster stores streams of records in categories called topics.</p> 
   <p>Each record consists of a key, a value, and a timestamp.</p> 
  </blockquote> 
  <p>　　Kafka作为集群运行在一个或多个可以跨多个数据中心的服务器上</p> 
  <p>　　从这句话表达了三个意思：</p> 
  <ol>
   <li>Kafka是以集群方式运行的</li> 
   <li>集群中可以只有一台服务器，也有可能有多台服务器。也就是说，一台服务器也是一个集群，多台服务器也可以组成一个集群</li> 
   <li>这些服务器可以跨多个数据中心</li> 
  </ol>
  <p>　　Kafka集群按分类存储流记录，这个分类叫做主题</p> 
  <p>　　这句话表达了以下几个信息：</p> 
  <ol>
   <li>流记录是分类存储的，也就说记录是归类的</li> 
   <li>我们称这种分类为主题</li> 
   <li>简单地来讲，记录是按主题划分归类存储的</li> 
  </ol>
  <p>　　每个记录由一个键、一个值和一个时间戳组成</p> 
  <p><strong>1.4&nbsp; Kafka有四个核心API：</strong></p> 
  <ul>
   <li><strong>Producer API</strong>&nbsp;：允许应用发布一条流记录到一个或多个主题</li> 
   <li><strong>Consumer API</strong>&nbsp;：允许应用订阅一个或多个主题，并处理流记录</li> 
   <li><strong>Streams API</strong>&nbsp;：允许应用作为一个流处理器，从一个或多个主题那里消费输入流，并将输出流输出到一个或多个输出主题，从而有效地讲输入流转换为输出流</li> 
   <li><strong>Connector API</strong>&nbsp;：允许将主题连接到已经存在的应用或者数据系统，以构建并允许可重用的生产者或消费者。例如，一个关系型数据库的连接器可能捕获到一张表的每一次变更</li> 
  </ul>
  <p>（画外音：我理解这四个核心API其实就是：发布、订阅、转换处理、从第三方采集数据。）</p> 
  <p>在Kafka中，客户端和服务器之间的通信是使用简单的、高性能的、与语言无关的TCP协议完成的。</p> 
  <p><strong>2.&nbsp;&nbsp;Topics and Logs（主题和日志）</strong></p> 
  <p>一个topic是一个分类，或者说是记录被发布的时候的一个名字（画外音：可以理解为记录要被发到哪儿去）。</p> 
  <p>在Kafka中，topic总是有多个订阅者，因此，一个topic可能有0个，1个或多个订阅该数据的消费者。</p> 
  <p>对于每个主题，Kafka集群维护一个分区日志，如下图所示：</p> 
  <p><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvODc0OTYzLzIwMTgwOC84NzQ5NjMtMjAxODA4MDMyMDM2NDA3NzUtNjkyNTA5NDc1LnBuZw"></p> 
  <p><strong>每个分区都是一个有序的、不可变的记录序列，而且记录会不断的被追加，一条记录就是一个结构化的提交日志（a structured commit log）。</strong></p> 
  <p><strong>分区中的每条记录都被分配了一个连续的id号，这个id号被叫做offset（偏移量），这个偏移量唯一的标识出分区中的每条记录。（PS：如果把分区比作数据库表的话，那么偏移量就是主键）</strong></p> 
  <p>Kafka集群持久化所有已发布的记录，无论它们有没有被消费，记录被保留的时间是可以配置的。例如，如果保留策略被设置为两天，那么在记录发布后的两天内，可以使用它，之后将其丢弃以释放空间。在对数据大小方面，Kafka的性能是高效的，恒定常量级的，因此长时间存储数据不是问题。</p> 
  <p><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvODc0OTYzLzIwMTgwOC84NzQ5NjMtMjAxODA4MDMyMDQxNTQyNTItNzgxMTE2NTQ1LnBuZw"></p> 
  <p>事实上，唯一维护在每个消费者上的元数据是消费者在日志中的位置或者叫偏移量。偏移量是由消费者控制的：通常消费者在读取记录的时候会线性的增加它的偏移量，但是，事实上，由于位置（偏移量）是由消费者控制的，所有它可以按任意它喜欢的顺序消费记录。例如：一个消费者可以重置到一个较旧的偏移量来重新处理之前已经处理过的数据，或者跳转到最近的记录并从“现在”开始消费。</p> 
  <p>这种特性意味着消费者非常廉价————他们可以来来去去的消息而不会对集群或者其它消费者造成太大影响。</p> 
  <p>日志中的分区有几个用途。首先，它们允许日志的规模超出单个服务器的大小。每个独立分区都必须与宿主的服务器相匹配，但一个主题可能有多个分区，所以它可以处理任意数量的数据。第二，它们作为并行的单位——稍后再进一步。</p> 
  <p>（</p> 
  <p>画外音：简单地来说，日志分区的作用有两个：一、日志的规模不再受限于单个服务器；二、分区意味着可以并行。</p> 
  <p>什么意思呢？主题建立在集群之上，每个主题维护了一个分区日志，顾名思义，日志是分区的；每个分区所在的服务器的资源（比如：CPU、内存、带宽、磁盘等）是有限的，如果不分区（可以理解为等同于只有一个）的话，必然受限于这个分区所在的服务器，那么多个分区的话就不一样了，就突破了这种限制，服务器可以随便加，分区也可以随便加。</p> 
  <p>）</p> 
  <p><strong>3.&nbsp;&nbsp;Distribution（分布）</strong></p> 
  <p>日志的分区分布在集群中的服务器上，每个服务器处理数据，并且分区请求是共享的。每个分区被复制到多个服务器上以实现容错，到底复制到多少个服务器上是可以配置的。</p> 
  <p>Each partition is replicated across a configurable number of servers for fault tolerance.</p> 
  <p>每个分区都有一个服务器充当“<strong>leader</strong>”角色，并且有0个或者多个服务器作为“<strong>followers</strong>”。<strong>leader</strong>处理对这个分区的所有读和写请求，而<strong>followers</strong>被动的从<strong>leader</strong>那里复制数据。如果<strong>leader</strong>失败，<strong>followers</strong>中的其中一个会自动变成新的<strong>leader</strong>。每个服务器充当一些分区的“<strong>leader</strong>”的同时也是其它分区的“<strong>follower</strong>”，因此在整个集群中负载是均衡的。</p> 
  <p>也就是说，每个服务器既是“<strong>leader</strong>”也是“<strong>follower</strong>”。我们知道一个主题可能有多个分区，一个分区可能在一个服务器上也可能跨多个服务器，然而这并不以为着一台服务器上只有一个分区，是可能有多个分区的。每个分区中有一个服务器充当“<strong>leader</strong>”，其余是“<strong>follower</strong>”。leader负责处理这个它作为<strong>leader</strong>所负责的分区的所有读写请求，而该分区中的<strong>follow</strong>只是被动复制<strong>leader</strong>的数据。这个有点儿像HDFS中的副本机制。例如：分区-1有服务器A和B组成，A是<strong>leader</strong>，B是<strong>follower</strong>，有请求要往分区-1中写数据的时候就由A处理，然后A把刚才写的数据同步给B，这样的话正常请求相当于A和B的数据是一样的，都有分区-1的全部数据，如果A宕机了，B成为<strong>leader</strong>，接替A继续处理对分区-1的读写请求。</p> 
  <p>需要注意的是，分区是一个虚拟的概念，是一个逻辑单元。</p> 
  <p><strong>4.&nbsp;&nbsp;Producers（生产者）</strong></p> 
  <p>生产者发布数据到它们选择的主题中。生产者负责选择将记录投递到哪个主题的哪个分区中。要做这件事情，可以简单地用循环方式以到达负载均衡，或者根据一些语义分区函数（比如：基于记录中的某些key）</p> 
  <p><strong>5.&nbsp;&nbsp;Consumers（消费者）</strong></p> 
  <p>消费者用一个消费者组名来标识它们自己（PS：相当于给自己贴一个标签，标签的名字是组名，以表明自己属于哪个组），并且每一条发布到主题中的记录只会投递给每个订阅的消费者组中的其中一个消费者实例。消费者实例可能是单独的进程或者在单独的机器上。</p> 
  <p>如果所有的消费者实例都使用相同的消费者组，那么记录将会在这些消费者之间有效的负载均衡。</p> 
  <p>如果所有的消费者实例都使用不同的消费者组，那么每条记录将会广播给所有的消费者进程。</p> 
  <p><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvODc0OTYzLzIwMTgwOC84NzQ5NjMtMjAxODA4MDMyMDQyMzk1NzMtMTMyNTMyMDE2NC5wbmc"></p> 
  <p>上图中其实那个Kafka Cluster换成Topic会更准确一些</p> 
  <p>一个Kafka集群有2个服务器，4个分区（P0-P3），有两个消费者组。组A中有2个消费者实例，组B中有4个消费者实例。<br> 通常我们会发现，主题不会有太多的消费者组，每个消费者组是一个“逻辑订阅者”（以消费者组的名义订阅主题，而非以消费者实例的名义去订阅）。每个组由许多消费者实例组成，以实现可扩展性和容错。这仍然是发布/订阅，只不过订阅者是一个消费者群体，而非单个进程。</p> 
  <p>在Kafka中，这种消费方式是通过用日志中的分区除以使用者实例来实现的，这样可以保证在任意时刻每个消费者都是排它的消费，即“公平共享”。Kafka协议动态的处理维护组中的成员。如果有心的实例加入到组中，它们将从组中的其它成员那里接管一些分区；如果组中有一个实例死了，那么它的分区将会被分给其它实例。</p> 
  <p>（画外音：什么意思呢？举个例子，在上面的图中，4个分区，组A有2个消费者，组B有4个消费者，那么对A来讲组中的每个消费者负责4/2=2个分区，对组B来说组中的每个消费者负责4/4=1个分区，而且同一时间消息只能被组中的一个实例消费。如果组中的成员数量有变化，则重新分配。）</p> 
  <p>Kafka只提供分区下的记录的总的顺序，而不提供主题下不同分区的总的顺序。每个分区结合按key划分数据的能力排序对大多数应用来说是足够的。然而，如果你需要主题下总的记录顺序，你可以只使用一个分区，这样做的做的话就意味着每个消费者组中只能有一个消费者实例。</p> 
  <p><strong>6.&nbsp; 保证</strong></p> 
  <p>在一个高级别的Kafka给出下列保证：</p> 
  <ol>
   <li>被一个生产者发送到指定主题分区的消息将会按照它们被发送的顺序追加到分区中。也就是说，如果记录M1和M2是被同一个生产者发送到同一个分区的，而且M1是先发送的，M2是后发送的，那么在分区中M1的偏移量一定比M2小，并且M1出现在日志中的位置更靠前。</li> 
   <li>一个消费者看到记录的顺序和它们在日志中存储的顺序是一样的。</li> 
   <li>对于一个副本因子是N的主题，我们可以容忍最多N-1个服务器失败，而不会丢失已经提交给日志的任何记录。</li> 
  </ol>
  <p><strong>7.&nbsp; Spring Kafka</strong></p> 
  <p>Spring提供了一个“模板”作为发送消息的高级抽象。它也通过使用@KafkaListener注释和“监听器容器”提供对消息驱动POJOs的支持。这些库促进了依赖注入和声明式的使用。</p> 
  <p><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvODc0OTYzLzIwMTgwOC84NzQ5NjMtMjAxODA4MDMyMTIyMTY5NjQtMjkxOTIwNzI3LnBuZw"></p> 
  <p><strong>7.1&nbsp; 纯Java方式</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example.quickstart;
 2 
 3 import org.apache.kafka.clients.consumer.ConsumerConfig;
 4 import org.apache.kafka.clients.consumer.ConsumerRecord;
 5 import org.apache.kafka.clients.producer.ProducerConfig;
 6 import org.apache.kafka.common.serialization.IntegerDeserializer;
 7 import org.apache.kafka.common.serialization.IntegerSerializer;
 8 import org.apache.kafka.common.serialization.StringDeserializer;
 9 import org.apache.kafka.common.serialization.StringSerializer;
10 import org.springframework.kafka.core.*;
11 import org.springframework.kafka.listener.KafkaMessageListenerContainer;
12 import org.springframework.kafka.listener.MessageListener;
13 import org.springframework.kafka.listener.config.ContainerProperties;
14 
15 import java.util.HashMap;
16 import java.util.Map;
17 
18 public class PureJavaDemo {
19 
20     /**
21      * 生产者配置
22      */
23     private static Map&lt;String, Object&gt; senderProps() {
24         Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
25         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.101.5:9093");
26         props.put(ProducerConfig.RETRIES_CONFIG, 0);
27         props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
28         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
29         props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
30         return props;
31     }
32 
33     /**
34      * 消费者配置
35      */
36     private static Map&lt;String, Object&gt; consumerProps() {
37         Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
38         props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.101.5:9093");
39         props.put(ConsumerConfig.GROUP_ID_CONFIG, "hello");
40         props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
41         props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "100");
42         props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "15000");
43         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class);
44         props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
45         return props;
46     }
47 
48     /**
49      * 发送模板配置
50      */
51     private static KafkaTemplate&lt;Integer, String&gt; createTemplate() {
52         Map&lt;String, Object&gt; senderProps = senderProps();
53         ProducerFactory&lt;Integer, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(senderProps);
54         KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = new KafkaTemplate&lt;&gt;(producerFactory);
55         return kafkaTemplate;
56     }
57 
58     /**
59      * 消息监听器容器配置
60      */
61     private static KafkaMessageListenerContainer&lt;Integer, String&gt; createContainer() {
62         Map&lt;String, Object&gt; consumerProps = consumerProps();
63         ConsumerFactory&lt;Integer, String&gt; consumerFactory = new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps);
64         ContainerProperties containerProperties = new ContainerProperties("test");
65         KafkaMessageListenerContainer&lt;Integer, String&gt; container = new KafkaMessageListenerContainer&lt;&gt;(consumerFactory, containerProperties);
66         return container;
67     }
68 
69 
70     public static void main(String[] args) throws InterruptedException {
71         String topic1 = "test"; //  主题
72 
73         KafkaMessageListenerContainer container = createContainer();
74         ContainerProperties containerProperties = container.getContainerProperties();
75         containerProperties.setMessageListener(new MessageListener&lt;Integer, String&gt;() {
76             @Override
77             public void onMessage(ConsumerRecord&lt;Integer, String&gt; record) {
78                 System.out.println("Received: " + record);
79             }
80         });
81         container.setBeanName("testAuto");
82 
83         container.start();
84 
85         KafkaTemplate&lt;Integer, String&gt; kafkaTemplate = createTemplate();
86         kafkaTemplate.setDefaultTopic(topic1);
87 
88         kafkaTemplate.sendDefault(0, "foo");
89         kafkaTemplate.sendDefault(2, "bar");
90         kafkaTemplate.sendDefault(0, "baz");
91         kafkaTemplate.sendDefault(2, "qux");
92 
93         kafkaTemplate.flush();
94         container.stop();
95 
96         System.out.println("结束");
97     }
98 
99 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p>运行结果：</p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
Received: ConsumerRecord(topic = test, partition = 0, offset = 67, CreateTime = 1533300970788, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = foo)
Received: ConsumerRecord(topic = test, partition = 0, offset = 68, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = bar)
Received: ConsumerRecord(topic = test, partition = 0, offset = 69, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = baz)
Received: ConsumerRecord(topic = test, partition = 0, offset = 70, CreateTime = 1533300970793, serialized key size = 4, serialized value size = 3, headers = RecordHeaders(headers = [], isReadOnly = false), key = 2, value = qux)</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p><strong>7.2&nbsp; 更简单一点儿，用SpringBoot</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example.quickstart;
 2 
 3 import org.apache.kafka.clients.consumer.ConsumerRecord;
 4 import org.springframework.beans.factory.annotation.Autowired;
 5 import org.springframework.boot.CommandLineRunner;
 6 import org.springframework.context.annotation.Bean;
 7 import org.springframework.context.annotation.Configuration;
 8 import org.springframework.kafka.annotation.KafkaListener;
 9 import org.springframework.kafka.core.KafkaTemplate;
10 
11 @Configuration
12 public class JavaConfigurationDemo {
13 
14     @KafkaListener(topics = "test")
15     public void listen(ConsumerRecord&lt;String, String&gt; record) {
16         System.out.println("收到消息: " + record);
17     }
18 
19     @Bean
20     public CommandLineRunner commandLineRunner() {
21         return new MyRunner();
22     }
23 
24     class MyRunner implements CommandLineRunner {
25 
26         @Autowired
27         private KafkaTemplate&lt;String, String&gt; kafkaTemplate;
28 
29         @Override
30         public void run(String... args) throws Exception {
31             kafkaTemplate.send("test", "foo1");
32             kafkaTemplate.send("test", "foo2");
33             kafkaTemplate.send("test", "foo3");
34             kafkaTemplate.send("test", "foo4");
35         }
36     }
37 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p>application.properties配置</p> 
  <pre>
spring.kafka.bootstrap-servers=192.168.101.5:9092
spring.kafka.consumer.group-id=world</pre> 
  <p><strong>8.&nbsp; 生产者</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example.send;
 2 
 3 import org.apache.kafka.clients.producer.ProducerConfig;
 4 import org.apache.kafka.common.serialization.IntegerSerializer;
 5 import org.apache.kafka.common.serialization.StringSerializer;
 6 import org.springframework.context.annotation.Bean;
 7 import org.springframework.context.annotation.Configuration;
 8 import org.springframework.kafka.core.DefaultKafkaProducerFactory;
 9 import org.springframework.kafka.core.KafkaTemplate;
10 import org.springframework.kafka.core.ProducerFactory;
11 
12 import java.util.HashMap;
13 import java.util.Map;
14 
15 @Configuration
16 public class Config {
17 
18     public Map&lt;String, Object&gt; producerConfigs() {
19         Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
20         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.101.5:9092");
21         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
22         props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
23         return props;
24     }
25 
26     public ProducerFactory&lt;Integer, String&gt; producerFactory() {
27         return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());
28     }
29 
30     @Bean
31     public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() {
32         return new KafkaTemplate&lt;Integer, String&gt;(producerFactory());
33     }
34 
35 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example.send;
 2 
 3 import org.springframework.beans.factory.annotation.Autowired;
 4 import org.springframework.boot.CommandLineRunner;
 5 import org.springframework.kafka.core.KafkaTemplate;
 6 import org.springframework.kafka.support.SendResult;
 7 import org.springframework.stereotype.Component;
 8 import org.springframework.util.concurrent.ListenableFuture;
 9 import org.springframework.util.concurrent.ListenableFutureCallback;
10 
11 @Component
12 public class MyCommandLineRunner implements CommandLineRunner {
13 
14     @Autowired
15     private KafkaTemplate&lt;Integer, String&gt; kafkaTemplate;
16 
17     public void sendTo(Integer key, String value) {
18         ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; listenableFuture = kafkaTemplate.send("test", key, value);
19         listenableFuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() {
20             @Override
21             public void onFailure(Throwable throwable) {
22                 System.out.println("发送失败啦");
23                 throwable.printStackTrace();
24             }
25 
26             @Override
27             public void onSuccess(SendResult&lt;Integer, String&gt; sendResult) {
28                 System.out.println("发送成功，" + sendResult);
29             }
30         });
31     }
32 
33     @Override
34     public void run(String... args) throws Exception {
35         sendTo(1, "aaa");
36         sendTo(2, "bbb");
37         sendTo(3, "ccc");
38     }
39 
40 
41 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p>运行结果：</p> 
  <pre>
发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=1, value=aaa, timestamp=null), recordMetadata=test-0@37]
发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=2, value=bbb, timestamp=null), recordMetadata=test-0@38]
发送成功，SendResult [producerRecord=ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=3, value=ccc, timestamp=null), recordMetadata=test-0@39]</pre> 
  <p><strong>9.&nbsp; 消费者@KafkaListener</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example.receive;
 2 
 3 import org.apache.kafka.clients.consumer.ConsumerConfig;
 4 import org.apache.kafka.clients.consumer.ConsumerRecord;
 5 import org.apache.kafka.common.serialization.IntegerDeserializer;
 6 import org.apache.kafka.common.serialization.StringDeserializer;
 7 import org.springframework.context.annotation.Bean;
 8 import org.springframework.context.annotation.Configuration;
 9 import org.springframework.kafka.annotation.KafkaListener;
10 import org.springframework.kafka.annotation.TopicPartition;
11 import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
12 import org.springframework.kafka.config.KafkaListenerContainerFactory;
13 import org.springframework.kafka.core.ConsumerFactory;
14 import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
15 import org.springframework.kafka.listener.AbstractMessageListenerContainer;
16 import org.springframework.kafka.listener.ConcurrentMessageListenerContainer;
17 import org.springframework.kafka.listener.config.ContainerProperties;
18 import org.springframework.kafka.support.Acknowledgment;
19 import org.springframework.kafka.support.KafkaHeaders;
20 import org.springframework.messaging.handler.annotation.Header;
21 import org.springframework.messaging.handler.annotation.Payload;
22 
23 import java.util.HashMap;
24 import java.util.List;
25 import java.util.Map;
26 
27 @Configuration
28 public class Config2 {
29 
30     @Bean
31     public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaListenerContainerFactory() {
32         ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;();
33         factory.setConsumerFactory(consumerFactory());
34         factory.setConcurrency(3);
35         ContainerProperties containerProperties = factory.getContainerProperties();
36         containerProperties.setPollTimeout(2000);
37 //        containerProperties.setAckMode(AbstractMessageListenerContainer.AckMode.MANUAL_IMMEDIATE);
38         return factory;
39     }
40 
41     private ConsumerFactory&lt;Integer,String&gt; consumerFactory() {
42         return new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps());
43     }
44 
45     private Map&lt;String, Object&gt; consumerProps() {
46         Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
47         props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.101.5:9092");
48         props.put(ConsumerConfig.GROUP_ID_CONFIG, "hahaha");
49 //        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
50         props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class);
51         props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
52         return props;
53     }
54 
55 
56     @KafkaListener(topics = "test")
57     public void listen(String data) {
58         System.out.println("listen 收到: " + data);
59     }
60 
61 
62     @KafkaListener(topics = "test", containerFactory = "kafkaListenerContainerFactory")
63     public void listen2(String data, Acknowledgment ack) {
64         System.out.println("listen2 收到: " + data);
65         ack.acknowledge();
66     }
67 
68     @KafkaListener(topicPartitions = {@TopicPartition(topic = "test", partitions = "0")})
69     public void listen3(ConsumerRecord&lt;?, ?&gt; record) {
70         System.out.println("listen3 收到: " + record.value());
71     }
72 
73 
74     @KafkaListener(id = "xyz", topics = "test")
75     public void listen4(@Payload String foo,
76                         @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) Integer key,
77                         @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition,
78                         @Header(KafkaHeaders.RECEIVED_TOPIC) String topic,
79                         @Header(KafkaHeaders.OFFSET) List&lt;Long&gt; offsets) {
80         System.out.println("listen4 收到: ");
81         System.out.println(foo);
82         System.out.println(key);
83         System.out.println(partition);
84         System.out.println(topic);
85         System.out.println(offsets);
86     }
87 
88 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p><strong>9.1&nbsp; Committing Offsets</strong></p> 
  <p>如果enable.auto.commit设置为true，那么kafka将自动提交offset。如果设置为false，则支持下列AckMode（确认模式）。</p> 
  <p>消费者poll()方法将返回一个或多个ConsumerRecords</p> 
  <ul>
   <li>RECORD ：处理完记录以后，当监听器返回时，提交offset</li> 
   <li>BATCH&nbsp; ：当对poll()返回的所有记录进行处理完以后，提交偏offset</li> 
   <li>TIME&nbsp; &nbsp;：当对poll()返回的所有记录进行处理完以后，只要距离上一次提交已经过了ackTime时间后就提交</li> 
   <li>COUNT&nbsp; ：当poll()返回的所有记录都被处理时，只要从上次提交以来收到了ackCount条记录，就可以提交</li> 
   <li>COUNT_TIME ：和TIME以及COUNT类似，只要这两个中有一个为true，则提交</li> 
   <li>MANUAL ：消息监听器负责调用Acknowledgment.acknowledge()方法，此后和BATCH是一样的</li> 
   <li>MANUAL_IMMEDIATE ：当监听器调用Acknowledgment.acknowledge()方法后立即提交</li> 
  </ul>
  <p><strong>10.&nbsp; Spring Boot Kafka</strong></p> 
  <p><strong>10.1&nbsp; application.properties</strong></p> 
  <pre>
spring.kafka.bootstrap-servers=192.168.101.5:9092</pre> 
  <p><strong>10.2&nbsp; 发送消息</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example;
 2 
 3 import org.springframework.beans.factory.annotation.Autowired;
 4 import org.springframework.kafka.core.KafkaTemplate;
 5 import org.springframework.web.bind.annotation.RequestMapping;
 6 import org.springframework.web.bind.annotation.RestController;
 7 
 8 import javax.annotation.Resource;
 9 
10 @RestController
11 @RequestMapping("/msg")
12 public class MessageController {
13 
14     @Resource
15     private KafkaTemplate&lt;String, String&gt; kafkaTemplate;
16 
17     @RequestMapping("/send")
18     public String send(String topic, String key, String value) {
19         kafkaTemplate.send(topic, key, value);
20         return "ok";
21     }
22 
23 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p><strong>10.3&nbsp; 接收消息</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
 1 package com.cjs.example;
 2 
 3 import org.apache.kafka.clients.consumer.ConsumerRecord;
 4 import org.springframework.kafka.annotation.KafkaListener;
 5 import org.springframework.kafka.annotation.KafkaListeners;
 6 import org.springframework.stereotype.Component;
 7 
 8 @Component
 9 public class MessageListener {
10 
11     /**
12      * 监听订单消息
13      */
14     @KafkaListener(topics = "ORDER", groupId = "OrderGroup")
15     public void listenToOrder(String data) {
16         System.out.println("收到订单消息：" + data);
17     }
18 
19     /**
20      * 监听会员消息
21      */
22     @KafkaListener(topics = "MEMBER", groupId = "MemberGroup")
23     public void listenToMember(ConsumerRecord&lt;String, String&gt; record) {
24         System.out.println("收到会员消息：" + record);
25     }
26 
27     /**
28      * 监听所有消息
29      *
30      * 任意时刻，一条消息只会发给组中的一个消费者
31      *
32      * 消费者组中的成员数量不能超过分区数，这里分区数是1，因此订阅该主题的消费者组成员不能超过1
33      */
34 //    @KafkaListeners({@KafkaListener(topics = "ORDER", groupId = "OrderGroup"),
35 //            @KafkaListener(topics = "MEMBER", groupId = "MemberGroup")})
36 //    public void listenToAll(String data) {
37 //        System.out.println("啊啊啊");
38 //    }
39 
40 }</pre> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <p><strong>11.&nbsp; pom.xml</strong></p> 
  <p><a><img alt="复制代码" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jb21tb24uY25ibG9ncy5jb20vaW1hZ2VzL2NvcHljb2RlLmdpZg"></a></p> 
  <pre>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cjs.example&lt;/groupId&gt;
    &lt;artifactId&gt;cjs-kafka-example&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;cjs-kafka-example&lt;/name&gt;
    &lt;description&gt;&lt;/description&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;
            &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;


&lt;/project&gt;</pre> 
  <p><br><br> 参考：https://www.jianshu.com/p/c9581f695d64<br> &nbsp; &nbsp;：https://blog.csdn.net/saytime/article/details/79950635&nbsp;</p> 
  <p>&nbsp; &nbsp; &nbsp;<a href="https://www.cnblogs.com/cjsblog/p/9416380.html" rel="nofollow" data-token="8c9766a57f607e725c49944fb112145e">https://www.cnblogs.com/cjsblog/p/9416380.html</a></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
