<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>ICLR 2019 Oral 论文 BigGAN 解读 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="ICLR 2019 Oral 论文 BigGAN 解读" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="简称：BigGAN 全称：Large Scale GAN Training for High Fidelity Natural Image Synthesis 来源：ICLR 2019 Oral 一、概述 （一）概要说一下 BigGAN 的研究背景： 到 BigGAN 提出为止，虽然 GANs 在图像生成领域取得了很多显著的成果，但是在学习像 ImageNet 这类复杂的数据集的能力还不够，并且生成高分辨率、多样性的图像样本的效果也不太理想。 （二）概要说一下 BigGAN 的研究目的： 合成具有更高分辨率、更加多样性的图像样本 （三）概要说一下 BigGAN 做的事情： （1）首先，BigGAN 在基线模型 SA-GANs 的基础上增加每个批次的数据量为原来的2、4、8倍，发现增大每个批次训练数据的数量能够带来更好的效果； （2）其次，增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍，同样发现能够得到更好的效果； （3）然后，为有效利用类别条件嵌入同时不增加参数数量，BigGANs 采用共享嵌入方法将类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度； （4）紧接，为了从潜空间采用的随机噪声向量 z 能够直接影响不同分辨率及层次结构级别下的特征，BigGANs 通过层次化潜在空间将随机噪声向量 z 输入到生成器的每一层，从而降低了内存和计算成本，主要是降低了第一个线性层的参数数量； （5）再次，BigGAN 研究工作探索了多种不同的随机噪声分布，并发现 {0,1} 伯努利分布和设限的正态分布(Censored Normal) 比从正态分布和均匀分布的效果更好，但由于截断技巧 比这两种分布的效果更好，而这两种分布并不适用截断技巧，因此 BigGAN 舍弃使用这两种分布而选择使用传统的正态分布，并通过截断技巧来权衡合成样本的保真度和多样性； （6）其后，通过正交正则化来解决一些较大模型使用截断技巧造成的饱和伪影问题，将生成器调节平滑，强制使其适应截断技巧，从而更有效利用整个随机噪声向量空间合成更高质量的样本； （7）最后，使用以上方法和技巧的虽然提高了模型的效果，但是模型在训练时也容易崩溃，所以在实际使用中需要采取提前停止训练的措施。针对这个问题，BigGANs 探索能够指示训练崩溃的度量指标，进一步分别研究和分析了生成器和判别器在大尺度下出现的不稳定性的原因，并提出了针对性的措施和解决方法。 （四）概览一下 BiGAN 的效果： （1）512 x 512分辨率合成图像的效果 （2）初始分数（Inception Score）与弗雷歇初始距离（FID）的效果 初始分数（IS） 弗雷歇初始距离（FID） 分辨率 真实图像 233 128*128 SAGAN 52.52 18.65 128*128 BigGAN 166.3 9.6 128*128 BigGAN 232.5 8.1 256*256 BigGAN 241.5 11.5 512*512 其中，初始分数（Inception Score，IS） 和弗雷歇初始距离（Fréchet Incepton Distance，FID）是目前评价 GANs 合成样本最常用的两个评价标准 初始分数（Inception Score，IS） 数值越大，GANs 合成的样本质量越高 弗雷歇初始距离（Fréchet Incepton Distance，FID）数值越小，GANs 合成的样本质量越高 二、核心方法 大批量 每个批次训练数据的数量增加到 2048 大通道 增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍 共享嵌入 类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度，而不是为每个嵌入分别设置单独一层，如下图： 层次化潜在空间 将随机噪声向量 z 对应不同的分辨率划分为多个块，然后将每一块随机噪声向量 z’ 与条件向量 c 连接在一起，再映射到 BatchNorm 层的权重和偏置，如上图： 截断技巧 通过重新采样数值高于选定阈值的值来截断 z z z 矢量，减小 z z z 的采样范围可以改善单个样品质量，但整体样品多样性，而增大 z z z 的采样范围可以降低单个样品质量，而提高整体样品多样性。因此，可以通过阶段技巧来对样本的保真度和多样性进行细粒度地调节。 正交正则化 一些较大的模型输入截断噪声向量 z z z 是会产生饱和伪影，如下图所示： 因此许多模型并不适合使用截断技巧。针对这种情况 BigGAN 通过正交正则化（Orthogonal Regularization）将 G 调节为平滑，强制使其适合使用截断技巧： R β ( W ) = β ∥ W T W ⊙ ( 1 − I ) ∥ F 2 R_{\beta}(W)=\beta\left\|W^{T}W\odot(\bm{1}-I)\right\|^{2}_{F} Rβ​(W)=β∥∥​WTW⊙(1−I)∥∥​F2​ 其中， W W W 为权重矩阵， β \beta β 为超参数， 1 \bm{1} 1 表示元素全为 1 的矩阵。 BigGAN 这里所采用的正交正则化方法与传统的正交正则化是有区别的，从正则化中删除对角线项，从而最小化滤波器之间的成对余弦相似性，但并不限制它们的范数。 生成器的不稳定性及对策 在 BigGAN 的大尺度批量和参数量的情况下，探索能够预示训练开始发生崩溃的标准，发现每一项权重的前三个最大的奇异值 σ 0 , σ 1 , σ 2 \sigma_{0},\sigma_{1},\sigma_{2} σ0​,σ1​,σ2​ 最具信息量来做这件事情，并研究对生成器强加额外的条件防止谱的突爆问题。 第一种方式，正则化每一项权重的最大奇异值 σ 0 \sigma_{0} σ0​：接近一个固定值 σ r e g \sigma_{reg} σreg​ 或第二大奇异值乘以某一比率 r ⋅ s g ( σ 1 ) r\cdot sg(\sigma_{1}) r⋅sg(σ1​)（其中，sg 表示停止梯度操作来防止正则化增加 σ 1 \sigma_{1} σ1​ ）。 第二种方式，或者采用偏奇异值分解（partial sigular value decomposition）来钳制 σ 0 \sigma_{0} σ0​。 给定权重 W W W，其第一个奇异向量为 μ 0 \mu_{0} μ0​ 和 v 0 v_{0} v0​， σ c l a m p \sigma_{clamp} σclamp​ 表示钳制 σ 0 \sigma_{0} σ0​ 的值，要么设置为 σ r e g \sigma_{reg} σreg​，要么设置为 r ⋅ s g ( σ 1 ) r\cdot sg(\sigma_{1}) r⋅sg(σ1​)，则权重被优化为： W = W − m a x ( 0 , σ 0 − σ c l a m p ) v 0 u 0 T W=W-max(0,\sigma_{0}-\sigma_{clamp})v_{0}u_{0}^{T} W=W−max(0,σ0​−σclamp​)v0​u0T​ 这样处理权重后的效果就是：不管使用不用谱归一化（Spectral Normalization），上述技术都能够防止 σ 0 \sigma_{0} σ0​ 或 σ 0 σ 1 \frac{\sigma_{0}}{\sigma_{1}} σ1​σ0​​ 的逐渐增加至爆炸。 但是文章也指出，在某情况下上述方法可以提高性能，但是并不能防止训练崩溃，这就表明调节生成器 G 可能改善稳定性，但并不足以保证稳定，因此将研究的关注点转到判别器上。 判别器的不稳定性及对策 分析 D 的权重的谱曲线（论文中图 3b），与 G 不同，D 的谱是嘈杂的， σ 0 σ 1 \frac{\sigma_{0}}{\sigma_{1}} σ1​σ0​​ 表现良好，并且奇异值在整个训练过程中一直增长，尽在崩溃时发生值跳跃而不是值爆炸。D 中谱出现的尖峰（spikes）噪声与训练不稳定有关，并探索 R 1 R_{1} R1​ 领中心梯度惩罚来显式地正则化 D 的雅克比行列式的变化： R 1 : = λ 2 E p D ( x ) [ ∥ ∇ D ( x ) ∥ F 2 ] R_{1} :=\frac{\lambda}{2} \mathbb{E}_{p_{\mathcal{D}}(x)}\left[\|\nabla D(x)\|_{F}^{2}\right] R1​:=2λ​EpD​(x)​[∥∇D(x)∥F2​] 通过降低惩罚强度 γ \gamma γ 来提高训练稳定性，但同样会导致 IS 值下降。通过设置不同强度的正交正则化、DropOut、L2 等正则化策略的试验都证明：惩罚 D 的力度足够大时，训练就变得稳定，但是会严重牺牲性能。 文章也通过在 ImageNet 上的训练与验证试验证明了 D 的损失在训练时趋于 0，但在崩溃时出现急剧增长的原因是 D 记忆了训练数据，但文章认为这符合 D 的角色，不显式地泛化，而是提炼训练数据并为生成器提供有用的训练信号。 三、实验 数据集 ImageNet ILSVRC 2012(128x128、256x256、512x512)、JFT-300M(更大、更复杂、更多样)、CIFAR-10(32323)图像超分辨率 结果 四、总结 BigGAN 最大的特色就是通过较大的批量数据以及较大的参数数量（增加通道数）来提高建模具有多种类别的复杂数据集（如 ImageNet），从而提高合成样本的质量（保真度和多样性）。 BigGAN 使用了很多技术和策略来提高合成样本的质量、平衡保真度与多样性、提高训练速度及稳定性等，整体来说是集现有 GANs 技术的一大作。 分析了在大规模配置下， GANs 的不稳定性的来源，是 G 和 D 在对抗训练过程中的相互作用，而不是单独地来源于 G 或 D。并发现通过对 D 施加很强的约束可以稳定训练。通过现有的技术，通过放松约束调节并允许训练后期阶段发生崩溃，可以实现更好的效果。 但 BigGANs 也存在一些不足：如：虽然大尺度提高合成样本的质量，但是也使模型容易不稳定，陷于完全崩溃的状态；虽然使用一些现有的策略和方法能够提高训练稳定，但不能彻底地避免崩溃；虽然对 D 施加较强的约束可以提高训练稳定性，但在性能上会造成很大的牺牲。 BigGAN 所采用的 batch_size = 2048 而取得的效果是是需要一定的硬件实力支撑的（BigGAN 的计算硬件：128 ~ 512 个核的 Google TPUv3 Pod） 五、源代码 作者正式非官方 PyTorch源码：https://github.com/ajbrock/BigGAN-PyTorch 六、附录 BigGAN 探索可用的潜空间： gongchang 正太分布： N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 均与分布： U [ − 1 , 1 ] \mathcal{U}[-1,1] U[−1,1] 伯努利分布：Bernoulli{0,1} 截取正太分布： m a x ( N ( 0 , I ) ) max(\mathcal{N}(0,I)) max(N(0,I)) − 1 , 0 , 1 {-1,0,1} −1,0,1独立类别，以相同概率采样 N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 乘以 Bernoulli{0,1} N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 连接 Bernoulli{0,1} 方差退火 N ( 0 , σ I ) \mathcal{N}(0,\sigma I) N(0,σI) 各样本可变方差： N ( 0 , σ i I ) \mathcal{N}(0,\sigma_{i} I) N(0,σi​I)，其中 σ i ∼ U [ σ l , σ h ] \sigma_{i}\sim\mathcal{U}[\sigma_{l},\sigma_{h}] σi​∼U[σl​,σh​] （未截止。。。待续。。。）" />
<meta property="og:description" content="简称：BigGAN 全称：Large Scale GAN Training for High Fidelity Natural Image Synthesis 来源：ICLR 2019 Oral 一、概述 （一）概要说一下 BigGAN 的研究背景： 到 BigGAN 提出为止，虽然 GANs 在图像生成领域取得了很多显著的成果，但是在学习像 ImageNet 这类复杂的数据集的能力还不够，并且生成高分辨率、多样性的图像样本的效果也不太理想。 （二）概要说一下 BigGAN 的研究目的： 合成具有更高分辨率、更加多样性的图像样本 （三）概要说一下 BigGAN 做的事情： （1）首先，BigGAN 在基线模型 SA-GANs 的基础上增加每个批次的数据量为原来的2、4、8倍，发现增大每个批次训练数据的数量能够带来更好的效果； （2）其次，增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍，同样发现能够得到更好的效果； （3）然后，为有效利用类别条件嵌入同时不增加参数数量，BigGANs 采用共享嵌入方法将类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度； （4）紧接，为了从潜空间采用的随机噪声向量 z 能够直接影响不同分辨率及层次结构级别下的特征，BigGANs 通过层次化潜在空间将随机噪声向量 z 输入到生成器的每一层，从而降低了内存和计算成本，主要是降低了第一个线性层的参数数量； （5）再次，BigGAN 研究工作探索了多种不同的随机噪声分布，并发现 {0,1} 伯努利分布和设限的正态分布(Censored Normal) 比从正态分布和均匀分布的效果更好，但由于截断技巧 比这两种分布的效果更好，而这两种分布并不适用截断技巧，因此 BigGAN 舍弃使用这两种分布而选择使用传统的正态分布，并通过截断技巧来权衡合成样本的保真度和多样性； （6）其后，通过正交正则化来解决一些较大模型使用截断技巧造成的饱和伪影问题，将生成器调节平滑，强制使其适应截断技巧，从而更有效利用整个随机噪声向量空间合成更高质量的样本； （7）最后，使用以上方法和技巧的虽然提高了模型的效果，但是模型在训练时也容易崩溃，所以在实际使用中需要采取提前停止训练的措施。针对这个问题，BigGANs 探索能够指示训练崩溃的度量指标，进一步分别研究和分析了生成器和判别器在大尺度下出现的不稳定性的原因，并提出了针对性的措施和解决方法。 （四）概览一下 BiGAN 的效果： （1）512 x 512分辨率合成图像的效果 （2）初始分数（Inception Score）与弗雷歇初始距离（FID）的效果 初始分数（IS） 弗雷歇初始距离（FID） 分辨率 真实图像 233 128*128 SAGAN 52.52 18.65 128*128 BigGAN 166.3 9.6 128*128 BigGAN 232.5 8.1 256*256 BigGAN 241.5 11.5 512*512 其中，初始分数（Inception Score，IS） 和弗雷歇初始距离（Fréchet Incepton Distance，FID）是目前评价 GANs 合成样本最常用的两个评价标准 初始分数（Inception Score，IS） 数值越大，GANs 合成的样本质量越高 弗雷歇初始距离（Fréchet Incepton Distance，FID）数值越小，GANs 合成的样本质量越高 二、核心方法 大批量 每个批次训练数据的数量增加到 2048 大通道 增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍 共享嵌入 类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度，而不是为每个嵌入分别设置单独一层，如下图： 层次化潜在空间 将随机噪声向量 z 对应不同的分辨率划分为多个块，然后将每一块随机噪声向量 z’ 与条件向量 c 连接在一起，再映射到 BatchNorm 层的权重和偏置，如上图： 截断技巧 通过重新采样数值高于选定阈值的值来截断 z z z 矢量，减小 z z z 的采样范围可以改善单个样品质量，但整体样品多样性，而增大 z z z 的采样范围可以降低单个样品质量，而提高整体样品多样性。因此，可以通过阶段技巧来对样本的保真度和多样性进行细粒度地调节。 正交正则化 一些较大的模型输入截断噪声向量 z z z 是会产生饱和伪影，如下图所示： 因此许多模型并不适合使用截断技巧。针对这种情况 BigGAN 通过正交正则化（Orthogonal Regularization）将 G 调节为平滑，强制使其适合使用截断技巧： R β ( W ) = β ∥ W T W ⊙ ( 1 − I ) ∥ F 2 R_{\beta}(W)=\beta\left\|W^{T}W\odot(\bm{1}-I)\right\|^{2}_{F} Rβ​(W)=β∥∥​WTW⊙(1−I)∥∥​F2​ 其中， W W W 为权重矩阵， β \beta β 为超参数， 1 \bm{1} 1 表示元素全为 1 的矩阵。 BigGAN 这里所采用的正交正则化方法与传统的正交正则化是有区别的，从正则化中删除对角线项，从而最小化滤波器之间的成对余弦相似性，但并不限制它们的范数。 生成器的不稳定性及对策 在 BigGAN 的大尺度批量和参数量的情况下，探索能够预示训练开始发生崩溃的标准，发现每一项权重的前三个最大的奇异值 σ 0 , σ 1 , σ 2 \sigma_{0},\sigma_{1},\sigma_{2} σ0​,σ1​,σ2​ 最具信息量来做这件事情，并研究对生成器强加额外的条件防止谱的突爆问题。 第一种方式，正则化每一项权重的最大奇异值 σ 0 \sigma_{0} σ0​：接近一个固定值 σ r e g \sigma_{reg} σreg​ 或第二大奇异值乘以某一比率 r ⋅ s g ( σ 1 ) r\cdot sg(\sigma_{1}) r⋅sg(σ1​)（其中，sg 表示停止梯度操作来防止正则化增加 σ 1 \sigma_{1} σ1​ ）。 第二种方式，或者采用偏奇异值分解（partial sigular value decomposition）来钳制 σ 0 \sigma_{0} σ0​。 给定权重 W W W，其第一个奇异向量为 μ 0 \mu_{0} μ0​ 和 v 0 v_{0} v0​， σ c l a m p \sigma_{clamp} σclamp​ 表示钳制 σ 0 \sigma_{0} σ0​ 的值，要么设置为 σ r e g \sigma_{reg} σreg​，要么设置为 r ⋅ s g ( σ 1 ) r\cdot sg(\sigma_{1}) r⋅sg(σ1​)，则权重被优化为： W = W − m a x ( 0 , σ 0 − σ c l a m p ) v 0 u 0 T W=W-max(0,\sigma_{0}-\sigma_{clamp})v_{0}u_{0}^{T} W=W−max(0,σ0​−σclamp​)v0​u0T​ 这样处理权重后的效果就是：不管使用不用谱归一化（Spectral Normalization），上述技术都能够防止 σ 0 \sigma_{0} σ0​ 或 σ 0 σ 1 \frac{\sigma_{0}}{\sigma_{1}} σ1​σ0​​ 的逐渐增加至爆炸。 但是文章也指出，在某情况下上述方法可以提高性能，但是并不能防止训练崩溃，这就表明调节生成器 G 可能改善稳定性，但并不足以保证稳定，因此将研究的关注点转到判别器上。 判别器的不稳定性及对策 分析 D 的权重的谱曲线（论文中图 3b），与 G 不同，D 的谱是嘈杂的， σ 0 σ 1 \frac{\sigma_{0}}{\sigma_{1}} σ1​σ0​​ 表现良好，并且奇异值在整个训练过程中一直增长，尽在崩溃时发生值跳跃而不是值爆炸。D 中谱出现的尖峰（spikes）噪声与训练不稳定有关，并探索 R 1 R_{1} R1​ 领中心梯度惩罚来显式地正则化 D 的雅克比行列式的变化： R 1 : = λ 2 E p D ( x ) [ ∥ ∇ D ( x ) ∥ F 2 ] R_{1} :=\frac{\lambda}{2} \mathbb{E}_{p_{\mathcal{D}}(x)}\left[\|\nabla D(x)\|_{F}^{2}\right] R1​:=2λ​EpD​(x)​[∥∇D(x)∥F2​] 通过降低惩罚强度 γ \gamma γ 来提高训练稳定性，但同样会导致 IS 值下降。通过设置不同强度的正交正则化、DropOut、L2 等正则化策略的试验都证明：惩罚 D 的力度足够大时，训练就变得稳定，但是会严重牺牲性能。 文章也通过在 ImageNet 上的训练与验证试验证明了 D 的损失在训练时趋于 0，但在崩溃时出现急剧增长的原因是 D 记忆了训练数据，但文章认为这符合 D 的角色，不显式地泛化，而是提炼训练数据并为生成器提供有用的训练信号。 三、实验 数据集 ImageNet ILSVRC 2012(128x128、256x256、512x512)、JFT-300M(更大、更复杂、更多样)、CIFAR-10(32323)图像超分辨率 结果 四、总结 BigGAN 最大的特色就是通过较大的批量数据以及较大的参数数量（增加通道数）来提高建模具有多种类别的复杂数据集（如 ImageNet），从而提高合成样本的质量（保真度和多样性）。 BigGAN 使用了很多技术和策略来提高合成样本的质量、平衡保真度与多样性、提高训练速度及稳定性等，整体来说是集现有 GANs 技术的一大作。 分析了在大规模配置下， GANs 的不稳定性的来源，是 G 和 D 在对抗训练过程中的相互作用，而不是单独地来源于 G 或 D。并发现通过对 D 施加很强的约束可以稳定训练。通过现有的技术，通过放松约束调节并允许训练后期阶段发生崩溃，可以实现更好的效果。 但 BigGANs 也存在一些不足：如：虽然大尺度提高合成样本的质量，但是也使模型容易不稳定，陷于完全崩溃的状态；虽然使用一些现有的策略和方法能够提高训练稳定，但不能彻底地避免崩溃；虽然对 D 施加较强的约束可以提高训练稳定性，但在性能上会造成很大的牺牲。 BigGAN 所采用的 batch_size = 2048 而取得的效果是是需要一定的硬件实力支撑的（BigGAN 的计算硬件：128 ~ 512 个核的 Google TPUv3 Pod） 五、源代码 作者正式非官方 PyTorch源码：https://github.com/ajbrock/BigGAN-PyTorch 六、附录 BigGAN 探索可用的潜空间： gongchang 正太分布： N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 均与分布： U [ − 1 , 1 ] \mathcal{U}[-1,1] U[−1,1] 伯努利分布：Bernoulli{0,1} 截取正太分布： m a x ( N ( 0 , I ) ) max(\mathcal{N}(0,I)) max(N(0,I)) − 1 , 0 , 1 {-1,0,1} −1,0,1独立类别，以相同概率采样 N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 乘以 Bernoulli{0,1} N ( 0 , I ) \mathcal{N}(0,I) N(0,I) 连接 Bernoulli{0,1} 方差退火 N ( 0 , σ I ) \mathcal{N}(0,\sigma I) N(0,σI) 各样本可变方差： N ( 0 , σ i I ) \mathcal{N}(0,\sigma_{i} I) N(0,σi​I)，其中 σ i ∼ U [ σ l , σ h ] \sigma_{i}\sim\mathcal{U}[\sigma_{l},\sigma_{h}] σi​∼U[σl​,σh​] （未截止。。。待续。。。）" />
<link rel="canonical" href="https://uzzz.org/2019/08/01/792490.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/01/792490.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-01T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"简称：BigGAN 全称：Large Scale GAN Training for High Fidelity Natural Image Synthesis 来源：ICLR 2019 Oral 一、概述 （一）概要说一下 BigGAN 的研究背景： 到 BigGAN 提出为止，虽然 GANs 在图像生成领域取得了很多显著的成果，但是在学习像 ImageNet 这类复杂的数据集的能力还不够，并且生成高分辨率、多样性的图像样本的效果也不太理想。 （二）概要说一下 BigGAN 的研究目的： 合成具有更高分辨率、更加多样性的图像样本 （三）概要说一下 BigGAN 做的事情： （1）首先，BigGAN 在基线模型 SA-GANs 的基础上增加每个批次的数据量为原来的2、4、8倍，发现增大每个批次训练数据的数量能够带来更好的效果； （2）其次，增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍，同样发现能够得到更好的效果； （3）然后，为有效利用类别条件嵌入同时不增加参数数量，BigGANs 采用共享嵌入方法将类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度； （4）紧接，为了从潜空间采用的随机噪声向量 z 能够直接影响不同分辨率及层次结构级别下的特征，BigGANs 通过层次化潜在空间将随机噪声向量 z 输入到生成器的每一层，从而降低了内存和计算成本，主要是降低了第一个线性层的参数数量； （5）再次，BigGAN 研究工作探索了多种不同的随机噪声分布，并发现 {0,1} 伯努利分布和设限的正态分布(Censored Normal) 比从正态分布和均匀分布的效果更好，但由于截断技巧 比这两种分布的效果更好，而这两种分布并不适用截断技巧，因此 BigGAN 舍弃使用这两种分布而选择使用传统的正态分布，并通过截断技巧来权衡合成样本的保真度和多样性； （6）其后，通过正交正则化来解决一些较大模型使用截断技巧造成的饱和伪影问题，将生成器调节平滑，强制使其适应截断技巧，从而更有效利用整个随机噪声向量空间合成更高质量的样本； （7）最后，使用以上方法和技巧的虽然提高了模型的效果，但是模型在训练时也容易崩溃，所以在实际使用中需要采取提前停止训练的措施。针对这个问题，BigGANs 探索能够指示训练崩溃的度量指标，进一步分别研究和分析了生成器和判别器在大尺度下出现的不稳定性的原因，并提出了针对性的措施和解决方法。 （四）概览一下 BiGAN 的效果： （1）512 x 512分辨率合成图像的效果 （2）初始分数（Inception Score）与弗雷歇初始距离（FID）的效果 初始分数（IS） 弗雷歇初始距离（FID） 分辨率 真实图像 233 128*128 SAGAN 52.52 18.65 128*128 BigGAN 166.3 9.6 128*128 BigGAN 232.5 8.1 256*256 BigGAN 241.5 11.5 512*512 其中，初始分数（Inception Score，IS） 和弗雷歇初始距离（Fréchet Incepton Distance，FID）是目前评价 GANs 合成样本最常用的两个评价标准 初始分数（Inception Score，IS） 数值越大，GANs 合成的样本质量越高 弗雷歇初始距离（Fréchet Incepton Distance，FID）数值越小，GANs 合成的样本质量越高 二、核心方法 大批量 每个批次训练数据的数量增加到 2048 大通道 增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍 共享嵌入 类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度，而不是为每个嵌入分别设置单独一层，如下图： 层次化潜在空间 将随机噪声向量 z 对应不同的分辨率划分为多个块，然后将每一块随机噪声向量 z’ 与条件向量 c 连接在一起，再映射到 BatchNorm 层的权重和偏置，如上图： 截断技巧 通过重新采样数值高于选定阈值的值来截断 z z z 矢量，减小 z z z 的采样范围可以改善单个样品质量，但整体样品多样性，而增大 z z z 的采样范围可以降低单个样品质量，而提高整体样品多样性。因此，可以通过阶段技巧来对样本的保真度和多样性进行细粒度地调节。 正交正则化 一些较大的模型输入截断噪声向量 z z z 是会产生饱和伪影，如下图所示： 因此许多模型并不适合使用截断技巧。针对这种情况 BigGAN 通过正交正则化（Orthogonal Regularization）将 G 调节为平滑，强制使其适合使用截断技巧： R β ( W ) = β ∥ W T W ⊙ ( 1 − I ) ∥ F 2 R_{\\beta}(W)=\\beta\\left\\|W^{T}W\\odot(\\bm{1}-I)\\right\\|^{2}_{F} Rβ​(W)=β∥∥​WTW⊙(1−I)∥∥​F2​ 其中， W W W 为权重矩阵， β \\beta β 为超参数， 1 \\bm{1} 1 表示元素全为 1 的矩阵。 BigGAN 这里所采用的正交正则化方法与传统的正交正则化是有区别的，从正则化中删除对角线项，从而最小化滤波器之间的成对余弦相似性，但并不限制它们的范数。 生成器的不稳定性及对策 在 BigGAN 的大尺度批量和参数量的情况下，探索能够预示训练开始发生崩溃的标准，发现每一项权重的前三个最大的奇异值 σ 0 , σ 1 , σ 2 \\sigma_{0},\\sigma_{1},\\sigma_{2} σ0​,σ1​,σ2​ 最具信息量来做这件事情，并研究对生成器强加额外的条件防止谱的突爆问题。 第一种方式，正则化每一项权重的最大奇异值 σ 0 \\sigma_{0} σ0​：接近一个固定值 σ r e g \\sigma_{reg} σreg​ 或第二大奇异值乘以某一比率 r ⋅ s g ( σ 1 ) r\\cdot sg(\\sigma_{1}) r⋅sg(σ1​)（其中，sg 表示停止梯度操作来防止正则化增加 σ 1 \\sigma_{1} σ1​ ）。 第二种方式，或者采用偏奇异值分解（partial sigular value decomposition）来钳制 σ 0 \\sigma_{0} σ0​。 给定权重 W W W，其第一个奇异向量为 μ 0 \\mu_{0} μ0​ 和 v 0 v_{0} v0​， σ c l a m p \\sigma_{clamp} σclamp​ 表示钳制 σ 0 \\sigma_{0} σ0​ 的值，要么设置为 σ r e g \\sigma_{reg} σreg​，要么设置为 r ⋅ s g ( σ 1 ) r\\cdot sg(\\sigma_{1}) r⋅sg(σ1​)，则权重被优化为： W = W − m a x ( 0 , σ 0 − σ c l a m p ) v 0 u 0 T W=W-max(0,\\sigma_{0}-\\sigma_{clamp})v_{0}u_{0}^{T} W=W−max(0,σ0​−σclamp​)v0​u0T​ 这样处理权重后的效果就是：不管使用不用谱归一化（Spectral Normalization），上述技术都能够防止 σ 0 \\sigma_{0} σ0​ 或 σ 0 σ 1 \\frac{\\sigma_{0}}{\\sigma_{1}} σ1​σ0​​ 的逐渐增加至爆炸。 但是文章也指出，在某情况下上述方法可以提高性能，但是并不能防止训练崩溃，这就表明调节生成器 G 可能改善稳定性，但并不足以保证稳定，因此将研究的关注点转到判别器上。 判别器的不稳定性及对策 分析 D 的权重的谱曲线（论文中图 3b），与 G 不同，D 的谱是嘈杂的， σ 0 σ 1 \\frac{\\sigma_{0}}{\\sigma_{1}} σ1​σ0​​ 表现良好，并且奇异值在整个训练过程中一直增长，尽在崩溃时发生值跳跃而不是值爆炸。D 中谱出现的尖峰（spikes）噪声与训练不稳定有关，并探索 R 1 R_{1} R1​ 领中心梯度惩罚来显式地正则化 D 的雅克比行列式的变化： R 1 : = λ 2 E p D ( x ) [ ∥ ∇ D ( x ) ∥ F 2 ] R_{1} :=\\frac{\\lambda}{2} \\mathbb{E}_{p_{\\mathcal{D}}(x)}\\left[\\|\\nabla D(x)\\|_{F}^{2}\\right] R1​:=2λ​EpD​(x)​[∥∇D(x)∥F2​] 通过降低惩罚强度 γ \\gamma γ 来提高训练稳定性，但同样会导致 IS 值下降。通过设置不同强度的正交正则化、DropOut、L2 等正则化策略的试验都证明：惩罚 D 的力度足够大时，训练就变得稳定，但是会严重牺牲性能。 文章也通过在 ImageNet 上的训练与验证试验证明了 D 的损失在训练时趋于 0，但在崩溃时出现急剧增长的原因是 D 记忆了训练数据，但文章认为这符合 D 的角色，不显式地泛化，而是提炼训练数据并为生成器提供有用的训练信号。 三、实验 数据集 ImageNet ILSVRC 2012(128x128、256x256、512x512)、JFT-300M(更大、更复杂、更多样)、CIFAR-10(32323)图像超分辨率 结果 四、总结 BigGAN 最大的特色就是通过较大的批量数据以及较大的参数数量（增加通道数）来提高建模具有多种类别的复杂数据集（如 ImageNet），从而提高合成样本的质量（保真度和多样性）。 BigGAN 使用了很多技术和策略来提高合成样本的质量、平衡保真度与多样性、提高训练速度及稳定性等，整体来说是集现有 GANs 技术的一大作。 分析了在大规模配置下， GANs 的不稳定性的来源，是 G 和 D 在对抗训练过程中的相互作用，而不是单独地来源于 G 或 D。并发现通过对 D 施加很强的约束可以稳定训练。通过现有的技术，通过放松约束调节并允许训练后期阶段发生崩溃，可以实现更好的效果。 但 BigGANs 也存在一些不足：如：虽然大尺度提高合成样本的质量，但是也使模型容易不稳定，陷于完全崩溃的状态；虽然使用一些现有的策略和方法能够提高训练稳定，但不能彻底地避免崩溃；虽然对 D 施加较强的约束可以提高训练稳定性，但在性能上会造成很大的牺牲。 BigGAN 所采用的 batch_size = 2048 而取得的效果是是需要一定的硬件实力支撑的（BigGAN 的计算硬件：128 ~ 512 个核的 Google TPUv3 Pod） 五、源代码 作者正式非官方 PyTorch源码：https://github.com/ajbrock/BigGAN-PyTorch 六、附录 BigGAN 探索可用的潜空间： gongchang 正太分布： N ( 0 , I ) \\mathcal{N}(0,I) N(0,I) 均与分布： U [ − 1 , 1 ] \\mathcal{U}[-1,1] U[−1,1] 伯努利分布：Bernoulli{0,1} 截取正太分布： m a x ( N ( 0 , I ) ) max(\\mathcal{N}(0,I)) max(N(0,I)) − 1 , 0 , 1 {-1,0,1} −1,0,1独立类别，以相同概率采样 N ( 0 , I ) \\mathcal{N}(0,I) N(0,I) 乘以 Bernoulli{0,1} N ( 0 , I ) \\mathcal{N}(0,I) N(0,I) 连接 Bernoulli{0,1} 方差退火 N ( 0 , σ I ) \\mathcal{N}(0,\\sigma I) N(0,σI) 各样本可变方差： N ( 0 , σ i I ) \\mathcal{N}(0,\\sigma_{i} I) N(0,σi​I)，其中 σ i ∼ U [ σ l , σ h ] \\sigma_{i}\\sim\\mathcal{U}[\\sigma_{l},\\sigma_{h}] σi​∼U[σl​,σh​] （未截止。。。待续。。。）","@type":"BlogPosting","url":"https://uzzz.org/2019/08/01/792490.html","headline":"ICLR 2019 Oral 论文 BigGAN 解读","dateModified":"2019-08-01T00:00:00+08:00","datePublished":"2019-08-01T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/01/792490.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>ICLR 2019 Oral 论文 BigGAN 解读</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p>简称：BigGAN</p> 
  <p>全称：Large Scale GAN Training for High Fidelity Natural Image Synthesis</p> 
  <p>来源：ICLR 2019 Oral</p> 
  <h4><a id="_6"></a>一、概述</h4> 
  <p><strong>（一）概要说一下 BigGAN 的研究背景：</strong><br> 到 BigGAN 提出为止，虽然 GANs 在图像生成领域取得了很多显著的成果，但是在学习像 ImageNet 这类复杂的数据集的能力还不够，并且生成高分辨率、多样性的图像样本的效果也不太理想。</p> 
  <p><strong>（二）概要说一下 BigGAN 的研究目的：</strong><br> 合成具有更高分辨率、更加多样性的图像样本</p> 
  <p><strong>（三）概要说一下 BigGAN 做的事情：</strong><br> （1）首先，BigGAN 在基线模型 SA-GANs 的基础上增加每个批次的数据量为原来的2、4、8倍，发现增大每个批次训练数据的数量能够带来更好的效果；<br> （2）其次，增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍，同样发现能够得到更好的效果；<br> （3）然后，为有效利用类别条件嵌入同时不增加参数数量，BigGANs 采用<font color="#FF0000"><strong>共享嵌入</strong></font>方法将类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度；<br> （4）紧接，为了从潜空间采用的随机噪声向量 z 能够直接影响不同分辨率及层次结构级别下的特征，BigGANs 通过<font color="#FF0000"><strong>层次化潜在空间</strong></font>将随机噪声向量 z 输入到生成器的每一层，从而降低了内存和计算成本，主要是降低了第一个线性层的参数数量；<br> （5）再次，BigGAN 研究工作探索了多种不同的随机噪声分布，并发现 {0,1} 伯努利分布和设限的正态分布(Censored Normal) 比从正态分布和均匀分布的效果更好，但由于<font color="#FF0000"><strong>截断技巧</strong></font> 比这两种分布的效果更好，而这两种分布并不适用截断技巧，因此 BigGAN 舍弃使用这两种分布而选择使用传统的正态分布，并通过截断技巧来权衡合成样本的保真度和多样性；<br> （6）其后，通过<font color="#FF0000"><strong>正交正则化</strong></font>来解决一些较大模型使用截断技巧造成的饱和伪影问题，将生成器调节平滑，强制使其适应截断技巧，从而更有效利用整个随机噪声向量空间合成更高质量的样本；<br> （7）最后，使用以上方法和技巧的虽然提高了模型的效果，但是模型在训练时也容易崩溃，所以在实际使用中需要采取提前停止训练的措施。针对这个问题，BigGANs 探索能够指示训练崩溃的度量指标，进一步分别研究和分析了生成器和判别器在大尺度下出现的不稳定性的原因，并提出了针对性的措施和解决方法。</p> 
  <p><strong>（四）概览一下 BiGAN 的效果：</strong><br> <strong>（1）512 x 512分辨率合成图像的效果</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801222449640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkbnV3anc=,size_16,color_FFFFFF,t_70" width="100%" alt=""></p> 
  <p><strong>（2）初始分数（Inception Score）与弗雷歇初始距离（FID）的效果</strong></p> 
  <table> 
   <thead> 
    <tr> 
     <th></th> 
     <th>初始分数（IS）</th> 
     <th>弗雷歇初始距离（FID）</th> 
     <th>分辨率</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>真实图像</td> 
     <td>233</td> 
     <td></td> 
     <td>128*128</td> 
    </tr> 
    <tr> 
     <td>SAGAN</td> 
     <td>52.52</td> 
     <td>18.65</td> 
     <td>128*128</td> 
    </tr> 
    <tr> 
     <td>BigGAN</td> 
     <td><font color="#FF0000">166.3</font></td> 
     <td><font color="#FF0000">9.6</font></td> 
     <td>128*128</td> 
    </tr> 
    <tr> 
     <td>BigGAN</td> 
     <td>232.5</td> 
     <td>8.1</td> 
     <td>256*256</td> 
    </tr> 
    <tr> 
     <td>BigGAN</td> 
     <td>241.5</td> 
     <td>11.5</td> 
     <td>512*512</td> 
    </tr> 
   </tbody> 
  </table>
  <p>其中，初始分数（Inception Score，IS） 和弗雷歇初始距离（Fréchet Incepton Distance，FID）是目前评价 GANs 合成样本最常用的两个评价标准</p> 
  <ul> 
   <li>初始分数（Inception Score，IS） 数值越大，GANs 合成的样本质量越高</li> 
   <li>弗雷歇初始距离（Fréchet Incepton Distance，FID）数值越小，GANs 合成的样本质量越高</li> 
  </ul> 
  <h4><a id="_40"></a>二、核心方法</h4> 
  <ul> 
   <li> <p><font color="#FF0000"><strong>大批量</strong></font><br> 每个批次训练数据的数量增加到 2048</p> </li> 
   <li> <p><font color="#FF0000"><strong>大通道</strong></font><br> 增加每一层网络的通道数为先前工作的1.5倍，使网络参数的数量增加为原来的2~4倍</p> </li> 
   <li> <p><font color="#FF0000"><strong>共享嵌入</strong></font><br> 类别条件线性投影到每个 BatchNorm 层的权重和偏置，从而降低了计算和内存成本，提高了训练速度，而不是为每个嵌入分别设置单独一层，如下图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801214854693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkbnV3anc=,size_16,color_FFFFFF,t_70" width="90%" alt=""></p> </li> 
   <li> <p><font color="#FF0000"><strong>层次化潜在空间</strong></font><br> 将随机噪声向量 z 对应不同的分辨率划分为多个块，然后将每一块随机噪声向量 z’ 与条件向量 c 连接在一起，再映射到 BatchNorm 层的权重和偏置，如上图：</p> </li> 
   <li> <p><font color="#FF0000"><strong>截断技巧</strong></font><br> 通过重新采样数值高于选定阈值的值来截断 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            z
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           z
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.04398em;">z</span></span></span></span></span> 矢量，减小 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            z
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           z
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.04398em;">z</span></span></span></span></span> 的采样范围可以改善单个样品质量，但整体样品多样性，而增大 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            z
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           z
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.04398em;">z</span></span></span></span></span> 的采样范围可以降低单个样品质量，而提高整体样品多样性。因此，可以通过阶段技巧来对样本的保真度和多样性进行细粒度地调节。</p> </li> 
   <li> <p><font color="#FF0000"><strong>正交正则化</strong></font><br> 一些较大的模型输入截断噪声向量 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            z
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           z
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.04398em;">z</span></span></span></span></span> 是会产生饱和伪影，如下图所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080122080176.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkbnV3anc=,size_16,color_FFFFFF,t_70" width="30%" alt=""><br> 因此许多模型并不适合使用截断技巧。针对这种情况 BigGAN 通过正交正则化（Orthogonal Regularization）将 G 调节为平滑，强制使其适合使用截断技巧：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
         <math>
          <semantics>
           <mrow>
            <msub>
             <mi>
              R
             </mi>
             <mi>
              β
             </mi>
            </msub>
            <mo>
             (
            </mo>
            <mi>
             W
            </mi>
            <mo>
             )
            </mo>
            <mo>
             =
            </mo>
            <mi>
             β
            </mi>
            <msubsup>
             <mrow>
              <mo fence="true">
               ∥
              </mo>
              <msup>
               <mi>
                W
               </mi>
               <mi>
                T
               </mi>
              </msup>
              <mi>
               W
              </mi>
              <mo>
               ⊙
              </mo>
              <mo>
               (
              </mo>
              <mn mathvariant="bold-italic">
               1
              </mn>
              <mo>
               −
              </mo>
              <mi>
               I
              </mi>
              <mo>
               )
              </mo>
              <mo fence="true">
               ∥
              </mo>
             </mrow>
             <mi>
              F
             </mi>
             <mn>
              2
             </mn>
            </msubsup>
           </mrow>
           <annotation encoding="application/x-tex">
            R_{\beta}(W)=\beta\left\|W^{T}W\odot(\bm{1}-I)\right\|^{2}_{F}
           </annotation>
          </semantics>
         </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.036108em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361079999999999em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.00773em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.05278em;">β</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 1.4950489999999999em; vertical-align: -0.3997099999999999em;"></span><span class="mord mathit" style="margin-right: 0.05278em;">β</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.86199em;"><span class="" style="top: -2.2559899999999997em;"><span class="pstrut" style="height: 2.606em;"></span><span class="delimsizinginner delim-size1"><span class="">∥</span></span></span><span class="" style="top: -2.86199em;"><span class="pstrut" style="height: 2.606em;"></span><span class="delimsizinginner delim-size1"><span class="">∥</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.35000999999999993em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913309999999999em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">1</span></span></span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.86199em;"><span class="" style="top: -2.2559899999999997em;"><span class="pstrut" style="height: 2.606em;"></span><span class="delimsizinginner delim-size1"><span class="">∥</span></span></span><span class="" style="top: -2.86199em;"><span class="pstrut" style="height: 2.606em;"></span><span class="delimsizinginner delim-size1"><span class="">∥</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.35000999999999993em;"><span class=""></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0953389999999998em;"><span class="" style="top: -2.3002900000000004em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.13889em;">F</span></span></span></span><span class="" style="top: -3.344231em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3997099999999999em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span><br> 其中，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            W
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           W
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">W</span></span></span></span></span> 为权重矩阵，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            β
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           \beta
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8888799999999999em; vertical-align: -0.19444em;"></span><span class="mord mathit" style="margin-right: 0.05278em;">β</span></span></span></span></span> 为超参数， <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mn mathvariant="bold-italic">
            1
           </mn>
          </mrow>
          <annotation encoding="application/x-tex">
           \bm{1}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">1</span></span></span></span></span></span></span> 表示元素全为 1 的矩阵。<br> BigGAN 这里所采用的正交正则化方法与传统的正交正则化是有区别的，从正则化中删除对角线项，从而最小化滤波器之间的成对余弦相似性，但并不限制它们的范数。</p> </li> 
   <li> <p><font color="#FF0000"><strong>生成器的不稳定性及对策</strong></font><br> 在 BigGAN 的大尺度批量和参数量的情况下，探索能够预示训练开始发生崩溃的标准，发现每一项权重的前三个最大的奇异值 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             0
            </mn>
           </msub>
           <mo separator="true">
            ,
           </mo>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             1
            </mn>
           </msub>
           <mo separator="true">
            ,
           </mo>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             2
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{0},\sigma_{1},\sigma_{2}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 最具信息量来做这件事情，并研究对生成器强加额外的条件防止谱的突爆问题。<br> <strong>第一种方式</strong>，正则化每一项权重的最大奇异值 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>：接近一个固定值 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mrow>
             <mi>
              r
             </mi>
             <mi>
              e
             </mi>
             <mi>
              g
             </mi>
            </mrow>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{reg}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.15139200000000003em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.02778em;">r</span><span class="mord mathit mtight">e</span><span class="mord mathit mtight" style="margin-right: 0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 或第二大奇异值乘以某一比率 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            r
           </mi>
           <mo>
            ⋅
           </mo>
           <mi>
            s
           </mi>
           <mi>
            g
           </mi>
           <mo>
            (
           </mo>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             1
            </mn>
           </msub>
           <mo>
            )
           </mo>
          </mrow>
          <annotation encoding="application/x-tex">
           r\cdot sg(\sigma_{1})
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.44445em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">s</span><span class="mord mathit" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>（其中，sg 表示停止梯度操作来防止正则化增加 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             1
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{1}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> ）。<br> <strong>第二种方式</strong>，或者采用偏奇异值分解（partial sigular value decomposition）来钳制 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。<br> 给定权重 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            W
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           W
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">W</span></span></span></span></span>，其第一个奇异向量为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             μ
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \mu_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             v
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           v_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mrow>
             <mi>
              c
             </mi>
             <mi>
              l
             </mi>
             <mi>
              a
             </mi>
             <mi>
              m
             </mi>
             <mi>
              p
             </mi>
            </mrow>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{clamp}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361079999999999em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">c</span><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="mord mathit mtight">a</span><span class="mord mathit mtight">m</span><span class="mord mathit mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 表示钳制 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 的值，要么设置为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mrow>
             <mi>
              r
             </mi>
             <mi>
              e
             </mi>
             <mi>
              g
             </mi>
            </mrow>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{reg}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.15139200000000003em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.02778em;">r</span><span class="mord mathit mtight">e</span><span class="mord mathit mtight" style="margin-right: 0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，要么设置为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            r
           </mi>
           <mo>
            ⋅
           </mo>
           <mi>
            s
           </mi>
           <mi>
            g
           </mi>
           <mo>
            (
           </mo>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             1
            </mn>
           </msub>
           <mo>
            )
           </mo>
          </mrow>
          <annotation encoding="application/x-tex">
           r\cdot sg(\sigma_{1})
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.44445em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">s</span><span class="mord mathit" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，则权重被优化为：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
         <math>
          <semantics>
           <mrow>
            <mi>
             W
            </mi>
            <mo>
             =
            </mo>
            <mi>
             W
            </mi>
            <mo>
             −
            </mo>
            <mi>
             m
            </mi>
            <mi>
             a
            </mi>
            <mi>
             x
            </mi>
            <mo>
             (
            </mo>
            <mn>
             0
            </mn>
            <mo separator="true">
             ,
            </mo>
            <msub>
             <mi>
              σ
             </mi>
             <mn>
              0
             </mn>
            </msub>
            <mo>
             −
            </mo>
            <msub>
             <mi>
              σ
             </mi>
             <mrow>
              <mi>
               c
              </mi>
              <mi>
               l
              </mi>
              <mi>
               a
              </mi>
              <mi>
               m
              </mi>
              <mi>
               p
              </mi>
             </mrow>
            </msub>
            <mo>
             )
            </mo>
            <msub>
             <mi>
              v
             </mi>
             <mn>
              0
             </mn>
            </msub>
            <msubsup>
             <mi>
              u
             </mi>
             <mn>
              0
             </mn>
             <mi>
              T
             </mi>
            </msubsup>
           </mrow>
           <annotation encoding="application/x-tex">
            W=W-max(0,\sigma_{0}-\sigma_{clamp})v_{0}u_{0}^{T}
           </annotation>
          </semantics>
         </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 0.76666em; vertical-align: -0.08333em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 1.177439em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361079999999999em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">c</span><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="mord mathit mtight">a</span><span class="mord mathit mtight">m</span><span class="mord mathit mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathit">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8913309999999999em;"><span class="" style="top: -2.4530000000000003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span><br> 这样处理权重后的效果就是：不管使用不用谱归一化（Spectral Normalization），上述技术都能够防止 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             σ
            </mi>
            <mn>
             0
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           \sigma_{0}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 或 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mfrac>
            <msub>
             <mi>
              σ
             </mi>
             <mn>
              0
             </mn>
            </msub>
            <msub>
             <mi>
              σ
             </mi>
             <mn>
              1
             </mn>
            </msub>
           </mfrac>
          </mrow>
          <annotation encoding="application/x-tex">
           \frac{\sigma_{0}}{\sigma_{1}}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.1565919999999998em; vertical-align: -0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7114919999999999em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31731428571428577em;"><span class="" style="top: -2.357em; margin-left: -0.03588em; margin-right: 0.07142857142857144em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4101em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31731428571428577em;"><span class="" style="top: -2.357em; margin-left: -0.03588em; margin-right: 0.07142857142857144em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.44509999999999994em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> 的逐渐增加至爆炸。<br> 但是文章也指出，在某情况下上述方法可以提高性能，但是并不能防止训练崩溃，这就表明调节生成器 G 可能改善稳定性，但并不足以保证稳定，因此将研究的关注点转到判别器上。</p> </li> 
   <li> <p><font color="#FF0000"><strong>判别器的不稳定性及对策</strong></font><br> 分析 D 的权重的谱曲线（论文中图 3b），与 G 不同，D 的谱是嘈杂的，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mfrac>
            <msub>
             <mi>
              σ
             </mi>
             <mn>
              0
             </mn>
            </msub>
            <msub>
             <mi>
              σ
             </mi>
             <mn>
              1
             </mn>
            </msub>
           </mfrac>
          </mrow>
          <annotation encoding="application/x-tex">
           \frac{\sigma_{0}}{\sigma_{1}}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.1565919999999998em; vertical-align: -0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7114919999999999em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31731428571428577em;"><span class="" style="top: -2.357em; margin-left: -0.03588em; margin-right: 0.07142857142857144em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4101em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31731428571428577em;"><span class="" style="top: -2.357em; margin-left: -0.03588em; margin-right: 0.07142857142857144em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.44509999999999994em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> 表现良好，并且奇异值在整个训练过程中一直增长，尽在崩溃时发生值跳跃而不是值爆炸。D 中谱出现的尖峰（spikes）噪声与训练不稳定有关，并探索 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             R
            </mi>
            <mn>
             1
            </mn>
           </msub>
          </mrow>
          <annotation encoding="application/x-tex">
           R_{1}
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.00773em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 领中心梯度惩罚来显式地正则化 D 的雅克比行列式的变化：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
         <math>
          <semantics>
           <mrow>
            <msub>
             <mi>
              R
             </mi>
             <mn>
              1
             </mn>
            </msub>
            <mo>
             :
            </mo>
            <mo>
             =
            </mo>
            <mfrac>
             <mi>
              λ
             </mi>
             <mn>
              2
             </mn>
            </mfrac>
            <msub>
             <mi mathvariant="double-struck">
              E
             </mi>
             <mrow>
              <msub>
               <mi>
                p
               </mi>
               <mi mathvariant="script">
                D
               </mi>
              </msub>
              <mo>
               (
              </mo>
              <mi>
               x
              </mi>
              <mo>
               )
              </mo>
             </mrow>
            </msub>
            <mrow>
             <mo fence="true">
              [
             </mo>
             <mi mathvariant="normal">
              ∥
             </mi>
             <mi mathvariant="normal">
              ∇
             </mi>
             <mi>
              D
             </mi>
             <mo>
              (
             </mo>
             <mi>
              x
             </mi>
             <mo>
              )
             </mo>
             <msubsup>
              <mi mathvariant="normal">
               ∥
              </mi>
              <mi>
               F
              </mi>
              <mn>
               2
              </mn>
             </msubsup>
             <mo fence="true">
              ]
             </mo>
            </mrow>
           </mrow>
           <annotation encoding="application/x-tex">
            R_{1} :=\frac{\lambda}{2} \mathbb{E}_{p_{\mathcal{D}}(x)}\left[\|\nabla D(x)\|_{F}^{2}\right]
           </annotation>
          </semantics>
         </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.00773em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height: 0.36687em; vertical-align: 0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 2.05744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">2</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.34480000000000005em;"><span class="" style="top: -2.5198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567071428571427em; margin-left: 0em; margin-right: 0.07142857142857144em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right: 0.02778em;">D</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.14329285714285717em;"><span class=""></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathit mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3551999999999999em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">[</span></span><span class="mord">∥</span><span class="mord">∇</span><span class="mord mathit" style="margin-right: 0.02778em;">D</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641079999999999em;"><span class="" style="top: -2.4530000000000003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.13889em;">F</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">]</span></span></span></span></span></span></span></span><br> 通过降低惩罚强度 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <mi>
            γ
           </mi>
          </mrow>
          <annotation encoding="application/x-tex">
           \gamma
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathit" style="margin-right: 0.05556em;">γ</span></span></span></span></span> 来提高训练稳定性，但同样会导致 IS 值下降。通过设置不同强度的正交正则化、DropOut、L2 等正则化策略的试验都证明：惩罚 D 的力度足够大时，训练就变得稳定，但是会严重牺牲性能。<br> 文章也通过在 ImageNet 上的训练与验证试验证明了 D 的损失在训练时趋于 0，但在崩溃时出现急剧增长的原因是 D 记忆了训练数据，但文章认为这符合 D 的角色，不显式地泛化，而是提炼训练数据并为生成器提供有用的训练信号。</p> </li> 
  </ul> 
  <h4><a id="_77"></a>三、实验</h4> 
  <p><strong>数据集</strong><br> ImageNet ILSVRC 2012(128x128、256x256、512x512)、JFT-300M(更大、更复杂、更多样)、CIFAR-10(32<em>32</em>3)图像超分辨率<br> <strong>结果</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801222907646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkbnV3anc=,size_16,color_FFFFFF,t_70" width="100%" alt=""></p> 
  <h4><a id="_82"></a>四、总结</h4> 
  <ol> 
   <li>BigGAN 最大的特色就是通过较大的批量数据以及较大的参数数量（增加通道数）来提高建模具有多种类别的复杂数据集（如 ImageNet），从而提高合成样本的质量（保真度和多样性）。</li> 
   <li>BigGAN 使用了很多技术和策略来提高合成样本的质量、平衡保真度与多样性、提高训练速度及稳定性等，整体来说是集现有 GANs 技术的一大作。</li> 
   <li>分析了在大规模配置下， GANs 的不稳定性的来源，是 G 和 D 在对抗训练过程中的相互作用，而不是单独地来源于 G 或 D。并发现通过对 D 施加很强的约束可以稳定训练。通过现有的技术，通过放松约束调节并允许训练后期阶段发生崩溃，可以实现更好的效果。</li> 
   <li>但 BigGANs 也存在一些不足：如：虽然大尺度提高合成样本的质量，但是也使模型容易不稳定，陷于完全崩溃的状态；虽然使用一些现有的策略和方法能够提高训练稳定，但不能彻底地避免崩溃；虽然对 D 施加较强的约束可以提高训练稳定性，但在性能上会造成很大的牺牲。</li> 
   <li>BigGAN 所采用的 batch_size = 2048 而取得的效果是是需要一定的硬件实力支撑的（BigGAN 的计算硬件：128 ~ 512 个核的 Google TPUv3 Pod）</li> 
  </ol> 
  <h4><a id="_89"></a>五、源代码</h4> 
  <p>作者正式非官方 PyTorch源码：<a href="https://github.com/ajbrock/BigGAN-PyTorch" rel="nofollow" data-token="2b790531569c3587a95e19b9a1a2b97a">https://github.com/ajbrock/BigGAN-PyTorch</a></p> 
  <h4><a id="_92"></a>六、附录</h4> 
  <p><strong>BigGAN 探索可用的潜空间：</strong><br> gongchang</p> 
  <ul> 
   <li>正太分布：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{N}(0,I)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span></span></span></span></span></li> 
   <li>均与分布：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           U
          </mi>
          <mo>
           [
          </mo>
          <mo>
           −
          </mo>
          <mn>
           1
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mn>
           1
          </mn>
          <mo>
           ]
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{U}[-1,1]
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.09931em;">U</span></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span></li> 
   <li>伯努利分布：Bernoulli{0,1}</li> 
   <li>截取正太分布：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           m
          </mi>
          <mi>
           a
          </mi>
          <mi>
           x
          </mi>
          <mo>
           (
          </mo>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          max(\mathcal{N}(0,I))
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></li> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mo>
           −
          </mo>
          <mn>
           1
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <annotation encoding="application/x-tex">
          {-1,0,1}
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8388800000000001em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord">1</span></span></span></span></span></span>独立类别，以相同概率采样</li> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{N}(0,I)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span></span></span></span></span> 乘以 Bernoulli{0,1}</li> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{N}(0,I)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span></span></span></span></span> 连接 Bernoulli{0,1}</li> 
   <li>方差退火<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <mi>
           σ
          </mi>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{N}(0,\sigma I)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span></span></span></span></span></li> 
   <li>各样本可变方差：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi mathvariant="script">
           N
          </mi>
          <mo>
           (
          </mo>
          <mn>
           0
          </mn>
          <mo separator="true">
           ,
          </mo>
          <msub>
           <mi>
            σ
           </mi>
           <mi>
            i
           </mi>
          </msub>
          <mi>
           I
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \mathcal{N}(0,\sigma_{i} I)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31166399999999994em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathit" style="margin-right: 0.07847em;">I</span><span class="mclose">)</span></span></span></span></span>，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi>
            σ
           </mi>
           <mi>
            i
           </mi>
          </msub>
          <mo>
           ∼
          </mo>
          <mi mathvariant="script">
           U
          </mi>
          <mo>
           [
          </mo>
          <msub>
           <mi>
            σ
           </mi>
           <mi>
            l
           </mi>
          </msub>
          <mo separator="true">
           ,
          </mo>
          <msub>
           <mi>
            σ
           </mi>
           <mi>
            h
           </mi>
          </msub>
          <mo>
           ]
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          \sigma_{i}\sim\mathcal{U}[\sigma_{l},\sigma_{h}]
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.31166399999999994em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.09931em;">U</span></span><span class="mopen">[</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.33610799999999996em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.33610799999999996em;"><span class="" style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></li> 
  </ul> 
  <p>（未截止。。。待续。。。）</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
