<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Secure Federated Transfer Learning（论文笔记） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Secure Federated Transfer Learning（论文笔记）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="论文链接：https://arxiv.org/pdf/1812.03337.pdf 一、概述 机器学习依赖于大量数据的可用性来进行训练。然而，实际上，大多数数据分散在不同的组织中，并且在许多法律和实际限制下很难聚合。在本文中，我们引入了一种新技术和框架，称为联邦迁移学习（FTL），以改进数据联合下的统计模型。联盟允许在不损害用户隐私的情况下共享知识，并且允许在网络中传送互补知识。因此，目标域方可以通过利用源域方的丰富标签来构建更灵活，更强大的模型。还提出了一种安全传输交叉验证方法来保护联邦下的FTL性能。该框架需要对现有模型结构进行少量的修改，并提供与非隐私保护方法相同的准确度。该框架非常灵活，可以有效地适应各种安全的多方机器学习任务。 二、简介 □背景： ☆Recent Artificial Intelligence (AI) achievements have been depending on the availability of massive amount of labeled data. ☆AlphaGo (Silver et al. 2016) uses 30 millions of moves from 160,000 actual games.The ImageNet dataset (Deng et al. 2009) has over 14 million images. □困难： However,across various industries, more fields of application have only small or poor quality data. Labeling data is very expensive, especially in fields which require human expertise and domain knowledge. In addition, data needed for a specific task may not be kept in one place. Many organizations may only have unlabeled data, and some other organizations may have very limited amount of labels. It has been increasingly difficult for organizations to combine their data too. 在各个行业中，更多的应用领域仅有较少或质量差的数据。给数据打标签非常昂贵，特别是在需要人类专业知识和领域知识的领域。此外，特定任务所需的数据不能保存在一个地方。许多组织可能只有未标注的数据，而其他一些组织的标签数量可能非常有限。 组织也越来越难以将其数据结合起来。 □应对： ① Google first introduced a federated learning (FL) system (McMahan et al. 2016) in which a global machine learning model is updated by a federation of distributed participants while keeping their data locally. △不足： These existing approaches are only applicable to either common features or common samples under a federation. （在现实中，公共实体的集合可能很小，从而降低了联邦的吸引力，使得大多数不重叠的数据受到了破坏。） ② In this paper, we propose a possible solution to these challenges: Federated Transfer Learning (FTL), which leverages transfer learning technique (Pan et al. 2010) to provide solutions for the entire sample and feature space under a federation. △主要贡献： We introduce federated transfer learning in a privacy preserving setting to provide solutions for federation problems beyond the scope of existing federated learning approaches; We provide an end-to-end solution to the proposed FTL problem and show that convergence and accuracy of the proposed approach is comparable to the non-privacy preserving approach; We provide a novel approach for adopting additively homomorphic encryption (HE) to multi-party computation (MPC) with neural networks such that only minimal modifications to the neural network is required and the accuracy is almost lossless, whereas most of the existing secure deep learning frameworks suffer from loss of accuracy when adopting privacy-preserving techniques. （①我们在privacypreserving设置中引入联合转移学习，以提供超出现有联合学习方法范围的联邦问题的隐私保护解决方案*; ②我们为拟议的FTL问题提供端到端解决方案，并表明所提方法的收敛性和准确性与非私有保留方法相当; ③我们提供了一种采用 加性同态加密（HE）与神经网络的多方计算（MPC） 的新方法，这样只需要对神经网络进行最小的修改，并且精度几乎是无损的，而大多数现有的安全深度 学习框架在采用隐私保护技术时会失去准确性。 ）* 三、相关工作 （一）Federated learning and Secure Deep Learning Server-end Models:(applicable for inference only) ① Google：a secure aggregation scheme(安全聚合方案) ②CryptoNets：Neural computations to work with data encrypted with Homomorphic Encryption ③CryptoDL: the activation functions in neural networks with low degree polynomials ④DeepSecure(uses Yao’s Garbled Circuit Protocol for data encryption instead of HE) In this paper: SecureML 加密：use secret-sharing and Yao’s Garble Circuit for encryption 训练：support collaborative training for linear regression(线性回归) , logistic regression and neural networks （二）Transfer Learning 应用情景：small dataset（小数据集） or weak supervison（弱监督） 实际应用：图像分类、情感分析…… 要求：（尽量）同行业——&gt;知识迁移 四、Problem Definition 数据集： ☆ Without losing generality, we assume all labels are in party A, but all the deduction here can be adapted to the case where labels exist in party B. One can ﬁnd the commonly shared sample ID set in a privacy-preserving setting by masking data IDs with encryption techniques such as RSA scheme. Here we assume that A and B already found or both know their commonly shared sample IDs. Given the above setting, the objective is for the two parities to build a transfer learning model to predict labels for the target-domain party as accurately as possible without exposing data to each other. △Security Definition: ① all parties are honest-but-curious ② assume a threat model with a semi-honest adversary D (半诚实的敌人) ③ Protocol P（协议P） 作用：控制信息的披露 五、Proposed Approach ① Transfer Learning Model and Federated Framework ② Deep Neural Networks ③ Hidden representation layer :d ④ Prediction function ⑤ Translator function ⑥ Loss function （logistic loss） ⑦ minimize the alignment loss ⑧ Final objective function ⑨ Gradients(梯度——用来更新参数) Additively Homomorphic Encryption（加法同态加密） 背景：广泛用于隐私保护机器学习 本文：二阶泰勒级数计算loss和gradients ☆Federated Transfer Learning架构（三个算法） （一）Federated Transfer Learning: Training ① 初始化并在本地独立运行神经网络Net（A）,Net（B）获取隐藏表示u（i,A）,u(i,B) ② A方计算并加密，发送给B协助B计算梯度Net（B） ③ B方同理② 存在风险：间接泄露（梯度） 应对：采用随机掩码加密传输 （二）Federated Transfer Learning: Prediction 模型训练完后。就可以对B方未打标签的数据进行预测，评估了： ① B方利用训练好的神经网络的参数Θ(B)计算u(j,B),并把加密结果[[G(u(j,B)]]发送给A方 ② A使用随机值进行评估和掩码，并将加密和掩码的φ（u(j,B)）发送到B，B解密并发送回A ③ A获得解密好的φ（u(j,B)）从而得到标签，并把标签发送给B方 唯一的性能损失：最终损失函数的二阶泰勒级数（而不是神经网络中每个非线性激活层） 优点：如实验部分所示，损耗和梯度计算中的误差以及采用我们的方法导致的精度损失很小。 因此，该方法可扩展并且灵活地适应神经网络结构的变化。 （三）Federated Transfer Learning: Cross Validation 方法： a secure transfer cross validation approach (TrCV) ① 将有标签的源域数据集划分为k折，每一轮（总共k轮）去一折作为测试集，使用剩余的k-1折数据根据算法1来建模，利用算法2进行标签预测 ② 将预测的标签和已有的数据集结合（对应）起来，用算法1对模型重新训练并用一折的测试集进行评估： ③最后获得最终的模型： 注意： TrCV使用源域标签执行验证，这在目标标签难以获得的情况下可能是有利的。 自学习监督模型MF，Dc也是用Dc建立的，以提供防止负转移的保障措施。 在标签位于源域方的情况下，自学习被简化为基于特征的联合学习问题。 否则，目标域方将自己构建自学模型。 在转移学习模型不如自学模型的情况下，知识不需要转移。 （Notice that TrCV performs validations using source domain labels, which could be advantageous in situations where target labels are difﬁcult to obtain. A self-learning supervised model MF,Dc is also built with Dc to provide safeguards against negative transfer (Kuzborskij and Orabona 2013; Zhong et al. 2010). In the scenario that the labels are in the source-domain party, the self-learning is reduced to a feature-based federated learning problem. Otherwise the target-domain party will build the self-learning model itself. In the cases that the transfer learning model is inferior to a self-learning model, knowledge needs not to be transfered.） Security Analysis Theorem 1. The protocol in Algorithm 1 and 2 is secure under our security deﬁnition, provided that the underlying additively homomorphic encryption scheme is secure. Proof： ① The training protocol in Algorithm 1 and 2 do not reveal any information, because all A and B learns are the masked gradients. As long as the encryption scheme is considered secure, the protocol is secure. ② At inference time, the two parties need to collaboratively compute the prediction results. Note the protocol does not deal with a malicious party. If party A fakes its inputs and submits only one non-zero input, it may tell the value of u(B) i at that input’s position. It still can not tell x(B) i or Θ(B), and neither party will get correct results. 六、实验 （一）过程：(略) （二）Impact of Taylor approximation ①As we increased the depth of the neural networks, the convergence and the performance of the model do not decay. （随着神经网络深度增加，收敛性和性能不会衰减） ②大多数现有的安全深度学习神经网络框架在采用隐私保护的方法时会造成精度下降，而本文的方法对更深的网络具有很强的适应性 （三）Transfer learning vs self-learning ① 在使用少量样本时，迁移学习方法优于自主学习 ② 随样本数增加，性能表现得到改进 ③ 性能随重叠样本数的增加而增加 （四）Scalability As expected from the above analysis, as we increase the dimension of the hidden representation d, the increase of the running time is accelerating across different values of number of overlapping samples tested. On the other hand, the running time grows linearly with respect to the number of target-domain features, as well as the number of samples shared. （随着我们隐藏表示维度d的增加，运行时间的增加在所测试的重叠样本数量的不同值上加速。 另一方面，运行时间相对于目标域特征的数量以及共享的样本数量线性增长。） 七、结论 ① The proposed framework is a complete privacypreserving solution which includes training, evaluation and cross validation. ② The current framework is not limited to any speciﬁc learning models but rather a general framework for privacy-preserving transfer learning. ③ Future works for FTL may include exploring and adopting the methodology to other deep learning systems where privacy-preservingdata collaborationis needed,and continuingimprovingthe efﬁciencyof the algorithms by using distributed computing techniques, and ﬁnding less expensive encryption schemes. ①FTL框架是一个完整的隐私保护解决方案，包括训练，评估和交叉验证。 ②目前的框架不局限于任何特定的学习模式，而是保护隐私的迁移学习的一般框架。 ③FTL的未来工作可能包括探索和采用其他深度学习系统的方法，其中需要隐私保护数据协作，并通过使用分布式计算技术继续提高算法的效率，并找到更便宜的加密方案。" />
<meta property="og:description" content="论文链接：https://arxiv.org/pdf/1812.03337.pdf 一、概述 机器学习依赖于大量数据的可用性来进行训练。然而，实际上，大多数数据分散在不同的组织中，并且在许多法律和实际限制下很难聚合。在本文中，我们引入了一种新技术和框架，称为联邦迁移学习（FTL），以改进数据联合下的统计模型。联盟允许在不损害用户隐私的情况下共享知识，并且允许在网络中传送互补知识。因此，目标域方可以通过利用源域方的丰富标签来构建更灵活，更强大的模型。还提出了一种安全传输交叉验证方法来保护联邦下的FTL性能。该框架需要对现有模型结构进行少量的修改，并提供与非隐私保护方法相同的准确度。该框架非常灵活，可以有效地适应各种安全的多方机器学习任务。 二、简介 □背景： ☆Recent Artificial Intelligence (AI) achievements have been depending on the availability of massive amount of labeled data. ☆AlphaGo (Silver et al. 2016) uses 30 millions of moves from 160,000 actual games.The ImageNet dataset (Deng et al. 2009) has over 14 million images. □困难： However,across various industries, more fields of application have only small or poor quality data. Labeling data is very expensive, especially in fields which require human expertise and domain knowledge. In addition, data needed for a specific task may not be kept in one place. Many organizations may only have unlabeled data, and some other organizations may have very limited amount of labels. It has been increasingly difficult for organizations to combine their data too. 在各个行业中，更多的应用领域仅有较少或质量差的数据。给数据打标签非常昂贵，特别是在需要人类专业知识和领域知识的领域。此外，特定任务所需的数据不能保存在一个地方。许多组织可能只有未标注的数据，而其他一些组织的标签数量可能非常有限。 组织也越来越难以将其数据结合起来。 □应对： ① Google first introduced a federated learning (FL) system (McMahan et al. 2016) in which a global machine learning model is updated by a federation of distributed participants while keeping their data locally. △不足： These existing approaches are only applicable to either common features or common samples under a federation. （在现实中，公共实体的集合可能很小，从而降低了联邦的吸引力，使得大多数不重叠的数据受到了破坏。） ② In this paper, we propose a possible solution to these challenges: Federated Transfer Learning (FTL), which leverages transfer learning technique (Pan et al. 2010) to provide solutions for the entire sample and feature space under a federation. △主要贡献： We introduce federated transfer learning in a privacy preserving setting to provide solutions for federation problems beyond the scope of existing federated learning approaches; We provide an end-to-end solution to the proposed FTL problem and show that convergence and accuracy of the proposed approach is comparable to the non-privacy preserving approach; We provide a novel approach for adopting additively homomorphic encryption (HE) to multi-party computation (MPC) with neural networks such that only minimal modifications to the neural network is required and the accuracy is almost lossless, whereas most of the existing secure deep learning frameworks suffer from loss of accuracy when adopting privacy-preserving techniques. （①我们在privacypreserving设置中引入联合转移学习，以提供超出现有联合学习方法范围的联邦问题的隐私保护解决方案*; ②我们为拟议的FTL问题提供端到端解决方案，并表明所提方法的收敛性和准确性与非私有保留方法相当; ③我们提供了一种采用 加性同态加密（HE）与神经网络的多方计算（MPC） 的新方法，这样只需要对神经网络进行最小的修改，并且精度几乎是无损的，而大多数现有的安全深度 学习框架在采用隐私保护技术时会失去准确性。 ）* 三、相关工作 （一）Federated learning and Secure Deep Learning Server-end Models:(applicable for inference only) ① Google：a secure aggregation scheme(安全聚合方案) ②CryptoNets：Neural computations to work with data encrypted with Homomorphic Encryption ③CryptoDL: the activation functions in neural networks with low degree polynomials ④DeepSecure(uses Yao’s Garbled Circuit Protocol for data encryption instead of HE) In this paper: SecureML 加密：use secret-sharing and Yao’s Garble Circuit for encryption 训练：support collaborative training for linear regression(线性回归) , logistic regression and neural networks （二）Transfer Learning 应用情景：small dataset（小数据集） or weak supervison（弱监督） 实际应用：图像分类、情感分析…… 要求：（尽量）同行业——&gt;知识迁移 四、Problem Definition 数据集： ☆ Without losing generality, we assume all labels are in party A, but all the deduction here can be adapted to the case where labels exist in party B. One can ﬁnd the commonly shared sample ID set in a privacy-preserving setting by masking data IDs with encryption techniques such as RSA scheme. Here we assume that A and B already found or both know their commonly shared sample IDs. Given the above setting, the objective is for the two parities to build a transfer learning model to predict labels for the target-domain party as accurately as possible without exposing data to each other. △Security Definition: ① all parties are honest-but-curious ② assume a threat model with a semi-honest adversary D (半诚实的敌人) ③ Protocol P（协议P） 作用：控制信息的披露 五、Proposed Approach ① Transfer Learning Model and Federated Framework ② Deep Neural Networks ③ Hidden representation layer :d ④ Prediction function ⑤ Translator function ⑥ Loss function （logistic loss） ⑦ minimize the alignment loss ⑧ Final objective function ⑨ Gradients(梯度——用来更新参数) Additively Homomorphic Encryption（加法同态加密） 背景：广泛用于隐私保护机器学习 本文：二阶泰勒级数计算loss和gradients ☆Federated Transfer Learning架构（三个算法） （一）Federated Transfer Learning: Training ① 初始化并在本地独立运行神经网络Net（A）,Net（B）获取隐藏表示u（i,A）,u(i,B) ② A方计算并加密，发送给B协助B计算梯度Net（B） ③ B方同理② 存在风险：间接泄露（梯度） 应对：采用随机掩码加密传输 （二）Federated Transfer Learning: Prediction 模型训练完后。就可以对B方未打标签的数据进行预测，评估了： ① B方利用训练好的神经网络的参数Θ(B)计算u(j,B),并把加密结果[[G(u(j,B)]]发送给A方 ② A使用随机值进行评估和掩码，并将加密和掩码的φ（u(j,B)）发送到B，B解密并发送回A ③ A获得解密好的φ（u(j,B)）从而得到标签，并把标签发送给B方 唯一的性能损失：最终损失函数的二阶泰勒级数（而不是神经网络中每个非线性激活层） 优点：如实验部分所示，损耗和梯度计算中的误差以及采用我们的方法导致的精度损失很小。 因此，该方法可扩展并且灵活地适应神经网络结构的变化。 （三）Federated Transfer Learning: Cross Validation 方法： a secure transfer cross validation approach (TrCV) ① 将有标签的源域数据集划分为k折，每一轮（总共k轮）去一折作为测试集，使用剩余的k-1折数据根据算法1来建模，利用算法2进行标签预测 ② 将预测的标签和已有的数据集结合（对应）起来，用算法1对模型重新训练并用一折的测试集进行评估： ③最后获得最终的模型： 注意： TrCV使用源域标签执行验证，这在目标标签难以获得的情况下可能是有利的。 自学习监督模型MF，Dc也是用Dc建立的，以提供防止负转移的保障措施。 在标签位于源域方的情况下，自学习被简化为基于特征的联合学习问题。 否则，目标域方将自己构建自学模型。 在转移学习模型不如自学模型的情况下，知识不需要转移。 （Notice that TrCV performs validations using source domain labels, which could be advantageous in situations where target labels are difﬁcult to obtain. A self-learning supervised model MF,Dc is also built with Dc to provide safeguards against negative transfer (Kuzborskij and Orabona 2013; Zhong et al. 2010). In the scenario that the labels are in the source-domain party, the self-learning is reduced to a feature-based federated learning problem. Otherwise the target-domain party will build the self-learning model itself. In the cases that the transfer learning model is inferior to a self-learning model, knowledge needs not to be transfered.） Security Analysis Theorem 1. The protocol in Algorithm 1 and 2 is secure under our security deﬁnition, provided that the underlying additively homomorphic encryption scheme is secure. Proof： ① The training protocol in Algorithm 1 and 2 do not reveal any information, because all A and B learns are the masked gradients. As long as the encryption scheme is considered secure, the protocol is secure. ② At inference time, the two parties need to collaboratively compute the prediction results. Note the protocol does not deal with a malicious party. If party A fakes its inputs and submits only one non-zero input, it may tell the value of u(B) i at that input’s position. It still can not tell x(B) i or Θ(B), and neither party will get correct results. 六、实验 （一）过程：(略) （二）Impact of Taylor approximation ①As we increased the depth of the neural networks, the convergence and the performance of the model do not decay. （随着神经网络深度增加，收敛性和性能不会衰减） ②大多数现有的安全深度学习神经网络框架在采用隐私保护的方法时会造成精度下降，而本文的方法对更深的网络具有很强的适应性 （三）Transfer learning vs self-learning ① 在使用少量样本时，迁移学习方法优于自主学习 ② 随样本数增加，性能表现得到改进 ③ 性能随重叠样本数的增加而增加 （四）Scalability As expected from the above analysis, as we increase the dimension of the hidden representation d, the increase of the running time is accelerating across different values of number of overlapping samples tested. On the other hand, the running time grows linearly with respect to the number of target-domain features, as well as the number of samples shared. （随着我们隐藏表示维度d的增加，运行时间的增加在所测试的重叠样本数量的不同值上加速。 另一方面，运行时间相对于目标域特征的数量以及共享的样本数量线性增长。） 七、结论 ① The proposed framework is a complete privacypreserving solution which includes training, evaluation and cross validation. ② The current framework is not limited to any speciﬁc learning models but rather a general framework for privacy-preserving transfer learning. ③ Future works for FTL may include exploring and adopting the methodology to other deep learning systems where privacy-preservingdata collaborationis needed,and continuingimprovingthe efﬁciencyof the algorithms by using distributed computing techniques, and ﬁnding less expensive encryption schemes. ①FTL框架是一个完整的隐私保护解决方案，包括训练，评估和交叉验证。 ②目前的框架不局限于任何特定的学习模式，而是保护隐私的迁移学习的一般框架。 ③FTL的未来工作可能包括探索和采用其他深度学习系统的方法，其中需要隐私保护数据协作，并通过使用分布式计算技术继续提高算法的效率，并找到更便宜的加密方案。" />
<link rel="canonical" href="https://uzzz.org/2019/08/02/792522.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/02/792522.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-02T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"论文链接：https://arxiv.org/pdf/1812.03337.pdf 一、概述 机器学习依赖于大量数据的可用性来进行训练。然而，实际上，大多数数据分散在不同的组织中，并且在许多法律和实际限制下很难聚合。在本文中，我们引入了一种新技术和框架，称为联邦迁移学习（FTL），以改进数据联合下的统计模型。联盟允许在不损害用户隐私的情况下共享知识，并且允许在网络中传送互补知识。因此，目标域方可以通过利用源域方的丰富标签来构建更灵活，更强大的模型。还提出了一种安全传输交叉验证方法来保护联邦下的FTL性能。该框架需要对现有模型结构进行少量的修改，并提供与非隐私保护方法相同的准确度。该框架非常灵活，可以有效地适应各种安全的多方机器学习任务。 二、简介 □背景： ☆Recent Artificial Intelligence (AI) achievements have been depending on the availability of massive amount of labeled data. ☆AlphaGo (Silver et al. 2016) uses 30 millions of moves from 160,000 actual games.The ImageNet dataset (Deng et al. 2009) has over 14 million images. □困难： However,across various industries, more fields of application have only small or poor quality data. Labeling data is very expensive, especially in fields which require human expertise and domain knowledge. In addition, data needed for a specific task may not be kept in one place. Many organizations may only have unlabeled data, and some other organizations may have very limited amount of labels. It has been increasingly difficult for organizations to combine their data too. 在各个行业中，更多的应用领域仅有较少或质量差的数据。给数据打标签非常昂贵，特别是在需要人类专业知识和领域知识的领域。此外，特定任务所需的数据不能保存在一个地方。许多组织可能只有未标注的数据，而其他一些组织的标签数量可能非常有限。 组织也越来越难以将其数据结合起来。 □应对： ① Google first introduced a federated learning (FL) system (McMahan et al. 2016) in which a global machine learning model is updated by a federation of distributed participants while keeping their data locally. △不足： These existing approaches are only applicable to either common features or common samples under a federation. （在现实中，公共实体的集合可能很小，从而降低了联邦的吸引力，使得大多数不重叠的数据受到了破坏。） ② In this paper, we propose a possible solution to these challenges: Federated Transfer Learning (FTL), which leverages transfer learning technique (Pan et al. 2010) to provide solutions for the entire sample and feature space under a federation. △主要贡献： We introduce federated transfer learning in a privacy preserving setting to provide solutions for federation problems beyond the scope of existing federated learning approaches; We provide an end-to-end solution to the proposed FTL problem and show that convergence and accuracy of the proposed approach is comparable to the non-privacy preserving approach; We provide a novel approach for adopting additively homomorphic encryption (HE) to multi-party computation (MPC) with neural networks such that only minimal modifications to the neural network is required and the accuracy is almost lossless, whereas most of the existing secure deep learning frameworks suffer from loss of accuracy when adopting privacy-preserving techniques. （①我们在privacypreserving设置中引入联合转移学习，以提供超出现有联合学习方法范围的联邦问题的隐私保护解决方案*; ②我们为拟议的FTL问题提供端到端解决方案，并表明所提方法的收敛性和准确性与非私有保留方法相当; ③我们提供了一种采用 加性同态加密（HE）与神经网络的多方计算（MPC） 的新方法，这样只需要对神经网络进行最小的修改，并且精度几乎是无损的，而大多数现有的安全深度 学习框架在采用隐私保护技术时会失去准确性。 ）* 三、相关工作 （一）Federated learning and Secure Deep Learning Server-end Models:(applicable for inference only) ① Google：a secure aggregation scheme(安全聚合方案) ②CryptoNets：Neural computations to work with data encrypted with Homomorphic Encryption ③CryptoDL: the activation functions in neural networks with low degree polynomials ④DeepSecure(uses Yao’s Garbled Circuit Protocol for data encryption instead of HE) In this paper: SecureML 加密：use secret-sharing and Yao’s Garble Circuit for encryption 训练：support collaborative training for linear regression(线性回归) , logistic regression and neural networks （二）Transfer Learning 应用情景：small dataset（小数据集） or weak supervison（弱监督） 实际应用：图像分类、情感分析…… 要求：（尽量）同行业——&gt;知识迁移 四、Problem Definition 数据集： ☆ Without losing generality, we assume all labels are in party A, but all the deduction here can be adapted to the case where labels exist in party B. One can ﬁnd the commonly shared sample ID set in a privacy-preserving setting by masking data IDs with encryption techniques such as RSA scheme. Here we assume that A and B already found or both know their commonly shared sample IDs. Given the above setting, the objective is for the two parities to build a transfer learning model to predict labels for the target-domain party as accurately as possible without exposing data to each other. △Security Definition: ① all parties are honest-but-curious ② assume a threat model with a semi-honest adversary D (半诚实的敌人) ③ Protocol P（协议P） 作用：控制信息的披露 五、Proposed Approach ① Transfer Learning Model and Federated Framework ② Deep Neural Networks ③ Hidden representation layer :d ④ Prediction function ⑤ Translator function ⑥ Loss function （logistic loss） ⑦ minimize the alignment loss ⑧ Final objective function ⑨ Gradients(梯度——用来更新参数) Additively Homomorphic Encryption（加法同态加密） 背景：广泛用于隐私保护机器学习 本文：二阶泰勒级数计算loss和gradients ☆Federated Transfer Learning架构（三个算法） （一）Federated Transfer Learning: Training ① 初始化并在本地独立运行神经网络Net（A）,Net（B）获取隐藏表示u（i,A）,u(i,B) ② A方计算并加密，发送给B协助B计算梯度Net（B） ③ B方同理② 存在风险：间接泄露（梯度） 应对：采用随机掩码加密传输 （二）Federated Transfer Learning: Prediction 模型训练完后。就可以对B方未打标签的数据进行预测，评估了： ① B方利用训练好的神经网络的参数Θ(B)计算u(j,B),并把加密结果[[G(u(j,B)]]发送给A方 ② A使用随机值进行评估和掩码，并将加密和掩码的φ（u(j,B)）发送到B，B解密并发送回A ③ A获得解密好的φ（u(j,B)）从而得到标签，并把标签发送给B方 唯一的性能损失：最终损失函数的二阶泰勒级数（而不是神经网络中每个非线性激活层） 优点：如实验部分所示，损耗和梯度计算中的误差以及采用我们的方法导致的精度损失很小。 因此，该方法可扩展并且灵活地适应神经网络结构的变化。 （三）Federated Transfer Learning: Cross Validation 方法： a secure transfer cross validation approach (TrCV) ① 将有标签的源域数据集划分为k折，每一轮（总共k轮）去一折作为测试集，使用剩余的k-1折数据根据算法1来建模，利用算法2进行标签预测 ② 将预测的标签和已有的数据集结合（对应）起来，用算法1对模型重新训练并用一折的测试集进行评估： ③最后获得最终的模型： 注意： TrCV使用源域标签执行验证，这在目标标签难以获得的情况下可能是有利的。 自学习监督模型MF，Dc也是用Dc建立的，以提供防止负转移的保障措施。 在标签位于源域方的情况下，自学习被简化为基于特征的联合学习问题。 否则，目标域方将自己构建自学模型。 在转移学习模型不如自学模型的情况下，知识不需要转移。 （Notice that TrCV performs validations using source domain labels, which could be advantageous in situations where target labels are difﬁcult to obtain. A self-learning supervised model MF,Dc is also built with Dc to provide safeguards against negative transfer (Kuzborskij and Orabona 2013; Zhong et al. 2010). In the scenario that the labels are in the source-domain party, the self-learning is reduced to a feature-based federated learning problem. Otherwise the target-domain party will build the self-learning model itself. In the cases that the transfer learning model is inferior to a self-learning model, knowledge needs not to be transfered.） Security Analysis Theorem 1. The protocol in Algorithm 1 and 2 is secure under our security deﬁnition, provided that the underlying additively homomorphic encryption scheme is secure. Proof： ① The training protocol in Algorithm 1 and 2 do not reveal any information, because all A and B learns are the masked gradients. As long as the encryption scheme is considered secure, the protocol is secure. ② At inference time, the two parties need to collaboratively compute the prediction results. Note the protocol does not deal with a malicious party. If party A fakes its inputs and submits only one non-zero input, it may tell the value of u(B) i at that input’s position. It still can not tell x(B) i or Θ(B), and neither party will get correct results. 六、实验 （一）过程：(略) （二）Impact of Taylor approximation ①As we increased the depth of the neural networks, the convergence and the performance of the model do not decay. （随着神经网络深度增加，收敛性和性能不会衰减） ②大多数现有的安全深度学习神经网络框架在采用隐私保护的方法时会造成精度下降，而本文的方法对更深的网络具有很强的适应性 （三）Transfer learning vs self-learning ① 在使用少量样本时，迁移学习方法优于自主学习 ② 随样本数增加，性能表现得到改进 ③ 性能随重叠样本数的增加而增加 （四）Scalability As expected from the above analysis, as we increase the dimension of the hidden representation d, the increase of the running time is accelerating across different values of number of overlapping samples tested. On the other hand, the running time grows linearly with respect to the number of target-domain features, as well as the number of samples shared. （随着我们隐藏表示维度d的增加，运行时间的增加在所测试的重叠样本数量的不同值上加速。 另一方面，运行时间相对于目标域特征的数量以及共享的样本数量线性增长。） 七、结论 ① The proposed framework is a complete privacypreserving solution which includes training, evaluation and cross validation. ② The current framework is not limited to any speciﬁc learning models but rather a general framework for privacy-preserving transfer learning. ③ Future works for FTL may include exploring and adopting the methodology to other deep learning systems where privacy-preservingdata collaborationis needed,and continuingimprovingthe efﬁciencyof the algorithms by using distributed computing techniques, and ﬁnding less expensive encryption schemes. ①FTL框架是一个完整的隐私保护解决方案，包括训练，评估和交叉验证。 ②目前的框架不局限于任何特定的学习模式，而是保护隐私的迁移学习的一般框架。 ③FTL的未来工作可能包括探索和采用其他深度学习系统的方法，其中需要隐私保护数据协作，并通过使用分布式计算技术继续提高算法的效率，并找到更便宜的加密方案。","@type":"BlogPosting","url":"https://uzzz.org/2019/08/02/792522.html","headline":"Secure Federated Transfer Learning（论文笔记）","dateModified":"2019-08-02T00:00:00+08:00","datePublished":"2019-08-02T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/02/792522.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Secure Federated Transfer Learning（论文笔记）</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p>论文链接：<a href="https://arxiv.org/pdf/1812.03337.pdf" rel="nofollow" data-token="e3ed5deda8785cda7b5f57802eb56356">https://arxiv.org/pdf/1812.03337.pdf</a></p> 
  <h2><a id="_2"></a>一、概述</h2> 
  <p>机器学习依赖于大量数据的可用性来进行训练。然而，实际上，大多数数据分散在不同的组织中，并且在许多法律和实际限制下很难聚合。在本文中，我们引入了一种新技术和框架，称为<strong>联邦迁移学习（FTL）</strong>，以改进数据联合下的统计模型。联盟允许在不损害用户隐私的情况下共享知识，并且允许在网络中传送互补知识。因此，目标域方可以通过利用源域方的丰富标签来构建更灵活，更强大的模型。还提出了一种<strong>安全传输交叉验证方法来保护联邦下的FTL性能</strong>。该框架需要对现有模型结构进行少量的修改，并提供与非隐私保护方法<strong>相同的准确度</strong>。该框架非常灵活，可以<strong>有效地适应各种安全的多方机器学习任务</strong>。</p> 
  <h2><a id="_5"></a>二、简介</h2> 
  <p><strong>□背景：</strong><br> ☆Recent Artificial Intelligence (AI) achievements have been depending on the availability of massive amount of labeled data.<br> ☆AlphaGo (Silver et al. 2016) uses 30 millions of moves from 160,000 actual games.The ImageNet dataset (Deng et al. 2009) has over 14 million images.</p> 
  <p><strong>□困难：</strong><br> However,across various industries, more fields of application <em><strong>have only small or poor quality data. Labeling data is very expensive</strong></em>, especially in fields which require human expertise and domain knowledge. In addition, <em><strong>data needed for a specific task may not be kept in one place</strong></em>. Many organizations may only have unlabeled data, and some other organizations may have very limited amount of labels. It has been increasingly <em><strong>difficult for organizations to combine their data</strong></em> too.<br> 在各个行业中，更多的应用领域仅有<strong>较少或质量差的数据</strong>。<strong>给数据打标签非常昂贵</strong>，特别是在需要人类专业知识和领域知识的领域。此外，特定任务所需的<strong>数据不能保存在一个地方</strong>。许多组织可能只有未标注的数据，而其他一些组织的标签数量可能非常有限。 组织也越来越<strong>难以将其数据结合起来</strong>。</p> 
  <p><strong>□应对：</strong><br> ①<br> <em><strong>Google</strong></em> first introduced a <em><strong>federated learning (FL) system</strong></em> (McMahan et al. 2016) in which a global machine learning model is updated by a federation of distributed participants while keeping their data locally.<br> △不足：<br> These existing approaches are only applicable to either common features or common samples under a federation.<br> <em>（在现实中，公共实体的集合可能很小，从而降低了联邦的吸引力，使得大多数不重叠的数据受到了破坏。）</em><br> ②<br> <em><strong>In this paper,</strong></em> we propose a possible solution to these challenges: <em><strong>Federated Transfer Learning (FTL),</strong></em> which leverages transfer learning technique (Pan et al. 2010) to provide solutions for the entire sample and feature space under a federation.<br> △主要贡献：</p> 
  <ul> 
   <li>We introduce federated transfer learning in a privacy preserving setting to provide solutions for federation problems beyond the scope of existing federated learning approaches;</li> 
   <li>We provide an end-to-end solution to the proposed FTL problem and show that convergence and accuracy of the proposed approach is comparable to the non-privacy preserving approach;</li> 
   <li>We provide a novel approach for adopting additively homomorphic encryption (HE) to multi-party computation (MPC) with neural networks such that only minimal modifications to the neural network is required and the accuracy is almost lossless, whereas most of the existing secure deep learning frameworks suffer from loss of accuracy when adopting privacy-preserving techniques.</li> 
  </ul> 
  <p><em>（①我们在privacypreserving设置中引入<strong>联合转移学习</strong>，以提供超出现有联合学习方法范围的联邦问题的</em>隐私保护解决方案*;<br> ②我们为拟议的FTL问题提供<strong>端到端解决方案</strong>，并表明所提方法的<em>收敛性和准确性</em>与非私有保留方法<em>相当</em>;<br> ③我们提供了一种采用 <strong>加性同态加密（HE）与神经网络的多方计算（MPC）</strong> 的新方法，这样只需要对神经网络进行最小的修改，并且精度几乎是<strong>无损</strong>的，而大多数现有的安全深度 学习框架在采用隐私保护技术时会失去准确性。 ）*</p> 
  <h2><a id="_31"></a>三、相关工作</h2> 
  <p><em><strong>（一）Federated learning and Secure Deep Learning</strong></em></p> 
  <p><strong>Server-end Models</strong>:(applicable for inference only)<br> ① Google：a secure aggregation scheme(安全聚合方案)<br> ②CryptoNets：Neural computations to work with data encrypted with Homomorphic Encryption<br> ③CryptoDL: the activation functions in neural networks with low degree polynomials<br> ④DeepSecure(uses Yao’s Garbled Circuit Protocol for data encryption instead of HE)</p> 
  <p><strong>In this paper:</strong> <em><strong>SecureML</strong></em><br> 加密：use <em><strong>secret-sharing</strong></em> and <em><strong>Yao’s Garble Circuit</strong></em> for encryption<br> 训练：support <em><strong>collaborative training</strong></em> for linear regression(线性回归) , <em><strong>logistic regression</strong></em> and <em><strong>neural networks</strong></em></p> 
  <p><em><strong>（二）Transfer Learning</strong></em></p> 
  <p>应用情景：small dataset（小数据集） or weak supervison（弱监督）<br> 实际应用：图像分类、情感分析……<br> 要求：（尽量）同行业——&gt;知识迁移</p> 
  <h2><a id="Problem_Definition_50"></a>四、Problem Definition</h2> 
  <p>数据集：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080122242182.png" alt="在这里插入图片描述"> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080122251675.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801222607374.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801222638725.png" alt="在这里插入图片描述"><br> ☆ Without losing generality, we <em><strong>assume all labels are in party A</strong></em>, but all the deduction here can be adapted to the case where labels exist in party B. One can <em><strong>ﬁnd the commonly shared sample ID</strong></em> set in a privacy-preserving setting by masking data IDs <em><strong>with encryption techniques such as RSA scheme</strong></em>. Here we <em><strong>assume that A and B already found or both know their commonly shared sample IDs</strong></em>. Given the above setting, the objective is for the two parities to <em><strong>build a transfer learning model</strong></em> to <em><strong>predict labels</strong></em> for the target-domain party as accurately as possible without exposing data to each other.</p> 
  <p><strong>△Security Definition:</strong><br> ① all parties are honest-but-curious<br> ② assume a threat model with a semi-honest adversary D (半诚实的敌人)<br> ③ Protocol P（协议P）</p> 
  <p>作用：控制信息的披露</p> 
  <h2><a id="Proposed_Approach_62"></a>五、Proposed Approach</h2> 
  <p><strong>① Transfer Learning Model and Federated Framework</strong><br> <strong>② Deep Neural Networks</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080122511572.png" alt="在这里插入图片描述"> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225137547.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225202822.png" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225325458.png" alt="在这里插入图片描述"><br> <strong>③ Hidden representation layer :d</strong><br> <strong>④ Prediction function</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080122540160.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225458854.png" alt="在这里插入图片描述"><br> <strong>⑤ Translator function</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225530994.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225552590.png" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225741796.png" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225814524.png" alt="在这里插入图片描述"><br> <strong>⑥ Loss function （logistic loss）</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225941995.png" alt="在这里插入图片描述"><br> <strong>⑦ minimize the alignment loss</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225842724.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801225900400.png" alt="在这里插入图片描述"><br> <strong>⑧ Final objective function</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801230007543.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801230039910.png" alt="在这里插入图片描述"><br> <strong>⑨ Gradients(梯度——用来更新参数)</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801230101237.png" alt="在这里插入图片描述"></p> 
  <h2><a id="Additively_Homomorphic_Encryption_83"></a>Additively Homomorphic Encryption（加法同态加密）</h2> 
  <p>背景：广泛用于隐私保护机器学习<br> 本文：二阶泰勒级数计算loss和gradients<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801231025179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019080123105419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801231119211.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801231145155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="Federated_Transfer_Learning_91"></a>☆Federated Transfer Learning架构（三个算法）</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801231719495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="Federated_Transfer_Learning_Training_94"></a>（一）Federated Transfer Learning: Training</h2> 
  <p>① 初始化并在本地独立运行神经网络Net（A）,Net（B）获取隐藏表示u（i,A）,u(i,B)<br> ② A方计算并加密，发送给B协助B计算梯度Net（B）<br> ③ B方同理②</p> 
  <p>存在风险：间接泄露（梯度）</p> 
  <p>应对：采用随机掩码加密传输</p> 
  <h2><a id="Federated_Transfer_Learning_Prediction_103"></a>（二）Federated Transfer Learning: Prediction</h2> 
  <p>模型训练完后。就可以对B方未打标签的数据进行预测，评估了：<br> ① B方利用训练好的神经网络的参数Θ(B)计算u(j,B),并把加密结果[[G(u(j,B)]]发送给A方<br> ② A使用随机值进行评估和掩码，并将加密和掩码的φ（u(j,B)）发送到B，B解密并发送回A<br> ③ A获得解密好的φ（u(j,B)）从而得到标签，并把标签发送给B方</p> 
  <p>唯一的性能损失：最终损失函数的二阶泰勒级数（而不是神经网络中每个非线性激活层）</p> 
  <p>优点：如实验部分所示，损耗和梯度计算中的误差以及采用我们的方法导致的精度损失很小。 因此，该方法可扩展并且灵活地适应神经网络结构的变化。</p> 
  <h2><a id="Federated_Transfer_Learning_Cross_Validation_112"></a>（三）Federated Transfer Learning: Cross Validation</h2> 
  <p>方法： a secure transfer cross validation approach (TrCV)</p> 
  <p>① 将有标签的源域数据集划分为k折，每一轮（总共k轮）去一折作为测试集，使用剩余的k-1折数据根据算法1来建模，利用算法2进行标签预测<br> ② 将预测的标签和已有的数据集结合（对应）起来，用算法1对模型重新训练并用一折的测试集进行评估：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190802102614321.png" alt="在这里插入图片描述"><br> ③最后获得最终的模型：<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190802102731846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 注意：<br> TrCV使用源域标签执行验证，这在目标标签难以获得的情况下可能是有利的。<br> 自学习监督模型MF，Dc也是用Dc建立的，以提供防止负转移的保障措施。<br> 在标签位于源域方的情况下，自学习被简化为基于特征的联合学习问题。 否则，目标域方将自己构建自学模型。 在转移学习模型不如自学模型的情况下，知识不需要转移。<br> <em>（Notice that TrCV performs validations using source domain labels, which could be advantageous in situations where target labels are difﬁcult to obtain. A self-learning supervised<br> model MF,Dc is also built with Dc to provide safeguards against negative transfer (Kuzborskij and Orabona 2013; Zhong et al. 2010). In the scenario that the labels are in the source-domain party, the self-learning is reduced to a feature-based federated learning problem. Otherwise the target-domain party will build the self-learning model itself. In the cases that the transfer learning model is inferior to a self-learning model, knowledge needs not to be transfered.）</em></p> 
  <h2><a id="Security_Analysis_127"></a>Security Analysis</h2> 
  <p><strong>Theorem 1.</strong> The protocol in Algorithm 1 and 2 is secure under our security deﬁnition, provided that the underlying additively homomorphic encryption scheme is secure.<br> <strong>Proof：</strong><br> ① The training protocol in Algorithm 1 and 2 do not reveal any information, because all A and B learns are the masked gradients.<br> As long as the encryption scheme is considered secure, the protocol is secure.<br> ② At inference time, the two parties need to collaboratively compute the prediction results. Note the protocol does not deal with a malicious party. If party A fakes its inputs and submits only one non-zero input, it may tell the value of u(B) i at that input’s position. It still can not tell x(B) i or Θ(B), and neither party will get correct results.<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190802104202337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAwMjgyOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_134"></a>六、实验</h2> 
  <p><strong>（一）过程：(略)</strong><br> <strong>（二）Impact of Taylor approximation</strong><br> ①As we increased the depth of the neural networks, the convergence and the performance of the model do not decay. （随着神经网络深度增加，收敛性和性能不会衰减）<br> ②大多数现有的安全深度学习神经网络框架在采用隐私保护的方法时会造成精度下降，而本文的方法对更深的网络具有很强的适应性<br> <strong>（三）Transfer learning vs self-learning</strong><br> ① 在使用少量样本时，迁移学习方法优于自主学习<br> ② 随样本数增加，性能表现得到改进<br> ③ 性能随重叠样本数的增加而增加<br> <strong>（四）Scalability</strong><br> As expected from the above analysis, as we increase the dimension of the hidden representation d, the increase of the running time is accelerating across different values of number of overlapping samples tested. On the other hand, the running time grows linearly with respect to the number of target-domain features, as well as the number of samples shared.<br> <em>（随着我们隐藏表示维度d的增加，运行时间的增加在所测试的重叠样本数量的不同值上加速。<br> 另一方面，运行时间相对于目标域特征的数量以及共享的样本数量线性增长。）</em></p> 
  <h2><a id="_148"></a>七、结论</h2> 
  <p>① The proposed framework is a complete privacypreserving solution which includes training, evaluation and cross validation.<br> ② The current framework is not limited to any speciﬁc learning models but rather a general framework for privacy-preserving transfer learning.<br> ③ Future works for FTL may include exploring and adopting the methodology to other deep learning systems where privacy-preservingdata collaborationis needed,and continuingimprovingthe efﬁciencyof the algorithms by using distributed computing techniques, and ﬁnding less expensive encryption schemes.<br> ①FTL框架是一个完整的隐私保护解决方案，包括训练，评估和交叉验证。<br> ②目前的框架不局限于任何特定的学习模式，而是保护隐私的迁移学习的一般框架。<br> ③FTL的未来工作可能包括探索和采用其他深度学习系统的方法，其中需要隐私保护数据协作，并通过使用分布式计算技术继续提高算法的效率，并找到更便宜的加密方案。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
