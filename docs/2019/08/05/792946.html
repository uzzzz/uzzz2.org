<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>计算机视觉算法岗面试题 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="计算机视觉算法岗面试题" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="大佬的面试经验：https://www.nowcoder.com/discuss/128148 以及大佬的博客：https://blog.csdn.net/liuxiao214/article/details/83043170 根据大佬的面试经验一点一点填坑吧。 常见概念 最大似然估计：最大似然估计是一种统计方法，最大似然估计函数在采样样本总数趋于无穷的时候达到最小方差。步骤：1.写出似然函数 2.取对数 3.求导数并令其为0。 最小二乘法：通过最小化误差的平方和寻找数据的最佳函数匹配。 梯度下降法： 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。 模型融合方法： 目前的集成学习方法大致可以分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和随机森林。 1.投票： 假设对于一个二分类问题，有3个基础模型，那么就采取投票制的方法，投票多者确定为最终的分类。 2.平均： 对于回归问题，一个简单直接的思路是取平均。稍稍改进的方法是进行加权平均。权值可以用排序的方法确定，举个例子，比如A、B、C三种基本模型，模型效果进行排名，假设排名分别是1，2，3，那么给这三个模型赋予的权值分别是3/6、2/6、1/6。这两种方法看似简单，其实后面的高级算法也可以说是基于此而产生的，Bagging或者Boosting都是一种把许多弱分类器这样融合成强分类器的思想。 3.Bagging： 就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步： ① 重复K次，有放回地重复抽样建模，训练子模型 ② 模型融合，分类问题：voting，回归问题：average 随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。 4.Boosting： Bagging算法可以并行处理，而Boosting的思想是一种迭代的方法。 AdaBoost 是Boosting 算法家族中代表算法，AdaBoost 每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例，最终将这些弱分类器进行加权相加。AdaBoost模型是弱分类器的线性组合，AdaBoost算法的一个解释是该算法实际上是前向分步算法的一个实现，在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。 xgboost相对AdaBoost区别，对损失函数做了二阶的泰勒展开，并在目标函数之外加入了正则项对整体求最优解，用以权衡目标函数的下降和模型的复杂程度，避免过拟合。所以不考虑细节方面，两者最大的不同就是目标函数的定义 L1L2正则： 判别式模型与生成式模型：： 判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机SVM、神经网络等。 生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi， 常见的生成式模型有 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA等。https://blog.csdn.net/huangfei711/article/details/79834780 熵-交叉熵-KL散度： 熵：信息熵是度量随机变量不确定度的指标，信息熵越大意味着随机变量不确定度越高，意味着系统的有序程度越低。 交叉熵：主要用于度量两个概率分布间的差异性信息。 KL散度/相对熵：是描述两个概率分布P和Q差异的一种方法。 三者间关系： 最优化方法（梯度下降，牛顿法，共轭梯度法）： 牛顿法： 交叉验证： 第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。 第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。 第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。 此外还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法(bootstrapping)。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。 皮尔逊系数： 皮尔逊相关系数广泛用于度量两个变量之间的相关程度，其值介于-1与1之间。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商： bias-variance-tradeoff：偏差方差权衡 1、Bias and Variance tradeoff的最简单方法 当Bias很高的时候，就增加模型的复杂度（比如增加神经网络的神经元个数，神经网络的层数） 当Variance很高的时候，就增加训练的样本量。 然而以上的原则只是一个大的指导方向，因为在实际操作中增加模型的复杂程度将会大大增加计算机的计算量，而且还容易造成Overfitting。 下面详细介绍在实际操作中处理Bias 和 Variance 的具体方法。 2、减少Bias的几大原则 增加模型复杂度 根据误差分析结果，调整输入特征(feature) 减少或者去除Regularization(正则化) 修改模型结构 增加更多的训练样本 3、减少Variance的几大原则 增加更多的训练样本 增加Regularization(正则化) 加入提前终止(Early Stopping) 选择性减少输入的特征(Features) 减小模型规模 根据误差分析结果，调整输入特征(feature) 修改模型结构 无偏估计：无偏估计是用样本统计量来估计总体参数时的一种无偏推断。估计量的数学期望等于被估计参数的真实值，则称此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。 ROC，recall，precision： 分类器的ROC曲线和相关指标 准确率(Accuracy)：ACC=(TP+TN)/(TP+TN+FP+FN) mAP是什么 P：precision即准确率，TP / (TP + FP)，分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例; R：recall即召回率，TP / (TP + FN)，分类器认为是正类并且确实是正类的部分占所有确实是正类的比例; 目标检测中： TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次） FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量 FN: 没有检测到的GT的数量 PR曲线：以P和R为纵横坐标的曲线; AP值：Average Precision平均精确度，为PR曲线下面积; mAP:各类AP的平均值; 举例： 假设，对于Aeroplane类别，我们网络有以下输出(BB表示BoundingBox序号，IoU&gt;0.5时GT=1)： BB | confidence | GT ---------------------- BB1 | 0.9 | 1 ---------------------- BB2 | 0.9 | 1 ---------------------- BB1 | 0.8 | 1 ---------------------- BB3 | 0.7 | 0 ---------------------- BB4 | 0.7 | 0 ---------------------- BB5 | 0.7 | 1 ---------------------- BB6 | 0.7 | 0 ---------------------- BB7 | 0.7 | 0 ---------------------- BB8 | 0.7 | 1 ---------------------- BB9 | 0.7 | 1 ---------------------- 因此，我们有 TP=5 (BB1, BB2, BB5, BB8, BB9), FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2. 这时我们就可以按照Confidence的顺序给出各处的PR值，如下： rank=1 precision=1.00 and recall=0.14 ---------- rank=2 precision=1.00 and recall=0.29 ---------- rank=3 precision=0.66 and recall=0.29 ---------- rank=4 precision=0.50 and recall=0.29 ---------- rank=5 precision=0.40 and recall=0.29 ---------- rank=6 precision=0.50 and recall=0.43 ---------- rank=7 precision=0.43 and recall=0.43 ---------- rank=8 precision=0.38 and recall=0.43 ---------- rank=9 precision=0.44 and recall=0.57 ---------- rank=10 precision=0.50 and recall=0.71 对于Recall &gt;= 0, 0.14, 0.29, 0.43, 0.57, 0.71, 1，我们选取此时Percision的最大值：1, 1, 1, 0.5, 0.5, 0.5, 0。此时Aeroplane类别的 AP = (0.14-0)*1 + (0.29-0.14)*1 + (0.43-0.29)*0.5 + (0.57-0.43)*0.5 + (0.71-0.57)*0.5 + (1-0.71)*0 = 0.5 mAP就是对每一个类别都计算出AP然后再计算AP平均值就好了。 图像分类方法 逻辑回归，支持向量机，随机森林，GBDT，深度学习。 逻辑回归：https://www.jianshu.com/p/1bf35d61995f 支持向量机：https://blog.csdn.net/u011630575/article/details/78916747 距离超平面最小的样例，我们称之为支持向量，我们所要找的最优超平面，就是使支持向量到超平面距离最大，我们认为，这样的超平面，就是最优的，下面也是要想办法求出这个超平面。SVM的核心问题就是找到这一超平面 最大间隔分类： 随机森林：https://blog.csdn.net/yangyin007/article/details/82385967?tdsourcetag=s_pcqq_aiomsg GBDT： LR和SVM的异同 相同点： 第一，LR和SVM都是分类算法。 第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。 第三，LR和SVM都是监督学习算法。 第四，LR和SVM都是判别模型。 第五，LR和SVM在学术界和工业界都广为人知并且应用广泛。 不同点： 第一，损失函数不同 第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。 第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。 第四，​线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响。 第五，SVM的损失函数就自带正则（损失函数中的1/2||w||^2项），这就是为什么SVM是结构风险最小化算法的原因，而LR必须另外在损失函数上添加正则项 函数间隔和几何间隔 函数间隔 几何间隔 视频分类 思路： 1.通过将视频的每一帧视为一幅单独的图像，利用二维 CNN 进行处理。这种方法将视频分类问题简化为图像分类问题。每帧视频图像都有类别输出，并且根据各帧输出的类别，选择频率最高的类别作为视频的分类结果。 2.创建一个单一的网络，将二维 CNN 与一个 RNN 结合在一起。这个想法是，CNN 将考虑到图像分量，而 RNN 将考虑每个视频的序列信息。这种类型的网络可能非常难以训练，因为要优化的参数数量非常大。 3.使用三维卷积网络，其中三维卷积网络是二维 CNN 的在 3D 张量（时间，图像宽度，图像高度）上运行的扩展。这种方法是图像分类的另一个自然延伸，但三维卷积网络可能很难训练。 4.基于智能方法的直觉。它们可以用于存储视频中每个帧的离线功能，而不是直接使用 CNN 进行分类。这个想法基于，特征提取可以非常有效地进行迁移学习，如前面章节所示。在提取所有的特征之后，可以将它们作为一组输入传递给RNN，其将在多个帧中学习序列并输出最终的分类。 5.第四种方法的简单变体，其中最后一层是 MLP 而不是 RNN。在某些情况下，就计算需求而言，这种方法可以更简单并且成本更低。 6.第四种方法的变体，其中特征提取阶段采用三维 CNN 来提取空间和视觉特征，然后将这些特征传递给 RNN 或 MLP。 细粒度分类 https://blog.csdn.net/qq_25439417/article/details/82764183 细粒度分类：同一类中不同子类物体间的分类。 1.Part-based R-CNN。 如上所示，局部区域将从自底向上的候选区域开始（左上角），我们将基于深度卷积特征同时训练目标和局部区域。在推断阶段，所有的窗口都会由检测器评分（中间），且我们可以应用非参几何约束（底部）重新评估窗口并选择最优的目标和局部检测（右上角）。最后的步骤就是抽取局部语义信息来用于细粒度识别，并训练一个分类器预测最终类别。 2.Bilinear deep network models 3.FCN attention。 在抽取特征后，模型需要学习哪些局部区域对最终分类是重要的，而确定重要性的标准即局部区域对最终预测是否有帮助。在这一阶段中，注意力网络会将基本的局部卷积特征图生成一张评分图或置信图，即通过叠加的两个卷积层将特征图转换为通道数为 1 的评分图。一般第一个卷积层可使用 64 个 3×3 的卷积核，而第二个卷积层可使用 1 个 3×3 的卷积核将通道数降为 1，这一张置信图展示了模型关注的兴趣点。 兴趣点是网络自己学到的，而裁剪的大小是我们给定的。我们首先会给一个 8×8 的较大裁剪窗口，相当于关注较大的区域。随着迭代的进行，我们会慢慢减小裁剪窗口，这相当于关注更小的细节。裁剪后的特征图一般需要馈送到 Softmax 层以将置信图转换为概率图。 你知道attention起源是用在哪里？pixel还是frame，是soft还是hard 对于 Attention的作用角度出发，可以分为： 空间注意力 Spatial Attention，时间注意力 Temporal Attention 这样的分类更多的是从应用层面上；而从 Attention的作用方法上，可以将其分为 Soft Attention 和 Hard Attention，这既我们所说的， Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。 attention机制：https://blog.csdn.net/xiewenbo/article/details/79382785 Soft Attention：传统的Attention Mechanism就是Soft Attention,即通过确定性的得分计算来得到attended之后的编码隐状态。Soft Attention是参数化的（Parameterization），因此可导，可以被嵌入到模型中去，直接训练。梯度可以经过Attention Mechanism模块，反向传播到模型其他部分。 Hard Attention：是一个随机的过程。Hard Attention不会选择整个encoder的隐层输出做为其输入，Hard Attention会依概率Si来采样输入端的隐状态一部分来进行计算，而不是整个encoder的隐状态。为了实现梯度的反向传播，需要采用蒙特卡洛采样的方法来估计模块的梯度。 两种Attention Mechanism都有各自的优势，但目前更多的研究和应用还是更倾向于使用Soft Attention，因为其可以直接求导，进行梯度反向传播 网络用的损失函数是什么 L1 loss：绝对差平均损失，又称MAE . 2.L2 loss：平方差平均损失，又称MSE 3.Smooth L1 loss，又称Huber损失 4.BCE loss，二分类用的交叉熵损失，用的时候需要在该层前面加上 Sigmoid 函数 5.BCEWithlogitsLoss，将sigmoid函数集成到BCE loss上 6.CrossEntoryLoss，交叉熵损失函数 第一种形式： 第二种形式： softmax的交叉熵： 7.NllLoss：负对数似然损失。 监督学习和无监督学习 监督学习(supervised learning)：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。 无监督学习(unsupervised learning)：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。 强化学习(reinforcement learning)：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。 弱监督学习(weakly supervised learning)： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。 半监督学习(semi supervised learning) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，学习已知标签和未知标签的数据，将输入数据映射到标签的过程。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。 多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。 softmax loss softmax的交叉熵： LR为什么要用sigmoid函数 3. LR 损失函数为什么用极大似然函数？ 1.因为我们想要让每一个样本的预测都要得到最大的概率，即将所有的样本预测后的概率进行相乘都最大，也就是极大似然函数. 2.对极大似然函数取对数以后相当于对数损失函数，由上面梯度更新的公式可以看出，对数损失函数的训练求解参数的速度是比较快的，而且更新速度只和x，y有关，比较的稳定。 3.为什么不用平方损失函数 如果使用平方损失函数，梯度更新的速度会和 sigmod 函数的梯度相关，sigmod 函数在定义域内的梯度都不大于0.25，导致训练速度会非常慢。 而且平方损失会导致损失函数是 theta 的非凸函数，不利于求解，因为非凸函数存在很多局部最优解 softmax交叉熵损失函数求导 https://blog.csdn.net/qian99/article/details/78046329 softmax和logistic回归的区别和联系 1.softmax用来解决多分类问题，lr解决二分类问题 2.softmax输出每一类的概率值，并确定概率最大的类是正确的，lr只区别是还是不是。事实上softmax是lr的一般情况。 https://blog.csdn.net/chnguoshiwushuang/article/details/80514626 全连接的作用 因为用到了所有的局部特征，所以叫全连接。将学到的“分布式特征表示”映射到样本标记空间的作用。 GD、SGD、mini batch GD的区别 GD：梯度下降法的物理意义很好理解，就是沿着当前点的梯度方向进行线搜索，找到下一个迭代点 SGD：随机梯度下降法，每次计算梯度时，只随机的选取一个样本来计算梯度,这样就大大的减小了计算的复杂度，随机梯度下降法速度快，但每次的方向不稳定，甚至可能向反方向。 mini batch GD：故每次计算梯度时，选取一部分样本，即小批量梯度下降法。 S3D了解吗？ 边缘检测算子有哪些 1.差分算子。 一阶微分： 2.Roberts算子，对角线方向相邻两象素之差近似梯度幅值检测边缘，对噪声敏感,无法抑制噪声的影响。 3.Sobel算子，该算子包含两组3 * 3的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差分近似值，在结合横向和纵向 4.Prewitt算子，一阶微分算子的边缘检测，模板3 * 3利用像素点上下、左右邻点的灰度差，在边缘处达到极值检测边缘，去掉部分伪边缘，对噪声具有平滑作用 。 二阶微分 5.Laplacian算子，存在噪声情况下，使用Laplacian算子检测边缘之前需要先进行低通滤波，模板3 * 3。 6.Log算子，进行高斯滤波再进行拉普拉斯算子检测，模板5 * 5。 非微分 7.Canny算子： 1)使用高斯滤波器，以平滑图像，滤除噪声。 2)计算图像中每个像素点的梯度强度和方向。 3)应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。 4)应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。 5)通过抑制孤立的弱边缘最终完成边缘检测。 霍夫变换 说一下SVM核函数 在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。核函数的价值在于它虽然也是讲特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算。 1.多项式核函数 2.高斯核函数 3.线性核函数 4.字符串核函数 PCA PCA(principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据压缩算法。它可以通过线性变换将原始数据变换为一组各维度线性无关的表示，以此来提取数据的主要线性分量。 具体可以看这篇文章：https://blog.csdn.net/hustqb/article/details/78394058 伪代码： 去除平均值 计算协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值排序 保留前N个最大的特征值对应的特征向量 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩） L1、L2范数 sigmoid优缺点 优点：可以将函数值的范围压缩到[0,1]，可以压缩数据，且幅度不变。在特征相差比较复杂或是相差不是特别大时效果比较好。可以看到sigmoid函数处处连续便于求导；便于前向传输。 缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法。反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练 RefineNet理解 针对语义分割所提出的网络模型，可以分为两段对应于U-Net中向下（特征逐步降采样同时提取语义特征）和向上（逐步上采样特征恢复细节信息）两段通路。其中向下的通路以ResNet为基础。向上的通路使用了新提出的RefineNet作为基础，并作为本通路特征与ResNet中低层特征的融合器。下图a为标准CNN，b图为带孔卷积，RefineNet的框架如c图所示： 其中左边的四组特征是从ResNet的四个对应的block取出的。此框架与U-Net没有太大区别。不过如作者所说，RefineNet是一个灵活的模块，其输入的尺度个数可以变化，因此整个网络的拓扑结构可以有很多改变。 RefineNet可以分为三个主要部分： 1. 不同尺度（也可能只有一个输入尺度）的特征输入首先经过两个Residual模块的处理； 2. 之后是不同尺寸的特征进行融合。当然如果只有一个输入尺度，该模块则可以省去。所有特征上采样至最大的输入尺寸，然后进行加和。上采样之前的卷积模块是为了调整不同特征的数值尺度； 3. 最后是一个链式的pooling模块。其设计本意是使用侧支上一系列的pooling来获取背景信息（通常尺寸较大）。直连通路上的ReLU可以在不显著影响梯度流通的情况下提高后续pooling的性能，同时不让网络的训练对学习率很敏感。最后再经过一个Residual模块即得RefineNet的输出。 详细架构如下： 引用：https://blog.csdn.net/gqixf/article/details/82911220 densenet结构优缺点以及应用场景 优点： (1) 相比ResNet拥有更少的参数数量. (2) 旁路加强了特征的重用. (3) 网络更易于训练,并具有一定的正则效果. (4) 缓解了gradient vanishing和model degradation的问题. 缺点： DenseNet在训练时十分消耗内存，这是由于算法实现不优带来的。当前的深度学习框架对 DenseNet 的密集连接没有很好的支持，所以只能借助于反复的拼接（Concatenation）操作，将之前层的输出与当前层的输出拼接在一起，然后传给下一层。对于大多数框架（如Torch和TensorFlow），每次拼接操作都会开辟新的内存来保存拼接后的特征。这样就导致一个 L 层的网络，要消耗相当于 L(L+1)/2 层网络的内存. pooling层： 由于在DenseNet中需要对不同层的feature map进行cat操作,所以需要不同层的feature map保持相同的feature size,这就限制了网络中Down sampling的实现.为了使用Down sampling,作者将DenseNet分为多个Denseblock,如下图所示: 在同一个Denseblock中要求feature size保持相同大小,在不同Denseblock之间设置transition layers实现Down sampling, 在作者的实验中transition layer由BN + Conv(1×1) ＋2×2 average-pooling组成. Growth rate： 在Denseblock中,假设每一个非线性变换H的输出为K个feature map, 那么第i层网络的输入便为K0+(i-1)×K, 这里我们可以看到DenseNet和现有网络的一个主要的不同点:DenseNet可以接受较少的特征图数量作为网络层的输出,如下图所示 原因就是在同一个Denseblock中的每一层都与之前所有层相关联,如果我们把feature看作是一个Denseblock的全局状态,那么每一层的训练目标便是通过现有的全局状态,判断需要添加给全局状态的更新值.因而每个网络层输出的特征图数量K又称为Growth rate,同样决定着每一层需要给全局状态更新的信息的多少 Bottleneck Layers： 虽然DenseNet接受较少的k,也就是feature map的数量作为输出,但由于不同层feature map之间由cat操作组合在一起,最终仍然会是feature map的channel较大而成为网络的负担.作者在这里使用1×1 Conv(Bottleneck)作为特征降维的方法来降低channel数量,以提高计算效率.经过改善后的非线性变换变为BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3),使用Bottleneck layers的DenseNet被作者称为DenseNet-B. Compression： 为了进一步优化模型的简洁性,我们同样可以在transition layer中降低feature map的数量.若一个Denseblock中包含m个feature maps,那么我们使其输出连接的transition layer层生成⌊θm⌋个输出feature map.其中θ为Compression factor, 当θ=1时,transition layer将保留原feature维度不变. 实验结论 a) 一些较早层提取出的特征仍可能被较深层直接使用 b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征 c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,既Compression的必要性. d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生. vggnet网络 inception网络 https://blog.csdn.net/u011021773/article/details/80791650?tdsourcetag=s_pcqq_aiomsg Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 v1 v2 v3 Inception V3 inception V3把googlenet里一些77的卷积变成了17和71的两层串联，33的也一样，变成了13和31，这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299. Inception V4 inception v4实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。 另外就是V4把一个先11再33那步换成了先33再11. 论文说引入resnet不是用来提高深度，进而提高准确度的，只是用来提高速度的。 对Resnet的理解 1.避免梯度消失，解决网络退化。 2.残差模块可以更容易学习更细致的信息。 Resnet网络 https://blog.csdn.net/lanran2/article/details/80247515 resnet-50结构图 https://blog.csdn.net/qq_21046135/article/details/81674605 解释dropout以及实现机制 dropout原理：在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据(batchsize个样本) 作用 ：1.减少特征冗余，减少过拟合 2.提升泛化能力，增加模型的鲁棒性 缺点：减慢收敛速度：由于每次迭代只有一部分参数更新，可能导致梯度下降变慢 为什么梯度会消失和爆炸 1.损失函数 2.网络结构(深层) 3.权值初始化值太大 4.学习率过大 正则化方法以及特点 1.数据增强 数据增强技术如水平、垂直、镜像翻转图像、裁剪、色彩变换、扩展和旋转，滤波，噪点等等 2.提前终止 3.Bagging 4.dropout 5.batch normalizatin 6.参数范数惩罚：https://www.cnblogs.com/pinking/p/9310728.html 深度学习中有什么加快收敛/降低训练难度的方法： 1.瓶颈结构 2.残差 3.学习率、步长、动量 4.优化方法 5.预训练 预训练网络freeze某几层 过拟合怎么做 Parameter Norm Penalties(参数范数惩罚)；Dataset Augmentation (数据集增强)；Early Stopping(提前终止)；Parameter Tying and Parameter Sharing (参数绑定与参数共享)；Bagging and Other Ensemble Methods(Bagging 和其他集成方法)；dropout；regularization； batch normalizatin；加噪声。是解决Overfitting的常用手段。 GAN的公式以及发展历程 https://www.jqr.com/article/000325 https://blog.csdn.net/qq_19272431/article/details/93380342 https://blog.csdn.net/qq_32439305/article/details/86766792 相对判别器 在标准生成对抗网络（SGAN）中，判别器负责估计输入数据是真实数据的概率，根据这个数值，我们再训练生成器以提高伪数据是真实数据的概率。但本文认为，判别器在提高“伪数据为真”的概率的同时，也应该降低“实际数据为真”的概率，原因有三： 1.mini-batch中一半的数据是伪数据，这个先验会带来不合逻辑的结果； 2.在最小化散度（divergence minimization）的过程中，两个概率不是同步变化； 3.实验证实，经过相对判别器诱导，SGAN的性能可以媲美基于IPM的GAN（WGAN、WGAN-GP等），而后者实际上已经具有相对判别器的雏形，因此也更稳定。 本文提出相对GAN（RGAN），并在它的基础上又提出了一个变体——相对均值GAN（RaGAN），变体用平均估计计算判别器概率。此外，论文还显示基于IPM的GAN其实是RGAN的子集。 通过比较，文章发现：(1)相比非相对GAN，RGAN和RaGAN更稳定，产出的数据样本质量更高；(2)在RaGAN上加入梯度惩罚后，它能生成比WGAN-GP质量更高的数据，同时训练时长仅为原先的1/5；(3)RaGAN能够基于非常小的样本（N = 2011）生成合理的高分辨率图像（256x256），撇开做不到的GAN和LSGAN，这些图像在质量上也明显优于WGAN-GP和SGAN生成的归一化图像。 通用GAN的形式： 相对的GAN 简化形式 相对平均GAN 感受野的理解和dilated conv优缺点以及应用场景 https://blog.csdn.net/CV_YOU/article/details/81633645 k为原来卷积核，rate为扩张率，感受野=(k+1)(rate-1)+k 相似度计算 1.余弦距离 2.欧式距离 3.汉明距离 汉明距离/Hamming Distance也能用来计算两个向量的相似度；即通过比较向量每一位是否相同，若不同则汉明距离加1，这样得到汉明距离。向量相似度越高，对应的汉明距离越小。如10001001和10110001有3位不同。 4.马氏距离 如果我们以厘米为单位来测量人的身高，以克（g）为单位测量人的体重。每个人被表示为一个两维向量，如一个人身高173cm，体重50000g，表示为（173,50000），根据身高体重的信息来判断体型的相似程度。 我们已知小明（160,60000）；小王（160,59000）；小李（170，60000）。根据常识可以知道小明和小王体型相似。但是如果根据欧几里得距离来判断，小明和小王的距离要远远大于小明和小李之间的距离，即小明和小李体型相似。这是因为不同特征的度量标准之间存在差异而导致判断出错。 色彩空间 https://blog.csdn.net/ABigDeal/article/details/84836269 RGB和BGR RGB：PIL，scipy； BGR：caffe，opencv。 opencv通道转换 import cv2 img = cv2.imread(&#39;test.jpg&#39;) B, G, R = cv2.split(img) #BGR转RGB，方法1 img_rgb1 = cv2.merge([R, G, B]) #BGR转RGB，方法2 img_rgb2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #BGR转RGB，方法3 img_rgb3 = img[:,:,::-1] PIL转opencv import cv2 from PIL import Image import numpy image = Image.open(&quot;test.jpg&quot;) image.show() img = cv2.cvtColor(numpy.asarray(image),cv2.COLOR_RGB2BGR) cv2.imshow(&quot;OpenCV&quot;,img) cv2.waitKey() opencv转PIL import cv2 from PIL import Image import numpy img = cv2.imread(&quot;test.jpg&quot;) cv2.imshow(&quot;OpenCV&quot;,img) image = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)) image.show() cv2.waitKey() 有什么图像的锐化方法 1.滤波 2.边缘检测 全局和局部特征提取算法分别有 图像的特征提取有哪些算法 ①基于颜色特征：如颜色直方图、颜色集、颜色矩、颜色聚合向量等； ②基于纹理特征：如Tamura纹理特征、自回归纹理模型、Gabor变换、小波变换、MPEG7边缘直方图等； ③基于形状特征：如傅立叶形状描述符、不变矩、小波轮廓描述符等 1、LBP特征提取算法 LBP（Local Binary Patterns，局部二值模式）是提取局部特征作为判别依据的，为一种有效的纹理描述算子，度量和提取图像局部的纹理信息，对光照具有不变性。有多种改进型，LBP结合BP神经网络已经用于人脸识别等领域。LBP的基本思想是定义于像素的8邻域中, 以中心像素的灰度值为阈值, 将周围8 个像素的值与其比较, 如果周围的像素值小于中心像素的灰度值, 该像素位置就被标记为0, 否则标记为1. 每个像素得到一个二进制组合, 就像00010011. 每个像素有8个相邻的像素点,即有2^8种可能性组合。 2.HOG特征提取算法 方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。 不变性：具有光照不变性，不具有尺寸和旋转不变性。 应用：HoG算法提取的是图像各个像素梯度的统计直方图，一般会将这些梯度直方图转化成一个向量，用于分类器的训练输入。 3.Haar特征提取算子 常和AdaBoost结合用于识别人脸。Haar特征很简单，分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。 4.LoG特征提取算法 LoG（DoG是一阶边缘提取）是二阶拉普拉斯-高斯边缘提取算法，先高斯滤波然后拉普拉斯边缘提取。Laplace算子对通过图像进行操作实现边缘检测的时，对离散点和噪声比较敏感。于是，首先对图像进行高斯卷积滤波进行降噪处理，再采用Laplace算子进行边缘检测，就可以提高算子对噪声抗干扰能力, 这一个过程中高斯-拉普拉斯（Laplacian of Gaussian(LOG)）边缘检测算子就诞生了。 5.Harris角点特征提取算法 http://www.cnblogs.com/zhchoutai/p/7182438.html 6.SIFT特征提取算子 SIFT算子是一种检测局部特征的算法，该算法通过求一幅图中的特征点及其有关尺寸和方向的描述子得到特征并进行图像特征点匹配，获得了良好效果。每个特征点的SIFT特征是128维向量，因此计算量巨大。 不变性：具有尺寸和旋转不变性。 改进型：PCA-SIFT，如名称所说“主成分SIFT特征”，主要提取了128维特征向量中的20个特征，大大减少了计算。 http://www.cnblogs.com/liuchaogege/p/5155739.html 7.SURF特征提取算法 SURF是SIFT角点检测算法的改进版，主要体现在速度上，SURF是SIFT速度的3倍。SIFT在尺度和旋转变换的情况下匹配效果比SURF好，而SURF在亮度变化下匹配效果比较好。 http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html 什么是Kmeans，与EM怎么联系 yolo、ssd、faster rcnn的区别 yolo v1：没有使用多层特征，没有使用anchor机制，使用网格预测，每个网格随机预测2个box，直接预测x，y，w，h，损失函数也不一样，使用全连接。 yolo v3：使用多层特征，使用anchor机制，使用网格预测，anchor使用kmeans算法产生，使用3层特征，每层特征使用3个大小的anchor，没有直接预测x，y，w，h，损失函数也不一样，没有使用全连接。 ssd：https://blog.csdn.net/u010712012/article/details/86555814?tdsourcetag=s_pcqq_aiomsg 使用多层特征(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)，使用anchor机制，使用特征图预测，特征图上的每一个特征都预测4个anchor，没有直接预测x，y，w，h，损失函数不一样。 d是先验框，b是预测框 3.faster rcnn 两步走：RPN+ROIP RPN特征图预测anchor，每个特征点预测9个anchor大小，最后得到ROI区域进行池化，最后分类和边框回归。 inception_resnet_v2 faster rcnn RPN实现细节 ROI层是怎么实现的，怎么做的映射 1.根据输入image，将ROI映射到feature map对应位置；首先计算rois映射到feature map的坐标，即原始坐标*spacial_scale(大小为所有stride的乘积分之一)，然后针对每个输出来进行计算，即每个输出点都代表原先的一块区域，这个区域大小为bin_h= roi_height / pooled_ height, bin_w=roi_width / pooled_width.遍历所有top的点所映射回feature map的区域，并找到最大值，记录最大值所在的位置。 2.将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）； 3.对每个sections进行max pooling操作； BN层的moving——mean怎么求得 为什么使用BN层 1.可以选择较大的学习率，使得训练速度增长很快，具有快速收敛性。 2.可以不去理会Dropout，L2正则项参数的选择，如果选择使用BN，甚至可以去掉这两项。 3.去掉局部响应归一化层（LRN）。（AlexNet中使用的方法，BN层出来之后这个就不再用了） 4.可以把训练数据打乱，防止每批训练的时候，某一个样本被经常挑选到。 batch_norm 在test的时候，，用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。所以需要在训练时把BN层的参数保存下来，然后在预测时加载。 BN的学习参数 假设BN层输入为32×128×200×200(NCHW)的大小Tensor，BN层学习的参数可能有：128的倍数。 pooling层的反向传播 手动实现卷积 def conv2d(img, kernel): height, width, in_channels = img.shape kernel_height, kernel_width, in_channels, out_channels = kernel.shape out_height = height - kernel_height + 1 out_width = width - kernel_width + 1 feature_maps = np.zeros(shape=(out_height, out_width, out_channels)) for oc in range(out_channels): # Iterate out_channels (# of kernels) for h in range(out_height): # Iterate out_height for w in range(out_width): # Iterate out_width for ic in range(in_channels): # Iterate in_channels patch = img[h: h + kernel_height, w: w + kernel_width, ic] feature_maps[h, w, oc] += np.sum(patch * kernel[:, :, ic, oc]) return feature_maps 实现卷积层的backward编程 有哪些轻量化模型？ 一、SequeezeNet： 核心思想： 1.使用1x1卷积核代替3x3卷积核，减少参数量； 2.通过squeeze layer限制通道数量，减少参数量； 3.借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding； 4.减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率； 5.使用全局平均池化代替全连接层; 1-3通过fire module实现，如下图所示： 网络结构： 二、Xception 核心思想： 主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释） 首先xception类似于下图，但是区别有两点： 1.Xception中没有relu激活函数； 2.图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。 3.进行残差连接时，不再是concat，而是采用加法操作。 网络结构： 三、MobileNet 核心思想： 1.主要采用depthwise separable convolution，就是分离卷积核； 2.设置宽度因子width multipler和分辨率因子resolution multiplier； 怎么才能使网络进一步压缩呢？可以进一步减少feature map的通道数和size，通过宽度因子减少通道数，分辨率因子减少size。 DK为卷积核大小，DF为特征图大小，M为输入特征图通道，N为输出特征图通道 1、宽度因子α 2、分辨率因子ρ 两个参数都属于(0,1]之间，当为1时则是标准mobileNet。 基本模块： 网络结构： 四、ShuffleNet 核心思想： 1.借鉴resnext分组卷积思想，但不同的是采用1x1卷积核； 2.进行通道清洗，加强通道间的信息流通，提高信息表示能力。 分组卷积和通道清洗： Shuffle的方法： 1.卷积后一共得到g×n个输出通道的feature map； 2.将feature map 进行 reshape为(g,n); 3.进行转置为(n,g)； 4.对转置结果flatten，再分回g组作为下一层的输入。 三种Shuffle unit： 网络结构： 计算一层的参数量、计算量 https://zhuanlan.zhihu.com/p/31575074 inception v1-v3的发展： Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 撕代码：iou计算、k-means、NMS非极大值抑制 iou： def IOU(rectangle A, rectangleB): W = min(A.RT.x, B.RT.x) - max(A.LB.x, B.LB.x) H = min(A.RT.y, B.RT.y) - max(A.LB.y, B.LB.y) if W &lt;= 0 or H &lt;= 0: return 0; SA = (A.RT.x - A.LB.x) * (A.RT.y - A.LB.y) SB = (B.RT.x - B.LB.x) * (B.RT.y - B.LB.y) cross = W * H return cross/(SA + SB - cross) kmeans: def kmeans(self, boxes, k, dist=np.median): box_number = boxes.shape[0] distances = np.empty((box_number, k)) last_nearest = np.zeros((box_number,)) np.random.seed() clusters = boxes[np.random.choice( box_number, k, replace=False)] # init k clusters while True: distances = 1 - self.iou(boxes, clusters) current_nearest = np.argmin(distances, axis=1) if (last_nearest == current_nearest).all(): break # clusters won&#39;t change for cluster in range(k): clusters[cluster] = dist( # update clusters boxes[current_nearest == cluster], axis=0) last_nearest = current_nearest return clusters NMS: def py_cpu_nms(dets, thresh): &quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot; x1 = dets[:, 0] y1 = dets[:, 1] x2 = dets[:, 2] y2 = dets[:, 3] scores = dets[:, 4] areas = (x2 - x1 + 1) * (y2 - y1 + 1) order = scores.argsort()[::-1] keep = [] while order.size &gt; 0: i = order[0] keep.append(i)#保留该类剩余box中得分最高的一个 xx1 = np.maximum(x1[i], x1[order[1:]]) yy1 = np.maximum(y1[i], y1[order[1:]]) xx2 = np.minimum(x2[i], x2[order[1:]]) yy2 = np.minimum(y2[i], y2[order[1:]]) w = np.maximum(0.0, xx2 - xx1 + 1) h = np.maximum(0.0, yy2 - yy1 + 1) inter = w * h ovr = inter / (areas[i] + areas[order[1:]] - inter) inds = np.where(ovr &lt;= thresh)[0] order = order[inds + 1] return keep linux命令 常用命令在这里： https://blog.csdn.net/weixin_43304184/article/details/85102655 查看文件大小命令 df -h du -h --max-depth=1 /home https://www.cnblogs.com/lixuwu/p/5944062.html 查看文件多少行命令 wc -l filename 就是查看文件里有多少行 wc -w filename 看文件里有多少个word。 wc -L filename 文件里最长的那一行是多少个字。 图像哈希算法 1.均值哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算平均值。计算所有64个像素的灰度平均值。 第四步，比较像素的灰度。将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。 第五步，计算哈希值。将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。 如果图片放大或缩小，或改变纵横比，结果值也不会改变。增加或减少亮度或对比度，或改变颜色，对hash值都不会太大的影响。最大的优点：计算速度快！ 如果想比较两张图片，为每张图片构造hash值并且计算不同位的个数。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 2.感知哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算DCT（离散余弦变换）。DCT是把图片分解频率聚集和梯状形，虽然JPEG使用8 * 8的DCT变换，在这里使用32 * 32的DCT变换。 第四步，缩小DCT。虽然DCT的结果是32 * 32大小的矩阵，但我们只要保留左上角的8*8的矩阵，这部分呈现了图片中的最低频率。 第五步，计算平均值。计算所有64个值的平均值。 第六步，进一步减小DCT。这是最主要的一步，根据8 * 8的DCT矩阵，设置0或1的64位的hash值，大于等于DCT均值的设为”1”，小于DCT均值的设为“0”。结果并不能告诉我们真实性的低频率，只能粗略地告诉我们相对于平均值频率的相对比例。只要图片的整体结构保持不变，hash结果值就不变。能够避免伽马校正或颜色直方图被调整带来的影响。 第七步，计算哈希值。将64bit设置成64位的长整型，组合的次序并不重要，只要保证所有图片都采用同样次序就行了。将32 * 32的DCT转换成32 * 32的图像。 将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了（例如，自左到右、自顶向下、big-endian）。 得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算汉明距离。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 3.差异哈希算法 第一步，缩小尺寸，缩放到9 * 8尺寸。 第二步，转换灰度值，转换到0-255之间。 第三步，差异值计算，差异值是通过计算每行相邻像素的强度对比得出的。我们的图片为9 * 8的分辨率，那么就有8行，每行9个像素。差异值是每行分别计算的，也就是第二行的第一个像素不会与第一行的任何像素比较。每一行有9个像素，那么就会产生8个差异值，这也是为何我们选择9作为宽度，因为8bit刚好可以组成一个byte，方便转换为16进制值。 如果前一个像素的颜色强度大于第二个像素，那么差异值就设置为True（也就是1），如果不大于第二个像素，就设置为False（也就是0）。 第四步，转化为hash值，将差异值数组中每一个值看做一个bit，每8个bit组成为一个16进制值，将16进制值连接起来转换为字符串，就得出了最后的dHash值。 第五步，计算汉明距离，如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 boost、Adaboost 线性回归和逻辑回归的区别 逻辑回归多了一个Sigmoid函数，使样本能映射到[0,1]之间的数值，用来做分类问题。 1.线性回归用来预测，逻辑回归用来分类。 2.线性回归是拟合函数，逻辑回归是预测函数 3.线性回归的参数计算方法是最小二乘法，逻辑回归的参数计算方法是梯度下降 什么是全卷积网络，如何实现 https://blog.csdn.net/kekong0713/article/details/52585074 FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,1,1）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。 可以发现，经过多次卷积（还有pooling）以后，得到的图像越来越小,分辨率越来越低（粗略的图像），那么FCN是如何得到图像中每一个像素的类别的呢？为了从这个分辨率低的粗略图像恢复到原图的分辨率，FCN使用了上采样。例如经过5次卷积(和pooling)以后，图像的分辨率依次缩小了2，4，8，16，32倍。对于最后一层的输出图像，需要进行32倍的上采样，以得到原图一样的大小。 这个上采样是通过反卷积（deconvolution）实现的。对第5层的输出（32倍放大）反卷积到原图大小，得到的结果还是不够精确，一些细节无法恢复。于是Jonathan将第4层的输出和第3层的输出也依次反卷积，分别需要16倍和8倍上采样，结果就精细一些了。下图是这个卷积和反卷积上采样的过程： 与传统的基于CNN 的图像分割方法相比，FCN有两个明显优势： 1.可以接受任意大小的输入； 2.避免了重复存储和计算，更加高效。 如何理解LSTM https://blog.csdn.net/menc15/article/details/71271566 如何解决RNN的梯度爆炸和消失 多标签问题 1.问题转换： ①重新组合 ②二元关联 ③分类器链 2.改编算法 修改全连接 3.集成方法 精确率高、召回率低是为什么 一个人有很多框，什么原因造成的 两种情况： 1.框不是重叠的，模型没有训练好。 2.框有重叠，非极大值抑制没有做好，模型没有训练好。 图像旋转、旋转矩阵、像素点怎么填充 openpose openpose的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。研究自下而上算法（得到关键点位置再获得骨架）而不是自上而下算法（先检测人，再回归关键点），是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。 光流怎么计算 https://blog.csdn.net/u011076940/article/details/60766423 优化器有哪些，怎么演进的，平时怎么用，如何调参数 1.梯度下降BGD： 采用整个训练集的数据来计算 cost function 对参数的梯度，由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。参数：学习率。 2.随机梯度下降SGD SGD 每次更新时对每个样本进行梯度更新， 对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡，此外SGD对噪声比较敏感。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处，因为鞍点周围的error 是一样的，所有维度的梯度都接近于0，SGD 很容易被困在这里。参数：学习率。 3.批随机梯度下降MSGD n 个样本进行计算， 这样它可以降低参数更新时的方差，收敛更稳定， 另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。参数：学习率。 4.动量梯度下降法Momentum 动量梯度下降法则对各个mini-batch求得的梯度使用指数加权平均，并使用新的参数更新之前的参数。并设有衰减率，使得前面的影响越来越小。参数：学习率、动量系数0.9。 5.NAG 先以原方向梯度进行超前计算在和下一点的梯度方向进行融合。参数：学习率、动量系数0.9。 6.Adagrad 将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。随着算法不断迭代，整体的学习率会越来越小，学习率也随之变慢。所以，一般来说AdaGrad算法一开始是激励收敛，到了后面就慢慢变成惩罚收敛，速度越来越慢。参数：学习率，小常数。 Adagrad缺点：需要自己手动指定初始学习率，而且由于分母中对历史梯度一直累加，学习率将逐渐下降至0，并且如果初始梯度很大的话，会导致整个训练过程的学习率一直很小，从而导致学习时间变长。 7.Adadelta Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。 8.RMSprop 对Adagrad优化，引入动量，调整梯度。参数：学习率、动量系数0.9、衰减系数0.001、小常数。 https://blog.csdn.net/bvl10101111/article/details/72616378 9.Adam Adam算法是将Momentum算法和RMSProp算法结合起来使用的一种算法。参数：学习率、、两个指数衰减系数0.999,0.9，小常数。 归一化层 1.(0,1)标准化： def MaxMinNormalization(x,Max,Min): x = (x - Min) / (Max - Min); return x 2.Z-scores 这里一样，mu（即均值）用np.average()，sigma（即标准差）用np.std()即可 def Z_ScoreNormalization(x,mu,sigma): x = (x - mu) / sigma; return x 3.sigmoid函数 def sigmoid(X,useStatus): if useStatus: return 1.0 / (1 + np.exp(-float(X))); else: return float(X) 设随机变量X1,X2,…Xn相互独立，且都服从（0,θ）上的均匀分布。求U=max{X1,X2,…Xn}数学期望 声音特征是怎么提取的 https://www.cnblogs.com/BaroC/p/4283380.html BN层，先加BN还是激活，有什么区别 tensorflow pb模型量化 量化(quantitative)是用比 32 位浮点数更少的空间来存储和运行模型，并且 TensorFlow 量化的实现屏蔽了存储和运行细节。神经网络训练时要求速度和准确率，训练通常在 GPU 上进行，所以使用浮点数影响不大。但是在预测阶段，使用浮点数会影响速度。量化可以在加快速度的同时，保持较高的精度。 量化网络的动机主要有两个。最初的动机是减小模型文件的大小。模型文件往往占据很大的磁盘空间，有时，每个模型都接近 200 MB，模型中存储的是分布在大量层中的权值。在存储模型的时候用 8 位整数，模型大小可以缩小为原来 32 位的 25%左右。在加载模型后运算时转换回 32 位浮点数，这样已有的浮点计算代码无需改动即可正常运行。 量化的另一个动机是降低预测过程需要的计算资源。这在嵌入式和移动端非常有意义，能够更快地运行模型，功耗更低。从体系架构的角度来说，8 位的访问次数要比 32 位多，在读取 8 位整数时只需要 32 位浮点数的 1/4 的内存带宽，例如，在 32 位内存带宽的情况下，8 位整数可以一次访问 4 个，32 位浮点数只能 1 次访问 1 个。而且使用 SIMD 指令(19.2节会加速介绍该指令集)，可以在一个时钟周期里实现更多的计算。另一方面，8 位对嵌入式设备的利用更充分，因为很多嵌入式芯片都是 8 位、16 位的，如单片机、数字信号处理器(DSP 芯片)，8 位可以充分利用这些。 此外，神经网络对于噪声的健壮性很强，因为量化会带来精度损失(这种损失可以认为是一种噪声)，并不会危害到整体结果的准确度。 那能否用低精度格式来直接训练呢?答案是，大多数情况下是不能的。因为在训练时，尽管前向传播能够顺利进行，但往往反向传播中需要计算梯度。例如，梯度是 0.2，使用浮点数可以很好地表示，而整数就不能很好地表示，这会导致梯度消失。因此需要使用高于 8 位的值来计算梯度。因此，正如在本节一开始介绍的那样，在移动端训练模型的思路往往是，在 PC 上正常训练好浮点数模型，然后直接将模型转换成 8 位，移动端是使用 8 位的模型来执行预测的过程。 图的遍历 深度优先和广度优先 bagging 1.给定一个弱学习算法,和一个训练集; 2.单个弱学习算法准确率不高; 3.将该学习算法使用多次,得出预测函数序列,进行投票; 4.最后结果准确率将得到提高. 算法： 1.For t = 1, 2, …, T Do 从数据集S中取样（放回选样） 训练得到模型Ht 对未知样本X分类时,每个模型Ht都得出一个分类，得票最高的即为未知样本X的分类 2.也可通过得票的平均值用于连续值的预测 全局对比度增强 1.直方图均衡化 Histogram Equalization 算法： 1）根据图像灰度计算灰度概率密度函数PDF 2）计算累积概率分布函数CDF 3）将CDF归一化到原图灰度取值范围，如[0,255]。 4）之后CDF四舍五入取整，得到灰度转换函数sk=T(rk) 5）将CDF作为转换函数，将灰度为rk的点转换为sk灰度 2. 直方图匹配 Histogram Matching 算法： 1）根据图像计算概率密度分布pr®； 2）根据pr®计算累计分布函数sk=T(rk)； 3）根据给定的目标分布pz(z)计算累计分布函数G(zq)； 4）对于每一个k，找到一个q，使得G(zq)约等于sk； 5）将原图中灰度为k的点变为灰度q； 局部对比度增强 1.邻域直方图均衡：将全局直方图均衡的思想应用于邻域直方图处理中。 2.邻域直方图匹配：将全局直方图匹配的思想应用于邻域直方图处理中。 3.邻域统计方法 算法 1）初始化：增强常数E，灰度下阈值k0，标准差下阈值k1，标准差上阈值k2，窗口半宽s； 2）计算图像灰度均值MG和灰度标准差σG； 3）对于每一个像素，计算邻域（大小为2∗step+1的方块）内灰度均值ML和标准差σL； 4）如果ML&lt;=k0∗MGML&lt;=k0∗MG并且k1∗σG&lt;=σL&lt;=k2∗σG，将像素灰度乘以E。 目标跟踪算法 https://blog.csdn.net/ms961516792/article/details/82682451 这篇文章比较详细。 相机的参数主要包括哪些，标定的步骤及原理，评价标准 相机参数： 相机的内参数是6个分别为：1/dx、1/dy、r、u0、v0、f。opencv1里的说内参数是4个其为fx、fy、u0、v0。实际其fx=F*Sx，其中的F就是焦距上面的f,Sx是像素/没毫米即上面的dx，其是最后面图里的后两个矩阵进行先相乘，得出的，则把它看成整体，就相当于4个内参。其是把r等于零，实际上也是六个。 相机的外参数是6个：三个轴的旋转参数分别为（ω、δ、 θ）,然后把每个轴的33旋转矩阵进行组合（即先矩阵之间相乘），得到集合三个轴旋转信息的R，其大小还是33；T的三个轴的平移参数（Tx、Ty、Tz）。R、T组合成成的3*4的矩阵，其是转换到标定纸坐标的关键。其中绕X轴旋转θ，则其如图： 现以NiKon D700相机为例进行求解其内参数矩阵： 就算大家身边没有这款相机也无所谓，可以在网上百度一下，很方便的就知道其一些参数—— 焦距 f = 35mm 最高分辨率：4256×2832 传感器尺寸：36.0×23.9 mm 根据以上定义可以有： u0= 4256/2 = 2128 v0= 2832/2 = 1416 dx = 36.0/4256 dy = 23.9/2832 fx = f/dx = 4137.8 fy = f/dy = 4147.3 标定方法：相机标定方法有：传统相机标定法、主动视觉相机标定方法、相机自标定法。 标定步骤：https://blog.csdn.net/dcrmg/article/details/52939318 准备标定图片 对每一张标定图片，提取角点信息 对每一张标定图片，进一步提取亚像素角点信息 在棋盘标定图上绘制找到的内角点（非必须，仅为了显示） 相机标定 对标定结果进行评价 查看标定效果——利用标定结果对棋盘图进行矫正 时域滤波和频域滤波 频域的处理有时域不能比拟的优势，就是对于不规则的噪声值，通过傅里叶变换可以得到很好的平滑效果；但相应的，时域在边缘提取上，要比频域的处理更优秀。 常见滤波算法以及特点 高斯滤波 由于高斯函数的傅立叶变换仍是高斯函数, 因此高斯函数能构成一个在频域具有平滑性能的低通滤波器。可以通过在频域做乘积来实现高斯滤波。均值滤波是对是对信号进行局部平均, 以平均值来代表该像素点的灰度值。矩形滤波器(Averaging Box Filter)对这个二维矢量的每一个分量进行独立的平滑处理。通过计算和转化 ,得到一幅单位矢量图。这个 512×512的矢量图被划分成一个 8×8的小区域 ,再在每一个小区域中 ,统计这个区域内的主要方向 ,亦即将对该区域内点方向数进行统计,最多的方向作为区域的主方向。于是就得到了一个新的64×64的矢量图。这个新的矢量图还可以采用一个 3×3模板进行进一步的平滑。 均值滤波 把每个像素都用周围的8个像素来做均值操作。可以平滑图像，速度快，算法简单。但是无法去掉噪声，这能微弱的减弱它。 中值滤波 常用的非线性滤波方法 ,也是图像处理技术中最常用的预处理技术。它在平滑脉冲噪声方面非常有效,同时它可以保护图像尖锐的边缘。加权中值滤波能够改进中值滤波的边缘信号保持效果。但对方向性很强的指纹图像进行滤波处理时 ,有必要引入方向信息,即利用指纹方向图来指导中值滤波的进行。 最小均方差滤波器 亦称维纳滤波器,其设计思想是使输入信号乘响应后的输出,与期望输出的均方误差为最小。 Gabor滤波 Gabor变换是英国物理学家 Gabor提出来的,由“测不准原理”可知,它具有最小的时频窗,即Gabor函数能做到具有最精确的时间-频率的局部化；另外, Gabor函数与哺乳动物的视觉感受野相当吻合,这一点对研究图像特征检测或空间频率滤波非常有用。恰当的选择其参数, Gabor变换可以出色地进行图像分割、识别与理解。如文献提出的基于Gabor滤波器的增强算法。 面试问题 1.格灵深瞳 batchnormal的作用，你怎么看待它。batchnormal的几个参数，参数计算，能不能整合到前面的conv里，训练时和测试时的区别。 说一下感受野计算。 说一下3×3，s=1与5×5，s=2卷积核计算量。 尽可能多的说出1×1卷积的作用 轻量级网络有哪些？具体说说：squeezenet、mobilenet、shuttlenet细节 resnet两个版本的区别，说出每个block的结构。resnet为什么好训练。 介绍一个项目 介绍一个你熟悉的算法 bottlenect 深度优先和广度优先，主要用什么数据结构。" />
<meta property="og:description" content="大佬的面试经验：https://www.nowcoder.com/discuss/128148 以及大佬的博客：https://blog.csdn.net/liuxiao214/article/details/83043170 根据大佬的面试经验一点一点填坑吧。 常见概念 最大似然估计：最大似然估计是一种统计方法，最大似然估计函数在采样样本总数趋于无穷的时候达到最小方差。步骤：1.写出似然函数 2.取对数 3.求导数并令其为0。 最小二乘法：通过最小化误差的平方和寻找数据的最佳函数匹配。 梯度下降法： 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。 模型融合方法： 目前的集成学习方法大致可以分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和随机森林。 1.投票： 假设对于一个二分类问题，有3个基础模型，那么就采取投票制的方法，投票多者确定为最终的分类。 2.平均： 对于回归问题，一个简单直接的思路是取平均。稍稍改进的方法是进行加权平均。权值可以用排序的方法确定，举个例子，比如A、B、C三种基本模型，模型效果进行排名，假设排名分别是1，2，3，那么给这三个模型赋予的权值分别是3/6、2/6、1/6。这两种方法看似简单，其实后面的高级算法也可以说是基于此而产生的，Bagging或者Boosting都是一种把许多弱分类器这样融合成强分类器的思想。 3.Bagging： 就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步： ① 重复K次，有放回地重复抽样建模，训练子模型 ② 模型融合，分类问题：voting，回归问题：average 随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。 4.Boosting： Bagging算法可以并行处理，而Boosting的思想是一种迭代的方法。 AdaBoost 是Boosting 算法家族中代表算法，AdaBoost 每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例，最终将这些弱分类器进行加权相加。AdaBoost模型是弱分类器的线性组合，AdaBoost算法的一个解释是该算法实际上是前向分步算法的一个实现，在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。 xgboost相对AdaBoost区别，对损失函数做了二阶的泰勒展开，并在目标函数之外加入了正则项对整体求最优解，用以权衡目标函数的下降和模型的复杂程度，避免过拟合。所以不考虑细节方面，两者最大的不同就是目标函数的定义 L1L2正则： 判别式模型与生成式模型：： 判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机SVM、神经网络等。 生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi， 常见的生成式模型有 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA等。https://blog.csdn.net/huangfei711/article/details/79834780 熵-交叉熵-KL散度： 熵：信息熵是度量随机变量不确定度的指标，信息熵越大意味着随机变量不确定度越高，意味着系统的有序程度越低。 交叉熵：主要用于度量两个概率分布间的差异性信息。 KL散度/相对熵：是描述两个概率分布P和Q差异的一种方法。 三者间关系： 最优化方法（梯度下降，牛顿法，共轭梯度法）： 牛顿法： 交叉验证： 第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。 第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。 第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。 此外还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法(bootstrapping)。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。 皮尔逊系数： 皮尔逊相关系数广泛用于度量两个变量之间的相关程度，其值介于-1与1之间。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商： bias-variance-tradeoff：偏差方差权衡 1、Bias and Variance tradeoff的最简单方法 当Bias很高的时候，就增加模型的复杂度（比如增加神经网络的神经元个数，神经网络的层数） 当Variance很高的时候，就增加训练的样本量。 然而以上的原则只是一个大的指导方向，因为在实际操作中增加模型的复杂程度将会大大增加计算机的计算量，而且还容易造成Overfitting。 下面详细介绍在实际操作中处理Bias 和 Variance 的具体方法。 2、减少Bias的几大原则 增加模型复杂度 根据误差分析结果，调整输入特征(feature) 减少或者去除Regularization(正则化) 修改模型结构 增加更多的训练样本 3、减少Variance的几大原则 增加更多的训练样本 增加Regularization(正则化) 加入提前终止(Early Stopping) 选择性减少输入的特征(Features) 减小模型规模 根据误差分析结果，调整输入特征(feature) 修改模型结构 无偏估计：无偏估计是用样本统计量来估计总体参数时的一种无偏推断。估计量的数学期望等于被估计参数的真实值，则称此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。 ROC，recall，precision： 分类器的ROC曲线和相关指标 准确率(Accuracy)：ACC=(TP+TN)/(TP+TN+FP+FN) mAP是什么 P：precision即准确率，TP / (TP + FP)，分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例; R：recall即召回率，TP / (TP + FN)，分类器认为是正类并且确实是正类的部分占所有确实是正类的比例; 目标检测中： TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次） FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量 FN: 没有检测到的GT的数量 PR曲线：以P和R为纵横坐标的曲线; AP值：Average Precision平均精确度，为PR曲线下面积; mAP:各类AP的平均值; 举例： 假设，对于Aeroplane类别，我们网络有以下输出(BB表示BoundingBox序号，IoU&gt;0.5时GT=1)： BB | confidence | GT ---------------------- BB1 | 0.9 | 1 ---------------------- BB2 | 0.9 | 1 ---------------------- BB1 | 0.8 | 1 ---------------------- BB3 | 0.7 | 0 ---------------------- BB4 | 0.7 | 0 ---------------------- BB5 | 0.7 | 1 ---------------------- BB6 | 0.7 | 0 ---------------------- BB7 | 0.7 | 0 ---------------------- BB8 | 0.7 | 1 ---------------------- BB9 | 0.7 | 1 ---------------------- 因此，我们有 TP=5 (BB1, BB2, BB5, BB8, BB9), FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2. 这时我们就可以按照Confidence的顺序给出各处的PR值，如下： rank=1 precision=1.00 and recall=0.14 ---------- rank=2 precision=1.00 and recall=0.29 ---------- rank=3 precision=0.66 and recall=0.29 ---------- rank=4 precision=0.50 and recall=0.29 ---------- rank=5 precision=0.40 and recall=0.29 ---------- rank=6 precision=0.50 and recall=0.43 ---------- rank=7 precision=0.43 and recall=0.43 ---------- rank=8 precision=0.38 and recall=0.43 ---------- rank=9 precision=0.44 and recall=0.57 ---------- rank=10 precision=0.50 and recall=0.71 对于Recall &gt;= 0, 0.14, 0.29, 0.43, 0.57, 0.71, 1，我们选取此时Percision的最大值：1, 1, 1, 0.5, 0.5, 0.5, 0。此时Aeroplane类别的 AP = (0.14-0)*1 + (0.29-0.14)*1 + (0.43-0.29)*0.5 + (0.57-0.43)*0.5 + (0.71-0.57)*0.5 + (1-0.71)*0 = 0.5 mAP就是对每一个类别都计算出AP然后再计算AP平均值就好了。 图像分类方法 逻辑回归，支持向量机，随机森林，GBDT，深度学习。 逻辑回归：https://www.jianshu.com/p/1bf35d61995f 支持向量机：https://blog.csdn.net/u011630575/article/details/78916747 距离超平面最小的样例，我们称之为支持向量，我们所要找的最优超平面，就是使支持向量到超平面距离最大，我们认为，这样的超平面，就是最优的，下面也是要想办法求出这个超平面。SVM的核心问题就是找到这一超平面 最大间隔分类： 随机森林：https://blog.csdn.net/yangyin007/article/details/82385967?tdsourcetag=s_pcqq_aiomsg GBDT： LR和SVM的异同 相同点： 第一，LR和SVM都是分类算法。 第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。 第三，LR和SVM都是监督学习算法。 第四，LR和SVM都是判别模型。 第五，LR和SVM在学术界和工业界都广为人知并且应用广泛。 不同点： 第一，损失函数不同 第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。 第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。 第四，​线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响。 第五，SVM的损失函数就自带正则（损失函数中的1/2||w||^2项），这就是为什么SVM是结构风险最小化算法的原因，而LR必须另外在损失函数上添加正则项 函数间隔和几何间隔 函数间隔 几何间隔 视频分类 思路： 1.通过将视频的每一帧视为一幅单独的图像，利用二维 CNN 进行处理。这种方法将视频分类问题简化为图像分类问题。每帧视频图像都有类别输出，并且根据各帧输出的类别，选择频率最高的类别作为视频的分类结果。 2.创建一个单一的网络，将二维 CNN 与一个 RNN 结合在一起。这个想法是，CNN 将考虑到图像分量，而 RNN 将考虑每个视频的序列信息。这种类型的网络可能非常难以训练，因为要优化的参数数量非常大。 3.使用三维卷积网络，其中三维卷积网络是二维 CNN 的在 3D 张量（时间，图像宽度，图像高度）上运行的扩展。这种方法是图像分类的另一个自然延伸，但三维卷积网络可能很难训练。 4.基于智能方法的直觉。它们可以用于存储视频中每个帧的离线功能，而不是直接使用 CNN 进行分类。这个想法基于，特征提取可以非常有效地进行迁移学习，如前面章节所示。在提取所有的特征之后，可以将它们作为一组输入传递给RNN，其将在多个帧中学习序列并输出最终的分类。 5.第四种方法的简单变体，其中最后一层是 MLP 而不是 RNN。在某些情况下，就计算需求而言，这种方法可以更简单并且成本更低。 6.第四种方法的变体，其中特征提取阶段采用三维 CNN 来提取空间和视觉特征，然后将这些特征传递给 RNN 或 MLP。 细粒度分类 https://blog.csdn.net/qq_25439417/article/details/82764183 细粒度分类：同一类中不同子类物体间的分类。 1.Part-based R-CNN。 如上所示，局部区域将从自底向上的候选区域开始（左上角），我们将基于深度卷积特征同时训练目标和局部区域。在推断阶段，所有的窗口都会由检测器评分（中间），且我们可以应用非参几何约束（底部）重新评估窗口并选择最优的目标和局部检测（右上角）。最后的步骤就是抽取局部语义信息来用于细粒度识别，并训练一个分类器预测最终类别。 2.Bilinear deep network models 3.FCN attention。 在抽取特征后，模型需要学习哪些局部区域对最终分类是重要的，而确定重要性的标准即局部区域对最终预测是否有帮助。在这一阶段中，注意力网络会将基本的局部卷积特征图生成一张评分图或置信图，即通过叠加的两个卷积层将特征图转换为通道数为 1 的评分图。一般第一个卷积层可使用 64 个 3×3 的卷积核，而第二个卷积层可使用 1 个 3×3 的卷积核将通道数降为 1，这一张置信图展示了模型关注的兴趣点。 兴趣点是网络自己学到的，而裁剪的大小是我们给定的。我们首先会给一个 8×8 的较大裁剪窗口，相当于关注较大的区域。随着迭代的进行，我们会慢慢减小裁剪窗口，这相当于关注更小的细节。裁剪后的特征图一般需要馈送到 Softmax 层以将置信图转换为概率图。 你知道attention起源是用在哪里？pixel还是frame，是soft还是hard 对于 Attention的作用角度出发，可以分为： 空间注意力 Spatial Attention，时间注意力 Temporal Attention 这样的分类更多的是从应用层面上；而从 Attention的作用方法上，可以将其分为 Soft Attention 和 Hard Attention，这既我们所说的， Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。 attention机制：https://blog.csdn.net/xiewenbo/article/details/79382785 Soft Attention：传统的Attention Mechanism就是Soft Attention,即通过确定性的得分计算来得到attended之后的编码隐状态。Soft Attention是参数化的（Parameterization），因此可导，可以被嵌入到模型中去，直接训练。梯度可以经过Attention Mechanism模块，反向传播到模型其他部分。 Hard Attention：是一个随机的过程。Hard Attention不会选择整个encoder的隐层输出做为其输入，Hard Attention会依概率Si来采样输入端的隐状态一部分来进行计算，而不是整个encoder的隐状态。为了实现梯度的反向传播，需要采用蒙特卡洛采样的方法来估计模块的梯度。 两种Attention Mechanism都有各自的优势，但目前更多的研究和应用还是更倾向于使用Soft Attention，因为其可以直接求导，进行梯度反向传播 网络用的损失函数是什么 L1 loss：绝对差平均损失，又称MAE . 2.L2 loss：平方差平均损失，又称MSE 3.Smooth L1 loss，又称Huber损失 4.BCE loss，二分类用的交叉熵损失，用的时候需要在该层前面加上 Sigmoid 函数 5.BCEWithlogitsLoss，将sigmoid函数集成到BCE loss上 6.CrossEntoryLoss，交叉熵损失函数 第一种形式： 第二种形式： softmax的交叉熵： 7.NllLoss：负对数似然损失。 监督学习和无监督学习 监督学习(supervised learning)：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。 无监督学习(unsupervised learning)：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。 强化学习(reinforcement learning)：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。 弱监督学习(weakly supervised learning)： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。 半监督学习(semi supervised learning) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，学习已知标签和未知标签的数据，将输入数据映射到标签的过程。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。 多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。 softmax loss softmax的交叉熵： LR为什么要用sigmoid函数 3. LR 损失函数为什么用极大似然函数？ 1.因为我们想要让每一个样本的预测都要得到最大的概率，即将所有的样本预测后的概率进行相乘都最大，也就是极大似然函数. 2.对极大似然函数取对数以后相当于对数损失函数，由上面梯度更新的公式可以看出，对数损失函数的训练求解参数的速度是比较快的，而且更新速度只和x，y有关，比较的稳定。 3.为什么不用平方损失函数 如果使用平方损失函数，梯度更新的速度会和 sigmod 函数的梯度相关，sigmod 函数在定义域内的梯度都不大于0.25，导致训练速度会非常慢。 而且平方损失会导致损失函数是 theta 的非凸函数，不利于求解，因为非凸函数存在很多局部最优解 softmax交叉熵损失函数求导 https://blog.csdn.net/qian99/article/details/78046329 softmax和logistic回归的区别和联系 1.softmax用来解决多分类问题，lr解决二分类问题 2.softmax输出每一类的概率值，并确定概率最大的类是正确的，lr只区别是还是不是。事实上softmax是lr的一般情况。 https://blog.csdn.net/chnguoshiwushuang/article/details/80514626 全连接的作用 因为用到了所有的局部特征，所以叫全连接。将学到的“分布式特征表示”映射到样本标记空间的作用。 GD、SGD、mini batch GD的区别 GD：梯度下降法的物理意义很好理解，就是沿着当前点的梯度方向进行线搜索，找到下一个迭代点 SGD：随机梯度下降法，每次计算梯度时，只随机的选取一个样本来计算梯度,这样就大大的减小了计算的复杂度，随机梯度下降法速度快，但每次的方向不稳定，甚至可能向反方向。 mini batch GD：故每次计算梯度时，选取一部分样本，即小批量梯度下降法。 S3D了解吗？ 边缘检测算子有哪些 1.差分算子。 一阶微分： 2.Roberts算子，对角线方向相邻两象素之差近似梯度幅值检测边缘，对噪声敏感,无法抑制噪声的影响。 3.Sobel算子，该算子包含两组3 * 3的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差分近似值，在结合横向和纵向 4.Prewitt算子，一阶微分算子的边缘检测，模板3 * 3利用像素点上下、左右邻点的灰度差，在边缘处达到极值检测边缘，去掉部分伪边缘，对噪声具有平滑作用 。 二阶微分 5.Laplacian算子，存在噪声情况下，使用Laplacian算子检测边缘之前需要先进行低通滤波，模板3 * 3。 6.Log算子，进行高斯滤波再进行拉普拉斯算子检测，模板5 * 5。 非微分 7.Canny算子： 1)使用高斯滤波器，以平滑图像，滤除噪声。 2)计算图像中每个像素点的梯度强度和方向。 3)应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。 4)应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。 5)通过抑制孤立的弱边缘最终完成边缘检测。 霍夫变换 说一下SVM核函数 在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。核函数的价值在于它虽然也是讲特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算。 1.多项式核函数 2.高斯核函数 3.线性核函数 4.字符串核函数 PCA PCA(principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据压缩算法。它可以通过线性变换将原始数据变换为一组各维度线性无关的表示，以此来提取数据的主要线性分量。 具体可以看这篇文章：https://blog.csdn.net/hustqb/article/details/78394058 伪代码： 去除平均值 计算协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值排序 保留前N个最大的特征值对应的特征向量 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩） L1、L2范数 sigmoid优缺点 优点：可以将函数值的范围压缩到[0,1]，可以压缩数据，且幅度不变。在特征相差比较复杂或是相差不是特别大时效果比较好。可以看到sigmoid函数处处连续便于求导；便于前向传输。 缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法。反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练 RefineNet理解 针对语义分割所提出的网络模型，可以分为两段对应于U-Net中向下（特征逐步降采样同时提取语义特征）和向上（逐步上采样特征恢复细节信息）两段通路。其中向下的通路以ResNet为基础。向上的通路使用了新提出的RefineNet作为基础，并作为本通路特征与ResNet中低层特征的融合器。下图a为标准CNN，b图为带孔卷积，RefineNet的框架如c图所示： 其中左边的四组特征是从ResNet的四个对应的block取出的。此框架与U-Net没有太大区别。不过如作者所说，RefineNet是一个灵活的模块，其输入的尺度个数可以变化，因此整个网络的拓扑结构可以有很多改变。 RefineNet可以分为三个主要部分： 1. 不同尺度（也可能只有一个输入尺度）的特征输入首先经过两个Residual模块的处理； 2. 之后是不同尺寸的特征进行融合。当然如果只有一个输入尺度，该模块则可以省去。所有特征上采样至最大的输入尺寸，然后进行加和。上采样之前的卷积模块是为了调整不同特征的数值尺度； 3. 最后是一个链式的pooling模块。其设计本意是使用侧支上一系列的pooling来获取背景信息（通常尺寸较大）。直连通路上的ReLU可以在不显著影响梯度流通的情况下提高后续pooling的性能，同时不让网络的训练对学习率很敏感。最后再经过一个Residual模块即得RefineNet的输出。 详细架构如下： 引用：https://blog.csdn.net/gqixf/article/details/82911220 densenet结构优缺点以及应用场景 优点： (1) 相比ResNet拥有更少的参数数量. (2) 旁路加强了特征的重用. (3) 网络更易于训练,并具有一定的正则效果. (4) 缓解了gradient vanishing和model degradation的问题. 缺点： DenseNet在训练时十分消耗内存，这是由于算法实现不优带来的。当前的深度学习框架对 DenseNet 的密集连接没有很好的支持，所以只能借助于反复的拼接（Concatenation）操作，将之前层的输出与当前层的输出拼接在一起，然后传给下一层。对于大多数框架（如Torch和TensorFlow），每次拼接操作都会开辟新的内存来保存拼接后的特征。这样就导致一个 L 层的网络，要消耗相当于 L(L+1)/2 层网络的内存. pooling层： 由于在DenseNet中需要对不同层的feature map进行cat操作,所以需要不同层的feature map保持相同的feature size,这就限制了网络中Down sampling的实现.为了使用Down sampling,作者将DenseNet分为多个Denseblock,如下图所示: 在同一个Denseblock中要求feature size保持相同大小,在不同Denseblock之间设置transition layers实现Down sampling, 在作者的实验中transition layer由BN + Conv(1×1) ＋2×2 average-pooling组成. Growth rate： 在Denseblock中,假设每一个非线性变换H的输出为K个feature map, 那么第i层网络的输入便为K0+(i-1)×K, 这里我们可以看到DenseNet和现有网络的一个主要的不同点:DenseNet可以接受较少的特征图数量作为网络层的输出,如下图所示 原因就是在同一个Denseblock中的每一层都与之前所有层相关联,如果我们把feature看作是一个Denseblock的全局状态,那么每一层的训练目标便是通过现有的全局状态,判断需要添加给全局状态的更新值.因而每个网络层输出的特征图数量K又称为Growth rate,同样决定着每一层需要给全局状态更新的信息的多少 Bottleneck Layers： 虽然DenseNet接受较少的k,也就是feature map的数量作为输出,但由于不同层feature map之间由cat操作组合在一起,最终仍然会是feature map的channel较大而成为网络的负担.作者在这里使用1×1 Conv(Bottleneck)作为特征降维的方法来降低channel数量,以提高计算效率.经过改善后的非线性变换变为BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3),使用Bottleneck layers的DenseNet被作者称为DenseNet-B. Compression： 为了进一步优化模型的简洁性,我们同样可以在transition layer中降低feature map的数量.若一个Denseblock中包含m个feature maps,那么我们使其输出连接的transition layer层生成⌊θm⌋个输出feature map.其中θ为Compression factor, 当θ=1时,transition layer将保留原feature维度不变. 实验结论 a) 一些较早层提取出的特征仍可能被较深层直接使用 b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征 c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,既Compression的必要性. d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生. vggnet网络 inception网络 https://blog.csdn.net/u011021773/article/details/80791650?tdsourcetag=s_pcqq_aiomsg Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 v1 v2 v3 Inception V3 inception V3把googlenet里一些77的卷积变成了17和71的两层串联，33的也一样，变成了13和31，这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299. Inception V4 inception v4实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。 另外就是V4把一个先11再33那步换成了先33再11. 论文说引入resnet不是用来提高深度，进而提高准确度的，只是用来提高速度的。 对Resnet的理解 1.避免梯度消失，解决网络退化。 2.残差模块可以更容易学习更细致的信息。 Resnet网络 https://blog.csdn.net/lanran2/article/details/80247515 resnet-50结构图 https://blog.csdn.net/qq_21046135/article/details/81674605 解释dropout以及实现机制 dropout原理：在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据(batchsize个样本) 作用 ：1.减少特征冗余，减少过拟合 2.提升泛化能力，增加模型的鲁棒性 缺点：减慢收敛速度：由于每次迭代只有一部分参数更新，可能导致梯度下降变慢 为什么梯度会消失和爆炸 1.损失函数 2.网络结构(深层) 3.权值初始化值太大 4.学习率过大 正则化方法以及特点 1.数据增强 数据增强技术如水平、垂直、镜像翻转图像、裁剪、色彩变换、扩展和旋转，滤波，噪点等等 2.提前终止 3.Bagging 4.dropout 5.batch normalizatin 6.参数范数惩罚：https://www.cnblogs.com/pinking/p/9310728.html 深度学习中有什么加快收敛/降低训练难度的方法： 1.瓶颈结构 2.残差 3.学习率、步长、动量 4.优化方法 5.预训练 预训练网络freeze某几层 过拟合怎么做 Parameter Norm Penalties(参数范数惩罚)；Dataset Augmentation (数据集增强)；Early Stopping(提前终止)；Parameter Tying and Parameter Sharing (参数绑定与参数共享)；Bagging and Other Ensemble Methods(Bagging 和其他集成方法)；dropout；regularization； batch normalizatin；加噪声。是解决Overfitting的常用手段。 GAN的公式以及发展历程 https://www.jqr.com/article/000325 https://blog.csdn.net/qq_19272431/article/details/93380342 https://blog.csdn.net/qq_32439305/article/details/86766792 相对判别器 在标准生成对抗网络（SGAN）中，判别器负责估计输入数据是真实数据的概率，根据这个数值，我们再训练生成器以提高伪数据是真实数据的概率。但本文认为，判别器在提高“伪数据为真”的概率的同时，也应该降低“实际数据为真”的概率，原因有三： 1.mini-batch中一半的数据是伪数据，这个先验会带来不合逻辑的结果； 2.在最小化散度（divergence minimization）的过程中，两个概率不是同步变化； 3.实验证实，经过相对判别器诱导，SGAN的性能可以媲美基于IPM的GAN（WGAN、WGAN-GP等），而后者实际上已经具有相对判别器的雏形，因此也更稳定。 本文提出相对GAN（RGAN），并在它的基础上又提出了一个变体——相对均值GAN（RaGAN），变体用平均估计计算判别器概率。此外，论文还显示基于IPM的GAN其实是RGAN的子集。 通过比较，文章发现：(1)相比非相对GAN，RGAN和RaGAN更稳定，产出的数据样本质量更高；(2)在RaGAN上加入梯度惩罚后，它能生成比WGAN-GP质量更高的数据，同时训练时长仅为原先的1/5；(3)RaGAN能够基于非常小的样本（N = 2011）生成合理的高分辨率图像（256x256），撇开做不到的GAN和LSGAN，这些图像在质量上也明显优于WGAN-GP和SGAN生成的归一化图像。 通用GAN的形式： 相对的GAN 简化形式 相对平均GAN 感受野的理解和dilated conv优缺点以及应用场景 https://blog.csdn.net/CV_YOU/article/details/81633645 k为原来卷积核，rate为扩张率，感受野=(k+1)(rate-1)+k 相似度计算 1.余弦距离 2.欧式距离 3.汉明距离 汉明距离/Hamming Distance也能用来计算两个向量的相似度；即通过比较向量每一位是否相同，若不同则汉明距离加1，这样得到汉明距离。向量相似度越高，对应的汉明距离越小。如10001001和10110001有3位不同。 4.马氏距离 如果我们以厘米为单位来测量人的身高，以克（g）为单位测量人的体重。每个人被表示为一个两维向量，如一个人身高173cm，体重50000g，表示为（173,50000），根据身高体重的信息来判断体型的相似程度。 我们已知小明（160,60000）；小王（160,59000）；小李（170，60000）。根据常识可以知道小明和小王体型相似。但是如果根据欧几里得距离来判断，小明和小王的距离要远远大于小明和小李之间的距离，即小明和小李体型相似。这是因为不同特征的度量标准之间存在差异而导致判断出错。 色彩空间 https://blog.csdn.net/ABigDeal/article/details/84836269 RGB和BGR RGB：PIL，scipy； BGR：caffe，opencv。 opencv通道转换 import cv2 img = cv2.imread(&#39;test.jpg&#39;) B, G, R = cv2.split(img) #BGR转RGB，方法1 img_rgb1 = cv2.merge([R, G, B]) #BGR转RGB，方法2 img_rgb2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #BGR转RGB，方法3 img_rgb3 = img[:,:,::-1] PIL转opencv import cv2 from PIL import Image import numpy image = Image.open(&quot;test.jpg&quot;) image.show() img = cv2.cvtColor(numpy.asarray(image),cv2.COLOR_RGB2BGR) cv2.imshow(&quot;OpenCV&quot;,img) cv2.waitKey() opencv转PIL import cv2 from PIL import Image import numpy img = cv2.imread(&quot;test.jpg&quot;) cv2.imshow(&quot;OpenCV&quot;,img) image = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)) image.show() cv2.waitKey() 有什么图像的锐化方法 1.滤波 2.边缘检测 全局和局部特征提取算法分别有 图像的特征提取有哪些算法 ①基于颜色特征：如颜色直方图、颜色集、颜色矩、颜色聚合向量等； ②基于纹理特征：如Tamura纹理特征、自回归纹理模型、Gabor变换、小波变换、MPEG7边缘直方图等； ③基于形状特征：如傅立叶形状描述符、不变矩、小波轮廓描述符等 1、LBP特征提取算法 LBP（Local Binary Patterns，局部二值模式）是提取局部特征作为判别依据的，为一种有效的纹理描述算子，度量和提取图像局部的纹理信息，对光照具有不变性。有多种改进型，LBP结合BP神经网络已经用于人脸识别等领域。LBP的基本思想是定义于像素的8邻域中, 以中心像素的灰度值为阈值, 将周围8 个像素的值与其比较, 如果周围的像素值小于中心像素的灰度值, 该像素位置就被标记为0, 否则标记为1. 每个像素得到一个二进制组合, 就像00010011. 每个像素有8个相邻的像素点,即有2^8种可能性组合。 2.HOG特征提取算法 方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。 不变性：具有光照不变性，不具有尺寸和旋转不变性。 应用：HoG算法提取的是图像各个像素梯度的统计直方图，一般会将这些梯度直方图转化成一个向量，用于分类器的训练输入。 3.Haar特征提取算子 常和AdaBoost结合用于识别人脸。Haar特征很简单，分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。 4.LoG特征提取算法 LoG（DoG是一阶边缘提取）是二阶拉普拉斯-高斯边缘提取算法，先高斯滤波然后拉普拉斯边缘提取。Laplace算子对通过图像进行操作实现边缘检测的时，对离散点和噪声比较敏感。于是，首先对图像进行高斯卷积滤波进行降噪处理，再采用Laplace算子进行边缘检测，就可以提高算子对噪声抗干扰能力, 这一个过程中高斯-拉普拉斯（Laplacian of Gaussian(LOG)）边缘检测算子就诞生了。 5.Harris角点特征提取算法 http://www.cnblogs.com/zhchoutai/p/7182438.html 6.SIFT特征提取算子 SIFT算子是一种检测局部特征的算法，该算法通过求一幅图中的特征点及其有关尺寸和方向的描述子得到特征并进行图像特征点匹配，获得了良好效果。每个特征点的SIFT特征是128维向量，因此计算量巨大。 不变性：具有尺寸和旋转不变性。 改进型：PCA-SIFT，如名称所说“主成分SIFT特征”，主要提取了128维特征向量中的20个特征，大大减少了计算。 http://www.cnblogs.com/liuchaogege/p/5155739.html 7.SURF特征提取算法 SURF是SIFT角点检测算法的改进版，主要体现在速度上，SURF是SIFT速度的3倍。SIFT在尺度和旋转变换的情况下匹配效果比SURF好，而SURF在亮度变化下匹配效果比较好。 http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html 什么是Kmeans，与EM怎么联系 yolo、ssd、faster rcnn的区别 yolo v1：没有使用多层特征，没有使用anchor机制，使用网格预测，每个网格随机预测2个box，直接预测x，y，w，h，损失函数也不一样，使用全连接。 yolo v3：使用多层特征，使用anchor机制，使用网格预测，anchor使用kmeans算法产生，使用3层特征，每层特征使用3个大小的anchor，没有直接预测x，y，w，h，损失函数也不一样，没有使用全连接。 ssd：https://blog.csdn.net/u010712012/article/details/86555814?tdsourcetag=s_pcqq_aiomsg 使用多层特征(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)，使用anchor机制，使用特征图预测，特征图上的每一个特征都预测4个anchor，没有直接预测x，y，w，h，损失函数不一样。 d是先验框，b是预测框 3.faster rcnn 两步走：RPN+ROIP RPN特征图预测anchor，每个特征点预测9个anchor大小，最后得到ROI区域进行池化，最后分类和边框回归。 inception_resnet_v2 faster rcnn RPN实现细节 ROI层是怎么实现的，怎么做的映射 1.根据输入image，将ROI映射到feature map对应位置；首先计算rois映射到feature map的坐标，即原始坐标*spacial_scale(大小为所有stride的乘积分之一)，然后针对每个输出来进行计算，即每个输出点都代表原先的一块区域，这个区域大小为bin_h= roi_height / pooled_ height, bin_w=roi_width / pooled_width.遍历所有top的点所映射回feature map的区域，并找到最大值，记录最大值所在的位置。 2.将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）； 3.对每个sections进行max pooling操作； BN层的moving——mean怎么求得 为什么使用BN层 1.可以选择较大的学习率，使得训练速度增长很快，具有快速收敛性。 2.可以不去理会Dropout，L2正则项参数的选择，如果选择使用BN，甚至可以去掉这两项。 3.去掉局部响应归一化层（LRN）。（AlexNet中使用的方法，BN层出来之后这个就不再用了） 4.可以把训练数据打乱，防止每批训练的时候，某一个样本被经常挑选到。 batch_norm 在test的时候，，用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。所以需要在训练时把BN层的参数保存下来，然后在预测时加载。 BN的学习参数 假设BN层输入为32×128×200×200(NCHW)的大小Tensor，BN层学习的参数可能有：128的倍数。 pooling层的反向传播 手动实现卷积 def conv2d(img, kernel): height, width, in_channels = img.shape kernel_height, kernel_width, in_channels, out_channels = kernel.shape out_height = height - kernel_height + 1 out_width = width - kernel_width + 1 feature_maps = np.zeros(shape=(out_height, out_width, out_channels)) for oc in range(out_channels): # Iterate out_channels (# of kernels) for h in range(out_height): # Iterate out_height for w in range(out_width): # Iterate out_width for ic in range(in_channels): # Iterate in_channels patch = img[h: h + kernel_height, w: w + kernel_width, ic] feature_maps[h, w, oc] += np.sum(patch * kernel[:, :, ic, oc]) return feature_maps 实现卷积层的backward编程 有哪些轻量化模型？ 一、SequeezeNet： 核心思想： 1.使用1x1卷积核代替3x3卷积核，减少参数量； 2.通过squeeze layer限制通道数量，减少参数量； 3.借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding； 4.减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率； 5.使用全局平均池化代替全连接层; 1-3通过fire module实现，如下图所示： 网络结构： 二、Xception 核心思想： 主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释） 首先xception类似于下图，但是区别有两点： 1.Xception中没有relu激活函数； 2.图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。 3.进行残差连接时，不再是concat，而是采用加法操作。 网络结构： 三、MobileNet 核心思想： 1.主要采用depthwise separable convolution，就是分离卷积核； 2.设置宽度因子width multipler和分辨率因子resolution multiplier； 怎么才能使网络进一步压缩呢？可以进一步减少feature map的通道数和size，通过宽度因子减少通道数，分辨率因子减少size。 DK为卷积核大小，DF为特征图大小，M为输入特征图通道，N为输出特征图通道 1、宽度因子α 2、分辨率因子ρ 两个参数都属于(0,1]之间，当为1时则是标准mobileNet。 基本模块： 网络结构： 四、ShuffleNet 核心思想： 1.借鉴resnext分组卷积思想，但不同的是采用1x1卷积核； 2.进行通道清洗，加强通道间的信息流通，提高信息表示能力。 分组卷积和通道清洗： Shuffle的方法： 1.卷积后一共得到g×n个输出通道的feature map； 2.将feature map 进行 reshape为(g,n); 3.进行转置为(n,g)； 4.对转置结果flatten，再分回g组作为下一层的输入。 三种Shuffle unit： 网络结构： 计算一层的参数量、计算量 https://zhuanlan.zhihu.com/p/31575074 inception v1-v3的发展： Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 撕代码：iou计算、k-means、NMS非极大值抑制 iou： def IOU(rectangle A, rectangleB): W = min(A.RT.x, B.RT.x) - max(A.LB.x, B.LB.x) H = min(A.RT.y, B.RT.y) - max(A.LB.y, B.LB.y) if W &lt;= 0 or H &lt;= 0: return 0; SA = (A.RT.x - A.LB.x) * (A.RT.y - A.LB.y) SB = (B.RT.x - B.LB.x) * (B.RT.y - B.LB.y) cross = W * H return cross/(SA + SB - cross) kmeans: def kmeans(self, boxes, k, dist=np.median): box_number = boxes.shape[0] distances = np.empty((box_number, k)) last_nearest = np.zeros((box_number,)) np.random.seed() clusters = boxes[np.random.choice( box_number, k, replace=False)] # init k clusters while True: distances = 1 - self.iou(boxes, clusters) current_nearest = np.argmin(distances, axis=1) if (last_nearest == current_nearest).all(): break # clusters won&#39;t change for cluster in range(k): clusters[cluster] = dist( # update clusters boxes[current_nearest == cluster], axis=0) last_nearest = current_nearest return clusters NMS: def py_cpu_nms(dets, thresh): &quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot; x1 = dets[:, 0] y1 = dets[:, 1] x2 = dets[:, 2] y2 = dets[:, 3] scores = dets[:, 4] areas = (x2 - x1 + 1) * (y2 - y1 + 1) order = scores.argsort()[::-1] keep = [] while order.size &gt; 0: i = order[0] keep.append(i)#保留该类剩余box中得分最高的一个 xx1 = np.maximum(x1[i], x1[order[1:]]) yy1 = np.maximum(y1[i], y1[order[1:]]) xx2 = np.minimum(x2[i], x2[order[1:]]) yy2 = np.minimum(y2[i], y2[order[1:]]) w = np.maximum(0.0, xx2 - xx1 + 1) h = np.maximum(0.0, yy2 - yy1 + 1) inter = w * h ovr = inter / (areas[i] + areas[order[1:]] - inter) inds = np.where(ovr &lt;= thresh)[0] order = order[inds + 1] return keep linux命令 常用命令在这里： https://blog.csdn.net/weixin_43304184/article/details/85102655 查看文件大小命令 df -h du -h --max-depth=1 /home https://www.cnblogs.com/lixuwu/p/5944062.html 查看文件多少行命令 wc -l filename 就是查看文件里有多少行 wc -w filename 看文件里有多少个word。 wc -L filename 文件里最长的那一行是多少个字。 图像哈希算法 1.均值哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算平均值。计算所有64个像素的灰度平均值。 第四步，比较像素的灰度。将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。 第五步，计算哈希值。将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。 如果图片放大或缩小，或改变纵横比，结果值也不会改变。增加或减少亮度或对比度，或改变颜色，对hash值都不会太大的影响。最大的优点：计算速度快！ 如果想比较两张图片，为每张图片构造hash值并且计算不同位的个数。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 2.感知哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算DCT（离散余弦变换）。DCT是把图片分解频率聚集和梯状形，虽然JPEG使用8 * 8的DCT变换，在这里使用32 * 32的DCT变换。 第四步，缩小DCT。虽然DCT的结果是32 * 32大小的矩阵，但我们只要保留左上角的8*8的矩阵，这部分呈现了图片中的最低频率。 第五步，计算平均值。计算所有64个值的平均值。 第六步，进一步减小DCT。这是最主要的一步，根据8 * 8的DCT矩阵，设置0或1的64位的hash值，大于等于DCT均值的设为”1”，小于DCT均值的设为“0”。结果并不能告诉我们真实性的低频率，只能粗略地告诉我们相对于平均值频率的相对比例。只要图片的整体结构保持不变，hash结果值就不变。能够避免伽马校正或颜色直方图被调整带来的影响。 第七步，计算哈希值。将64bit设置成64位的长整型，组合的次序并不重要，只要保证所有图片都采用同样次序就行了。将32 * 32的DCT转换成32 * 32的图像。 将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了（例如，自左到右、自顶向下、big-endian）。 得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算汉明距离。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 3.差异哈希算法 第一步，缩小尺寸，缩放到9 * 8尺寸。 第二步，转换灰度值，转换到0-255之间。 第三步，差异值计算，差异值是通过计算每行相邻像素的强度对比得出的。我们的图片为9 * 8的分辨率，那么就有8行，每行9个像素。差异值是每行分别计算的，也就是第二行的第一个像素不会与第一行的任何像素比较。每一行有9个像素，那么就会产生8个差异值，这也是为何我们选择9作为宽度，因为8bit刚好可以组成一个byte，方便转换为16进制值。 如果前一个像素的颜色强度大于第二个像素，那么差异值就设置为True（也就是1），如果不大于第二个像素，就设置为False（也就是0）。 第四步，转化为hash值，将差异值数组中每一个值看做一个bit，每8个bit组成为一个16进制值，将16进制值连接起来转换为字符串，就得出了最后的dHash值。 第五步，计算汉明距离，如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 boost、Adaboost 线性回归和逻辑回归的区别 逻辑回归多了一个Sigmoid函数，使样本能映射到[0,1]之间的数值，用来做分类问题。 1.线性回归用来预测，逻辑回归用来分类。 2.线性回归是拟合函数，逻辑回归是预测函数 3.线性回归的参数计算方法是最小二乘法，逻辑回归的参数计算方法是梯度下降 什么是全卷积网络，如何实现 https://blog.csdn.net/kekong0713/article/details/52585074 FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,1,1）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。 可以发现，经过多次卷积（还有pooling）以后，得到的图像越来越小,分辨率越来越低（粗略的图像），那么FCN是如何得到图像中每一个像素的类别的呢？为了从这个分辨率低的粗略图像恢复到原图的分辨率，FCN使用了上采样。例如经过5次卷积(和pooling)以后，图像的分辨率依次缩小了2，4，8，16，32倍。对于最后一层的输出图像，需要进行32倍的上采样，以得到原图一样的大小。 这个上采样是通过反卷积（deconvolution）实现的。对第5层的输出（32倍放大）反卷积到原图大小，得到的结果还是不够精确，一些细节无法恢复。于是Jonathan将第4层的输出和第3层的输出也依次反卷积，分别需要16倍和8倍上采样，结果就精细一些了。下图是这个卷积和反卷积上采样的过程： 与传统的基于CNN 的图像分割方法相比，FCN有两个明显优势： 1.可以接受任意大小的输入； 2.避免了重复存储和计算，更加高效。 如何理解LSTM https://blog.csdn.net/menc15/article/details/71271566 如何解决RNN的梯度爆炸和消失 多标签问题 1.问题转换： ①重新组合 ②二元关联 ③分类器链 2.改编算法 修改全连接 3.集成方法 精确率高、召回率低是为什么 一个人有很多框，什么原因造成的 两种情况： 1.框不是重叠的，模型没有训练好。 2.框有重叠，非极大值抑制没有做好，模型没有训练好。 图像旋转、旋转矩阵、像素点怎么填充 openpose openpose的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。研究自下而上算法（得到关键点位置再获得骨架）而不是自上而下算法（先检测人，再回归关键点），是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。 光流怎么计算 https://blog.csdn.net/u011076940/article/details/60766423 优化器有哪些，怎么演进的，平时怎么用，如何调参数 1.梯度下降BGD： 采用整个训练集的数据来计算 cost function 对参数的梯度，由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。参数：学习率。 2.随机梯度下降SGD SGD 每次更新时对每个样本进行梯度更新， 对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡，此外SGD对噪声比较敏感。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处，因为鞍点周围的error 是一样的，所有维度的梯度都接近于0，SGD 很容易被困在这里。参数：学习率。 3.批随机梯度下降MSGD n 个样本进行计算， 这样它可以降低参数更新时的方差，收敛更稳定， 另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。参数：学习率。 4.动量梯度下降法Momentum 动量梯度下降法则对各个mini-batch求得的梯度使用指数加权平均，并使用新的参数更新之前的参数。并设有衰减率，使得前面的影响越来越小。参数：学习率、动量系数0.9。 5.NAG 先以原方向梯度进行超前计算在和下一点的梯度方向进行融合。参数：学习率、动量系数0.9。 6.Adagrad 将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。随着算法不断迭代，整体的学习率会越来越小，学习率也随之变慢。所以，一般来说AdaGrad算法一开始是激励收敛，到了后面就慢慢变成惩罚收敛，速度越来越慢。参数：学习率，小常数。 Adagrad缺点：需要自己手动指定初始学习率，而且由于分母中对历史梯度一直累加，学习率将逐渐下降至0，并且如果初始梯度很大的话，会导致整个训练过程的学习率一直很小，从而导致学习时间变长。 7.Adadelta Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。 8.RMSprop 对Adagrad优化，引入动量，调整梯度。参数：学习率、动量系数0.9、衰减系数0.001、小常数。 https://blog.csdn.net/bvl10101111/article/details/72616378 9.Adam Adam算法是将Momentum算法和RMSProp算法结合起来使用的一种算法。参数：学习率、、两个指数衰减系数0.999,0.9，小常数。 归一化层 1.(0,1)标准化： def MaxMinNormalization(x,Max,Min): x = (x - Min) / (Max - Min); return x 2.Z-scores 这里一样，mu（即均值）用np.average()，sigma（即标准差）用np.std()即可 def Z_ScoreNormalization(x,mu,sigma): x = (x - mu) / sigma; return x 3.sigmoid函数 def sigmoid(X,useStatus): if useStatus: return 1.0 / (1 + np.exp(-float(X))); else: return float(X) 设随机变量X1,X2,…Xn相互独立，且都服从（0,θ）上的均匀分布。求U=max{X1,X2,…Xn}数学期望 声音特征是怎么提取的 https://www.cnblogs.com/BaroC/p/4283380.html BN层，先加BN还是激活，有什么区别 tensorflow pb模型量化 量化(quantitative)是用比 32 位浮点数更少的空间来存储和运行模型，并且 TensorFlow 量化的实现屏蔽了存储和运行细节。神经网络训练时要求速度和准确率，训练通常在 GPU 上进行，所以使用浮点数影响不大。但是在预测阶段，使用浮点数会影响速度。量化可以在加快速度的同时，保持较高的精度。 量化网络的动机主要有两个。最初的动机是减小模型文件的大小。模型文件往往占据很大的磁盘空间，有时，每个模型都接近 200 MB，模型中存储的是分布在大量层中的权值。在存储模型的时候用 8 位整数，模型大小可以缩小为原来 32 位的 25%左右。在加载模型后运算时转换回 32 位浮点数，这样已有的浮点计算代码无需改动即可正常运行。 量化的另一个动机是降低预测过程需要的计算资源。这在嵌入式和移动端非常有意义，能够更快地运行模型，功耗更低。从体系架构的角度来说，8 位的访问次数要比 32 位多，在读取 8 位整数时只需要 32 位浮点数的 1/4 的内存带宽，例如，在 32 位内存带宽的情况下，8 位整数可以一次访问 4 个，32 位浮点数只能 1 次访问 1 个。而且使用 SIMD 指令(19.2节会加速介绍该指令集)，可以在一个时钟周期里实现更多的计算。另一方面，8 位对嵌入式设备的利用更充分，因为很多嵌入式芯片都是 8 位、16 位的，如单片机、数字信号处理器(DSP 芯片)，8 位可以充分利用这些。 此外，神经网络对于噪声的健壮性很强，因为量化会带来精度损失(这种损失可以认为是一种噪声)，并不会危害到整体结果的准确度。 那能否用低精度格式来直接训练呢?答案是，大多数情况下是不能的。因为在训练时，尽管前向传播能够顺利进行，但往往反向传播中需要计算梯度。例如，梯度是 0.2，使用浮点数可以很好地表示，而整数就不能很好地表示，这会导致梯度消失。因此需要使用高于 8 位的值来计算梯度。因此，正如在本节一开始介绍的那样，在移动端训练模型的思路往往是，在 PC 上正常训练好浮点数模型，然后直接将模型转换成 8 位，移动端是使用 8 位的模型来执行预测的过程。 图的遍历 深度优先和广度优先 bagging 1.给定一个弱学习算法,和一个训练集; 2.单个弱学习算法准确率不高; 3.将该学习算法使用多次,得出预测函数序列,进行投票; 4.最后结果准确率将得到提高. 算法： 1.For t = 1, 2, …, T Do 从数据集S中取样（放回选样） 训练得到模型Ht 对未知样本X分类时,每个模型Ht都得出一个分类，得票最高的即为未知样本X的分类 2.也可通过得票的平均值用于连续值的预测 全局对比度增强 1.直方图均衡化 Histogram Equalization 算法： 1）根据图像灰度计算灰度概率密度函数PDF 2）计算累积概率分布函数CDF 3）将CDF归一化到原图灰度取值范围，如[0,255]。 4）之后CDF四舍五入取整，得到灰度转换函数sk=T(rk) 5）将CDF作为转换函数，将灰度为rk的点转换为sk灰度 2. 直方图匹配 Histogram Matching 算法： 1）根据图像计算概率密度分布pr®； 2）根据pr®计算累计分布函数sk=T(rk)； 3）根据给定的目标分布pz(z)计算累计分布函数G(zq)； 4）对于每一个k，找到一个q，使得G(zq)约等于sk； 5）将原图中灰度为k的点变为灰度q； 局部对比度增强 1.邻域直方图均衡：将全局直方图均衡的思想应用于邻域直方图处理中。 2.邻域直方图匹配：将全局直方图匹配的思想应用于邻域直方图处理中。 3.邻域统计方法 算法 1）初始化：增强常数E，灰度下阈值k0，标准差下阈值k1，标准差上阈值k2，窗口半宽s； 2）计算图像灰度均值MG和灰度标准差σG； 3）对于每一个像素，计算邻域（大小为2∗step+1的方块）内灰度均值ML和标准差σL； 4）如果ML&lt;=k0∗MGML&lt;=k0∗MG并且k1∗σG&lt;=σL&lt;=k2∗σG，将像素灰度乘以E。 目标跟踪算法 https://blog.csdn.net/ms961516792/article/details/82682451 这篇文章比较详细。 相机的参数主要包括哪些，标定的步骤及原理，评价标准 相机参数： 相机的内参数是6个分别为：1/dx、1/dy、r、u0、v0、f。opencv1里的说内参数是4个其为fx、fy、u0、v0。实际其fx=F*Sx，其中的F就是焦距上面的f,Sx是像素/没毫米即上面的dx，其是最后面图里的后两个矩阵进行先相乘，得出的，则把它看成整体，就相当于4个内参。其是把r等于零，实际上也是六个。 相机的外参数是6个：三个轴的旋转参数分别为（ω、δ、 θ）,然后把每个轴的33旋转矩阵进行组合（即先矩阵之间相乘），得到集合三个轴旋转信息的R，其大小还是33；T的三个轴的平移参数（Tx、Ty、Tz）。R、T组合成成的3*4的矩阵，其是转换到标定纸坐标的关键。其中绕X轴旋转θ，则其如图： 现以NiKon D700相机为例进行求解其内参数矩阵： 就算大家身边没有这款相机也无所谓，可以在网上百度一下，很方便的就知道其一些参数—— 焦距 f = 35mm 最高分辨率：4256×2832 传感器尺寸：36.0×23.9 mm 根据以上定义可以有： u0= 4256/2 = 2128 v0= 2832/2 = 1416 dx = 36.0/4256 dy = 23.9/2832 fx = f/dx = 4137.8 fy = f/dy = 4147.3 标定方法：相机标定方法有：传统相机标定法、主动视觉相机标定方法、相机自标定法。 标定步骤：https://blog.csdn.net/dcrmg/article/details/52939318 准备标定图片 对每一张标定图片，提取角点信息 对每一张标定图片，进一步提取亚像素角点信息 在棋盘标定图上绘制找到的内角点（非必须，仅为了显示） 相机标定 对标定结果进行评价 查看标定效果——利用标定结果对棋盘图进行矫正 时域滤波和频域滤波 频域的处理有时域不能比拟的优势，就是对于不规则的噪声值，通过傅里叶变换可以得到很好的平滑效果；但相应的，时域在边缘提取上，要比频域的处理更优秀。 常见滤波算法以及特点 高斯滤波 由于高斯函数的傅立叶变换仍是高斯函数, 因此高斯函数能构成一个在频域具有平滑性能的低通滤波器。可以通过在频域做乘积来实现高斯滤波。均值滤波是对是对信号进行局部平均, 以平均值来代表该像素点的灰度值。矩形滤波器(Averaging Box Filter)对这个二维矢量的每一个分量进行独立的平滑处理。通过计算和转化 ,得到一幅单位矢量图。这个 512×512的矢量图被划分成一个 8×8的小区域 ,再在每一个小区域中 ,统计这个区域内的主要方向 ,亦即将对该区域内点方向数进行统计,最多的方向作为区域的主方向。于是就得到了一个新的64×64的矢量图。这个新的矢量图还可以采用一个 3×3模板进行进一步的平滑。 均值滤波 把每个像素都用周围的8个像素来做均值操作。可以平滑图像，速度快，算法简单。但是无法去掉噪声，这能微弱的减弱它。 中值滤波 常用的非线性滤波方法 ,也是图像处理技术中最常用的预处理技术。它在平滑脉冲噪声方面非常有效,同时它可以保护图像尖锐的边缘。加权中值滤波能够改进中值滤波的边缘信号保持效果。但对方向性很强的指纹图像进行滤波处理时 ,有必要引入方向信息,即利用指纹方向图来指导中值滤波的进行。 最小均方差滤波器 亦称维纳滤波器,其设计思想是使输入信号乘响应后的输出,与期望输出的均方误差为最小。 Gabor滤波 Gabor变换是英国物理学家 Gabor提出来的,由“测不准原理”可知,它具有最小的时频窗,即Gabor函数能做到具有最精确的时间-频率的局部化；另外, Gabor函数与哺乳动物的视觉感受野相当吻合,这一点对研究图像特征检测或空间频率滤波非常有用。恰当的选择其参数, Gabor变换可以出色地进行图像分割、识别与理解。如文献提出的基于Gabor滤波器的增强算法。 面试问题 1.格灵深瞳 batchnormal的作用，你怎么看待它。batchnormal的几个参数，参数计算，能不能整合到前面的conv里，训练时和测试时的区别。 说一下感受野计算。 说一下3×3，s=1与5×5，s=2卷积核计算量。 尽可能多的说出1×1卷积的作用 轻量级网络有哪些？具体说说：squeezenet、mobilenet、shuttlenet细节 resnet两个版本的区别，说出每个block的结构。resnet为什么好训练。 介绍一个项目 介绍一个你熟悉的算法 bottlenect 深度优先和广度优先，主要用什么数据结构。" />
<link rel="canonical" href="https://uzzz.org/2019/08/05/792946.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/05/792946.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"大佬的面试经验：https://www.nowcoder.com/discuss/128148 以及大佬的博客：https://blog.csdn.net/liuxiao214/article/details/83043170 根据大佬的面试经验一点一点填坑吧。 常见概念 最大似然估计：最大似然估计是一种统计方法，最大似然估计函数在采样样本总数趋于无穷的时候达到最小方差。步骤：1.写出似然函数 2.取对数 3.求导数并令其为0。 最小二乘法：通过最小化误差的平方和寻找数据的最佳函数匹配。 梯度下降法： 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。 模型融合方法： 目前的集成学习方法大致可以分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和随机森林。 1.投票： 假设对于一个二分类问题，有3个基础模型，那么就采取投票制的方法，投票多者确定为最终的分类。 2.平均： 对于回归问题，一个简单直接的思路是取平均。稍稍改进的方法是进行加权平均。权值可以用排序的方法确定，举个例子，比如A、B、C三种基本模型，模型效果进行排名，假设排名分别是1，2，3，那么给这三个模型赋予的权值分别是3/6、2/6、1/6。这两种方法看似简单，其实后面的高级算法也可以说是基于此而产生的，Bagging或者Boosting都是一种把许多弱分类器这样融合成强分类器的思想。 3.Bagging： 就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步： ① 重复K次，有放回地重复抽样建模，训练子模型 ② 模型融合，分类问题：voting，回归问题：average 随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。 4.Boosting： Bagging算法可以并行处理，而Boosting的思想是一种迭代的方法。 AdaBoost 是Boosting 算法家族中代表算法，AdaBoost 每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例，最终将这些弱分类器进行加权相加。AdaBoost模型是弱分类器的线性组合，AdaBoost算法的一个解释是该算法实际上是前向分步算法的一个实现，在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。 xgboost相对AdaBoost区别，对损失函数做了二阶的泰勒展开，并在目标函数之外加入了正则项对整体求最优解，用以权衡目标函数的下降和模型的复杂程度，避免过拟合。所以不考虑细节方面，两者最大的不同就是目标函数的定义 L1L2正则： 判别式模型与生成式模型：： 判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机SVM、神经网络等。 生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi， 常见的生成式模型有 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA等。https://blog.csdn.net/huangfei711/article/details/79834780 熵-交叉熵-KL散度： 熵：信息熵是度量随机变量不确定度的指标，信息熵越大意味着随机变量不确定度越高，意味着系统的有序程度越低。 交叉熵：主要用于度量两个概率分布间的差异性信息。 KL散度/相对熵：是描述两个概率分布P和Q差异的一种方法。 三者间关系： 最优化方法（梯度下降，牛顿法，共轭梯度法）： 牛顿法： 交叉验证： 第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。 第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。 第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。 此外还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法(bootstrapping)。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。 皮尔逊系数： 皮尔逊相关系数广泛用于度量两个变量之间的相关程度，其值介于-1与1之间。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商： bias-variance-tradeoff：偏差方差权衡 1、Bias and Variance tradeoff的最简单方法 当Bias很高的时候，就增加模型的复杂度（比如增加神经网络的神经元个数，神经网络的层数） 当Variance很高的时候，就增加训练的样本量。 然而以上的原则只是一个大的指导方向，因为在实际操作中增加模型的复杂程度将会大大增加计算机的计算量，而且还容易造成Overfitting。 下面详细介绍在实际操作中处理Bias 和 Variance 的具体方法。 2、减少Bias的几大原则 增加模型复杂度 根据误差分析结果，调整输入特征(feature) 减少或者去除Regularization(正则化) 修改模型结构 增加更多的训练样本 3、减少Variance的几大原则 增加更多的训练样本 增加Regularization(正则化) 加入提前终止(Early Stopping) 选择性减少输入的特征(Features) 减小模型规模 根据误差分析结果，调整输入特征(feature) 修改模型结构 无偏估计：无偏估计是用样本统计量来估计总体参数时的一种无偏推断。估计量的数学期望等于被估计参数的真实值，则称此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。 ROC，recall，precision： 分类器的ROC曲线和相关指标 准确率(Accuracy)：ACC=(TP+TN)/(TP+TN+FP+FN) mAP是什么 P：precision即准确率，TP / (TP + FP)，分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例; R：recall即召回率，TP / (TP + FN)，分类器认为是正类并且确实是正类的部分占所有确实是正类的比例; 目标检测中： TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次） FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量 FN: 没有检测到的GT的数量 PR曲线：以P和R为纵横坐标的曲线; AP值：Average Precision平均精确度，为PR曲线下面积; mAP:各类AP的平均值; 举例： 假设，对于Aeroplane类别，我们网络有以下输出(BB表示BoundingBox序号，IoU&gt;0.5时GT=1)： BB | confidence | GT ---------------------- BB1 | 0.9 | 1 ---------------------- BB2 | 0.9 | 1 ---------------------- BB1 | 0.8 | 1 ---------------------- BB3 | 0.7 | 0 ---------------------- BB4 | 0.7 | 0 ---------------------- BB5 | 0.7 | 1 ---------------------- BB6 | 0.7 | 0 ---------------------- BB7 | 0.7 | 0 ---------------------- BB8 | 0.7 | 1 ---------------------- BB9 | 0.7 | 1 ---------------------- 因此，我们有 TP=5 (BB1, BB2, BB5, BB8, BB9), FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2. 这时我们就可以按照Confidence的顺序给出各处的PR值，如下： rank=1 precision=1.00 and recall=0.14 ---------- rank=2 precision=1.00 and recall=0.29 ---------- rank=3 precision=0.66 and recall=0.29 ---------- rank=4 precision=0.50 and recall=0.29 ---------- rank=5 precision=0.40 and recall=0.29 ---------- rank=6 precision=0.50 and recall=0.43 ---------- rank=7 precision=0.43 and recall=0.43 ---------- rank=8 precision=0.38 and recall=0.43 ---------- rank=9 precision=0.44 and recall=0.57 ---------- rank=10 precision=0.50 and recall=0.71 对于Recall &gt;= 0, 0.14, 0.29, 0.43, 0.57, 0.71, 1，我们选取此时Percision的最大值：1, 1, 1, 0.5, 0.5, 0.5, 0。此时Aeroplane类别的 AP = (0.14-0)*1 + (0.29-0.14)*1 + (0.43-0.29)*0.5 + (0.57-0.43)*0.5 + (0.71-0.57)*0.5 + (1-0.71)*0 = 0.5 mAP就是对每一个类别都计算出AP然后再计算AP平均值就好了。 图像分类方法 逻辑回归，支持向量机，随机森林，GBDT，深度学习。 逻辑回归：https://www.jianshu.com/p/1bf35d61995f 支持向量机：https://blog.csdn.net/u011630575/article/details/78916747 距离超平面最小的样例，我们称之为支持向量，我们所要找的最优超平面，就是使支持向量到超平面距离最大，我们认为，这样的超平面，就是最优的，下面也是要想办法求出这个超平面。SVM的核心问题就是找到这一超平面 最大间隔分类： 随机森林：https://blog.csdn.net/yangyin007/article/details/82385967?tdsourcetag=s_pcqq_aiomsg GBDT： LR和SVM的异同 相同点： 第一，LR和SVM都是分类算法。 第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。 第三，LR和SVM都是监督学习算法。 第四，LR和SVM都是判别模型。 第五，LR和SVM在学术界和工业界都广为人知并且应用广泛。 不同点： 第一，损失函数不同 第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。 第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。 第四，​线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响。 第五，SVM的损失函数就自带正则（损失函数中的1/2||w||^2项），这就是为什么SVM是结构风险最小化算法的原因，而LR必须另外在损失函数上添加正则项 函数间隔和几何间隔 函数间隔 几何间隔 视频分类 思路： 1.通过将视频的每一帧视为一幅单独的图像，利用二维 CNN 进行处理。这种方法将视频分类问题简化为图像分类问题。每帧视频图像都有类别输出，并且根据各帧输出的类别，选择频率最高的类别作为视频的分类结果。 2.创建一个单一的网络，将二维 CNN 与一个 RNN 结合在一起。这个想法是，CNN 将考虑到图像分量，而 RNN 将考虑每个视频的序列信息。这种类型的网络可能非常难以训练，因为要优化的参数数量非常大。 3.使用三维卷积网络，其中三维卷积网络是二维 CNN 的在 3D 张量（时间，图像宽度，图像高度）上运行的扩展。这种方法是图像分类的另一个自然延伸，但三维卷积网络可能很难训练。 4.基于智能方法的直觉。它们可以用于存储视频中每个帧的离线功能，而不是直接使用 CNN 进行分类。这个想法基于，特征提取可以非常有效地进行迁移学习，如前面章节所示。在提取所有的特征之后，可以将它们作为一组输入传递给RNN，其将在多个帧中学习序列并输出最终的分类。 5.第四种方法的简单变体，其中最后一层是 MLP 而不是 RNN。在某些情况下，就计算需求而言，这种方法可以更简单并且成本更低。 6.第四种方法的变体，其中特征提取阶段采用三维 CNN 来提取空间和视觉特征，然后将这些特征传递给 RNN 或 MLP。 细粒度分类 https://blog.csdn.net/qq_25439417/article/details/82764183 细粒度分类：同一类中不同子类物体间的分类。 1.Part-based R-CNN。 如上所示，局部区域将从自底向上的候选区域开始（左上角），我们将基于深度卷积特征同时训练目标和局部区域。在推断阶段，所有的窗口都会由检测器评分（中间），且我们可以应用非参几何约束（底部）重新评估窗口并选择最优的目标和局部检测（右上角）。最后的步骤就是抽取局部语义信息来用于细粒度识别，并训练一个分类器预测最终类别。 2.Bilinear deep network models 3.FCN attention。 在抽取特征后，模型需要学习哪些局部区域对最终分类是重要的，而确定重要性的标准即局部区域对最终预测是否有帮助。在这一阶段中，注意力网络会将基本的局部卷积特征图生成一张评分图或置信图，即通过叠加的两个卷积层将特征图转换为通道数为 1 的评分图。一般第一个卷积层可使用 64 个 3×3 的卷积核，而第二个卷积层可使用 1 个 3×3 的卷积核将通道数降为 1，这一张置信图展示了模型关注的兴趣点。 兴趣点是网络自己学到的，而裁剪的大小是我们给定的。我们首先会给一个 8×8 的较大裁剪窗口，相当于关注较大的区域。随着迭代的进行，我们会慢慢减小裁剪窗口，这相当于关注更小的细节。裁剪后的特征图一般需要馈送到 Softmax 层以将置信图转换为概率图。 你知道attention起源是用在哪里？pixel还是frame，是soft还是hard 对于 Attention的作用角度出发，可以分为： 空间注意力 Spatial Attention，时间注意力 Temporal Attention 这样的分类更多的是从应用层面上；而从 Attention的作用方法上，可以将其分为 Soft Attention 和 Hard Attention，这既我们所说的， Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。 attention机制：https://blog.csdn.net/xiewenbo/article/details/79382785 Soft Attention：传统的Attention Mechanism就是Soft Attention,即通过确定性的得分计算来得到attended之后的编码隐状态。Soft Attention是参数化的（Parameterization），因此可导，可以被嵌入到模型中去，直接训练。梯度可以经过Attention Mechanism模块，反向传播到模型其他部分。 Hard Attention：是一个随机的过程。Hard Attention不会选择整个encoder的隐层输出做为其输入，Hard Attention会依概率Si来采样输入端的隐状态一部分来进行计算，而不是整个encoder的隐状态。为了实现梯度的反向传播，需要采用蒙特卡洛采样的方法来估计模块的梯度。 两种Attention Mechanism都有各自的优势，但目前更多的研究和应用还是更倾向于使用Soft Attention，因为其可以直接求导，进行梯度反向传播 网络用的损失函数是什么 L1 loss：绝对差平均损失，又称MAE . 2.L2 loss：平方差平均损失，又称MSE 3.Smooth L1 loss，又称Huber损失 4.BCE loss，二分类用的交叉熵损失，用的时候需要在该层前面加上 Sigmoid 函数 5.BCEWithlogitsLoss，将sigmoid函数集成到BCE loss上 6.CrossEntoryLoss，交叉熵损失函数 第一种形式： 第二种形式： softmax的交叉熵： 7.NllLoss：负对数似然损失。 监督学习和无监督学习 监督学习(supervised learning)：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。 无监督学习(unsupervised learning)：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。 强化学习(reinforcement learning)：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。 弱监督学习(weakly supervised learning)： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。 半监督学习(semi supervised learning) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，学习已知标签和未知标签的数据，将输入数据映射到标签的过程。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。 多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。 softmax loss softmax的交叉熵： LR为什么要用sigmoid函数 3. LR 损失函数为什么用极大似然函数？ 1.因为我们想要让每一个样本的预测都要得到最大的概率，即将所有的样本预测后的概率进行相乘都最大，也就是极大似然函数. 2.对极大似然函数取对数以后相当于对数损失函数，由上面梯度更新的公式可以看出，对数损失函数的训练求解参数的速度是比较快的，而且更新速度只和x，y有关，比较的稳定。 3.为什么不用平方损失函数 如果使用平方损失函数，梯度更新的速度会和 sigmod 函数的梯度相关，sigmod 函数在定义域内的梯度都不大于0.25，导致训练速度会非常慢。 而且平方损失会导致损失函数是 theta 的非凸函数，不利于求解，因为非凸函数存在很多局部最优解 softmax交叉熵损失函数求导 https://blog.csdn.net/qian99/article/details/78046329 softmax和logistic回归的区别和联系 1.softmax用来解决多分类问题，lr解决二分类问题 2.softmax输出每一类的概率值，并确定概率最大的类是正确的，lr只区别是还是不是。事实上softmax是lr的一般情况。 https://blog.csdn.net/chnguoshiwushuang/article/details/80514626 全连接的作用 因为用到了所有的局部特征，所以叫全连接。将学到的“分布式特征表示”映射到样本标记空间的作用。 GD、SGD、mini batch GD的区别 GD：梯度下降法的物理意义很好理解，就是沿着当前点的梯度方向进行线搜索，找到下一个迭代点 SGD：随机梯度下降法，每次计算梯度时，只随机的选取一个样本来计算梯度,这样就大大的减小了计算的复杂度，随机梯度下降法速度快，但每次的方向不稳定，甚至可能向反方向。 mini batch GD：故每次计算梯度时，选取一部分样本，即小批量梯度下降法。 S3D了解吗？ 边缘检测算子有哪些 1.差分算子。 一阶微分： 2.Roberts算子，对角线方向相邻两象素之差近似梯度幅值检测边缘，对噪声敏感,无法抑制噪声的影响。 3.Sobel算子，该算子包含两组3 * 3的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差分近似值，在结合横向和纵向 4.Prewitt算子，一阶微分算子的边缘检测，模板3 * 3利用像素点上下、左右邻点的灰度差，在边缘处达到极值检测边缘，去掉部分伪边缘，对噪声具有平滑作用 。 二阶微分 5.Laplacian算子，存在噪声情况下，使用Laplacian算子检测边缘之前需要先进行低通滤波，模板3 * 3。 6.Log算子，进行高斯滤波再进行拉普拉斯算子检测，模板5 * 5。 非微分 7.Canny算子： 1)使用高斯滤波器，以平滑图像，滤除噪声。 2)计算图像中每个像素点的梯度强度和方向。 3)应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。 4)应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。 5)通过抑制孤立的弱边缘最终完成边缘检测。 霍夫变换 说一下SVM核函数 在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。核函数的价值在于它虽然也是讲特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算。 1.多项式核函数 2.高斯核函数 3.线性核函数 4.字符串核函数 PCA PCA(principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据压缩算法。它可以通过线性变换将原始数据变换为一组各维度线性无关的表示，以此来提取数据的主要线性分量。 具体可以看这篇文章：https://blog.csdn.net/hustqb/article/details/78394058 伪代码： 去除平均值 计算协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值排序 保留前N个最大的特征值对应的特征向量 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩） L1、L2范数 sigmoid优缺点 优点：可以将函数值的范围压缩到[0,1]，可以压缩数据，且幅度不变。在特征相差比较复杂或是相差不是特别大时效果比较好。可以看到sigmoid函数处处连续便于求导；便于前向传输。 缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法。反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练 RefineNet理解 针对语义分割所提出的网络模型，可以分为两段对应于U-Net中向下（特征逐步降采样同时提取语义特征）和向上（逐步上采样特征恢复细节信息）两段通路。其中向下的通路以ResNet为基础。向上的通路使用了新提出的RefineNet作为基础，并作为本通路特征与ResNet中低层特征的融合器。下图a为标准CNN，b图为带孔卷积，RefineNet的框架如c图所示： 其中左边的四组特征是从ResNet的四个对应的block取出的。此框架与U-Net没有太大区别。不过如作者所说，RefineNet是一个灵活的模块，其输入的尺度个数可以变化，因此整个网络的拓扑结构可以有很多改变。 RefineNet可以分为三个主要部分： 1. 不同尺度（也可能只有一个输入尺度）的特征输入首先经过两个Residual模块的处理； 2. 之后是不同尺寸的特征进行融合。当然如果只有一个输入尺度，该模块则可以省去。所有特征上采样至最大的输入尺寸，然后进行加和。上采样之前的卷积模块是为了调整不同特征的数值尺度； 3. 最后是一个链式的pooling模块。其设计本意是使用侧支上一系列的pooling来获取背景信息（通常尺寸较大）。直连通路上的ReLU可以在不显著影响梯度流通的情况下提高后续pooling的性能，同时不让网络的训练对学习率很敏感。最后再经过一个Residual模块即得RefineNet的输出。 详细架构如下： 引用：https://blog.csdn.net/gqixf/article/details/82911220 densenet结构优缺点以及应用场景 优点： (1) 相比ResNet拥有更少的参数数量. (2) 旁路加强了特征的重用. (3) 网络更易于训练,并具有一定的正则效果. (4) 缓解了gradient vanishing和model degradation的问题. 缺点： DenseNet在训练时十分消耗内存，这是由于算法实现不优带来的。当前的深度学习框架对 DenseNet 的密集连接没有很好的支持，所以只能借助于反复的拼接（Concatenation）操作，将之前层的输出与当前层的输出拼接在一起，然后传给下一层。对于大多数框架（如Torch和TensorFlow），每次拼接操作都会开辟新的内存来保存拼接后的特征。这样就导致一个 L 层的网络，要消耗相当于 L(L+1)/2 层网络的内存. pooling层： 由于在DenseNet中需要对不同层的feature map进行cat操作,所以需要不同层的feature map保持相同的feature size,这就限制了网络中Down sampling的实现.为了使用Down sampling,作者将DenseNet分为多个Denseblock,如下图所示: 在同一个Denseblock中要求feature size保持相同大小,在不同Denseblock之间设置transition layers实现Down sampling, 在作者的实验中transition layer由BN + Conv(1×1) ＋2×2 average-pooling组成. Growth rate： 在Denseblock中,假设每一个非线性变换H的输出为K个feature map, 那么第i层网络的输入便为K0+(i-1)×K, 这里我们可以看到DenseNet和现有网络的一个主要的不同点:DenseNet可以接受较少的特征图数量作为网络层的输出,如下图所示 原因就是在同一个Denseblock中的每一层都与之前所有层相关联,如果我们把feature看作是一个Denseblock的全局状态,那么每一层的训练目标便是通过现有的全局状态,判断需要添加给全局状态的更新值.因而每个网络层输出的特征图数量K又称为Growth rate,同样决定着每一层需要给全局状态更新的信息的多少 Bottleneck Layers： 虽然DenseNet接受较少的k,也就是feature map的数量作为输出,但由于不同层feature map之间由cat操作组合在一起,最终仍然会是feature map的channel较大而成为网络的负担.作者在这里使用1×1 Conv(Bottleneck)作为特征降维的方法来降低channel数量,以提高计算效率.经过改善后的非线性变换变为BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3),使用Bottleneck layers的DenseNet被作者称为DenseNet-B. Compression： 为了进一步优化模型的简洁性,我们同样可以在transition layer中降低feature map的数量.若一个Denseblock中包含m个feature maps,那么我们使其输出连接的transition layer层生成⌊θm⌋个输出feature map.其中θ为Compression factor, 当θ=1时,transition layer将保留原feature维度不变. 实验结论 a) 一些较早层提取出的特征仍可能被较深层直接使用 b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征 c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,既Compression的必要性. d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生. vggnet网络 inception网络 https://blog.csdn.net/u011021773/article/details/80791650?tdsourcetag=s_pcqq_aiomsg Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 v1 v2 v3 Inception V3 inception V3把googlenet里一些77的卷积变成了17和71的两层串联，33的也一样，变成了13和31，这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299. Inception V4 inception v4实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。 另外就是V4把一个先11再33那步换成了先33再11. 论文说引入resnet不是用来提高深度，进而提高准确度的，只是用来提高速度的。 对Resnet的理解 1.避免梯度消失，解决网络退化。 2.残差模块可以更容易学习更细致的信息。 Resnet网络 https://blog.csdn.net/lanran2/article/details/80247515 resnet-50结构图 https://blog.csdn.net/qq_21046135/article/details/81674605 解释dropout以及实现机制 dropout原理：在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据(batchsize个样本) 作用 ：1.减少特征冗余，减少过拟合 2.提升泛化能力，增加模型的鲁棒性 缺点：减慢收敛速度：由于每次迭代只有一部分参数更新，可能导致梯度下降变慢 为什么梯度会消失和爆炸 1.损失函数 2.网络结构(深层) 3.权值初始化值太大 4.学习率过大 正则化方法以及特点 1.数据增强 数据增强技术如水平、垂直、镜像翻转图像、裁剪、色彩变换、扩展和旋转，滤波，噪点等等 2.提前终止 3.Bagging 4.dropout 5.batch normalizatin 6.参数范数惩罚：https://www.cnblogs.com/pinking/p/9310728.html 深度学习中有什么加快收敛/降低训练难度的方法： 1.瓶颈结构 2.残差 3.学习率、步长、动量 4.优化方法 5.预训练 预训练网络freeze某几层 过拟合怎么做 Parameter Norm Penalties(参数范数惩罚)；Dataset Augmentation (数据集增强)；Early Stopping(提前终止)；Parameter Tying and Parameter Sharing (参数绑定与参数共享)；Bagging and Other Ensemble Methods(Bagging 和其他集成方法)；dropout；regularization； batch normalizatin；加噪声。是解决Overfitting的常用手段。 GAN的公式以及发展历程 https://www.jqr.com/article/000325 https://blog.csdn.net/qq_19272431/article/details/93380342 https://blog.csdn.net/qq_32439305/article/details/86766792 相对判别器 在标准生成对抗网络（SGAN）中，判别器负责估计输入数据是真实数据的概率，根据这个数值，我们再训练生成器以提高伪数据是真实数据的概率。但本文认为，判别器在提高“伪数据为真”的概率的同时，也应该降低“实际数据为真”的概率，原因有三： 1.mini-batch中一半的数据是伪数据，这个先验会带来不合逻辑的结果； 2.在最小化散度（divergence minimization）的过程中，两个概率不是同步变化； 3.实验证实，经过相对判别器诱导，SGAN的性能可以媲美基于IPM的GAN（WGAN、WGAN-GP等），而后者实际上已经具有相对判别器的雏形，因此也更稳定。 本文提出相对GAN（RGAN），并在它的基础上又提出了一个变体——相对均值GAN（RaGAN），变体用平均估计计算判别器概率。此外，论文还显示基于IPM的GAN其实是RGAN的子集。 通过比较，文章发现：(1)相比非相对GAN，RGAN和RaGAN更稳定，产出的数据样本质量更高；(2)在RaGAN上加入梯度惩罚后，它能生成比WGAN-GP质量更高的数据，同时训练时长仅为原先的1/5；(3)RaGAN能够基于非常小的样本（N = 2011）生成合理的高分辨率图像（256x256），撇开做不到的GAN和LSGAN，这些图像在质量上也明显优于WGAN-GP和SGAN生成的归一化图像。 通用GAN的形式： 相对的GAN 简化形式 相对平均GAN 感受野的理解和dilated conv优缺点以及应用场景 https://blog.csdn.net/CV_YOU/article/details/81633645 k为原来卷积核，rate为扩张率，感受野=(k+1)(rate-1)+k 相似度计算 1.余弦距离 2.欧式距离 3.汉明距离 汉明距离/Hamming Distance也能用来计算两个向量的相似度；即通过比较向量每一位是否相同，若不同则汉明距离加1，这样得到汉明距离。向量相似度越高，对应的汉明距离越小。如10001001和10110001有3位不同。 4.马氏距离 如果我们以厘米为单位来测量人的身高，以克（g）为单位测量人的体重。每个人被表示为一个两维向量，如一个人身高173cm，体重50000g，表示为（173,50000），根据身高体重的信息来判断体型的相似程度。 我们已知小明（160,60000）；小王（160,59000）；小李（170，60000）。根据常识可以知道小明和小王体型相似。但是如果根据欧几里得距离来判断，小明和小王的距离要远远大于小明和小李之间的距离，即小明和小李体型相似。这是因为不同特征的度量标准之间存在差异而导致判断出错。 色彩空间 https://blog.csdn.net/ABigDeal/article/details/84836269 RGB和BGR RGB：PIL，scipy； BGR：caffe，opencv。 opencv通道转换 import cv2 img = cv2.imread(&#39;test.jpg&#39;) B, G, R = cv2.split(img) #BGR转RGB，方法1 img_rgb1 = cv2.merge([R, G, B]) #BGR转RGB，方法2 img_rgb2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #BGR转RGB，方法3 img_rgb3 = img[:,:,::-1] PIL转opencv import cv2 from PIL import Image import numpy image = Image.open(&quot;test.jpg&quot;) image.show() img = cv2.cvtColor(numpy.asarray(image),cv2.COLOR_RGB2BGR) cv2.imshow(&quot;OpenCV&quot;,img) cv2.waitKey() opencv转PIL import cv2 from PIL import Image import numpy img = cv2.imread(&quot;test.jpg&quot;) cv2.imshow(&quot;OpenCV&quot;,img) image = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)) image.show() cv2.waitKey() 有什么图像的锐化方法 1.滤波 2.边缘检测 全局和局部特征提取算法分别有 图像的特征提取有哪些算法 ①基于颜色特征：如颜色直方图、颜色集、颜色矩、颜色聚合向量等； ②基于纹理特征：如Tamura纹理特征、自回归纹理模型、Gabor变换、小波变换、MPEG7边缘直方图等； ③基于形状特征：如傅立叶形状描述符、不变矩、小波轮廓描述符等 1、LBP特征提取算法 LBP（Local Binary Patterns，局部二值模式）是提取局部特征作为判别依据的，为一种有效的纹理描述算子，度量和提取图像局部的纹理信息，对光照具有不变性。有多种改进型，LBP结合BP神经网络已经用于人脸识别等领域。LBP的基本思想是定义于像素的8邻域中, 以中心像素的灰度值为阈值, 将周围8 个像素的值与其比较, 如果周围的像素值小于中心像素的灰度值, 该像素位置就被标记为0, 否则标记为1. 每个像素得到一个二进制组合, 就像00010011. 每个像素有8个相邻的像素点,即有2^8种可能性组合。 2.HOG特征提取算法 方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。 不变性：具有光照不变性，不具有尺寸和旋转不变性。 应用：HoG算法提取的是图像各个像素梯度的统计直方图，一般会将这些梯度直方图转化成一个向量，用于分类器的训练输入。 3.Haar特征提取算子 常和AdaBoost结合用于识别人脸。Haar特征很简单，分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。 4.LoG特征提取算法 LoG（DoG是一阶边缘提取）是二阶拉普拉斯-高斯边缘提取算法，先高斯滤波然后拉普拉斯边缘提取。Laplace算子对通过图像进行操作实现边缘检测的时，对离散点和噪声比较敏感。于是，首先对图像进行高斯卷积滤波进行降噪处理，再采用Laplace算子进行边缘检测，就可以提高算子对噪声抗干扰能力, 这一个过程中高斯-拉普拉斯（Laplacian of Gaussian(LOG)）边缘检测算子就诞生了。 5.Harris角点特征提取算法 http://www.cnblogs.com/zhchoutai/p/7182438.html 6.SIFT特征提取算子 SIFT算子是一种检测局部特征的算法，该算法通过求一幅图中的特征点及其有关尺寸和方向的描述子得到特征并进行图像特征点匹配，获得了良好效果。每个特征点的SIFT特征是128维向量，因此计算量巨大。 不变性：具有尺寸和旋转不变性。 改进型：PCA-SIFT，如名称所说“主成分SIFT特征”，主要提取了128维特征向量中的20个特征，大大减少了计算。 http://www.cnblogs.com/liuchaogege/p/5155739.html 7.SURF特征提取算法 SURF是SIFT角点检测算法的改进版，主要体现在速度上，SURF是SIFT速度的3倍。SIFT在尺度和旋转变换的情况下匹配效果比SURF好，而SURF在亮度变化下匹配效果比较好。 http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html 什么是Kmeans，与EM怎么联系 yolo、ssd、faster rcnn的区别 yolo v1：没有使用多层特征，没有使用anchor机制，使用网格预测，每个网格随机预测2个box，直接预测x，y，w，h，损失函数也不一样，使用全连接。 yolo v3：使用多层特征，使用anchor机制，使用网格预测，anchor使用kmeans算法产生，使用3层特征，每层特征使用3个大小的anchor，没有直接预测x，y，w，h，损失函数也不一样，没有使用全连接。 ssd：https://blog.csdn.net/u010712012/article/details/86555814?tdsourcetag=s_pcqq_aiomsg 使用多层特征(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)，使用anchor机制，使用特征图预测，特征图上的每一个特征都预测4个anchor，没有直接预测x，y，w，h，损失函数不一样。 d是先验框，b是预测框 3.faster rcnn 两步走：RPN+ROIP RPN特征图预测anchor，每个特征点预测9个anchor大小，最后得到ROI区域进行池化，最后分类和边框回归。 inception_resnet_v2 faster rcnn RPN实现细节 ROI层是怎么实现的，怎么做的映射 1.根据输入image，将ROI映射到feature map对应位置；首先计算rois映射到feature map的坐标，即原始坐标*spacial_scale(大小为所有stride的乘积分之一)，然后针对每个输出来进行计算，即每个输出点都代表原先的一块区域，这个区域大小为bin_h= roi_height / pooled_ height, bin_w=roi_width / pooled_width.遍历所有top的点所映射回feature map的区域，并找到最大值，记录最大值所在的位置。 2.将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）； 3.对每个sections进行max pooling操作； BN层的moving——mean怎么求得 为什么使用BN层 1.可以选择较大的学习率，使得训练速度增长很快，具有快速收敛性。 2.可以不去理会Dropout，L2正则项参数的选择，如果选择使用BN，甚至可以去掉这两项。 3.去掉局部响应归一化层（LRN）。（AlexNet中使用的方法，BN层出来之后这个就不再用了） 4.可以把训练数据打乱，防止每批训练的时候，某一个样本被经常挑选到。 batch_norm 在test的时候，，用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。所以需要在训练时把BN层的参数保存下来，然后在预测时加载。 BN的学习参数 假设BN层输入为32×128×200×200(NCHW)的大小Tensor，BN层学习的参数可能有：128的倍数。 pooling层的反向传播 手动实现卷积 def conv2d(img, kernel): height, width, in_channels = img.shape kernel_height, kernel_width, in_channels, out_channels = kernel.shape out_height = height - kernel_height + 1 out_width = width - kernel_width + 1 feature_maps = np.zeros(shape=(out_height, out_width, out_channels)) for oc in range(out_channels): # Iterate out_channels (# of kernels) for h in range(out_height): # Iterate out_height for w in range(out_width): # Iterate out_width for ic in range(in_channels): # Iterate in_channels patch = img[h: h + kernel_height, w: w + kernel_width, ic] feature_maps[h, w, oc] += np.sum(patch * kernel[:, :, ic, oc]) return feature_maps 实现卷积层的backward编程 有哪些轻量化模型？ 一、SequeezeNet： 核心思想： 1.使用1x1卷积核代替3x3卷积核，减少参数量； 2.通过squeeze layer限制通道数量，减少参数量； 3.借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding； 4.减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率； 5.使用全局平均池化代替全连接层; 1-3通过fire module实现，如下图所示： 网络结构： 二、Xception 核心思想： 主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释） 首先xception类似于下图，但是区别有两点： 1.Xception中没有relu激活函数； 2.图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。 3.进行残差连接时，不再是concat，而是采用加法操作。 网络结构： 三、MobileNet 核心思想： 1.主要采用depthwise separable convolution，就是分离卷积核； 2.设置宽度因子width multipler和分辨率因子resolution multiplier； 怎么才能使网络进一步压缩呢？可以进一步减少feature map的通道数和size，通过宽度因子减少通道数，分辨率因子减少size。 DK为卷积核大小，DF为特征图大小，M为输入特征图通道，N为输出特征图通道 1、宽度因子α 2、分辨率因子ρ 两个参数都属于(0,1]之间，当为1时则是标准mobileNet。 基本模块： 网络结构： 四、ShuffleNet 核心思想： 1.借鉴resnext分组卷积思想，但不同的是采用1x1卷积核； 2.进行通道清洗，加强通道间的信息流通，提高信息表示能力。 分组卷积和通道清洗： Shuffle的方法： 1.卷积后一共得到g×n个输出通道的feature map； 2.将feature map 进行 reshape为(g,n); 3.进行转置为(n,g)； 4.对转置结果flatten，再分回g组作为下一层的输入。 三种Shuffle unit： 网络结构： 计算一层的参数量、计算量 https://zhuanlan.zhihu.com/p/31575074 inception v1-v3的发展： Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。 撕代码：iou计算、k-means、NMS非极大值抑制 iou： def IOU(rectangle A, rectangleB): W = min(A.RT.x, B.RT.x) - max(A.LB.x, B.LB.x) H = min(A.RT.y, B.RT.y) - max(A.LB.y, B.LB.y) if W &lt;= 0 or H &lt;= 0: return 0; SA = (A.RT.x - A.LB.x) * (A.RT.y - A.LB.y) SB = (B.RT.x - B.LB.x) * (B.RT.y - B.LB.y) cross = W * H return cross/(SA + SB - cross) kmeans: def kmeans(self, boxes, k, dist=np.median): box_number = boxes.shape[0] distances = np.empty((box_number, k)) last_nearest = np.zeros((box_number,)) np.random.seed() clusters = boxes[np.random.choice( box_number, k, replace=False)] # init k clusters while True: distances = 1 - self.iou(boxes, clusters) current_nearest = np.argmin(distances, axis=1) if (last_nearest == current_nearest).all(): break # clusters won&#39;t change for cluster in range(k): clusters[cluster] = dist( # update clusters boxes[current_nearest == cluster], axis=0) last_nearest = current_nearest return clusters NMS: def py_cpu_nms(dets, thresh): &quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot; x1 = dets[:, 0] y1 = dets[:, 1] x2 = dets[:, 2] y2 = dets[:, 3] scores = dets[:, 4] areas = (x2 - x1 + 1) * (y2 - y1 + 1) order = scores.argsort()[::-1] keep = [] while order.size &gt; 0: i = order[0] keep.append(i)#保留该类剩余box中得分最高的一个 xx1 = np.maximum(x1[i], x1[order[1:]]) yy1 = np.maximum(y1[i], y1[order[1:]]) xx2 = np.minimum(x2[i], x2[order[1:]]) yy2 = np.minimum(y2[i], y2[order[1:]]) w = np.maximum(0.0, xx2 - xx1 + 1) h = np.maximum(0.0, yy2 - yy1 + 1) inter = w * h ovr = inter / (areas[i] + areas[order[1:]] - inter) inds = np.where(ovr &lt;= thresh)[0] order = order[inds + 1] return keep linux命令 常用命令在这里： https://blog.csdn.net/weixin_43304184/article/details/85102655 查看文件大小命令 df -h du -h --max-depth=1 /home https://www.cnblogs.com/lixuwu/p/5944062.html 查看文件多少行命令 wc -l filename 就是查看文件里有多少行 wc -w filename 看文件里有多少个word。 wc -L filename 文件里最长的那一行是多少个字。 图像哈希算法 1.均值哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算平均值。计算所有64个像素的灰度平均值。 第四步，比较像素的灰度。将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。 第五步，计算哈希值。将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。 如果图片放大或缩小，或改变纵横比，结果值也不会改变。增加或减少亮度或对比度，或改变颜色，对hash值都不会太大的影响。最大的优点：计算速度快！ 如果想比较两张图片，为每张图片构造hash值并且计算不同位的个数。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 2.感知哈希算法： 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。 第三步，计算DCT（离散余弦变换）。DCT是把图片分解频率聚集和梯状形，虽然JPEG使用8 * 8的DCT变换，在这里使用32 * 32的DCT变换。 第四步，缩小DCT。虽然DCT的结果是32 * 32大小的矩阵，但我们只要保留左上角的8*8的矩阵，这部分呈现了图片中的最低频率。 第五步，计算平均值。计算所有64个值的平均值。 第六步，进一步减小DCT。这是最主要的一步，根据8 * 8的DCT矩阵，设置0或1的64位的hash值，大于等于DCT均值的设为”1”，小于DCT均值的设为“0”。结果并不能告诉我们真实性的低频率，只能粗略地告诉我们相对于平均值频率的相对比例。只要图片的整体结构保持不变，hash结果值就不变。能够避免伽马校正或颜色直方图被调整带来的影响。 第七步，计算哈希值。将64bit设置成64位的长整型，组合的次序并不重要，只要保证所有图片都采用同样次序就行了。将32 * 32的DCT转换成32 * 32的图像。 将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了（例如，自左到右、自顶向下、big-endian）。 得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算汉明距离。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 3.差异哈希算法 第一步，缩小尺寸，缩放到9 * 8尺寸。 第二步，转换灰度值，转换到0-255之间。 第三步，差异值计算，差异值是通过计算每行相邻像素的强度对比得出的。我们的图片为9 * 8的分辨率，那么就有8行，每行9个像素。差异值是每行分别计算的，也就是第二行的第一个像素不会与第一行的任何像素比较。每一行有9个像素，那么就会产生8个差异值，这也是为何我们选择9作为宽度，因为8bit刚好可以组成一个byte，方便转换为16进制值。 如果前一个像素的颜色强度大于第二个像素，那么差异值就设置为True（也就是1），如果不大于第二个像素，就设置为False（也就是0）。 第四步，转化为hash值，将差异值数组中每一个值看做一个bit，每8个bit组成为一个16进制值，将16进制值连接起来转换为字符串，就得出了最后的dHash值。 第五步，计算汉明距离，如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。 boost、Adaboost 线性回归和逻辑回归的区别 逻辑回归多了一个Sigmoid函数，使样本能映射到[0,1]之间的数值，用来做分类问题。 1.线性回归用来预测，逻辑回归用来分类。 2.线性回归是拟合函数，逻辑回归是预测函数 3.线性回归的参数计算方法是最小二乘法，逻辑回归的参数计算方法是梯度下降 什么是全卷积网络，如何实现 https://blog.csdn.net/kekong0713/article/details/52585074 FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,1,1）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。 可以发现，经过多次卷积（还有pooling）以后，得到的图像越来越小,分辨率越来越低（粗略的图像），那么FCN是如何得到图像中每一个像素的类别的呢？为了从这个分辨率低的粗略图像恢复到原图的分辨率，FCN使用了上采样。例如经过5次卷积(和pooling)以后，图像的分辨率依次缩小了2，4，8，16，32倍。对于最后一层的输出图像，需要进行32倍的上采样，以得到原图一样的大小。 这个上采样是通过反卷积（deconvolution）实现的。对第5层的输出（32倍放大）反卷积到原图大小，得到的结果还是不够精确，一些细节无法恢复。于是Jonathan将第4层的输出和第3层的输出也依次反卷积，分别需要16倍和8倍上采样，结果就精细一些了。下图是这个卷积和反卷积上采样的过程： 与传统的基于CNN 的图像分割方法相比，FCN有两个明显优势： 1.可以接受任意大小的输入； 2.避免了重复存储和计算，更加高效。 如何理解LSTM https://blog.csdn.net/menc15/article/details/71271566 如何解决RNN的梯度爆炸和消失 多标签问题 1.问题转换： ①重新组合 ②二元关联 ③分类器链 2.改编算法 修改全连接 3.集成方法 精确率高、召回率低是为什么 一个人有很多框，什么原因造成的 两种情况： 1.框不是重叠的，模型没有训练好。 2.框有重叠，非极大值抑制没有做好，模型没有训练好。 图像旋转、旋转矩阵、像素点怎么填充 openpose openpose的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。研究自下而上算法（得到关键点位置再获得骨架）而不是自上而下算法（先检测人，再回归关键点），是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。 光流怎么计算 https://blog.csdn.net/u011076940/article/details/60766423 优化器有哪些，怎么演进的，平时怎么用，如何调参数 1.梯度下降BGD： 采用整个训练集的数据来计算 cost function 对参数的梯度，由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。参数：学习率。 2.随机梯度下降SGD SGD 每次更新时对每个样本进行梯度更新， 对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡，此外SGD对噪声比较敏感。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处，因为鞍点周围的error 是一样的，所有维度的梯度都接近于0，SGD 很容易被困在这里。参数：学习率。 3.批随机梯度下降MSGD n 个样本进行计算， 这样它可以降低参数更新时的方差，收敛更稳定， 另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。参数：学习率。 4.动量梯度下降法Momentum 动量梯度下降法则对各个mini-batch求得的梯度使用指数加权平均，并使用新的参数更新之前的参数。并设有衰减率，使得前面的影响越来越小。参数：学习率、动量系数0.9。 5.NAG 先以原方向梯度进行超前计算在和下一点的梯度方向进行融合。参数：学习率、动量系数0.9。 6.Adagrad 将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。随着算法不断迭代，整体的学习率会越来越小，学习率也随之变慢。所以，一般来说AdaGrad算法一开始是激励收敛，到了后面就慢慢变成惩罚收敛，速度越来越慢。参数：学习率，小常数。 Adagrad缺点：需要自己手动指定初始学习率，而且由于分母中对历史梯度一直累加，学习率将逐渐下降至0，并且如果初始梯度很大的话，会导致整个训练过程的学习率一直很小，从而导致学习时间变长。 7.Adadelta Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。 8.RMSprop 对Adagrad优化，引入动量，调整梯度。参数：学习率、动量系数0.9、衰减系数0.001、小常数。 https://blog.csdn.net/bvl10101111/article/details/72616378 9.Adam Adam算法是将Momentum算法和RMSProp算法结合起来使用的一种算法。参数：学习率、、两个指数衰减系数0.999,0.9，小常数。 归一化层 1.(0,1)标准化： def MaxMinNormalization(x,Max,Min): x = (x - Min) / (Max - Min); return x 2.Z-scores 这里一样，mu（即均值）用np.average()，sigma（即标准差）用np.std()即可 def Z_ScoreNormalization(x,mu,sigma): x = (x - mu) / sigma; return x 3.sigmoid函数 def sigmoid(X,useStatus): if useStatus: return 1.0 / (1 + np.exp(-float(X))); else: return float(X) 设随机变量X1,X2,…Xn相互独立，且都服从（0,θ）上的均匀分布。求U=max{X1,X2,…Xn}数学期望 声音特征是怎么提取的 https://www.cnblogs.com/BaroC/p/4283380.html BN层，先加BN还是激活，有什么区别 tensorflow pb模型量化 量化(quantitative)是用比 32 位浮点数更少的空间来存储和运行模型，并且 TensorFlow 量化的实现屏蔽了存储和运行细节。神经网络训练时要求速度和准确率，训练通常在 GPU 上进行，所以使用浮点数影响不大。但是在预测阶段，使用浮点数会影响速度。量化可以在加快速度的同时，保持较高的精度。 量化网络的动机主要有两个。最初的动机是减小模型文件的大小。模型文件往往占据很大的磁盘空间，有时，每个模型都接近 200 MB，模型中存储的是分布在大量层中的权值。在存储模型的时候用 8 位整数，模型大小可以缩小为原来 32 位的 25%左右。在加载模型后运算时转换回 32 位浮点数，这样已有的浮点计算代码无需改动即可正常运行。 量化的另一个动机是降低预测过程需要的计算资源。这在嵌入式和移动端非常有意义，能够更快地运行模型，功耗更低。从体系架构的角度来说，8 位的访问次数要比 32 位多，在读取 8 位整数时只需要 32 位浮点数的 1/4 的内存带宽，例如，在 32 位内存带宽的情况下，8 位整数可以一次访问 4 个，32 位浮点数只能 1 次访问 1 个。而且使用 SIMD 指令(19.2节会加速介绍该指令集)，可以在一个时钟周期里实现更多的计算。另一方面，8 位对嵌入式设备的利用更充分，因为很多嵌入式芯片都是 8 位、16 位的，如单片机、数字信号处理器(DSP 芯片)，8 位可以充分利用这些。 此外，神经网络对于噪声的健壮性很强，因为量化会带来精度损失(这种损失可以认为是一种噪声)，并不会危害到整体结果的准确度。 那能否用低精度格式来直接训练呢?答案是，大多数情况下是不能的。因为在训练时，尽管前向传播能够顺利进行，但往往反向传播中需要计算梯度。例如，梯度是 0.2，使用浮点数可以很好地表示，而整数就不能很好地表示，这会导致梯度消失。因此需要使用高于 8 位的值来计算梯度。因此，正如在本节一开始介绍的那样，在移动端训练模型的思路往往是，在 PC 上正常训练好浮点数模型，然后直接将模型转换成 8 位，移动端是使用 8 位的模型来执行预测的过程。 图的遍历 深度优先和广度优先 bagging 1.给定一个弱学习算法,和一个训练集; 2.单个弱学习算法准确率不高; 3.将该学习算法使用多次,得出预测函数序列,进行投票; 4.最后结果准确率将得到提高. 算法： 1.For t = 1, 2, …, T Do 从数据集S中取样（放回选样） 训练得到模型Ht 对未知样本X分类时,每个模型Ht都得出一个分类，得票最高的即为未知样本X的分类 2.也可通过得票的平均值用于连续值的预测 全局对比度增强 1.直方图均衡化 Histogram Equalization 算法： 1）根据图像灰度计算灰度概率密度函数PDF 2）计算累积概率分布函数CDF 3）将CDF归一化到原图灰度取值范围，如[0,255]。 4）之后CDF四舍五入取整，得到灰度转换函数sk=T(rk) 5）将CDF作为转换函数，将灰度为rk的点转换为sk灰度 2. 直方图匹配 Histogram Matching 算法： 1）根据图像计算概率密度分布pr®； 2）根据pr®计算累计分布函数sk=T(rk)； 3）根据给定的目标分布pz(z)计算累计分布函数G(zq)； 4）对于每一个k，找到一个q，使得G(zq)约等于sk； 5）将原图中灰度为k的点变为灰度q； 局部对比度增强 1.邻域直方图均衡：将全局直方图均衡的思想应用于邻域直方图处理中。 2.邻域直方图匹配：将全局直方图匹配的思想应用于邻域直方图处理中。 3.邻域统计方法 算法 1）初始化：增强常数E，灰度下阈值k0，标准差下阈值k1，标准差上阈值k2，窗口半宽s； 2）计算图像灰度均值MG和灰度标准差σG； 3）对于每一个像素，计算邻域（大小为2∗step+1的方块）内灰度均值ML和标准差σL； 4）如果ML&lt;=k0∗MGML&lt;=k0∗MG并且k1∗σG&lt;=σL&lt;=k2∗σG，将像素灰度乘以E。 目标跟踪算法 https://blog.csdn.net/ms961516792/article/details/82682451 这篇文章比较详细。 相机的参数主要包括哪些，标定的步骤及原理，评价标准 相机参数： 相机的内参数是6个分别为：1/dx、1/dy、r、u0、v0、f。opencv1里的说内参数是4个其为fx、fy、u0、v0。实际其fx=F*Sx，其中的F就是焦距上面的f,Sx是像素/没毫米即上面的dx，其是最后面图里的后两个矩阵进行先相乘，得出的，则把它看成整体，就相当于4个内参。其是把r等于零，实际上也是六个。 相机的外参数是6个：三个轴的旋转参数分别为（ω、δ、 θ）,然后把每个轴的33旋转矩阵进行组合（即先矩阵之间相乘），得到集合三个轴旋转信息的R，其大小还是33；T的三个轴的平移参数（Tx、Ty、Tz）。R、T组合成成的3*4的矩阵，其是转换到标定纸坐标的关键。其中绕X轴旋转θ，则其如图： 现以NiKon D700相机为例进行求解其内参数矩阵： 就算大家身边没有这款相机也无所谓，可以在网上百度一下，很方便的就知道其一些参数—— 焦距 f = 35mm 最高分辨率：4256×2832 传感器尺寸：36.0×23.9 mm 根据以上定义可以有： u0= 4256/2 = 2128 v0= 2832/2 = 1416 dx = 36.0/4256 dy = 23.9/2832 fx = f/dx = 4137.8 fy = f/dy = 4147.3 标定方法：相机标定方法有：传统相机标定法、主动视觉相机标定方法、相机自标定法。 标定步骤：https://blog.csdn.net/dcrmg/article/details/52939318 准备标定图片 对每一张标定图片，提取角点信息 对每一张标定图片，进一步提取亚像素角点信息 在棋盘标定图上绘制找到的内角点（非必须，仅为了显示） 相机标定 对标定结果进行评价 查看标定效果——利用标定结果对棋盘图进行矫正 时域滤波和频域滤波 频域的处理有时域不能比拟的优势，就是对于不规则的噪声值，通过傅里叶变换可以得到很好的平滑效果；但相应的，时域在边缘提取上，要比频域的处理更优秀。 常见滤波算法以及特点 高斯滤波 由于高斯函数的傅立叶变换仍是高斯函数, 因此高斯函数能构成一个在频域具有平滑性能的低通滤波器。可以通过在频域做乘积来实现高斯滤波。均值滤波是对是对信号进行局部平均, 以平均值来代表该像素点的灰度值。矩形滤波器(Averaging Box Filter)对这个二维矢量的每一个分量进行独立的平滑处理。通过计算和转化 ,得到一幅单位矢量图。这个 512×512的矢量图被划分成一个 8×8的小区域 ,再在每一个小区域中 ,统计这个区域内的主要方向 ,亦即将对该区域内点方向数进行统计,最多的方向作为区域的主方向。于是就得到了一个新的64×64的矢量图。这个新的矢量图还可以采用一个 3×3模板进行进一步的平滑。 均值滤波 把每个像素都用周围的8个像素来做均值操作。可以平滑图像，速度快，算法简单。但是无法去掉噪声，这能微弱的减弱它。 中值滤波 常用的非线性滤波方法 ,也是图像处理技术中最常用的预处理技术。它在平滑脉冲噪声方面非常有效,同时它可以保护图像尖锐的边缘。加权中值滤波能够改进中值滤波的边缘信号保持效果。但对方向性很强的指纹图像进行滤波处理时 ,有必要引入方向信息,即利用指纹方向图来指导中值滤波的进行。 最小均方差滤波器 亦称维纳滤波器,其设计思想是使输入信号乘响应后的输出,与期望输出的均方误差为最小。 Gabor滤波 Gabor变换是英国物理学家 Gabor提出来的,由“测不准原理”可知,它具有最小的时频窗,即Gabor函数能做到具有最精确的时间-频率的局部化；另外, Gabor函数与哺乳动物的视觉感受野相当吻合,这一点对研究图像特征检测或空间频率滤波非常有用。恰当的选择其参数, Gabor变换可以出色地进行图像分割、识别与理解。如文献提出的基于Gabor滤波器的增强算法。 面试问题 1.格灵深瞳 batchnormal的作用，你怎么看待它。batchnormal的几个参数，参数计算，能不能整合到前面的conv里，训练时和测试时的区别。 说一下感受野计算。 说一下3×3，s=1与5×5，s=2卷积核计算量。 尽可能多的说出1×1卷积的作用 轻量级网络有哪些？具体说说：squeezenet、mobilenet、shuttlenet细节 resnet两个版本的区别，说出每个block的结构。resnet为什么好训练。 介绍一个项目 介绍一个你熟悉的算法 bottlenect 深度优先和广度优先，主要用什么数据结构。","@type":"BlogPosting","url":"https://uzzz.org/2019/08/05/792946.html","headline":"计算机视觉算法岗面试题","dateModified":"2019-08-05T00:00:00+08:00","datePublished":"2019-08-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/05/792946.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>计算机视觉算法岗面试题</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-tomorrow-night"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p>大佬的面试经验：<a href="https://www.nowcoder.com/discuss/128148" rel="nofollow" data-token="42c4ad9a1fdb8e3a206e4b546ab9994b">https://www.nowcoder.com/discuss/128148</a><br> 以及大佬的博客：<a href="https://blog.csdn.net/liuxiao214/article/details/83043170" rel="nofollow" data-token="e7847527f0e7288b6daebc3b287b3e6a">https://blog.csdn.net/liuxiao214/article/details/83043170</a><br> 根据大佬的面试经验一点一点填坑吧。</p> 
  <h2><a id="_3"></a>常见概念</h2> 
  <p><strong>最大似然估计</strong>：最大似然估计是一种统计方法，最大似然估计函数在采样样本总数趋于无穷的时候达到最小方差。步骤：1.写出似然函数 2.取对数 3.求导数并令其为0。<br> <strong>最小二乘法</strong>：通过最小化误差的平方和寻找数据的最佳函数匹配。<br> <strong>梯度下降法</strong>：<br> 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019071320005473.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>模型融合方法</strong>：<br> 目前的集成学习方法大致可以分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和随机森林。</p> 
  <p><strong>1.投票</strong>：<br> 假设对于一个二分类问题，有3个基础模型，那么就采取投票制的方法，投票多者确定为最终的分类。<br> <strong>2.平均</strong>：<br> 对于回归问题，一个简单直接的思路是取平均。稍稍改进的方法是进行加权平均。权值可以用排序的方法确定，举个例子，比如A、B、C三种基本模型，模型效果进行排名，假设排名分别是1，2，3，那么给这三个模型赋予的权值分别是3/6、2/6、1/6。这两种方法看似简单，其实后面的高级算法也可以说是基于此而产生的，Bagging或者Boosting都是一种把许多弱分类器这样融合成强分类器的思想。<br> <strong>3.Bagging</strong>：<br> 就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步：<br> ① 重复K次，有放回地重复抽样建模，训练子模型<br> ② 模型融合，分类问题：voting，回归问题：average<br> 随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。<br> <strong>4.Boosting</strong>：<br> Bagging算法可以并行处理，而Boosting的思想是一种迭代的方法。<br> AdaBoost 是Boosting 算法家族中代表算法，AdaBoost 每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例，最终将这些弱分类器进行加权相加。AdaBoost模型是弱分类器的线性组合，AdaBoost算法的一个解释是该算法实际上是前向分步算法的一个实现，在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。<br> xgboost相对AdaBoost区别，对损失函数做了二阶的泰勒展开，并在目标函数之外加入了正则项对整体求最优解，用以权衡目标函数的下降和模型的复杂程度，避免过拟合。所以不考虑细节方面，两者最大的不同就是目标函数的定义</p> 
  <p><strong>L1L2正则</strong>：<br> <strong>判别式模型与生成式模型：</strong>：<br> 判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机SVM、神经网络等。</p> 
  <p>生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi，<br> 常见的生成式模型有 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA等。<a href="https://blog.csdn.net/huangfei711/article/details/79834780" rel="nofollow" data-token="6d9140d9df0247e7ba2b804339334fb2">https://blog.csdn.net/huangfei711/article/details/79834780</a><br> <strong>熵-交叉熵-KL散度</strong>：<br> 熵：信息熵是度量随机变量不确定度的指标，信息熵越大意味着随机变量不确定度越高，意味着系统的有序程度越低。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190714112649597." alt="在这里插入图片描述"><br> 交叉熵：主要用于度量两个概率分布间的差异性信息。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190714112736999.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> KL散度/相对熵：是描述两个概率分布P和Q差异的一种方法。<br> 三者间关系：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190714112817975." alt="在这里插入图片描述"><br> <strong>最优化方法</strong>（梯度下降，牛顿法，共轭梯度法）：<br> 牛顿法：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190719102725935." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190719103236130.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>交叉验证</strong>：<br> 第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。<br> 第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。<br> 第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。<br> 此外还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法(bootstrapping)。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。</p> 
  <p><strong>皮尔逊系数</strong>：<br> 皮尔逊相关系数广泛用于度量两个变量之间的相关程度，其值介于-1与1之间。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190713202948781." alt="在这里插入图片描述"><br> <strong>bias-variance-tradeoff</strong>：偏差方差权衡<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190713205513164.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 1、Bias and Variance tradeoff的最简单方法<br> 当Bias很高的时候，就增加模型的复杂度（比如增加神经网络的神经元个数，神经网络的层数）<br> 当Variance很高的时候，就增加训练的样本量。</p> 
  <p>然而以上的原则只是一个大的指导方向，因为在实际操作中增加模型的复杂程度将会大大增加计算机的计算量，而且还容易造成Overfitting。 下面详细介绍在实际操作中处理Bias 和 Variance 的具体方法。</p> 
  <p>2、减少Bias的几大原则<br> 增加模型复杂度<br> 根据误差分析结果，调整输入特征(feature)<br> 减少或者去除Regularization(正则化)<br> 修改模型结构<br> 增加更多的训练样本</p> 
  <p>3、减少Variance的几大原则<br> 增加更多的训练样本<br> 增加Regularization(正则化)<br> 加入提前终止(Early Stopping)<br> 选择性减少输入的特征(Features)<br> 减小模型规模<br> 根据误差分析结果，调整输入特征(feature)<br> 修改模型结构</p> 
  <p><strong>无偏估计</strong>：无偏估计是用样本统计量来估计总体参数时的一种无偏推断。估计量的数学期望等于被估计参数的真实值，则称此估计量为被估计参数的无偏估计，即具有无偏性，是一种用于评价估计量优良性的准则。无偏估计的意义是：在多次重复下，它们的平均数接近所估计的参数真值。<br> <strong>ROC，recall，precision</strong>：</p> 
  <h2><a id="ROC_79"></a>分类器的ROC曲线和相关指标</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190402204449947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 准确率(Accuracy)：ACC=(TP+TN)/(TP+TN+FP+FN)</p> 
  <h2><a id="mAP_83"></a>mAP是什么</h2> 
  <p>P：precision即准确率，TP / (TP + FP)，分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例;<br> R：recall即召回率，TP / (TP + FN)，分类器认为是正类并且确实是正类的部分占所有确实是正类的比例;<br> 目标检测中：<br> TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次）<br> FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量<br> FN: 没有检测到的GT的数量<br> PR曲线：以P和R为纵横坐标的曲线;<br> AP值：Average Precision平均精确度，为PR曲线下面积;<br> mAP:各类AP的平均值;</p> 
  <p>举例：<br> 假设，对于Aeroplane类别，我们网络有以下输出(BB表示BoundingBox序号，IoU&gt;0.5时GT=1)：</p> 
  <pre><code>BB  | confidence | GT
----------------------
BB1 |  0.9       | 1
----------------------
BB2 |  0.9       | 1
----------------------
BB1 |  0.8       | 1
----------------------
BB3 |  0.7       | 0
----------------------
BB4 |  0.7       | 0
----------------------
BB5 |  0.7       | 1
----------------------
BB6 |  0.7       | 0
----------------------
BB7 |  0.7       | 0
----------------------
BB8 |  0.7       | 1
----------------------
BB9 |  0.7       | 1
----------------------
</code></pre> 
  <p>因此，我们有 TP=5 (BB1, BB2, BB5, BB8, BB9), FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2. 这时我们就可以按照Confidence的顺序给出各处的PR值，如下：</p> 
  <pre><code>rank=1  precision=1.00 and recall=0.14
----------
rank=2  precision=1.00 and recall=0.29
----------
rank=3  precision=0.66 and recall=0.29
----------
rank=4  precision=0.50 and recall=0.29
----------
rank=5  precision=0.40 and recall=0.29
----------
rank=6  precision=0.50 and recall=0.43
----------
rank=7  precision=0.43 and recall=0.43
----------
rank=8  precision=0.38 and recall=0.43
----------
rank=9  precision=0.44 and recall=0.57
----------
rank=10 precision=0.50 and recall=0.71
</code></pre> 
  <p>对于Recall &gt;= 0, 0.14, 0.29, 0.43, 0.57, 0.71, 1，我们选取此时Percision的最大值：1, 1, 1, 0.5, 0.5, 0.5, 0。此时Aeroplane类别的 AP = (0.14-0)*1 + (0.29-0.14)*1 + (0.43-0.29)*0.5 + (0.57-0.43)*0.5 + (0.71-0.57)*0.5 + (1-0.71)*0 = 0.5<br> mAP就是对每一个类别都计算出AP然后再计算AP平均值就好了。</p> 
  <h2><a id="_144"></a>图像分类方法</h2> 
  <p>逻辑回归，支持向量机，随机森林，GBDT，深度学习。<br> <strong>逻辑回归</strong>：<a href="https://www.jianshu.com/p/1bf35d61995f" rel="nofollow" data-token="32e68dc958d9fdd2b34caff0f1d7f919">https://www.jianshu.com/p/1bf35d61995f</a><br> <strong>支持向量机</strong>：<a href="https://blog.csdn.net/u011630575/article/details/78916747" rel="nofollow" data-token="04794b048eacefca5358f678ba6f7643">https://blog.csdn.net/u011630575/article/details/78916747</a><br> 距离超平面最小的样例，我们称之为支持向量，我们所要找的最优超平面，就是使支持向量到超平面距离最大，我们认为，这样的超平面，就是最优的，下面也是要想办法求出这个超平面。SVM的核心问题就是找到这一超平面<br> 最大间隔分类：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712161852551.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>随机森林</strong>：<a href="https://blog.csdn.net/yangyin007/article/details/82385967?tdsourcetag=s_pcqq_aiomsg" rel="nofollow" data-token="4aa040468de05a35e4059333a4257fe1">https://blog.csdn.net/yangyin007/article/details/82385967?tdsourcetag=s_pcqq_aiomsg</a><br> GBDT：</p> 
  <h2><a id="LRSVM_153"></a>LR和SVM的异同</h2> 
  <p>相同点：<br> 第一，LR和SVM都是分类算法。<br> 第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。<br> 第三，LR和SVM都是监督学习算法。<br> 第四，LR和SVM都是判别模型。<br> 第五，LR和SVM在学术界和工业界都广为人知并且应用广泛。</p> 
  <p>不同点：<br> 第一，损失函数不同<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019071216315072." alt="在这里插入图片描述"><br> 第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712163745651.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。<br> 第四，​线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响。<br> 第五，SVM的损失函数就自带正则（损失函数中的1/2||w||^2项），这就是为什么SVM是结构风险最小化算法的原因，而LR必须另外在损失函数上添加正则项</p> 
  <h2><a id="_169"></a>函数间隔和几何间隔</h2> 
  <p>函数间隔<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712164503530." alt="在这里插入图片描述"><br> 几何间隔<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712164538925." alt="在这里插入图片描述"></p> 
  <h2><a id="_174"></a>视频分类</h2> 
  <p>思路：<br> 1.通过将视频的每一帧视为一幅单独的图像，利用二维 CNN 进行处理。这种方法将视频分类问题简化为图像分类问题。每帧视频图像都有类别输出，并且根据各帧输出的类别，选择频率最高的类别作为视频的分类结果。<br> 2.创建一个单一的网络，将二维 CNN 与一个 RNN 结合在一起。这个想法是，CNN 将考虑到图像分量，而 RNN 将考虑每个视频的序列信息。这种类型的网络可能非常难以训练，因为要优化的参数数量非常大。<br> 3.使用三维卷积网络，其中三维卷积网络是二维 CNN 的在 3D 张量（时间，图像宽度，图像高度）上运行的扩展。这种方法是图像分类的另一个自然延伸，但三维卷积网络可能很难训练。<br> 4.基于智能方法的直觉。它们可以用于存储视频中每个帧的离线功能，而不是直接使用 CNN 进行分类。这个想法基于，特征提取可以非常有效地进行迁移学习，如前面章节所示。在提取所有的特征之后，可以将它们作为一组输入传递给RNN，其将在多个帧中学习序列并输出最终的分类。<br> 5.第四种方法的简单变体，其中最后一层是 MLP 而不是 RNN。在某些情况下，就计算需求而言，这种方法可以更简单并且成本更低。<br> 6.第四种方法的变体，其中特征提取阶段采用三维 CNN 来提取空间和视觉特征，然后将这些特征传递给 RNN 或 MLP。</p> 
  <h2><a id="_182"></a>细粒度分类</h2> 
  <p><a href="https://blog.csdn.net/qq_25439417/article/details/82764183" rel="nofollow" data-token="59a3e27541308e833d676659c9b333a5">https://blog.csdn.net/qq_25439417/article/details/82764183</a><br> 细粒度分类：同一类中不同子类物体间的分类。<br> 1.Part-based R-CNN。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190713203514561.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 如上所示，局部区域将从自底向上的候选区域开始（左上角），我们将基于深度卷积特征同时训练目标和局部区域。在推断阶段，所有的窗口都会由检测器评分（中间），且我们可以应用非参几何约束（底部）重新评估窗口并选择最优的目标和局部检测（右上角）。最后的步骤就是抽取局部语义信息来用于细粒度识别，并训练一个分类器预测最终类别。<br> 2.Bilinear deep network models<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190713203354714.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 3.FCN attention。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190708214827658.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 在抽取特征后，模型需要学习哪些局部区域对最终分类是重要的，而确定重要性的标准即局部区域对最终预测是否有帮助。在这一阶段中，注意力网络会将基本的局部卷积特征图生成一张评分图或置信图，即通过叠加的两个卷积层将特征图转换为通道数为 1 的评分图。一般第一个卷积层可使用 64 个 3×3 的卷积核，而第二个卷积层可使用 1 个 3×3 的卷积核将通道数降为 1，这一张置信图展示了模型关注的兴趣点。</p> 
  <p>兴趣点是网络自己学到的，而裁剪的大小是我们给定的。我们首先会给一个 8×8 的较大裁剪窗口，相当于关注较大的区域。随着迭代的进行，我们会慢慢减小裁剪窗口，这相当于关注更小的细节。裁剪后的特征图一般需要馈送到 Softmax 层以将置信图转换为概率图。</p> 
  <h2><a id="attentionpixelframesofthard_195"></a>你知道attention起源是用在哪里？pixel还是frame，是soft还是hard</h2> 
  <p>对于 Attention的作用角度出发，可以分为： 空间注意力 Spatial Attention，时间注意力 Temporal Attention<br> 这样的分类更多的是从应用层面上；而从 Attention的作用方法上，可以将其分为 Soft Attention 和 Hard Attention，这既我们所说的， Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。<br> attention机制：<a href="https://blog.csdn.net/xiewenbo/article/details/79382785" rel="nofollow" data-token="0884dc859ddb6c6177027aa4e981d12c">https://blog.csdn.net/xiewenbo/article/details/79382785</a><br> Soft Attention：传统的Attention Mechanism就是Soft Attention,即通过确定性的得分计算来得到attended之后的编码隐状态。Soft Attention是参数化的（Parameterization），因此可导，可以被嵌入到模型中去，直接训练。梯度可以经过Attention Mechanism模块，反向传播到模型其他部分。<br> Hard Attention：是一个随机的过程。Hard Attention不会选择整个encoder的隐层输出做为其输入，Hard Attention会依概率Si来采样输入端的隐状态一部分来进行计算，而不是整个encoder的隐状态。为了实现梯度的反向传播，需要采用蒙特卡洛采样的方法来估计模块的梯度。<br> 两种Attention Mechanism都有各自的优势，但目前更多的研究和应用还是更倾向于使用Soft Attention，因为其可以直接求导，进行梯度反向传播</p> 
  <h2><a id="_202"></a>网络用的损失函数是什么</h2> 
  <ol> 
   <li>L1 loss：绝对差平均损失，又称MAE<br> .<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403214534652." alt="在这里插入图片描述"><br> 2.L2 loss：平方差平均损失，又称MSE<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403214720422." alt="在这里插入图片描述"><br> 3.Smooth L1 loss，又称Huber损失<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403214815391." alt="在这里插入图片描述"><br> 4.BCE loss，二分类用的交叉熵损失，用的时候需要在该层前面加上 Sigmoid 函数<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403215311187." alt="在这里插入图片描述"><br> 5.BCEWithlogitsLoss，将sigmoid函数集成到BCE loss上<br> 6.CrossEntoryLoss，交叉熵损失函数<br> 第一种形式：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403220604806." alt="在这里插入图片描述"><br> 第二种形式：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403221110919." alt="在这里插入图片描述"><br> softmax的交叉熵：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403220534814." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403215622539." alt="在这里插入图片描述"><br> 7.NllLoss：负对数似然损失。</li> 
  </ol> 
  <h2><a id="_221"></a>监督学习和无监督学习</h2> 
  <p>监督学习(supervised learning)：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。</p> 
  <p>无监督学习(unsupervised learning)：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。</p> 
  <p>强化学习(reinforcement learning)：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。</p> 
  <p>弱监督学习(weakly supervised learning)： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。</p> 
  <p>半监督学习(semi supervised learning) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，学习已知标签和未知标签的数据，将输入数据映射到标签的过程。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。</p> 
  <p>多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。</p> 
  <h2><a id="softmax_loss_234"></a>softmax loss</h2> 
  <p>softmax的交叉熵：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403220534814." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403215622539." alt="在这里插入图片描述"></p> 
  <h2><a id="LRsigmoid_238"></a>LR为什么要用sigmoid函数</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050510383540.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="3_LR__240"></a>3. LR 损失函数为什么用极大似然函数？</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505103150946.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 1.因为我们想要让每一个样本的预测都要得到最大的概率，即将所有的样本预测后的概率进行相乘都最大，也就是极大似然函数.<br> 2.对极大似然函数取对数以后相当于对数损失函数，由上面梯度更新的公式可以看出，对数损失函数的训练求解参数的速度是比较快的，而且更新速度只和x，y有关，比较的稳定。<br> 3.为什么不用平方损失函数<br> 如果使用平方损失函数，梯度更新的速度会和 sigmod 函数的梯度相关，sigmod 函数在定义域内的梯度都不大于0.25，导致训练速度会非常慢。<br> 而且平方损失会导致损失函数是 theta 的非凸函数，不利于求解，因为非凸函数存在很多局部最优解</p> 
  <h2><a id="softmax_248"></a>softmax交叉熵损失函数求导</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505105600125." alt="在这里插入图片描述"><br> <a href="https://blog.csdn.net/qian99/article/details/78046329" rel="nofollow" data-token="9030293e74a646877d5d244ba42439f8">https://blog.csdn.net/qian99/article/details/78046329</a></p> 
  <h2><a id="softmaxlogistic_251"></a>softmax和logistic回归的区别和联系</h2> 
  <p>1.softmax用来解决多分类问题，lr解决二分类问题<br> 2.softmax输出每一类的概率值，并确定概率最大的类是正确的，lr只区别是还是不是。事实上softmax是lr的一般情况。</p> 
  <p><a href="https://blog.csdn.net/chnguoshiwushuang/article/details/80514626" rel="nofollow" data-token="aaa5abfd60afb2f8e4f9f06c93365750">https://blog.csdn.net/chnguoshiwushuang/article/details/80514626</a></p> 
  <h2><a id="_256"></a>全连接的作用</h2> 
  <p>因为用到了所有的局部特征，所以叫全连接。将学到的“分布式特征表示”映射到样本标记空间的作用。</p> 
  <h2><a id="GDSGDmini_batch_GD_258"></a>GD、SGD、mini batch GD的区别</h2> 
  <p>GD：梯度下降法的物理意义很好理解，就是沿着当前点的梯度方向进行线搜索，找到下一个迭代点<br> SGD：随机梯度下降法，每次计算梯度时，只随机的选取一个样本来计算梯度,这样就大大的减小了计算的复杂度，随机梯度下降法速度快，但每次的方向不稳定，甚至可能向反方向。<br> mini batch GD：故每次计算梯度时，选取一部分样本，即小批量梯度下降法。</p> 
  <h2><a id="S3D_263"></a>S3D了解吗？</h2> 
  <h2><a id="_264"></a>边缘检测算子有哪些</h2> 
  <p>1.差分算子。<br> <strong>一阶微分：</strong><br> 2.Roberts算子，对角线方向相邻两象素之差近似梯度幅值检测边缘，对噪声敏感,无法抑制噪声的影响。<br> 3.Sobel算子，该算子包含两组3 * 3的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差分近似值，在结合横向和纵向<br> 4.Prewitt算子，一阶微分算子的边缘检测，模板3 * 3利用像素点上下、左右邻点的灰度差，在边缘处达到极值检测边缘，去掉部分伪边缘，对噪声具有平滑作用 。<br> <strong>二阶微分</strong><br> 5.Laplacian算子，存在噪声情况下，使用Laplacian算子检测边缘之前需要先进行低通滤波，模板3 * 3。<br> 6.Log算子，进行高斯滤波再进行拉普拉斯算子检测，模板5 * 5。<br> <strong>非微分</strong><br> 7.Canny算子：<br> 1)使用高斯滤波器，以平滑图像，滤除噪声。<br> 2)计算图像中每个像素点的梯度强度和方向。<br> 3)应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。<br> 4)应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。<br> 5)通过抑制孤立的弱边缘最终完成边缘检测。</p> 
  <h2><a id="_280"></a>霍夫变换</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019042816113037.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428161549917.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428161728198.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019042816184244.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="SVM_286"></a>说一下SVM核函数</h2> 
  <p>在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。核函数的价值在于它虽然也是讲特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算。<br> 1.多项式核函数<br> 2.高斯核函数<br> 3.线性核函数<br> 4.字符串核函数</p> 
  <h2><a id="PCA_292"></a>PCA</h2> 
  <p>PCA(principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据压缩算法。它可以通过线性变换将原始数据变换为一组各维度线性无关的表示，以此来提取数据的主要线性分量。<br> 具体可以看这篇文章：<a href="https://blog.csdn.net/hustqb/article/details/78394058" rel="nofollow" data-token="bffaf09777ef924f049e874ff35c4cd9">https://blog.csdn.net/hustqb/article/details/78394058</a><br> 伪代码：<br> 去除平均值<br> 计算协方差矩阵<br> 计算协方差矩阵的特征值和特征向量<br> 将特征值排序<br> 保留前N个最大的特征值对应的特征向量<br> 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩）<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019071914290094.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="L1L2_303"></a>L1、L2范数</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428214848582.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="sigmoid_305"></a>sigmoid优缺点</h2> 
  <p>优点：可以将函数值的范围压缩到[0,1]，可以压缩数据，且幅度不变。在特征相差比较复杂或是相差不是特别大时效果比较好。可以看到sigmoid函数处处连续便于求导；便于前向传输。<br> 缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法。反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练</p> 
  <h2><a id="RefineNet_309"></a>RefineNet理解</h2> 
  <p>针对语义分割所提出的网络模型，可以分为两段对应于U-Net中向下（特征逐步降采样同时提取语义特征）和向上（逐步上采样特征恢复细节信息）两段通路。其中向下的通路以ResNet为基础。向上的通路使用了新提出的RefineNet作为基础，并作为本通路特征与ResNet中低层特征的融合器。下图a为标准CNN，b图为带孔卷积，RefineNet的框架如c图所示： 其中左边的四组特征是从ResNet的四个对应的block取出的。此框架与U-Net没有太大区别。不过如作者所说，RefineNet是一个灵活的模块，其输入的尺度个数可以变化，因此整个网络的拓扑结构可以有很多改变。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712091414672.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> RefineNet可以分为三个主要部分： 1. 不同尺度（也可能只有一个输入尺度）的特征输入首先经过两个Residual模块的处理； 2. 之后是不同尺寸的特征进行融合。当然如果只有一个输入尺度，该模块则可以省去。所有特征上采样至最大的输入尺寸，然后进行加和。上采样之前的卷积模块是为了调整不同特征的数值尺度； 3. 最后是一个链式的pooling模块。其设计本意是使用侧支上一系列的pooling来获取背景信息（通常尺寸较大）。直连通路上的ReLU可以在不显著影响梯度流通的情况下提高后续pooling的性能，同时不让网络的训练对学习率很敏感。最后再经过一个Residual模块即得RefineNet的输出。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712091642158.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 详细架构如下：<br> 引用：<a href="https://blog.csdn.net/gqixf/article/details/82911220" rel="nofollow" data-token="ff2f1a6406657f91b5b1abcf1da299c6">https://blog.csdn.net/gqixf/article/details/82911220</a><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190712092005154.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="densenet_317"></a>densenet结构优缺点以及应用场景</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702001430666.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702001118204." alt="在这里插入图片描述"><br> 优点：<br> (1) 相比ResNet拥有更少的参数数量.<br> (2) 旁路加强了特征的重用.<br> (3) 网络更易于训练,并具有一定的正则效果.<br> (4) 缓解了gradient vanishing和model degradation的问题.<br> 缺点：<br> DenseNet在训练时十分消耗内存，这是由于算法实现不优带来的。当前的深度学习框架对 DenseNet 的密集连接没有很好的支持，所以只能借助于反复的拼接（Concatenation）操作，将之前层的输出与当前层的输出拼接在一起，然后传给下一层。对于大多数框架（如Torch和TensorFlow），每次拼接操作都会开辟新的内存来保存拼接后的特征。这样就导致一个 L 层的网络，要消耗相当于 L(L+1)/2 层网络的内存.<br> <strong>pooling层：</strong><br> 由于在DenseNet中需要对不同层的feature map进行cat操作,所以需要不同层的feature map保持相同的feature size,这就限制了网络中Down sampling的实现.为了使用Down sampling,作者将DenseNet分为多个Denseblock,如下图所示:<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702001756946." alt="在这里插入图片描述"><br> 在同一个Denseblock中要求feature size保持相同大小,在不同Denseblock之间设置transition layers实现Down sampling, 在作者的实验中transition layer由BN + Conv(1×1) ＋2×2 average-pooling组成.<br> <strong>Growth rate：</strong><br> 在Denseblock中,假设每一个非线性变换H的输出为K个feature map, 那么第i层网络的输入便为K0+(i-1)×K, 这里我们可以看到DenseNet和现有网络的一个主要的不同点:DenseNet可以接受较少的特征图数量作为网络层的输出,如下图所示<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702002400505.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 原因就是在同一个Denseblock中的每一层都与之前所有层相关联,如果我们把feature看作是一个Denseblock的全局状态,那么每一层的训练目标便是通过现有的全局状态,判断需要添加给全局状态的更新值.因而每个网络层输出的特征图数量K又称为Growth rate,同样决定着每一层需要给全局状态更新的信息的多少<br> <strong>Bottleneck Layers：</strong><br> 虽然DenseNet接受较少的k,也就是feature map的数量作为输出,但由于不同层feature map之间由cat操作组合在一起,最终仍然会是feature map的channel较大而成为网络的负担.作者在这里使用1×1 Conv(Bottleneck)作为特征降维的方法来降低channel数量,以提高计算效率.经过改善后的非线性变换变为BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3),使用Bottleneck layers的DenseNet被作者称为DenseNet-B.<br> <strong>Compression：</strong><br> 为了进一步优化模型的简洁性,我们同样可以在transition layer中降低feature map的数量.若一个Denseblock中包含m个feature maps,那么我们使其输出连接的transition layer层生成⌊θm⌋个输出feature map.其中θ为Compression factor, 当θ=1时,transition layer将保留原feature维度不变.<br> <strong>实验结论</strong><br> a) 一些较早层提取出的特征仍可能被较深层直接使用<br> b) 即使是Transition layer也会使用到之前Denseblock中所有层的特征<br> c) 第2-3个Denseblock中的层对之前Transition layer利用率很低,说明transition layer输出大量冗余特征.这也为DenseNet-BC提供了证据支持,既Compression的必要性.<br> d) 最后的分类层虽然使用了之前Denseblock中的多层信息,但更偏向于使用最后几个feature map的特征,说明在网络的最后几层,某些high-level的特征可能被产生.</p> 
  <h2><a id="vggnet_344"></a>vggnet网络</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702004222820.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="inception_346"></a>inception网络</h2> 
  <p><a href="https://blog.csdn.net/u011021773/article/details/80791650?tdsourcetag=s_pcqq_aiomsg" rel="nofollow" data-token="8de442efe3d6bddfee0fd661ecc4940c">https://blog.csdn.net/u011021773/article/details/80791650?tdsourcetag=s_pcqq_aiomsg</a><br> Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。<br> <strong>v1</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702004737608.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>v2</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702004802616.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>v3</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702004922825.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>Inception V3</strong><br> inception V3把googlenet里一些7<em>7的卷积变成了1</em>7和7<em>1的两层串联，3</em>3的也一样，变成了1<em>3和3</em>1，这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299.<br> <strong>Inception V4</strong><br> inception v4实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。<br> 另外就是V4把一个先1<em>1再3</em>3那步换成了先3<em>3再1</em>1.<br> 论文说引入resnet不是用来提高深度，进而提高准确度的，只是用来提高速度的。</p> 
  <h2><a id="Resnet_361"></a>对Resnet的理解</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428220354630." alt="在这里插入图片描述"><br> 1.避免梯度消失，解决网络退化。 2.残差模块可以更容易学习更细致的信息。</p> 
  <h2><a id="Resnet_364"></a>Resnet网络</h2> 
  <p><a href="https://blog.csdn.net/lanran2/article/details/80247515" rel="nofollow" data-token="d7d4a3824d2bc58b6c0eb4e15714dd98">https://blog.csdn.net/lanran2/article/details/80247515</a><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429220839556.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>resnet-50结构图</strong><br> <a href="https://blog.csdn.net/qq_21046135/article/details/81674605" rel="nofollow" data-token="4331099a29d34317f2665ac5da4db686">https://blog.csdn.net/qq_21046135/article/details/81674605</a></p> 
  <h2><a id="dropout_369"></a>解释dropout以及实现机制</h2> 
  <p>dropout原理：在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据(batchsize个样本)</p> 
  <p><strong>作用</strong> ：1.减少特征冗余，减少过拟合 2.提升泛化能力，增加模型的鲁棒性<br> <strong>缺点</strong>：减慢收敛速度：由于每次迭代只有一部分参数更新，可能导致梯度下降变慢</p> 
  <h2><a id="_374"></a>为什么梯度会消失和爆炸</h2> 
  <p>1.损失函数<br> 2.网络结构(深层)<br> 3.权值初始化值太大<br> 4.学习率过大</p> 
  <h2><a id="_379"></a>正则化方法以及特点</h2> 
  <p>1.数据增强<br> 数据增强技术如水平、垂直、镜像翻转图像、裁剪、色彩变换、扩展和旋转，滤波，噪点等等<br> 2.提前终止<br> 3.Bagging<br> 4.dropout<br> 5.batch normalizatin<br> 6.参数范数惩罚：<a href="https://www.cnblogs.com/pinking/p/9310728.html" rel="nofollow" data-token="7ce859b25b235c523b996ef01c9c4ea8">https://www.cnblogs.com/pinking/p/9310728.html</a></p> 
  <h2><a id="_387"></a>深度学习中有什么加快收敛/降低训练难度的方法：</h2> 
  <p>1.瓶颈结构<br> 2.残差<br> 3.学习率、步长、动量<br> 4.优化方法<br> 5.预训练</p> 
  <p>预训练网络freeze某几层</p> 
  <h2><a id="_395"></a>过拟合怎么做</h2> 
  <p>Parameter Norm Penalties(参数范数惩罚)；Dataset Augmentation (数据集增强)；Early Stopping(提前终止)；Parameter Tying and Parameter Sharing (参数绑定与参数共享)；Bagging and Other Ensemble Methods(Bagging 和其他集成方法)；dropout；regularization； batch normalizatin；加噪声。是解决Overfitting的常用手段。</p> 
  <h2><a id="GAN_397"></a>GAN的公式以及发展历程</h2> 
  <p><a href="https://www.jqr.com/article/000325" rel="nofollow" data-token="a93dcb7139f7ed9b351453078e89565e">https://www.jqr.com/article/000325</a><br> <a href="https://blog.csdn.net/qq_19272431/article/details/93380342" rel="nofollow" data-token="fde9ee209af00e37ead4b8c1af397680">https://blog.csdn.net/qq_19272431/article/details/93380342</a><br> <a href="https://blog.csdn.net/qq_32439305/article/details/86766792" rel="nofollow" data-token="5f6daf94b46d0d56eeed042cbcff1199">https://blog.csdn.net/qq_32439305/article/details/86766792</a><br> <strong>相对判别器</strong><br> 在标准生成对抗网络（SGAN）中，判别器负责估计输入数据是真实数据的概率，根据这个数值，我们再训练生成器以提高伪数据是真实数据的概率。但本文认为，判别器在提高“伪数据为真”的概率的同时，也应该降低“实际数据为真”的概率，原因有三：</p> 
  <p>1.mini-batch中一半的数据是伪数据，这个先验会带来不合逻辑的结果；</p> 
  <p>2.在最小化散度（divergence minimization）的过程中，两个概率不是同步变化；</p> 
  <p>3.实验证实，经过相对判别器诱导，SGAN的性能可以媲美基于IPM的GAN（WGAN、WGAN-GP等），而后者实际上已经具有相对判别器的雏形，因此也更稳定。</p> 
  <p>本文提出相对GAN（RGAN），并在它的基础上又提出了一个变体——相对均值GAN（RaGAN），变体用平均估计计算判别器概率。此外，论文还显示基于IPM的GAN其实是RGAN的子集。</p> 
  <p>通过比较，文章发现：(1)相比非相对GAN，RGAN和RaGAN更稳定，产出的数据样本质量更高；(2)在RaGAN上加入梯度惩罚后，它能生成比WGAN-GP质量更高的数据，同时训练时长仅为原先的1/5；(3)RaGAN能够基于非常小的样本（N = 2011）生成合理的高分辨率图像（256x256），撇开做不到的GAN和LSGAN，这些图像在质量上也明显优于WGAN-GP和SGAN生成的归一化图像。<br> <strong>通用GAN的形式：</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722122409341." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722122321479.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>相对的GAN</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722125400134." alt="在这里插入图片描述"><br> <strong>简化形式</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722125413188." alt="在这里插入图片描述"><br> <strong>相对平均GAN</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190722124945772.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="dilated_conv_422"></a>感受野的理解和dilated conv优缺点以及应用场景</h2> 
  <p><a href="https://blog.csdn.net/CV_YOU/article/details/81633645" rel="nofollow" data-token="c4686300f85c63672d6578b5ef1b1738">https://blog.csdn.net/CV_YOU/article/details/81633645</a><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190702112735375.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> k为原来卷积核，rate为扩张率，感受野=(k+1)(rate-1)+k</p> 
  <h2><a id="_426"></a>相似度计算</h2> 
  <p>1.余弦距离<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428222312390." alt="在这里插入图片描述"><br> 2.欧式距离<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190428222211639." alt="在这里插入图片描述"><br> 3.汉明距离<br> 汉明距离/Hamming Distance也能用来计算两个向量的相似度；即通过比较向量每一位是否相同，若不同则汉明距离加1，这样得到汉明距离。向量相似度越高，对应的汉明距离越小。如10001001和10110001有3位不同。<br> 4.马氏距离<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019042822362443.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 如果我们以厘米为单位来测量人的身高，以克（g）为单位测量人的体重。每个人被表示为一个两维向量，如一个人身高173cm，体重50000g，表示为（173,50000），根据身高体重的信息来判断体型的相似程度。<br> 我们已知小明（160,60000）；小王（160,59000）；小李（170，60000）。根据常识可以知道小明和小王体型相似。但是如果根据欧几里得距离来判断，小明和小王的距离要远远大于小明和小李之间的距离，即小明和小李体型相似。这是因为不同特征的度量标准之间存在差异而导致判断出错。</p> 
  <h2><a id="_437"></a>色彩空间</h2> 
  <p><a href="https://blog.csdn.net/ABigDeal/article/details/84836269" rel="nofollow" data-token="be91837adad0929cfd0703eff2cee1f0">https://blog.csdn.net/ABigDeal/article/details/84836269</a></p> 
  <h2><a id="RGBBGR_439"></a>RGB和BGR</h2> 
  <p>RGB：PIL，scipy；<br> BGR：caffe，opencv。</p> 
  <p><strong>opencv通道转换</strong></p> 
  <pre><code class="prism language-py"><span class="token keyword">import</span> cv2

img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'test.jpg'</span><span class="token punctuation">)</span>
B<span class="token punctuation">,</span> G<span class="token punctuation">,</span> R <span class="token operator">=</span> cv2<span class="token punctuation">.</span>split<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
<span class="token comment">#BGR转RGB，方法1</span>
img_rgb1 <span class="token operator">=</span> cv2<span class="token punctuation">.</span>merge<span class="token punctuation">(</span><span class="token punctuation">[</span>R<span class="token punctuation">,</span> G<span class="token punctuation">,</span> B<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">#BGR转RGB，方法2</span>
img_rgb2 <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>

<span class="token comment">#BGR转RGB，方法3</span>
img_rgb3 <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
  <p><strong>PIL转opencv</strong></p> 
  <pre><code class="prism language-py"><span class="token keyword">import</span> cv2
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy

image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"test.jpg"</span><span class="token punctuation">)</span>
image<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>numpy<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">,</span>cv2<span class="token punctuation">.</span>COLOR_RGB2BGR<span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">"OpenCV"</span><span class="token punctuation">,</span>img<span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p><strong>opencv转PIL</strong></p> 
  <pre><code class="prism language-py"><span class="token keyword">import</span> cv2
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy

img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"test.jpg"</span><span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">"OpenCV"</span><span class="token punctuation">,</span>img<span class="token punctuation">)</span>
image <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>img<span class="token punctuation">,</span>cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span><span class="token punctuation">)</span>
image<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <h2><a id="_484"></a>有什么图像的锐化方法</h2> 
  <p>1.滤波<br> 2.边缘检测</p> 
  <h2><a id="_487"></a>全局和局部特征提取算法分别有</h2> 
  <h2><a id="_488"></a>图像的特征提取有哪些算法</h2> 
  <p>①基于颜色特征：如颜色直方图、颜色集、颜色矩、颜色聚合向量等；<br> ②基于纹理特征：如Tamura纹理特征、自回归纹理模型、Gabor变换、小波变换、MPEG7边缘直方图等；<br> ③基于形状特征：如傅立叶形状描述符、不变矩、小波轮廓描述符等</p> 
  <p><strong>1、LBP特征提取算法</strong><br> LBP（Local Binary Patterns，局部二值模式）是提取局部特征作为判别依据的，为一种有效的纹理描述算子，度量和提取图像局部的纹理信息，对光照具有不变性。有多种改进型，LBP结合BP神经网络已经用于人脸识别等领域。LBP的基本思想是定义于像素的8邻域中, 以中心像素的灰度值为阈值, 将周围8 个像素的值与其比较, 如果周围的像素值小于中心像素的灰度值, 该像素位置就被标记为0, 否则标记为1. 每个像素得到一个二进制组合, 就像00010011. 每个像素有8个相邻的像素点,即有2^8种可能性组合。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429100144484." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429100634352.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>2.HOG特征提取算法</strong><br> 方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。<br> 不变性：具有光照不变性，不具有尺寸和旋转不变性。<br> 应用：HoG算法提取的是图像各个像素梯度的统计直方图，一般会将这些梯度直方图转化成一个向量，用于分类器的训练输入。</p> 
  <p><strong>3.Haar特征提取算子</strong><br> 常和AdaBoost结合用于识别人脸。Haar特征很简单，分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429101256872.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>4.LoG特征提取算法</strong><br> LoG（DoG是一阶边缘提取）是二阶拉普拉斯-高斯边缘提取算法，先高斯滤波然后拉普拉斯边缘提取。Laplace算子对通过图像进行操作实现边缘检测的时，对离散点和噪声比较敏感。于是，首先对图像进行高斯卷积滤波进行降噪处理，再采用Laplace算子进行边缘检测，就可以提高算子对噪声抗干扰能力, 这一个过程中高斯-拉普拉斯（Laplacian of Gaussian(LOG)）边缘检测算子就诞生了。<br> <strong>5.Harris角点特征提取算法</strong><br> <a href="http://www.cnblogs.com/zhchoutai/p/7182438.html" rel="nofollow" data-token="12d6c6f218e48686d3e22e7ccb76f420">http://www.cnblogs.com/zhchoutai/p/7182438.html</a><br> <strong>6.SIFT特征提取算子</strong><br> SIFT算子是一种检测局部特征的算法，该算法通过求一幅图中的特征点及其有关尺寸和方向的描述子得到特征并进行图像特征点匹配，获得了良好效果。每个特征点的SIFT特征是128维向量，因此计算量巨大。<br> 不变性：具有尺寸和旋转不变性。<br> 改进型：PCA-SIFT，如名称所说“主成分SIFT特征”，主要提取了128维特征向量中的20个特征，大大减少了计算。<br> <a href="http://www.cnblogs.com/liuchaogege/p/5155739.html" rel="nofollow" data-token="767cc4e04e4ff6133f3b943f5aa5acbf">http://www.cnblogs.com/liuchaogege/p/5155739.html</a><br> <strong>7.SURF特征提取算法</strong><br> SURF是SIFT角点检测算法的改进版，主要体现在速度上，SURF是SIFT速度的3倍。SIFT在尺度和旋转变换的情况下匹配效果比SURF好，而SURF在亮度变化下匹配效果比较好。<br> <a href="http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html" rel="nofollow" data-token="e298ad20573ff9dac555d8d4e3a9d1b4">http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html</a></p> 
  <h2><a id="KmeansEM_517"></a>什么是Kmeans，与EM怎么联系</h2> 
  <h2><a id="yolossdfaster_rcnn_519"></a>yolo、ssd、faster rcnn的区别</h2> 
  <p><strong>yolo v1</strong>：没有使用多层特征，没有使用anchor机制，使用网格预测，每个网格随机预测2个box，直接预测x，y，w，h，损失函数也不一样，使用全连接。<br> <strong>yolo v3</strong>：使用多层特征，使用anchor机制，使用网格预测，anchor使用kmeans算法产生，使用3层特征，每层特征使用3个大小的anchor，没有直接预测x，y，w，h，损失函数也不一样，没有使用全连接。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429111924419.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190709213327544.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190709213404537.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>ssd</strong>：<a href="https://blog.csdn.net/u010712012/article/details/86555814?tdsourcetag=s_pcqq_aiomsg" rel="nofollow" data-token="8b103ba93ccb45c4116c82e29b29197c">https://blog.csdn.net/u010712012/article/details/86555814?tdsourcetag=s_pcqq_aiomsg</a><br> 使用多层特征(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)，使用anchor机制，使用特征图预测，特征图上的每一个特征都预测4个anchor，没有直接预测x，y，w，h，损失函数不一样。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429112049726.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> d是先验框，b是预测框<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429112132253." alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429114113729.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>3.faster rcnn</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429114200698.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 两步走：RPN+ROIP<br> RPN特征图预测anchor，每个特征点预测9个anchor大小，最后得到ROI区域进行池化，最后分类和边框回归。<br> inception_resnet_v2 faster rcnn<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190709213501185.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="RPN_537"></a>RPN实现细节</h2> 
  <h2><a id="ROI_538"></a>ROI层是怎么实现的，怎么做的映射</h2> 
  <p>1.根据输入image，将ROI映射到feature map对应位置；首先计算rois映射到feature map的坐标，即原始坐标*spacial_scale(大小为所有stride的乘积分之一)，然后针对每个输出来进行计算，即每个输出点都代表原先的一块区域，这个区域大小为bin_h= roi_height / pooled_ height, bin_w=roi_width / pooled_width.遍历所有top的点所映射回feature map的区域，并找到最大值，记录最大值所在的位置。<br> 2.将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）；<br> 3.对每个sections进行max pooling操作；</p> 
  <h2><a id="BNmovingmean_543"></a>BN层的moving——mean怎么求得</h2> 
  <p>为什么使用BN层<br> 1.可以选择较大的学习率，使得训练速度增长很快，具有快速收敛性。<br> 2.可以不去理会Dropout，L2正则项参数的选择，如果选择使用BN，甚至可以去掉这两项。<br> 3.去掉局部响应归一化层（LRN）。（AlexNet中使用的方法，BN层出来之后这个就不再用了）<br> 4.可以把训练数据打乱，防止每批训练的时候，某一个样本被经常挑选到。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429154505693.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> batch_norm 在test的时候，，用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。所以需要在训练时把BN层的参数保存下来，然后在预测时加载。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429153933704." alt="在这里插入图片描述"></p> 
  <h2><a id="BN_552"></a>BN的学习参数</h2> 
  <p>假设BN层输入为32×128×200×200(NCHW)的大小Tensor，BN层学习的参数可能有：128的倍数。</p> 
  <h2><a id="pooling_555"></a>pooling层的反向传播</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429160047752.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_557"></a>手动实现卷积</h2> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">conv2d</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> kernel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> in_channels <span class="token operator">=</span> img<span class="token punctuation">.</span>shape
    kernel_height<span class="token punctuation">,</span> kernel_width<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels <span class="token operator">=</span> kernel<span class="token punctuation">.</span>shape
    out_height <span class="token operator">=</span> height <span class="token operator">-</span> kernel_height <span class="token operator">+</span> <span class="token number">1</span>
    out_width <span class="token operator">=</span> width <span class="token operator">-</span> kernel_width <span class="token operator">+</span> <span class="token number">1</span>
    feature_maps <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>out_height<span class="token punctuation">,</span> out_width<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> oc <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token comment"># Iterate out_channels (# of kernels)</span>
        <span class="token keyword">for</span> h <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>out_height<span class="token punctuation">)</span><span class="token punctuation">:</span>             <span class="token comment"># Iterate out_height</span>
            <span class="token keyword">for</span> w <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>out_width<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token comment"># Iterate out_width</span>
                <span class="token keyword">for</span> ic <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment"># Iterate in_channels</span>
                    patch <span class="token operator">=</span> img<span class="token punctuation">[</span>h<span class="token punctuation">:</span> h <span class="token operator">+</span> kernel_height<span class="token punctuation">,</span> w<span class="token punctuation">:</span> w <span class="token operator">+</span> kernel_width<span class="token punctuation">,</span> ic<span class="token punctuation">]</span>
                    feature_maps<span class="token punctuation">[</span>h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> oc<span class="token punctuation">]</span> <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>patch <span class="token operator">*</span> kernel<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> ic<span class="token punctuation">,</span> oc<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> feature_maps
</code></pre> 
  <h2><a id="backward_575"></a>实现卷积层的backward编程</h2> 
  <h2><a id="_577"></a>有哪些轻量化模型？</h2> 
  <p>一、SequeezeNet：<br> 核心思想：<br> 1.使用1x1卷积核代替3x3卷积核，减少参数量；<br> 2.通过squeeze layer限制通道数量，减少参数量；<br> 3.借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding；<br> 4.减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率；<br> 5.使用全局平均池化代替全连接层;<br> 1-3通过fire module实现，如下图所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403145009206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">网络结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403145138346.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 二、Xception<br> 核心思想：<br> 主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释）<br> 首先xception类似于下图，但是区别有两点：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403145507640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 1.Xception中没有relu激活函数；<br> 2.图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。<br> 3.进行残差连接时，不再是concat，而是采用加法操作。<br> 网络结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403145719437.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>三、MobileNet<br> 核心思想：<br> 1.主要采用depthwise separable convolution，就是分离卷积核；<br> 2.设置宽度因子width multipler和分辨率因子resolution multiplier；<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403151307994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 怎么才能使网络进一步压缩呢？可以进一步减少feature map的通道数和size，通过宽度因子减少通道数，分辨率因子减少size。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190719163756449.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> DK为卷积核大小，DF为特征图大小，M为输入特征图通道，N为输出特征图通道<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190719164518615." alt="在这里插入图片描述"><br> 1、宽度因子α<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403151826409.png" alt="在这里插入图片描述"><br> 2、分辨率因子ρ<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403151849221.png" alt="这里写图片描述"><br> 两个参数都属于(0,1]之间，当为1时则是标准mobileNet。<br> 基本模块：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403152129472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 网络结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403152201286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 四、ShuffleNet<br> 核心思想：<br> 1.借鉴resnext分组卷积思想，但不同的是采用1x1卷积核；<br> 2.进行通道清洗，加强通道间的信息流通，提高信息表示能力。<br> 分组卷积和通道清洗：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403152647703.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">Shuffle的方法：<br> 1.卷积后一共得到g×n个输出通道的feature map；<br> 2.将feature map 进行 reshape为(g,n);<br> 3.进行转置为(n,g)；<br> 4.对转置结果flatten，再分回g组作为下一层的输入。<br> 三种Shuffle unit：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403153214265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">网络结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190403153300648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_629"></a>计算一层的参数量、计算量</h2> 
  <p><a href="https://zhuanlan.zhihu.com/p/31575074" rel="nofollow" data-token="d418be4e1d3800a74bcd31032551731a">https://zhuanlan.zhihu.com/p/31575074</a> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019042921580621.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="inception_v1v3_631"></a>inception v1-v3的发展：</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190429220339929.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> Inception V1网络使用1x1，3x3，5x5的卷积核进行卷积运算和池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果可以获得更好的图像表征。Inception V2网络加入批归一化层，使每层输出都规范化到N(0,1)的高斯分布上，此外使用2个3×3的卷积层代替inception模块中5x5的卷积核，既降低了参数数量，又加速了计算。Inception V3网络将部分inception结构进行分解，在输出为17×17×768的层使用1x7,7x1的卷积核，在输出为8×8×1280的层使用1×3，3×1的卷积核，这样既加速了计算，又增加了网络的深度，使网络的非线性增加，得到更丰富的空间特征。</p> 
  <h2><a id="ioukmeansNMS_635"></a>撕代码：iou计算、k-means、NMS非极大值抑制</h2> 
  <p>iou：</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">IOU</span><span class="token punctuation">(</span>rectangle A<span class="token punctuation">,</span> rectangleB<span class="token punctuation">)</span><span class="token punctuation">:</span>
    W <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>x<span class="token punctuation">,</span> B<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">max</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>x<span class="token punctuation">,</span> B<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>x<span class="token punctuation">)</span>
    H <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>y<span class="token punctuation">,</span> B<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>y<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">max</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>y<span class="token punctuation">,</span> B<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
    <span class="token keyword">if</span> W <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token operator">or</span> H <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
    SA <span class="token operator">=</span> <span class="token punctuation">(</span>A<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>x <span class="token operator">-</span> A<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>A<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>y <span class="token operator">-</span> A<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
    SB <span class="token operator">=</span> <span class="token punctuation">(</span>B<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>x <span class="token operator">-</span> B<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>B<span class="token punctuation">.</span>RT<span class="token punctuation">.</span>y <span class="token operator">-</span> B<span class="token punctuation">.</span>LB<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
    cross <span class="token operator">=</span> W <span class="token operator">*</span> H
    <span class="token keyword">return</span> cross<span class="token operator">/</span><span class="token punctuation">(</span>SA <span class="token operator">+</span> SB <span class="token operator">-</span> cross<span class="token punctuation">)</span>
</code></pre> 
  <p>kmeans:</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">kmeans</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> boxes<span class="token punctuation">,</span> k<span class="token punctuation">,</span> dist<span class="token operator">=</span>np<span class="token punctuation">.</span>median<span class="token punctuation">)</span><span class="token punctuation">:</span>
    box_number <span class="token operator">=</span> boxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    distances <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>box_number<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">)</span>
    last_nearest <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>box_number<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token punctuation">)</span>
    clusters <span class="token operator">=</span> boxes<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>
        box_number<span class="token punctuation">,</span> k<span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># init k clusters</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>

        distances <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>iou<span class="token punctuation">(</span>boxes<span class="token punctuation">,</span> clusters<span class="token punctuation">)</span>
        current_nearest <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>last_nearest <span class="token operator">==</span> current_nearest<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>  <span class="token comment"># clusters won't change</span>
        <span class="token keyword">for</span> cluster <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>
            clusters<span class="token punctuation">[</span>cluster<span class="token punctuation">]</span> <span class="token operator">=</span> dist<span class="token punctuation">(</span>  <span class="token comment"># update clusters</span>
                boxes<span class="token punctuation">[</span>current_nearest <span class="token operator">==</span> cluster<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        last_nearest <span class="token operator">=</span> current_nearest

    <span class="token keyword">return</span> clusters
</code></pre> 
  <p>NMS:</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">py_cpu_nms</span><span class="token punctuation">(</span>dets<span class="token punctuation">,</span> thresh<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Pure Python NMS baseline."""</span>
    x1 <span class="token operator">=</span> dets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    y1 <span class="token operator">=</span> dets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    x2 <span class="token operator">=</span> dets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
    y2 <span class="token operator">=</span> dets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
    scores <span class="token operator">=</span> dets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>

    areas <span class="token operator">=</span> <span class="token punctuation">(</span>x2 <span class="token operator">-</span> x1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y2 <span class="token operator">-</span> y1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    order <span class="token operator">=</span> scores<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

    keep <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">while</span> order<span class="token punctuation">.</span>size <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        i <span class="token operator">=</span> order<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        keep<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token comment">#保留该类剩余box中得分最高的一个</span>
        xx1 <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>x1<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> x1<span class="token punctuation">[</span>order<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        yy1 <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>y1<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> y1<span class="token punctuation">[</span>order<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>minimum<span class="token punctuation">(</span>x2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> x2<span class="token punctuation">[</span>order<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        yy2 <span class="token operator">=</span> np<span class="token punctuation">.</span>minimum<span class="token punctuation">(</span>y2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> y2<span class="token punctuation">[</span>order<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        w <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> xx2 <span class="token operator">-</span> xx1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> yy2 <span class="token operator">-</span> yy1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        inter <span class="token operator">=</span> w <span class="token operator">*</span> h
        ovr <span class="token operator">=</span> inter <span class="token operator">/</span> <span class="token punctuation">(</span>areas<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> areas<span class="token punctuation">[</span>order<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">-</span> inter<span class="token punctuation">)</span>

        inds <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ovr <span class="token operator">&lt;=</span> thresh<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        order <span class="token operator">=</span> order<span class="token punctuation">[</span>inds <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>

<span class="token keyword">return</span> keep
</code></pre> 
  <h2><a id="linux_704"></a>linux命令</h2> 
  <p><strong>常用命令在这里：</strong> <a href="https://blog.csdn.net/weixin_43304184/article/details/85102655" rel="nofollow" data-token="802909da1b7bbb4fd3b393c9482b23ec">https://blog.csdn.net/weixin_43304184/article/details/85102655</a><br> <strong>查看文件大小命令</strong><br> df -h<br> du -h --max-depth=1 /home<br> <a href="https://www.cnblogs.com/lixuwu/p/5944062.html" rel="nofollow" data-token="254587debc6e0eb808fc69d2c2261eb7">https://www.cnblogs.com/lixuwu/p/5944062.html</a><br> <strong>查看文件多少行命令</strong><br> wc -l filename 就是查看文件里有多少行<br> wc -w filename 看文件里有多少个word。<br> wc -L filename 文件里最长的那一行是多少个字。</p> 
  <h2><a id="_715"></a>图像哈希算法</h2> 
  <p><strong>1.均值哈希算法：</strong><br> 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。<br> 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。<br> 第三步，计算平均值。计算所有64个像素的灰度平均值。<br> 第四步，比较像素的灰度。将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。<br> 第五步，计算哈希值。将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。<br> 如果图片放大或缩小，或改变纵横比，结果值也不会改变。增加或减少亮度或对比度，或改变颜色，对hash值都不会太大的影响。最大的优点：计算速度快！</p> 
  <p>如果想比较两张图片，为每张图片构造hash值并且计算不同位的个数。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。</p> 
  <p><strong>2.感知哈希算法：</strong><br> 第一步，缩小尺寸。最快速的去除高频和细节，将图片缩小到8x8的尺寸，总共64个像素。摒弃不同尺寸、比例带来的图片差异。<br> 第二步，简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。<br> 第三步，计算DCT（离散余弦变换）。DCT是把图片分解频率聚集和梯状形，虽然JPEG使用8 * 8的DCT变换，在这里使用32 * 32的DCT变换。<br> 第四步，缩小DCT。虽然DCT的结果是32 * 32大小的矩阵，但我们只要保留左上角的8*8的矩阵，这部分呈现了图片中的最低频率。<br> 第五步，计算平均值。计算所有64个值的平均值。<br> 第六步，进一步减小DCT。这是最主要的一步，根据8 * 8的DCT矩阵，设置0或1的64位的hash值，大于等于DCT均值的设为”1”，小于DCT均值的设为“0”。结果并不能告诉我们真实性的低频率，只能粗略地告诉我们相对于平均值频率的相对比例。只要图片的整体结构保持不变，hash结果值就不变。能够避免伽马校正或颜色直方图被调整带来的影响。<br> 第七步，计算哈希值。将64bit设置成64位的长整型，组合的次序并不重要，只要保证所有图片都采用同样次序就行了。将32 * 32的DCT转换成32 * 32的图像。<br> 将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了（例如，自左到右、自顶向下、big-endian）。</p> 
  <p>得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算汉明距离。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。</p> 
  <p><strong>3.差异哈希算法</strong><br> 第一步，缩小尺寸，缩放到9 * 8尺寸。<br> 第二步，转换灰度值，转换到0-255之间。<br> 第三步，差异值计算，差异值是通过计算每行相邻像素的强度对比得出的。我们的图片为9 * 8的分辨率，那么就有8行，每行9个像素。差异值是每行分别计算的，也就是第二行的第一个像素不会与第一行的任何像素比较。每一行有9个像素，那么就会产生8个差异值，这也是为何我们选择9作为宽度，因为8bit刚好可以组成一个byte，方便转换为16进制值。<br> 如果前一个像素的颜色强度大于第二个像素，那么差异值就设置为True（也就是1），如果不大于第二个像素，就设置为False（也就是0）。<br> 第四步，转化为hash值，将差异值数组中每一个值看做一个bit，每8个bit组成为一个16进制值，将16进制值连接起来转换为字符串，就得出了最后的dHash值。<br> 第五步，计算汉明距离，如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。</p> 
  <h2><a id="boostAdaboost_745"></a>boost、Adaboost</h2> 
  <h2><a id="_747"></a>线性回归和逻辑回归的区别</h2> 
  <p>逻辑回归多了一个Sigmoid函数，使样本能映射到[0,1]之间的数值，用来做分类问题。<br> 1.线性回归用来预测，逻辑回归用来分类。<br> 2.线性回归是拟合函数，逻辑回归是预测函数<br> 3.线性回归的参数计算方法是最小二乘法，逻辑回归的参数计算方法是梯度下降</p> 
  <h2><a id="_753"></a>什么是全卷积网络，如何实现</h2> 
  <p><a href="https://blog.csdn.net/kekong0713/article/details/52585074" rel="nofollow" data-token="daafd40345bcca4c13a42bd657c74692">https://blog.csdn.net/kekong0713/article/details/52585074</a><br> FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,1,1）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190707110929534.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190707110606443.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 可以发现，经过多次卷积（还有pooling）以后，得到的图像越来越小,分辨率越来越低（粗略的图像），那么FCN是如何得到图像中每一个像素的类别的呢？为了从这个分辨率低的粗略图像恢复到原图的分辨率，FCN使用了上采样。例如经过5次卷积(和pooling)以后，图像的分辨率依次缩小了2，4，8，16，32倍。对于最后一层的输出图像，需要进行32倍的上采样，以得到原图一样的大小。</p> 
  <p>这个上采样是通过反卷积（deconvolution）实现的。对第5层的输出（32倍放大）反卷积到原图大小，得到的结果还是不够精确，一些细节无法恢复。于是Jonathan将第4层的输出和第3层的输出也依次反卷积，分别需要16倍和8倍上采样，结果就精细一些了。下图是这个卷积和反卷积上采样的过程：</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190707111544850.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 与传统的基于CNN 的图像分割方法相比，FCN有两个明显优势：<br> 1.可以接受任意大小的输入；<br> 2.避免了重复存储和计算，更加高效。</p> 
  <h2><a id="LSTM_765"></a>如何理解LSTM</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050418260696.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <a href="https://blog.csdn.net/menc15/article/details/71271566" rel="nofollow" data-token="d152738aab7ff823652840ceb8787e63">https://blog.csdn.net/menc15/article/details/71271566</a></p> 
  <h2><a id="RNN_768"></a>如何解决RNN的梯度爆炸和消失</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504195752641.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_770"></a>多标签问题</h2> 
  <p><strong>1.问题转换：</strong><br> ①重新组合<br> ②二元关联<br> ③分类器链<br> <strong>2.改编算法</strong><br> 修改全连接<br> <strong>3.集成方法</strong></p> 
  <h2><a id="_778"></a>精确率高、召回率低是为什么</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504202435586.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_780"></a>一个人有很多框，什么原因造成的</h2> 
  <p>两种情况：<br> 1.框不是重叠的，模型没有训练好。<br> 2.框有重叠，非极大值抑制没有做好，模型没有训练好。</p> 
  <h2><a id="httpsimgblogcsdnimgcn20190504204748767xossprocessimagewatermarktype_ZmFuZ3poZW5naGVpdGkshadow_10text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQzsize_16color_FFFFFFt_70_784"></a>图像旋转、旋转矩阵、像素点怎么填充<img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204748767.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></h2> 
  <h2><a id="openpose_785"></a>openpose</h2> 
  <p>openpose的核心是提出一种利用Part Affinity Fields（PAFs）的自下而上的人体姿态估计算法。研究自下而上算法（得到关键点位置再获得骨架）而不是自上而下算法（先检测人，再回归关键点），是因为后者运算时间会随着图像中人的个数而显著增加，而自下而上所需计算时间基本不变。</p> 
  <h2><a id="_788"></a>光流怎么计算</h2> 
  <p><a href="https://blog.csdn.net/u011076940/article/details/60766423" rel="nofollow" data-token="d8184b0e97908d551d0e5b33931aeac7">https://blog.csdn.net/u011076940/article/details/60766423</a></p> 
  <h2><a id="_791"></a>优化器有哪些，怎么演进的，平时怎么用，如何调参数</h2> 
  <p><strong>1.梯度下降BGD：</strong><br> 采用整个训练集的数据来计算 cost function 对参数的梯度，由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。参数：学习率。<br> <strong>2.随机梯度下降SGD</strong><br> SGD 每次更新时对每个样本进行梯度更新， 对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡，此外SGD对噪声比较敏感。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处，因为鞍点周围的error 是一样的，所有维度的梯度都接近于0，SGD 很容易被困在这里。参数：学习率。<br> <strong>3.批随机梯度下降MSGD</strong><br> n 个样本进行计算， 这样它可以降低参数更新时的方差，收敛更稳定， 另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。参数：学习率。<br> <strong>4.动量梯度下降法Momentum</strong><br> 动量梯度下降法则对各个mini-batch求得的梯度使用指数加权平均，并使用新的参数更新之前的参数。并设有衰减率，使得前面的影响越来越小。参数：学习率、动量系数0.9。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190508112939890.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>5.NAG</strong><br> 先以原方向梯度进行超前计算在和下一点的梯度方向进行融合。参数：学习率、动量系数0.9。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190508112921477.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>6.Adagrad</strong><br> 将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。随着算法不断迭代，整体的学习率会越来越小，学习率也随之变慢。所以，一般来说AdaGrad算法一开始是激励收敛，到了后面就慢慢变成惩罚收敛，速度越来越慢。参数：学习率，小常数。<br> Adagrad缺点：需要自己手动指定初始学习率，而且由于分母中对历史梯度一直累加，学习率将逐渐下降至0，并且如果初始梯度很大的话，会导致整个训练过程的学习率一直很小，从而导致学习时间变长。<br> <strong>7.Adadelta</strong><br> Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。<br> <strong>8.RMSprop</strong><br> 对Adagrad优化，引入动量，调整梯度。参数：学习率、动量系数0.9、衰减系数0.001、小常数。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190508114130864.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <a href="https://blog.csdn.net/bvl10101111/article/details/72616378" rel="nofollow" data-token="6596b44afebe86a4d66115afe3cd9a9b">https://blog.csdn.net/bvl10101111/article/details/72616378</a><br> <strong>9.Adam</strong><br> Adam算法是将Momentum算法和RMSProp算法结合起来使用的一种算法。参数：学习率、、两个指数衰减系数0.999,0.9，小常数。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190508115823367.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_816"></a>归一化层</h2> 
  <p>1.(0,1)标准化：</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">MaxMinNormalization</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>Max<span class="token punctuation">,</span>Min<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> Min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>Max <span class="token operator">-</span> Min<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> x
</code></pre> 
  <p>2.Z-scores<br> 这里一样，mu（即均值）用np.average()，sigma（即标准差）用np.std()即可</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">Z_ScoreNormalization</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>mu<span class="token punctuation">,</span>sigma<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mu<span class="token punctuation">)</span> <span class="token operator">/</span> sigma<span class="token punctuation">;</span>
    <span class="token keyword">return</span> x
</code></pre> 
  <p>3.sigmoid函数</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>useStatus<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> useStatus<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token builtin">float</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</code></pre> 
  <h2><a id="X1X2Xn0UmaxX1X2Xn_838"></a>设随机变量X1,X2,…Xn相互独立，且都服从（0,θ）上的均匀分布。求U=max{X1,X2,…Xn}数学期望</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190508141442645.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_840"></a>声音特征是怎么提取的</h2> 
  <p><a href="https://www.cnblogs.com/BaroC/p/4283380.html" rel="nofollow" data-token="f851a3b5b0333f3fa12c42c18e8d824f">https://www.cnblogs.com/BaroC/p/4283380.html</a><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509163526536.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509164739872.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509165358705.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509165436162.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="BNBN_846"></a>BN层，先加BN还是激活，有什么区别</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509154012951.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190509154229369.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="tensorflow_pb_849"></a>tensorflow pb模型量化</h2> 
  <p>量化(quantitative)是用比 32 位浮点数更少的空间来存储和运行模型，并且 TensorFlow 量化的实现屏蔽了存储和运行细节。神经网络训练时要求速度和准确率，训练通常在 GPU 上进行，所以使用浮点数影响不大。但是在预测阶段，使用浮点数会影响速度。量化可以在加快速度的同时，保持较高的精度。</p> 
  <p>量化网络的动机主要有两个。最初的动机是减小模型文件的大小。模型文件往往占据很大的磁盘空间，有时，每个模型都接近 200 MB，模型中存储的是分布在大量层中的权值。在存储模型的时候用 8 位整数，模型大小可以缩小为原来 32 位的 25%左右。在加载模型后运算时转换回 32 位浮点数，这样已有的浮点计算代码无需改动即可正常运行。</p> 
  <p>量化的另一个动机是降低预测过程需要的计算资源。这在嵌入式和移动端非常有意义，能够更快地运行模型，功耗更低。从体系架构的角度来说，8 位的访问次数要比 32 位多，在读取 8 位整数时只需要 32 位浮点数的 1/4 的内存带宽，例如，在 32 位内存带宽的情况下，8 位整数可以一次访问 4 个，32 位浮点数只能 1 次访问 1 个。而且使用 SIMD 指令(19.2节会加速介绍该指令集)，可以在一个时钟周期里实现更多的计算。另一方面，8 位对嵌入式设备的利用更充分，因为很多嵌入式芯片都是 8 位、16 位的，如单片机、数字信号处理器(DSP 芯片)，8 位可以充分利用这些。</p> 
  <p>此外，神经网络对于噪声的健壮性很强，因为量化会带来精度损失(这种损失可以认为是一种噪声)，并不会危害到整体结果的准确度。</p> 
  <p>那能否用低精度格式来直接训练呢?答案是，大多数情况下是不能的。因为在训练时，尽管前向传播能够顺利进行，但往往反向传播中需要计算梯度。例如，梯度是 0.2，使用浮点数可以很好地表示，而整数就不能很好地表示，这会导致梯度消失。因此需要使用高于 8 位的值来计算梯度。因此，正如在本节一开始介绍的那样，在移动端训练模型的思路往往是，在 PC 上正常训练好浮点数模型，然后直接将模型转换成 8 位，移动端是使用 8 位的模型来执行预测的过程。</p> 
  <h2><a id="_859"></a>图的遍历</h2> 
  <p>深度优先和广度优先</p> 
  <h2><a id="bagging_862"></a>bagging</h2> 
  <p>1.给定一个弱学习算法,和一个训练集;<br> 2.单个弱学习算法准确率不高;<br> 3.将该学习算法使用多次,得出预测函数序列,进行投票;<br> 4.最后结果准确率将得到提高.<br> 算法：<br> 1.For t = 1, 2, …, T Do<br> 从数据集S中取样（放回选样）<br> 训练得到模型Ht<br> 对未知样本X分类时,每个模型Ht都得出一个分类，得票最高的即为未知样本X的分类<br> 2.也可通过得票的平均值用于连续值的预测</p> 
  <h2><a id="_874"></a>全局对比度增强</h2> 
  <p>1.直方图均衡化 Histogram Equalization<br> 算法：<br> 1）根据图像灰度计算灰度概率密度函数PDF<br> 2）计算累积概率分布函数CDF<br> 3）将CDF归一化到原图灰度取值范围，如[0,255]。<br> 4）之后CDF四舍五入取整，得到灰度转换函数sk=T(rk)<br> 5）将CDF作为转换函数，将灰度为rk的点转换为sk灰度<br> 2. 直方图匹配 Histogram Matching<br> 算法：<br> 1）根据图像计算概率密度分布pr®；<br> 2）根据pr®计算累计分布函数sk=T(rk)；<br> 3）根据给定的目标分布pz(z)计算累计分布函数G(zq)；<br> 4）对于每一个k，找到一个q，使得G(zq)约等于sk；<br> 5）将原图中灰度为k的点变为灰度q；</p> 
  <h2><a id="_889"></a>局部对比度增强</h2> 
  <p>1.邻域直方图均衡：将全局直方图均衡的思想应用于邻域直方图处理中。<br> 2.邻域直方图匹配：将全局直方图匹配的思想应用于邻域直方图处理中。<br> 3.邻域统计方法<br> 算法<br> 1）初始化：增强常数E，灰度下阈值k0，标准差下阈值k1，标准差上阈值k2，窗口半宽s；<br> 2）计算图像灰度均值MG和灰度标准差σG；<br> 3）对于每一个像素，计算邻域（大小为2∗step+1的方块）内灰度均值ML和标准差σL；<br> 4）如果ML&lt;=k0∗MGML&lt;=k0∗MG并且k1∗σG&lt;=σL&lt;=k2∗σG，将像素灰度乘以E。</p> 
  <h2><a id="_899"></a>目标跟踪算法</h2> 
  <p><a href="https://blog.csdn.net/ms961516792/article/details/82682451" rel="nofollow" data-token="b366ef64a03c90fd88286a39240e1982">https://blog.csdn.net/ms961516792/article/details/82682451</a> 这篇文章比较详细。</p> 
  <h2><a id="_902"></a>相机的参数主要包括哪些，标定的步骤及原理，评价标准</h2> 
  <p><strong>相机参数：</strong><br> 相机的内参数是6个分别为：1/dx、1/dy、r、u0、v0、f。opencv1里的说内参数是4个其为fx、fy、u0、v0。实际其fx=F*Sx，其中的F就是焦距上面的f,Sx是像素/没毫米即上面的dx，其是最后面图里的后两个矩阵进行先相乘，得出的，则把它看成整体，就相当于4个内参。其是把r等于零，实际上也是六个。</p> 
  <p>相机的外参数是6个：三个轴的旋转参数分别为（ω、δ、 θ）,然后把每个轴的3<em>3旋转矩阵进行组合（即先矩阵之间相乘），得到集合三个轴旋转信息的R，其大小还是3</em>3；T的三个轴的平移参数（Tx、Ty、Tz）。R、T组合成成的3*4的矩阵，其是转换到标定纸坐标的关键。其中绕X轴旋转θ，则其如图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190629205719996.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190629205906513.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190629205626188.?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTA5ODQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 现以NiKon D700相机为例进行求解其内参数矩阵：<br> 就算大家身边没有这款相机也无所谓，可以在网上百度一下，很方便的就知道其一些参数——<br> 焦距 f = 35mm 最高分辨率：4256×2832 传感器尺寸：36.0×23.9 mm<br> 根据以上定义可以有：<br> u0= 4256/2 = 2128 v0= 2832/2 = 1416 dx = 36.0/4256 dy = 23.9/2832<br> fx = f/dx = 4137.8 fy = f/dy = 4147.3</p> 
  <p>标定方法：相机标定方法有：传统相机标定法、主动视觉相机标定方法、相机自标定法。<br> 标定步骤：<a href="https://blog.csdn.net/dcrmg/article/details/52939318" rel="nofollow" data-token="ae9c9a58782e4ba2cfb01b379f4c3951">https://blog.csdn.net/dcrmg/article/details/52939318</a></p> 
  <ol> 
   <li>准备标定图片</li> 
   <li>对每一张标定图片，提取角点信息</li> 
   <li>对每一张标定图片，进一步提取亚像素角点信息</li> 
   <li>在棋盘标定图上绘制找到的内角点（非必须，仅为了显示）</li> 
   <li>相机标定</li> 
   <li>对标定结果进行评价</li> 
   <li>查看标定效果——利用标定结果对棋盘图进行矫正</li> 
  </ol> 
  <h2><a id="_927"></a>时域滤波和频域滤波</h2> 
  <p>频域的处理有时域不能比拟的优势，就是对于不规则的噪声值，通过傅里叶变换可以得到很好的平滑效果；但相应的，时域在边缘提取上，要比频域的处理更优秀。</p> 
  <h2><a id="_929"></a>常见滤波算法以及特点</h2> 
  <p><strong>高斯滤波</strong><br> 由于高斯函数的傅立叶变换仍是高斯函数, 因此高斯函数能构成一个在频域具有平滑性能的低通滤波器。可以通过在频域做乘积来实现高斯滤波。均值滤波是对是对信号进行局部平均, 以平均值来代表该像素点的灰度值。矩形滤波器(Averaging Box Filter)对这个二维矢量的每一个分量进行独立的平滑处理。通过计算和转化 ,得到一幅单位矢量图。这个<br> 512×512的矢量图被划分成一个 8×8的小区域 ,再在每一个小区域中 ,统计这个区域内的主要方向 ,亦即将对该区域内点方向数进行统计,最多的方向作为区域的主方向。于是就得到了一个新的64×64的矢量图。这个新的矢量图还可以采用一个 3×3模板进行进一步的平滑。</p> 
  <p><strong>均值滤波</strong><br> 把每个像素都用周围的8个像素来做均值操作。可以平滑图像，速度快，算法简单。但是无法去掉噪声，这能微弱的减弱它。</p> 
  <p><strong>中值滤波</strong><br> 常用的非线性滤波方法 ,也是图像处理技术中最常用的预处理技术。它在平滑脉冲噪声方面非常有效,同时它可以保护图像尖锐的边缘。加权中值滤波能够改进中值滤波的边缘信号保持效果。但对方向性很强的指纹图像进行滤波处理时 ,有必要引入方向信息,即利用指纹方向图来指导中值滤波的进行。</p> 
  <p><strong>最小均方差滤波器</strong><br> 亦称维纳滤波器,其设计思想是使输入信号乘响应后的输出,与期望输出的均方误差为最小。</p> 
  <p><strong>Gabor滤波</strong><br> Gabor变换是英国物理学家 Gabor提出来的,由“测不准原理”可知,它具有最小的时频窗,即Gabor函数能做到具有最精确的时间-频率的局部化；另外, Gabor函数与哺乳动物的视觉感受野相当吻合,这一点对研究图像特征检测或空间频率滤波非常有用。恰当的选择其参数, Gabor变换可以出色地进行图像分割、识别与理解。如文献提出的基于Gabor滤波器的增强算法。</p> 
  <h2><a id="_948"></a>面试问题</h2> 
  <p><strong>1.格灵深瞳</strong></p> 
  <ol> 
   <li>batchnormal的作用，你怎么看待它。batchnormal的几个参数，参数计算，能不能整合到前面的conv里，训练时和测试时的区别。</li> 
   <li>说一下感受野计算。</li> 
   <li>说一下3×3，s=1与5×5，s=2卷积核计算量。</li> 
   <li>尽可能多的说出1×1卷积的作用</li> 
   <li>轻量级网络有哪些？具体说说：squeezenet、mobilenet、shuttlenet细节</li> 
   <li>resnet两个版本的区别，说出每个block的结构。resnet为什么好训练。</li> 
   <li>介绍一个项目</li> 
   <li>介绍一个你熟悉的算法</li> 
   <li>bottlenect</li> 
   <li>深度优先和广度优先，主要用什么数据结构。</li> 
  </ol> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
