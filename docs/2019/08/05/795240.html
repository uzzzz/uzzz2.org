<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>【大数据】Spark面试100问 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="【大数据】Spark面试100问" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Spark问题精华 Q：什么是Spark？ A：简单理解，Spark是在Hadoop基础上的改进，是UC&nbsp;Berkeley&nbsp;AMP&nbsp;lab所开源的类Hadoop&nbsp;MapReduce的通用的并行计算框架，Spark基于map&nbsp;reduce算法实现的分布式计算，拥有Hadoop&nbsp;MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map&nbsp;reduce的算法。 Q：为什么要学Spark? A：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。出于任务管道承接的考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果。 Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。 Q：Spark有什么特性？ A：1、高效性 运行速度提高100倍。Apache&nbsp;Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。 2、易用性 Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。 3、通用性 Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark&nbsp;SQL）、实时流处理（Spark&nbsp;Streaming）、机器学习（Spark&nbsp;MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。 4、兼容性 Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache&nbsp;Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。 Q：Spark生态圈介绍 A：Spark力图整合机器学习（MLib）、图算法（GraphX）、流式计算（Spark&nbsp;Streaming）和数据仓库（Spark&nbsp;SQL）等领域，通过计算引擎Spark，弹性分布式数据集（RDD），架构出一个新的大数据应用平台。 &nbsp;&nbsp;&nbsp;&nbsp;Spark生态圈以HDFS、S3、Techyon为底层存储引擎，以Yarn、Mesos和Standlone作为资源调度引擎；使用Spark，可以实现MapReduce应用；基于Spark，Spark&nbsp;SQL可以实现即席查询，Spark&nbsp;Streaming可以处理实时应用，MLib可以实现机器学习算法，GraphX可以实现图计算，SparkR可以实现复杂数学计算。 Q：Spark与Hadoop的对比 A：Spark的中间数据放到内存中，对于迭代运算效率更高。Spark更适合于迭代运算比较多的ML和DM运算。因为在Spark里面，有RDD的抽象概念。所以，Spark比Hadoop更通用。 Q：spark的组成有哪些？ A：Spark组成(BDAS)：全称伯克利数据分析栈，通过大规模集成算法、机器、人之间展现大数据应用的一个平台。也是处理大数据、云计算、通信的技术解决方案。 它的主要组件有： SparkCore：将分布式数据抽象为弹性分布式数据集（RDD），实现了应用任务调度、RPC、序列化和压缩，并为运行在其上的上层组件提供API。 SparkSQL：Spark Sql 是Spark来操作结构化数据的程序包，可以让我使用SQL语句的方式来查询数据，Spark支持 多种数据源，包含Hive表，parquest以及JSON等内容。 SparkStreaming：&nbsp;是Spark提供的实时数据进行流式计算的组件。 MLlib：提供常用机器学习算法的实现库。 GraphX：提供一个分布式图计算框架，能高效进行图计算。 BlinkDB：用于在海量数据上进行交互式SQL的近似查询引擎。 Tachyon：以内存为中心高容错的的分布式文件系统。 Q：Spark的工作流程是什么样的呢？ A：通俗的解释就是：Spark是为了处理数据而生的平台，用一个比喻来形容它是餐馆。餐馆搭建好了后，就会有顾客，顾客的各种需求都得有人去处理，那么这时的Master就像是服务员，负责了解顾客的要求并把需求按照一定规律分配给厨师（Worker），这个顾客的需求就是一个APP，但这个APP不止包括了一个菜（job），整个订单里有很多个job，每个job都得由这些厨师处理，厨师的手就像是具体处理的Executor，负责所有的包括shuffle啊，filter啊，map啊，reduce等等具体的对原材料（RDD）的处理。driver就像是懒惰的厨师长，worker向它申请资源，同时它负责接收下面的人处理好的半成品材料或者完成品的菜品，但它自己并不干具体的活，如果是别人处理好的半成品，driver就将它分配给它认为有空的人接着处理（可能是map后要reduce的东西），直到目前的stage结束得到具体想要的结果，如果是直接就是想要的数据形式（一个job的完成），那么driver就通知master收货并反馈给顾客（可能是python程序，scala程序等等）。 Q：Apache&nbsp;Spark和Apache&nbsp;Storm之间有什么差异，用户应该根据什么来加以选择？ A：Apache&nbsp;Spark是一个内存中的分布式数据分析平台-&nbsp;主要针对加快批量分析工作,反复机器学习的工作，交互式查询和图形处理。一个最主要区别是Spark使用弹性分布式数据集（RDD）。RDD是通过并行运算符来进行计算，并根据定义它是一成不变的。RDD允许Spark基于谱系信息容错的独特的形式。如果你对执行Hadoop&nbsp;MapReduce作业更快，那么Spark是一个很好的选择（即使在这里需要考虑内存的因素）。 Apache&nbsp;Storm是专注于流处理或者一些所谓复杂事件的处理。Storm实现容错的方法进行计算或者以流水线的方式多次计算一个事件，由于Storm进入一个需要特定格式的系统，那么可能导致它转换为一个非结构化的数据。 Storm和Spark存在相当不同的使用情况。Storm和Spark流更多是类似“苹果和苹果”比较。由于Spark的SSD本身是不可变的，Spark流实现在用户定义的时间间隔“定量”来实现更新，得到改造成自己的RDD的方法，从而Spark的并行操作人员可以对这些RDD进行计算。这是与Storm处理每个事的不同之处。 这两种技术之间的一个主要区别是，Spark进行数据的并行计算，而Storm则是任务的并行计算。无论是那种方法，都有它表现价值的一方面。 Q：RDD的核心概念是什么？ A：Client：客户端进程，负责提交作业到Master。 Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。 Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。 Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。 Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。 Q：RDD有哪些常见术语? A：DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。 TaskScheduler：实现Task分配到Executor上执行。 Task：运行在Executor上的工作单元 Job：SparkContext提交的具体Action操作，常和Action对应 Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类 Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。 Q：RDD提供了哪些操作？ A：RDD提供了两种类型的操作： transformation和action 1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD 2，action是得到一个值，或者一个结果(直接将RDD cache到内存中) 3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。 DataFrame：带有Schema信息的RDD，主要是对结构化数据的高度抽象。 DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。 Q：RDD中关于转换(transformation)与动作(action)有什么区别？ A：transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。 Q：RDD 与 DSM的最大不同是什么？ A：RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。" />
<meta property="og:description" content="Spark问题精华 Q：什么是Spark？ A：简单理解，Spark是在Hadoop基础上的改进，是UC&nbsp;Berkeley&nbsp;AMP&nbsp;lab所开源的类Hadoop&nbsp;MapReduce的通用的并行计算框架，Spark基于map&nbsp;reduce算法实现的分布式计算，拥有Hadoop&nbsp;MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map&nbsp;reduce的算法。 Q：为什么要学Spark? A：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。出于任务管道承接的考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果。 Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。 Q：Spark有什么特性？ A：1、高效性 运行速度提高100倍。Apache&nbsp;Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。 2、易用性 Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。 3、通用性 Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark&nbsp;SQL）、实时流处理（Spark&nbsp;Streaming）、机器学习（Spark&nbsp;MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。 4、兼容性 Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache&nbsp;Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。 Q：Spark生态圈介绍 A：Spark力图整合机器学习（MLib）、图算法（GraphX）、流式计算（Spark&nbsp;Streaming）和数据仓库（Spark&nbsp;SQL）等领域，通过计算引擎Spark，弹性分布式数据集（RDD），架构出一个新的大数据应用平台。 &nbsp;&nbsp;&nbsp;&nbsp;Spark生态圈以HDFS、S3、Techyon为底层存储引擎，以Yarn、Mesos和Standlone作为资源调度引擎；使用Spark，可以实现MapReduce应用；基于Spark，Spark&nbsp;SQL可以实现即席查询，Spark&nbsp;Streaming可以处理实时应用，MLib可以实现机器学习算法，GraphX可以实现图计算，SparkR可以实现复杂数学计算。 Q：Spark与Hadoop的对比 A：Spark的中间数据放到内存中，对于迭代运算效率更高。Spark更适合于迭代运算比较多的ML和DM运算。因为在Spark里面，有RDD的抽象概念。所以，Spark比Hadoop更通用。 Q：spark的组成有哪些？ A：Spark组成(BDAS)：全称伯克利数据分析栈，通过大规模集成算法、机器、人之间展现大数据应用的一个平台。也是处理大数据、云计算、通信的技术解决方案。 它的主要组件有： SparkCore：将分布式数据抽象为弹性分布式数据集（RDD），实现了应用任务调度、RPC、序列化和压缩，并为运行在其上的上层组件提供API。 SparkSQL：Spark Sql 是Spark来操作结构化数据的程序包，可以让我使用SQL语句的方式来查询数据，Spark支持 多种数据源，包含Hive表，parquest以及JSON等内容。 SparkStreaming：&nbsp;是Spark提供的实时数据进行流式计算的组件。 MLlib：提供常用机器学习算法的实现库。 GraphX：提供一个分布式图计算框架，能高效进行图计算。 BlinkDB：用于在海量数据上进行交互式SQL的近似查询引擎。 Tachyon：以内存为中心高容错的的分布式文件系统。 Q：Spark的工作流程是什么样的呢？ A：通俗的解释就是：Spark是为了处理数据而生的平台，用一个比喻来形容它是餐馆。餐馆搭建好了后，就会有顾客，顾客的各种需求都得有人去处理，那么这时的Master就像是服务员，负责了解顾客的要求并把需求按照一定规律分配给厨师（Worker），这个顾客的需求就是一个APP，但这个APP不止包括了一个菜（job），整个订单里有很多个job，每个job都得由这些厨师处理，厨师的手就像是具体处理的Executor，负责所有的包括shuffle啊，filter啊，map啊，reduce等等具体的对原材料（RDD）的处理。driver就像是懒惰的厨师长，worker向它申请资源，同时它负责接收下面的人处理好的半成品材料或者完成品的菜品，但它自己并不干具体的活，如果是别人处理好的半成品，driver就将它分配给它认为有空的人接着处理（可能是map后要reduce的东西），直到目前的stage结束得到具体想要的结果，如果是直接就是想要的数据形式（一个job的完成），那么driver就通知master收货并反馈给顾客（可能是python程序，scala程序等等）。 Q：Apache&nbsp;Spark和Apache&nbsp;Storm之间有什么差异，用户应该根据什么来加以选择？ A：Apache&nbsp;Spark是一个内存中的分布式数据分析平台-&nbsp;主要针对加快批量分析工作,反复机器学习的工作，交互式查询和图形处理。一个最主要区别是Spark使用弹性分布式数据集（RDD）。RDD是通过并行运算符来进行计算，并根据定义它是一成不变的。RDD允许Spark基于谱系信息容错的独特的形式。如果你对执行Hadoop&nbsp;MapReduce作业更快，那么Spark是一个很好的选择（即使在这里需要考虑内存的因素）。 Apache&nbsp;Storm是专注于流处理或者一些所谓复杂事件的处理。Storm实现容错的方法进行计算或者以流水线的方式多次计算一个事件，由于Storm进入一个需要特定格式的系统，那么可能导致它转换为一个非结构化的数据。 Storm和Spark存在相当不同的使用情况。Storm和Spark流更多是类似“苹果和苹果”比较。由于Spark的SSD本身是不可变的，Spark流实现在用户定义的时间间隔“定量”来实现更新，得到改造成自己的RDD的方法，从而Spark的并行操作人员可以对这些RDD进行计算。这是与Storm处理每个事的不同之处。 这两种技术之间的一个主要区别是，Spark进行数据的并行计算，而Storm则是任务的并行计算。无论是那种方法，都有它表现价值的一方面。 Q：RDD的核心概念是什么？ A：Client：客户端进程，负责提交作业到Master。 Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。 Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。 Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。 Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。 Q：RDD有哪些常见术语? A：DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。 TaskScheduler：实现Task分配到Executor上执行。 Task：运行在Executor上的工作单元 Job：SparkContext提交的具体Action操作，常和Action对应 Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类 Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。 Q：RDD提供了哪些操作？ A：RDD提供了两种类型的操作： transformation和action 1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD 2，action是得到一个值，或者一个结果(直接将RDD cache到内存中) 3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。 DataFrame：带有Schema信息的RDD，主要是对结构化数据的高度抽象。 DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。 Q：RDD中关于转换(transformation)与动作(action)有什么区别？ A：transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。 Q：RDD 与 DSM的最大不同是什么？ A：RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。" />
<link rel="canonical" href="https://uzzz.org/2019/08/05/795240.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/05/795240.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Spark问题精华 Q：什么是Spark？ A：简单理解，Spark是在Hadoop基础上的改进，是UC&nbsp;Berkeley&nbsp;AMP&nbsp;lab所开源的类Hadoop&nbsp;MapReduce的通用的并行计算框架，Spark基于map&nbsp;reduce算法实现的分布式计算，拥有Hadoop&nbsp;MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map&nbsp;reduce的算法。 Q：为什么要学Spark? A：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。出于任务管道承接的考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果。 Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。 Q：Spark有什么特性？ A：1、高效性 运行速度提高100倍。Apache&nbsp;Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。 2、易用性 Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。 3、通用性 Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark&nbsp;SQL）、实时流处理（Spark&nbsp;Streaming）、机器学习（Spark&nbsp;MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。 4、兼容性 Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache&nbsp;Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。 Q：Spark生态圈介绍 A：Spark力图整合机器学习（MLib）、图算法（GraphX）、流式计算（Spark&nbsp;Streaming）和数据仓库（Spark&nbsp;SQL）等领域，通过计算引擎Spark，弹性分布式数据集（RDD），架构出一个新的大数据应用平台。 &nbsp;&nbsp;&nbsp;&nbsp;Spark生态圈以HDFS、S3、Techyon为底层存储引擎，以Yarn、Mesos和Standlone作为资源调度引擎；使用Spark，可以实现MapReduce应用；基于Spark，Spark&nbsp;SQL可以实现即席查询，Spark&nbsp;Streaming可以处理实时应用，MLib可以实现机器学习算法，GraphX可以实现图计算，SparkR可以实现复杂数学计算。 Q：Spark与Hadoop的对比 A：Spark的中间数据放到内存中，对于迭代运算效率更高。Spark更适合于迭代运算比较多的ML和DM运算。因为在Spark里面，有RDD的抽象概念。所以，Spark比Hadoop更通用。 Q：spark的组成有哪些？ A：Spark组成(BDAS)：全称伯克利数据分析栈，通过大规模集成算法、机器、人之间展现大数据应用的一个平台。也是处理大数据、云计算、通信的技术解决方案。 它的主要组件有： SparkCore：将分布式数据抽象为弹性分布式数据集（RDD），实现了应用任务调度、RPC、序列化和压缩，并为运行在其上的上层组件提供API。 SparkSQL：Spark Sql 是Spark来操作结构化数据的程序包，可以让我使用SQL语句的方式来查询数据，Spark支持 多种数据源，包含Hive表，parquest以及JSON等内容。 SparkStreaming：&nbsp;是Spark提供的实时数据进行流式计算的组件。 MLlib：提供常用机器学习算法的实现库。 GraphX：提供一个分布式图计算框架，能高效进行图计算。 BlinkDB：用于在海量数据上进行交互式SQL的近似查询引擎。 Tachyon：以内存为中心高容错的的分布式文件系统。 Q：Spark的工作流程是什么样的呢？ A：通俗的解释就是：Spark是为了处理数据而生的平台，用一个比喻来形容它是餐馆。餐馆搭建好了后，就会有顾客，顾客的各种需求都得有人去处理，那么这时的Master就像是服务员，负责了解顾客的要求并把需求按照一定规律分配给厨师（Worker），这个顾客的需求就是一个APP，但这个APP不止包括了一个菜（job），整个订单里有很多个job，每个job都得由这些厨师处理，厨师的手就像是具体处理的Executor，负责所有的包括shuffle啊，filter啊，map啊，reduce等等具体的对原材料（RDD）的处理。driver就像是懒惰的厨师长，worker向它申请资源，同时它负责接收下面的人处理好的半成品材料或者完成品的菜品，但它自己并不干具体的活，如果是别人处理好的半成品，driver就将它分配给它认为有空的人接着处理（可能是map后要reduce的东西），直到目前的stage结束得到具体想要的结果，如果是直接就是想要的数据形式（一个job的完成），那么driver就通知master收货并反馈给顾客（可能是python程序，scala程序等等）。 Q：Apache&nbsp;Spark和Apache&nbsp;Storm之间有什么差异，用户应该根据什么来加以选择？ A：Apache&nbsp;Spark是一个内存中的分布式数据分析平台-&nbsp;主要针对加快批量分析工作,反复机器学习的工作，交互式查询和图形处理。一个最主要区别是Spark使用弹性分布式数据集（RDD）。RDD是通过并行运算符来进行计算，并根据定义它是一成不变的。RDD允许Spark基于谱系信息容错的独特的形式。如果你对执行Hadoop&nbsp;MapReduce作业更快，那么Spark是一个很好的选择（即使在这里需要考虑内存的因素）。 Apache&nbsp;Storm是专注于流处理或者一些所谓复杂事件的处理。Storm实现容错的方法进行计算或者以流水线的方式多次计算一个事件，由于Storm进入一个需要特定格式的系统，那么可能导致它转换为一个非结构化的数据。 Storm和Spark存在相当不同的使用情况。Storm和Spark流更多是类似“苹果和苹果”比较。由于Spark的SSD本身是不可变的，Spark流实现在用户定义的时间间隔“定量”来实现更新，得到改造成自己的RDD的方法，从而Spark的并行操作人员可以对这些RDD进行计算。这是与Storm处理每个事的不同之处。 这两种技术之间的一个主要区别是，Spark进行数据的并行计算，而Storm则是任务的并行计算。无论是那种方法，都有它表现价值的一方面。 Q：RDD的核心概念是什么？ A：Client：客户端进程，负责提交作业到Master。 Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。 Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。 Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。 Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。 Q：RDD有哪些常见术语? A：DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。 TaskScheduler：实现Task分配到Executor上执行。 Task：运行在Executor上的工作单元 Job：SparkContext提交的具体Action操作，常和Action对应 Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类 Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。 Q：RDD提供了哪些操作？ A：RDD提供了两种类型的操作： transformation和action 1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD 2，action是得到一个值，或者一个结果(直接将RDD cache到内存中) 3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。 DataFrame：带有Schema信息的RDD，主要是对结构化数据的高度抽象。 DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。 Q：RDD中关于转换(transformation)与动作(action)有什么区别？ A：transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。 Q：RDD 与 DSM的最大不同是什么？ A：RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。","@type":"BlogPosting","url":"https://uzzz.org/2019/08/05/795240.html","headline":"【大数据】Spark面试100问","dateModified":"2019-08-05T00:00:00+08:00","datePublished":"2019-08-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/05/795240.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>【大数据】Spark面试100问</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1>Spark问题精华</h1> 
  <hr>
  <p><strong>Q：</strong><strong>什么是Spark？</strong></p> 
  <p><strong>A：</strong>简单理解，Spark是在Hadoop基础上的改进，是UC&nbsp;Berkeley&nbsp;AMP&nbsp;lab所开源的类Hadoop&nbsp;MapReduce的通用的并行计算框架，<u>Spark基于map&nbsp;reduce算法实现的分布式计算，拥有Hadoop&nbsp;MapReduce所具有的优点</u>；但不同于MapReduce的是<strong><span style="color:#f33b45;">Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS</span></strong>，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map&nbsp;reduce的算法。</p> 
  <p><strong>Q：为什么要学Spark?</strong></p> 
  <p><strong>A：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。</strong>出于任务管道承接的考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果。</p> 
  <p>Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。</p> 
  <p><strong>Q：Spark有什么特性？</strong></p> 
  <p><strong>A：</strong>1、高效性</p> 
  <p>运行速度提高100倍。Apache&nbsp;Spark使用最先进的<strong>DAG调度程序</strong>，查询优化程序和物理执行引擎，实现<strong>批量和流式数据</strong>的高性能。</p> 
  <p>2、易用性</p> 
  <p>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</p> 
  <p>3、通用性</p> 
  <p>Spark提供了统一的解决方案。<span style="color:#f33b45;"><strong>Spark可以用于批处理、交互式查询（Spark&nbsp;SQL）、实时流处理（Spark&nbsp;Streaming）、机器学习（Spark&nbsp;MLlib）和图计算（GraphX）</strong></span>。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</p> 
  <p>4、兼容性</p> 
  <p>Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache&nbsp;Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。</p> 
  <p><strong>Q：Spark生态圈介绍</strong></p> 
  <p><strong>A：</strong>Spark力图整合机器学习（MLib）、图算法（GraphX）、流式计算（Spark&nbsp;Streaming）和数据仓库（Spark&nbsp;SQL）等领域，通过计算引擎Spark，弹性分布式数据集（RDD），架构出一个新的大数据应用平台。</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;Spark生态圈<strong>以HDFS、S3、Techyon为底层<span style="color:#f33b45;">存储引擎</span></strong>，以<strong>Yarn、Mesos和Standlone作为<span style="color:#f33b45;">资源调度引擎</span></strong>；使用Spark，可以实现MapReduce应用；基于Spark，Spark&nbsp;SQL可以实现即席查询，Spark&nbsp;Streaming可以处理实时应用，MLib可以实现机器学习算法，GraphX可以实现图计算，SparkR可以实现复杂数学计算。</p> 
  <p style="text-align:center;"><img alt="" class="has" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy96eG9MYWVDSTI4UWNlMU9hMmxRd1lqeEt1VG9vbGcwcldjeXJMRDVQWm8wSmhMT0RkNzJoU0hDaWFiYVZ5UGI3M1lHSDM5OHJkUmdpYXBiNURPc0dCbXl3LzY0MD93eF9mbXQ9cG5nJnRwPXdlYnAmd3hmcm9tPTUmd3hfbGF6eT0xJnd4X2NvPTE"></p> 
  <p><strong>Q：</strong><strong>Spark与Hadoop的对比</strong></p> 
  <p><strong>A：</strong>Spark的中间数据放到内存中，对于迭代运算效率更高。<strong>Spark更适合于迭代运算比较多的ML和DM运算</strong>。因为在Spark里面，有<span style="color:#f33b45;"><strong>RDD</strong></span>的抽象概念。所以，Spark比Hadoop更通用。</p> 
  <p><strong>Q：spark的组成有哪些？</strong></p> 
  <p><strong>A：</strong>Spark组成(BDAS)：全称伯克利数据分析栈，通过大规模集成算法、机器、人之间展现大数据应用的一个平台。也是处理大数据、云计算、通信的技术解决方案。</p> 
  <p>它的主要组件有：</p> 
  <p><strong>SparkCore</strong>：将分布式数据抽象为弹性分布式数据集（RDD），实现了应用任务调度、RPC、序列化和压缩，并为运行在其上的上层组件提供API。</p> 
  <p><strong>SparkSQL</strong>：Spark Sql 是Spark来操作结构化数据的程序包，可以让我使用SQL语句的方式来查询数据，Spark支持 多种数据源，包含Hive表，parquest以及JSON等内容。</p> 
  <p><strong>SparkStreaming</strong>：&nbsp;是Spark提供的实时数据进行流式计算的组件。</p> 
  <p><strong>MLlib</strong>：提供常用机器学习算法的实现库。</p> 
  <p><strong>GraphX</strong>：提供一个分布式图计算框架，能高效进行图计算。</p> 
  <p><strong>BlinkDB</strong>：用于在海量数据上进行交互式SQL的近似查询引擎。</p> 
  <p><strong>Tachyon</strong>：以内存为中心高容错的的分布式文件系统。</p> 
  <p><strong><strong>Q：Spark的工作流程是什么样的呢？</strong></strong></p> 
  <p><strong>A：</strong>通俗的解释就是：Spark是为了处理数据而生的平台，用一个比喻来形容它是餐馆。餐馆搭建好了后，就会有顾客，顾客的各种需求都得有人去处理，那么这时的Master就像是服务员，负责了解顾客的要求并把需求按照一定规律分配给厨师（Worker），这个顾客的需求就是一个APP，但这个APP不止包括了一个菜（job），整个订单里有很多个job，每个job都得由这些厨师处理，厨师的手就像是具体处理的Executor，负责所有的包括shuffle啊，filter啊，map啊，reduce等等具体的对原材料（RDD）的处理。driver就像是懒惰的厨师长，worker向它申请资源，同时它负责接收下面的人处理好的半成品材料或者完成品的菜品，但它自己并不干具体的活，如果是别人处理好的半成品，driver就将它分配给它认为有空的人接着处理（可能是map后要reduce的东西），直到目前的stage结束得到具体想要的结果，如果是直接就是想要的数据形式（一个job的完成），那么driver就通知master收货并反馈给顾客（可能是python程序，scala程序等等）。</p> 
  <p><strong>Q：Apache&nbsp;Spark和Apache&nbsp;Storm之间有什么差异，用户应该根据什么来加以选择？</strong></p> 
  <p><strong>A：</strong>Apache&nbsp;Spark是一个内存中的分布式数据分析平台-&nbsp;主要针对加快批量分析工作,反复机器学习的工作，交互式查询和图形处理。一个最主要区别是Spark使用弹性分布式数据集（RDD）。RDD是通过并行运算符来进行计算，并根据定义它是一成不变的。RDD允许Spark基于谱系信息容错的独特的形式。如果你对执行Hadoop&nbsp;MapReduce作业更快，那么Spark是一个很好的选择（即使在这里需要考虑内存的因素）。</p> 
  <p>Apache&nbsp;Storm是专注于流处理或者一些所谓复杂事件的处理。Storm实现容错的方法进行计算或者以流水线的方式多次计算一个事件，由于Storm进入一个需要特定格式的系统，那么可能导致它转换为一个非结构化的数据。</p> 
  <p>Storm和Spark存在相当不同的使用情况。Storm和Spark流更多是类似“苹果和苹果”比较。由于Spark的SSD本身是不可变的，Spark流实现在用户定义的时间间隔“定量”来实现更新，得到改造成自己的RDD的方法，从而Spark的并行操作人员可以对这些RDD进行计算。这是与Storm处理每个事的不同之处。</p> 
  <p>这两种技术之间的一个主要区别是，Spark进行数据的并行计算，而Storm则是任务的并行计算。无论是那种方法，都有它表现价值的一方面。</p> 
  <p><strong>Q：RDD的核心概念是什么</strong><strong>？</strong></p> 
  <p><strong>A：</strong>Client：客户端进程，负责提交作业到Master。</p> 
  <p>Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。</p> 
  <p>Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。</p> 
  <p>Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。</p> 
  <p>Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。</p> 
  <p><strong>Q：RDD有哪些常见术语?</strong></p> 
  <p><strong>A：</strong>DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</p> 
  <p>TaskScheduler：实现Task分配到Executor上执行。</p> 
  <p>Task：运行在Executor上的工作单元</p> 
  <p>Job：SparkContext提交的具体Action操作，常和Action对应</p> 
  <p>Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet</p> 
  <p>RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类</p> 
  <p>Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。</p> 
  <p><strong>Q：RDD提供了哪些操作？</strong></p> 
  <p><strong>A：</strong>RDD提供了两种类型的操作：</p> 
  <p>transformation和action</p> 
  <p>1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD</p> 
  <p>2，action是得到一个值，或者一个结果(直接将RDD cache到内存中)</p> 
  <p>3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。</p> 
  <p>DataFrame：带有Schema信息的RDD，主要是对结构化数据的高度抽象。</p> 
  <p>DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。</p> 
  <p><strong>Q：</strong><strong>RDD中关于转换(transformation)与动作(action)有什么区别？</strong></p> 
  <p><strong>A：</strong>transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。</p> 
  <p><strong>Q：</strong><strong>RDD 与 DSM的最大不同是什么？</strong></p> 
  <p><strong>A：</strong>RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
