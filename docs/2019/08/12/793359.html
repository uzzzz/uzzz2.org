<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>[正在进行中…] KG &amp; object detection | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="[正在进行中…] KG &amp; object detection" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="文章目录 The More You Know: Using Knowledge Graphs for Image Classification 模型 数据集 case Object Detection Meets Knowledge Graphs 方法 数据集 case Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning 基础 R-CNN SPP Net Fast R-CNN Faster R-CNN 总结一下各大算法的步骤 The More You Know: Using Knowledge Graphs for Image Classification paper：https://arxiv.org/pdf/1612.04844.pdf 人类和learning-based CV 算法最大的不同是：人类能够依靠背景知识在可视化世界中做推理。人可以只通过少量的样本了解到这个物品的特征、这个物品和其他物品的关系。 本文以KG作为背景知识，基于GGNN（Gated Graph Neural Network），提出Graph Search Neural Network（GSNN）进行多标签图片分类。比较GGNN，GSNN不更新整个graph上的点，1）只更新subset，因此计算效率更高， 2）利用importance network为每个结点计算重要程度来挑选subset的，因此有更强的可解释性。 模型 GGNN 1、propagation network ： h v ( t ) h_v^{(t)} hv(t)​:表示结点 v v v在时间 t t t的隐层状态， A v T A_v^T AvT​是邻接矩阵。 GSNN 1、首先用 Faster R-CNN得到80类的基础分类结果，将概率大于某个阈值的node拿出来作为初始的active node 2、训练importance network得到对于已有的active node来说top p重要的nodes进行下一步扩展。---- 为了训练importance network，我们需要对给定的图像为每个node安排重要度。安排的原则是：如果node是ground truth concept，则重要度为1，若是一跳的，重要度为 λ \lambda λ，若是两跳，重要度为 λ 2 \lambda^2 λ2，即：靠近最终输出在扩展的时候是最重要的。 3、 output network 通过BCE(Binary Cross Entropy)训练。相比GGNN的 g ( h v ( T ) , x v ) g(h_v^{(T)},x_v) g(hv(T)​,xv​),GSNN多了bias term n v n_v nv​，原因文中有提到。 L = g ( h v ( T ) , x v , n v ) L=g(h_v^{(T)}, x_v, n_v) L=g(hv(T)​,xv​,nv​) 数据集 目标检测： COCO Visual Genome dataset：100,000张图片，每个被标记为object，attributes and object之间/object和attribute之间的relations.每张图片平均21 labels。 VGML：论文构建的数据集，基于Visual Genome dataset中200个最常见的object，100个最常见的attributes，还有coco中多的16个，共316个visual concepts。 KG：通过Visual Genome dataset + WordNet进行构建。因为Visual Genome dataset 包含了scene-level relationships between objects，但是没有包含semantic relation，因此加入wordnet进行扩充。 实验结果： 1、 VG：Visual Genome graph ，WN：WordNet graph. 2、训练样本数量对结果的影响 3、在coco上的效果： case Object Detection Meets Knowledge Graphs 链接：https://www.ijcai.org/proceedings/2017/0230.pdf 在原始目标检测的优化过程中添加“semantic consistency”的约束进行优化，“semantic consistency”来自于背景知识。最终的实验结果是在不降低precision值的情况下recall相比之前提升6.3。 “semantic consistency”的理解：基于“家猫可能会坐在盘子上，而熊不会”这样的背景知识，1）即使训练的时候没有样本是关于 “猫、桌子”的，测试也可能会预测出来；2）当目标检测检测出来“熊”和“桌子”时候，这和背景知识是冲突的。 方法的两个技术难点是： 1）如何量化背景知识 因为KG一般是通过symbolic表示，而目标检测中subsymbolic或numerical表示上操作的，一次需要量化。文中提出量化的方式是为每对concepts计算numerical表示的语义一致度。如在KG中又“cat sits on table”，说明cat and table是语义一致的概念，而熊不是。 ！！！！【这里提到“cat licks plate” and “plate placed on table”.需要看下怎么做的？？？】 2）如何将语义一致性应用到我们的任务中 基于假设：“语义一致性高的更倾向于在同一张图片中出现”。如果用 ( o , p ) (o,p) (o,p)表示 o o o有 p p p的概率出现在图像中，那么(cat,0.8) &amp; (table,0.9) 看起来会比(bear,0.8) &amp; (table,0.9)更合理，模型可能会将后者纠正为(bear,0.01) &amp; (table,0.9)。论文将这种约束映射为一个优化问题。 方法 原始的目标检测： P = B ∗ L ∈ R P = B * L \in \mathbb{R} P=B∗L∈R ，其中 P b , l = p ( l ∣ b ) P_{b,l}=p(l|b) Pb,l​=p(l∣b)表示图像的bounding box b b b被打标为label l l l的概率为 P b , l P_{b,l} Pb,l​ KG-aware目标检测： P ^ \hat{P} P^是经过“semantic consistency”纠正后的 P P P，即文章中提到的“ P ^ \hat{P} P^ is a knowledge-aware enhancement of P P P” 目标检测输出： l ^ = a r g m a x l P ^ b , l \hat{l}=argmax_l\hat{P}_{b,l} l^=argmaxl​P^b,l​ 1）这里看到目标检测是需要box的，且box固定的？ 2）预测的结果看来是单分类的？不是，是每个box一个label 针对上述两个技术难点： 1、如何量化背景知识。Semantic Consistency， S ∈ R L , L S \in \mathbb{R}^{L,L} S∈RL,L，有“Frequency-based knowledge“和“Graph-based knowledge“两种方式计算。 Frequency-based knowledge， N N N是KG中总instances数量， n ( l , l ′ ) n(l,l&amp;#x27;) n(l,l′)是 l l l和 l ′ l&amp;#x27; l′共现频率 明显这种方式不能处理KG中没有直接相连的实体对，即多跳关系的实体对。 KG中的N是总instance数量是entity数量吗？ Graph-based knowledge。“random walk with restart”的思想，会构造出从 v 0 v_0 v0​到 v t v_t vt​的路径 v 0 , v 1 , . . . v t v_0,v_1,...v_t v0​,v1​,...vt​，让 p ( v t = l ′ ∣ v 0 = l ; α ) p(v_t=l&amp;#x27;|v_0=l;\alpha) p(vt​=l′∣v0​=l;α)表示从 l l l到经过 t t t步之后到达 l ′ l&amp;#x27; l′的概率。经过很长的游走之后，概率 p p p会收敛到 R l , l ′ = lim ⁡ t → ∞ p ( v t = l ′ ∣ v 0 = l ; α ) R_{l,l&amp;#x27;}=\lim_{t \rightarrow\infty }p(v_t=l&amp;#x27;|v_0=l;\alpha) Rl,l′​=t→∞lim​p(vt​=l′∣v0​=l;α) 这里 R l , l ′ = R_{l,l&amp;#x27;}= Rl,l′​=不是对称的，上面方法是。 S S S的计算如下： 和deepwalk的思想差不多，可能deepwalk是参考这个的？ 2、 如何将语义一致性应用到我们的任务中。回想上述假设：“语义一致性高的更倾向于在同一张图片中出现”，有下面的优化目标。第一项保证语义一致性高的得分近似，第二项保证经过KG纠正后的结果不应该太偏离原始目标检测出来的值。 具体的优化过程见论文。 数据集 KG：conceptNet 目标检测：MSCOCO15，PASCAL07 在MSCOCO15上结果 KF-ALL，KF-500是基于frequency-based knowledge，KG-CNet基于graph-based knowledge case 下面的图像中，橘黄色的ground-truth label，紫色是检测出来的，左边是FRCNN，右边是KG-CNet。 – 文中的“concept”对应KG中的“entity” restriction for my task: 会设置bouding box数量？ 最大的问题是要求目标在文中出现，即约束条件中设置了两个出现在图片中的object的出现概率差不多。训练的目标更多是让原始的object detection检测的更全一点。 Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning paper: https://arxiv.org/abs/1901.01703 github:https://github.com/Tencent/tencent-ml-images 为此，我们构建了一个大规模的多标签图像数据库，其中包含 18000000 个图像和 11000 个类别，我们称之为 Tencent ML-Images。我们基于大规模分布式深度学习框架，即 TFplus，在 Tencent ML-Images 上高效训练 ResNet-101 多标签输出模型，共 60 个 epoch，耗时 90 小时,128GPU。 通过 ImageNet 和 Caltech-256 上的单标签图像分类、PASCAL VOC 2007 上的对象检测、PASCAL VOC 2012 上的语义分割三个迁移学习任务，验证了 Tencent ML-Images checkpoint 的视觉表示质量良好。 ----https://blog.csdn.net/sophia_11/article/details/86326165 基础 建议直接看，以下都是来自于这俩篇 一文读懂目标检测：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD， 一文读懂Faster RCNN R-CNN Region Proposal + CNN。预先找出图中目标可能出现的位置，即候选区域（Region Proposal）。剩下的工作实际就是对候选区域进行图像分类的工作（特征提取+分类）。 R-CNN的简要步骤如下 (1) 输入测试图像 (2) 利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal (3) 因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征 SPP Net的第一个贡献就是在最后一个卷积层后，接入了金字塔池化层，保证传到下一层全连接层的输入固定。 换句话说，在普通的CNN机构中，输入图像的尺寸往往是固定的（比如224*224像素），输出则是一个固定维数的向量。SPP Net在普通的CNN结构中加入了ROI池化层（ROI Pooling），使得网络的输入图像可以是任意尺寸的，输出则不变，同样是一个固定维数的向量。 SPP Net R-CNN虽然不再像传统方法那样穷举，但R-CNN流程的第一步中对原始图片通过Selective Search提取的候选框region proposal多达2000个左右，而这2000个候选框每个框都需要进行CNN提特征+SVM分类，计算量很大，导致R-CNN检测速度很慢，一张图都需要47s。 有没有方法提速呢？答案是有的，这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。 但现在的问题是每个region proposal的尺度不一样，而全连接层输入必须是固定的长度，所以直接这样输入全连接层肯定是不行的。SPP Net恰好可以解决这个问题。 SPP-Net是出自2015年发表在IEEE上的论文-《Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition》。 CNN一般都含有卷积部分和全连接部分，其中，卷积层不需要固定尺寸的图像，而全连接层是需要固定大小的输入。所以当全连接层面对各种尺寸的输入数据时，就需要对输入数据进行crop（crop就是从一个大图扣出网络输入大小的patch，比如227×227），或warp（把一个边界框bounding box的内容resize成227×227）等一系列操作以统一图片的尺寸大小，比如224224（ImageNet）、3232(LenNet)、96*96等。 但warp/crop这种预处理，导致的问题要么被拉伸变形、要么物体不全，限制了识别精确度。没太明白？说句人话就是，一张16:9比例的图片你硬是要Resize成1:1的图片，你说图片失真不？ SPP Net的作者Kaiming He等人逆向思考，既然由于全连接FC层的存在，普通的CNN需要通过固定输入图片的大小来使得全连接层的输入固定。那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使得后面全连接层得到的输入变成固定的呢？ 这个“化腐朽为神奇”的结构就是spatial pyramid pooling layer。 简言之，CNN原本只能固定输入、固定输出，CNN加上SSP之后，便能任意输入、固定输出 Fast R-CNN R-CNN与Fast R-CNN的区别有哪些呢？ 先说R-CNN的缺点：即使使用了Selective Search等预处理步骤来提取潜在的bounding box作为输入，但是R-CNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。 R-CNN训练过程分为了三个阶段，而Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去Region Proposal提取阶段)。 也就是说，之前R-CNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast R-CNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。 画一画重点： R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。 大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。 解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征 原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归 现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归 Faster R-CNN Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？ 解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。 所以，rgbd在Fast R-CNN中引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题（anchor就是位置和大小固定的box，可以理解成事先设置好的固定的proposal）。 具体做法： 　　• 将RPN放在最后一个卷积层的后面 　　• RPN直接训练得到候选区域 总结一下各大算法的步骤 简言之，即如本文开头所列 R-CNN（Selective Search + CNN + SVM） SPP-net（ROI Pooling） Fast R-CNN（Selective Search + CNN + ROI） Faster R-CNN（RPN + CNN + ROI）" />
<meta property="og:description" content="文章目录 The More You Know: Using Knowledge Graphs for Image Classification 模型 数据集 case Object Detection Meets Knowledge Graphs 方法 数据集 case Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning 基础 R-CNN SPP Net Fast R-CNN Faster R-CNN 总结一下各大算法的步骤 The More You Know: Using Knowledge Graphs for Image Classification paper：https://arxiv.org/pdf/1612.04844.pdf 人类和learning-based CV 算法最大的不同是：人类能够依靠背景知识在可视化世界中做推理。人可以只通过少量的样本了解到这个物品的特征、这个物品和其他物品的关系。 本文以KG作为背景知识，基于GGNN（Gated Graph Neural Network），提出Graph Search Neural Network（GSNN）进行多标签图片分类。比较GGNN，GSNN不更新整个graph上的点，1）只更新subset，因此计算效率更高， 2）利用importance network为每个结点计算重要程度来挑选subset的，因此有更强的可解释性。 模型 GGNN 1、propagation network ： h v ( t ) h_v^{(t)} hv(t)​:表示结点 v v v在时间 t t t的隐层状态， A v T A_v^T AvT​是邻接矩阵。 GSNN 1、首先用 Faster R-CNN得到80类的基础分类结果，将概率大于某个阈值的node拿出来作为初始的active node 2、训练importance network得到对于已有的active node来说top p重要的nodes进行下一步扩展。---- 为了训练importance network，我们需要对给定的图像为每个node安排重要度。安排的原则是：如果node是ground truth concept，则重要度为1，若是一跳的，重要度为 λ \lambda λ，若是两跳，重要度为 λ 2 \lambda^2 λ2，即：靠近最终输出在扩展的时候是最重要的。 3、 output network 通过BCE(Binary Cross Entropy)训练。相比GGNN的 g ( h v ( T ) , x v ) g(h_v^{(T)},x_v) g(hv(T)​,xv​),GSNN多了bias term n v n_v nv​，原因文中有提到。 L = g ( h v ( T ) , x v , n v ) L=g(h_v^{(T)}, x_v, n_v) L=g(hv(T)​,xv​,nv​) 数据集 目标检测： COCO Visual Genome dataset：100,000张图片，每个被标记为object，attributes and object之间/object和attribute之间的relations.每张图片平均21 labels。 VGML：论文构建的数据集，基于Visual Genome dataset中200个最常见的object，100个最常见的attributes，还有coco中多的16个，共316个visual concepts。 KG：通过Visual Genome dataset + WordNet进行构建。因为Visual Genome dataset 包含了scene-level relationships between objects，但是没有包含semantic relation，因此加入wordnet进行扩充。 实验结果： 1、 VG：Visual Genome graph ，WN：WordNet graph. 2、训练样本数量对结果的影响 3、在coco上的效果： case Object Detection Meets Knowledge Graphs 链接：https://www.ijcai.org/proceedings/2017/0230.pdf 在原始目标检测的优化过程中添加“semantic consistency”的约束进行优化，“semantic consistency”来自于背景知识。最终的实验结果是在不降低precision值的情况下recall相比之前提升6.3。 “semantic consistency”的理解：基于“家猫可能会坐在盘子上，而熊不会”这样的背景知识，1）即使训练的时候没有样本是关于 “猫、桌子”的，测试也可能会预测出来；2）当目标检测检测出来“熊”和“桌子”时候，这和背景知识是冲突的。 方法的两个技术难点是： 1）如何量化背景知识 因为KG一般是通过symbolic表示，而目标检测中subsymbolic或numerical表示上操作的，一次需要量化。文中提出量化的方式是为每对concepts计算numerical表示的语义一致度。如在KG中又“cat sits on table”，说明cat and table是语义一致的概念，而熊不是。 ！！！！【这里提到“cat licks plate” and “plate placed on table”.需要看下怎么做的？？？】 2）如何将语义一致性应用到我们的任务中 基于假设：“语义一致性高的更倾向于在同一张图片中出现”。如果用 ( o , p ) (o,p) (o,p)表示 o o o有 p p p的概率出现在图像中，那么(cat,0.8) &amp; (table,0.9) 看起来会比(bear,0.8) &amp; (table,0.9)更合理，模型可能会将后者纠正为(bear,0.01) &amp; (table,0.9)。论文将这种约束映射为一个优化问题。 方法 原始的目标检测： P = B ∗ L ∈ R P = B * L \in \mathbb{R} P=B∗L∈R ，其中 P b , l = p ( l ∣ b ) P_{b,l}=p(l|b) Pb,l​=p(l∣b)表示图像的bounding box b b b被打标为label l l l的概率为 P b , l P_{b,l} Pb,l​ KG-aware目标检测： P ^ \hat{P} P^是经过“semantic consistency”纠正后的 P P P，即文章中提到的“ P ^ \hat{P} P^ is a knowledge-aware enhancement of P P P” 目标检测输出： l ^ = a r g m a x l P ^ b , l \hat{l}=argmax_l\hat{P}_{b,l} l^=argmaxl​P^b,l​ 1）这里看到目标检测是需要box的，且box固定的？ 2）预测的结果看来是单分类的？不是，是每个box一个label 针对上述两个技术难点： 1、如何量化背景知识。Semantic Consistency， S ∈ R L , L S \in \mathbb{R}^{L,L} S∈RL,L，有“Frequency-based knowledge“和“Graph-based knowledge“两种方式计算。 Frequency-based knowledge， N N N是KG中总instances数量， n ( l , l ′ ) n(l,l&amp;#x27;) n(l,l′)是 l l l和 l ′ l&amp;#x27; l′共现频率 明显这种方式不能处理KG中没有直接相连的实体对，即多跳关系的实体对。 KG中的N是总instance数量是entity数量吗？ Graph-based knowledge。“random walk with restart”的思想，会构造出从 v 0 v_0 v0​到 v t v_t vt​的路径 v 0 , v 1 , . . . v t v_0,v_1,...v_t v0​,v1​,...vt​，让 p ( v t = l ′ ∣ v 0 = l ; α ) p(v_t=l&amp;#x27;|v_0=l;\alpha) p(vt​=l′∣v0​=l;α)表示从 l l l到经过 t t t步之后到达 l ′ l&amp;#x27; l′的概率。经过很长的游走之后，概率 p p p会收敛到 R l , l ′ = lim ⁡ t → ∞ p ( v t = l ′ ∣ v 0 = l ; α ) R_{l,l&amp;#x27;}=\lim_{t \rightarrow\infty }p(v_t=l&amp;#x27;|v_0=l;\alpha) Rl,l′​=t→∞lim​p(vt​=l′∣v0​=l;α) 这里 R l , l ′ = R_{l,l&amp;#x27;}= Rl,l′​=不是对称的，上面方法是。 S S S的计算如下： 和deepwalk的思想差不多，可能deepwalk是参考这个的？ 2、 如何将语义一致性应用到我们的任务中。回想上述假设：“语义一致性高的更倾向于在同一张图片中出现”，有下面的优化目标。第一项保证语义一致性高的得分近似，第二项保证经过KG纠正后的结果不应该太偏离原始目标检测出来的值。 具体的优化过程见论文。 数据集 KG：conceptNet 目标检测：MSCOCO15，PASCAL07 在MSCOCO15上结果 KF-ALL，KF-500是基于frequency-based knowledge，KG-CNet基于graph-based knowledge case 下面的图像中，橘黄色的ground-truth label，紫色是检测出来的，左边是FRCNN，右边是KG-CNet。 – 文中的“concept”对应KG中的“entity” restriction for my task: 会设置bouding box数量？ 最大的问题是要求目标在文中出现，即约束条件中设置了两个出现在图片中的object的出现概率差不多。训练的目标更多是让原始的object detection检测的更全一点。 Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning paper: https://arxiv.org/abs/1901.01703 github:https://github.com/Tencent/tencent-ml-images 为此，我们构建了一个大规模的多标签图像数据库，其中包含 18000000 个图像和 11000 个类别，我们称之为 Tencent ML-Images。我们基于大规模分布式深度学习框架，即 TFplus，在 Tencent ML-Images 上高效训练 ResNet-101 多标签输出模型，共 60 个 epoch，耗时 90 小时,128GPU。 通过 ImageNet 和 Caltech-256 上的单标签图像分类、PASCAL VOC 2007 上的对象检测、PASCAL VOC 2012 上的语义分割三个迁移学习任务，验证了 Tencent ML-Images checkpoint 的视觉表示质量良好。 ----https://blog.csdn.net/sophia_11/article/details/86326165 基础 建议直接看，以下都是来自于这俩篇 一文读懂目标检测：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD， 一文读懂Faster RCNN R-CNN Region Proposal + CNN。预先找出图中目标可能出现的位置，即候选区域（Region Proposal）。剩下的工作实际就是对候选区域进行图像分类的工作（特征提取+分类）。 R-CNN的简要步骤如下 (1) 输入测试图像 (2) 利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal (3) 因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征 SPP Net的第一个贡献就是在最后一个卷积层后，接入了金字塔池化层，保证传到下一层全连接层的输入固定。 换句话说，在普通的CNN机构中，输入图像的尺寸往往是固定的（比如224*224像素），输出则是一个固定维数的向量。SPP Net在普通的CNN结构中加入了ROI池化层（ROI Pooling），使得网络的输入图像可以是任意尺寸的，输出则不变，同样是一个固定维数的向量。 SPP Net R-CNN虽然不再像传统方法那样穷举，但R-CNN流程的第一步中对原始图片通过Selective Search提取的候选框region proposal多达2000个左右，而这2000个候选框每个框都需要进行CNN提特征+SVM分类，计算量很大，导致R-CNN检测速度很慢，一张图都需要47s。 有没有方法提速呢？答案是有的，这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。 但现在的问题是每个region proposal的尺度不一样，而全连接层输入必须是固定的长度，所以直接这样输入全连接层肯定是不行的。SPP Net恰好可以解决这个问题。 SPP-Net是出自2015年发表在IEEE上的论文-《Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition》。 CNN一般都含有卷积部分和全连接部分，其中，卷积层不需要固定尺寸的图像，而全连接层是需要固定大小的输入。所以当全连接层面对各种尺寸的输入数据时，就需要对输入数据进行crop（crop就是从一个大图扣出网络输入大小的patch，比如227×227），或warp（把一个边界框bounding box的内容resize成227×227）等一系列操作以统一图片的尺寸大小，比如224224（ImageNet）、3232(LenNet)、96*96等。 但warp/crop这种预处理，导致的问题要么被拉伸变形、要么物体不全，限制了识别精确度。没太明白？说句人话就是，一张16:9比例的图片你硬是要Resize成1:1的图片，你说图片失真不？ SPP Net的作者Kaiming He等人逆向思考，既然由于全连接FC层的存在，普通的CNN需要通过固定输入图片的大小来使得全连接层的输入固定。那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使得后面全连接层得到的输入变成固定的呢？ 这个“化腐朽为神奇”的结构就是spatial pyramid pooling layer。 简言之，CNN原本只能固定输入、固定输出，CNN加上SSP之后，便能任意输入、固定输出 Fast R-CNN R-CNN与Fast R-CNN的区别有哪些呢？ 先说R-CNN的缺点：即使使用了Selective Search等预处理步骤来提取潜在的bounding box作为输入，但是R-CNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。 R-CNN训练过程分为了三个阶段，而Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去Region Proposal提取阶段)。 也就是说，之前R-CNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast R-CNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。 画一画重点： R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。 大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。 解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征 原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归 现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归 Faster R-CNN Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？ 解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。 所以，rgbd在Fast R-CNN中引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题（anchor就是位置和大小固定的box，可以理解成事先设置好的固定的proposal）。 具体做法： 　　• 将RPN放在最后一个卷积层的后面 　　• RPN直接训练得到候选区域 总结一下各大算法的步骤 简言之，即如本文开头所列 R-CNN（Selective Search + CNN + SVM） SPP-net（ROI Pooling） Fast R-CNN（Selective Search + CNN + ROI） Faster R-CNN（RPN + CNN + ROI）" />
<link rel="canonical" href="https://uzzz.org/2019/08/12/793359.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/12/793359.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-12T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"文章目录 The More You Know: Using Knowledge Graphs for Image Classification 模型 数据集 case Object Detection Meets Knowledge Graphs 方法 数据集 case Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning 基础 R-CNN SPP Net Fast R-CNN Faster R-CNN 总结一下各大算法的步骤 The More You Know: Using Knowledge Graphs for Image Classification paper：https://arxiv.org/pdf/1612.04844.pdf 人类和learning-based CV 算法最大的不同是：人类能够依靠背景知识在可视化世界中做推理。人可以只通过少量的样本了解到这个物品的特征、这个物品和其他物品的关系。 本文以KG作为背景知识，基于GGNN（Gated Graph Neural Network），提出Graph Search Neural Network（GSNN）进行多标签图片分类。比较GGNN，GSNN不更新整个graph上的点，1）只更新subset，因此计算效率更高， 2）利用importance network为每个结点计算重要程度来挑选subset的，因此有更强的可解释性。 模型 GGNN 1、propagation network ： h v ( t ) h_v^{(t)} hv(t)​:表示结点 v v v在时间 t t t的隐层状态， A v T A_v^T AvT​是邻接矩阵。 GSNN 1、首先用 Faster R-CNN得到80类的基础分类结果，将概率大于某个阈值的node拿出来作为初始的active node 2、训练importance network得到对于已有的active node来说top p重要的nodes进行下一步扩展。---- 为了训练importance network，我们需要对给定的图像为每个node安排重要度。安排的原则是：如果node是ground truth concept，则重要度为1，若是一跳的，重要度为 λ \\lambda λ，若是两跳，重要度为 λ 2 \\lambda^2 λ2，即：靠近最终输出在扩展的时候是最重要的。 3、 output network 通过BCE(Binary Cross Entropy)训练。相比GGNN的 g ( h v ( T ) , x v ) g(h_v^{(T)},x_v) g(hv(T)​,xv​),GSNN多了bias term n v n_v nv​，原因文中有提到。 L = g ( h v ( T ) , x v , n v ) L=g(h_v^{(T)}, x_v, n_v) L=g(hv(T)​,xv​,nv​) 数据集 目标检测： COCO Visual Genome dataset：100,000张图片，每个被标记为object，attributes and object之间/object和attribute之间的relations.每张图片平均21 labels。 VGML：论文构建的数据集，基于Visual Genome dataset中200个最常见的object，100个最常见的attributes，还有coco中多的16个，共316个visual concepts。 KG：通过Visual Genome dataset + WordNet进行构建。因为Visual Genome dataset 包含了scene-level relationships between objects，但是没有包含semantic relation，因此加入wordnet进行扩充。 实验结果： 1、 VG：Visual Genome graph ，WN：WordNet graph. 2、训练样本数量对结果的影响 3、在coco上的效果： case Object Detection Meets Knowledge Graphs 链接：https://www.ijcai.org/proceedings/2017/0230.pdf 在原始目标检测的优化过程中添加“semantic consistency”的约束进行优化，“semantic consistency”来自于背景知识。最终的实验结果是在不降低precision值的情况下recall相比之前提升6.3。 “semantic consistency”的理解：基于“家猫可能会坐在盘子上，而熊不会”这样的背景知识，1）即使训练的时候没有样本是关于 “猫、桌子”的，测试也可能会预测出来；2）当目标检测检测出来“熊”和“桌子”时候，这和背景知识是冲突的。 方法的两个技术难点是： 1）如何量化背景知识 因为KG一般是通过symbolic表示，而目标检测中subsymbolic或numerical表示上操作的，一次需要量化。文中提出量化的方式是为每对concepts计算numerical表示的语义一致度。如在KG中又“cat sits on table”，说明cat and table是语义一致的概念，而熊不是。 ！！！！【这里提到“cat licks plate” and “plate placed on table”.需要看下怎么做的？？？】 2）如何将语义一致性应用到我们的任务中 基于假设：“语义一致性高的更倾向于在同一张图片中出现”。如果用 ( o , p ) (o,p) (o,p)表示 o o o有 p p p的概率出现在图像中，那么(cat,0.8) &amp; (table,0.9) 看起来会比(bear,0.8) &amp; (table,0.9)更合理，模型可能会将后者纠正为(bear,0.01) &amp; (table,0.9)。论文将这种约束映射为一个优化问题。 方法 原始的目标检测： P = B ∗ L ∈ R P = B * L \\in \\mathbb{R} P=B∗L∈R ，其中 P b , l = p ( l ∣ b ) P_{b,l}=p(l|b) Pb,l​=p(l∣b)表示图像的bounding box b b b被打标为label l l l的概率为 P b , l P_{b,l} Pb,l​ KG-aware目标检测： P ^ \\hat{P} P^是经过“semantic consistency”纠正后的 P P P，即文章中提到的“ P ^ \\hat{P} P^ is a knowledge-aware enhancement of P P P” 目标检测输出： l ^ = a r g m a x l P ^ b , l \\hat{l}=argmax_l\\hat{P}_{b,l} l^=argmaxl​P^b,l​ 1）这里看到目标检测是需要box的，且box固定的？ 2）预测的结果看来是单分类的？不是，是每个box一个label 针对上述两个技术难点： 1、如何量化背景知识。Semantic Consistency， S ∈ R L , L S \\in \\mathbb{R}^{L,L} S∈RL,L，有“Frequency-based knowledge“和“Graph-based knowledge“两种方式计算。 Frequency-based knowledge， N N N是KG中总instances数量， n ( l , l ′ ) n(l,l&amp;#x27;) n(l,l′)是 l l l和 l ′ l&amp;#x27; l′共现频率 明显这种方式不能处理KG中没有直接相连的实体对，即多跳关系的实体对。 KG中的N是总instance数量是entity数量吗？ Graph-based knowledge。“random walk with restart”的思想，会构造出从 v 0 v_0 v0​到 v t v_t vt​的路径 v 0 , v 1 , . . . v t v_0,v_1,...v_t v0​,v1​,...vt​，让 p ( v t = l ′ ∣ v 0 = l ; α ) p(v_t=l&amp;#x27;|v_0=l;\\alpha) p(vt​=l′∣v0​=l;α)表示从 l l l到经过 t t t步之后到达 l ′ l&amp;#x27; l′的概率。经过很长的游走之后，概率 p p p会收敛到 R l , l ′ = lim ⁡ t → ∞ p ( v t = l ′ ∣ v 0 = l ; α ) R_{l,l&amp;#x27;}=\\lim_{t \\rightarrow\\infty }p(v_t=l&amp;#x27;|v_0=l;\\alpha) Rl,l′​=t→∞lim​p(vt​=l′∣v0​=l;α) 这里 R l , l ′ = R_{l,l&amp;#x27;}= Rl,l′​=不是对称的，上面方法是。 S S S的计算如下： 和deepwalk的思想差不多，可能deepwalk是参考这个的？ 2、 如何将语义一致性应用到我们的任务中。回想上述假设：“语义一致性高的更倾向于在同一张图片中出现”，有下面的优化目标。第一项保证语义一致性高的得分近似，第二项保证经过KG纠正后的结果不应该太偏离原始目标检测出来的值。 具体的优化过程见论文。 数据集 KG：conceptNet 目标检测：MSCOCO15，PASCAL07 在MSCOCO15上结果 KF-ALL，KF-500是基于frequency-based knowledge，KG-CNet基于graph-based knowledge case 下面的图像中，橘黄色的ground-truth label，紫色是检测出来的，左边是FRCNN，右边是KG-CNet。 – 文中的“concept”对应KG中的“entity” restriction for my task: 会设置bouding box数量？ 最大的问题是要求目标在文中出现，即约束条件中设置了两个出现在图片中的object的出现概率差不多。训练的目标更多是让原始的object detection检测的更全一点。 Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning paper: https://arxiv.org/abs/1901.01703 github:https://github.com/Tencent/tencent-ml-images 为此，我们构建了一个大规模的多标签图像数据库，其中包含 18000000 个图像和 11000 个类别，我们称之为 Tencent ML-Images。我们基于大规模分布式深度学习框架，即 TFplus，在 Tencent ML-Images 上高效训练 ResNet-101 多标签输出模型，共 60 个 epoch，耗时 90 小时,128GPU。 通过 ImageNet 和 Caltech-256 上的单标签图像分类、PASCAL VOC 2007 上的对象检测、PASCAL VOC 2012 上的语义分割三个迁移学习任务，验证了 Tencent ML-Images checkpoint 的视觉表示质量良好。 ----https://blog.csdn.net/sophia_11/article/details/86326165 基础 建议直接看，以下都是来自于这俩篇 一文读懂目标检测：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD， 一文读懂Faster RCNN R-CNN Region Proposal + CNN。预先找出图中目标可能出现的位置，即候选区域（Region Proposal）。剩下的工作实际就是对候选区域进行图像分类的工作（特征提取+分类）。 R-CNN的简要步骤如下 (1) 输入测试图像 (2) 利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal (3) 因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征 SPP Net的第一个贡献就是在最后一个卷积层后，接入了金字塔池化层，保证传到下一层全连接层的输入固定。 换句话说，在普通的CNN机构中，输入图像的尺寸往往是固定的（比如224*224像素），输出则是一个固定维数的向量。SPP Net在普通的CNN结构中加入了ROI池化层（ROI Pooling），使得网络的输入图像可以是任意尺寸的，输出则不变，同样是一个固定维数的向量。 SPP Net R-CNN虽然不再像传统方法那样穷举，但R-CNN流程的第一步中对原始图片通过Selective Search提取的候选框region proposal多达2000个左右，而这2000个候选框每个框都需要进行CNN提特征+SVM分类，计算量很大，导致R-CNN检测速度很慢，一张图都需要47s。 有没有方法提速呢？答案是有的，这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。 但现在的问题是每个region proposal的尺度不一样，而全连接层输入必须是固定的长度，所以直接这样输入全连接层肯定是不行的。SPP Net恰好可以解决这个问题。 SPP-Net是出自2015年发表在IEEE上的论文-《Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition》。 CNN一般都含有卷积部分和全连接部分，其中，卷积层不需要固定尺寸的图像，而全连接层是需要固定大小的输入。所以当全连接层面对各种尺寸的输入数据时，就需要对输入数据进行crop（crop就是从一个大图扣出网络输入大小的patch，比如227×227），或warp（把一个边界框bounding box的内容resize成227×227）等一系列操作以统一图片的尺寸大小，比如224224（ImageNet）、3232(LenNet)、96*96等。 但warp/crop这种预处理，导致的问题要么被拉伸变形、要么物体不全，限制了识别精确度。没太明白？说句人话就是，一张16:9比例的图片你硬是要Resize成1:1的图片，你说图片失真不？ SPP Net的作者Kaiming He等人逆向思考，既然由于全连接FC层的存在，普通的CNN需要通过固定输入图片的大小来使得全连接层的输入固定。那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使得后面全连接层得到的输入变成固定的呢？ 这个“化腐朽为神奇”的结构就是spatial pyramid pooling layer。 简言之，CNN原本只能固定输入、固定输出，CNN加上SSP之后，便能任意输入、固定输出 Fast R-CNN R-CNN与Fast R-CNN的区别有哪些呢？ 先说R-CNN的缺点：即使使用了Selective Search等预处理步骤来提取潜在的bounding box作为输入，但是R-CNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。 R-CNN训练过程分为了三个阶段，而Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去Region Proposal提取阶段)。 也就是说，之前R-CNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast R-CNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。 画一画重点： R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。 大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。 解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征 原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归 现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归 Faster R-CNN Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？ 解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。 所以，rgbd在Fast R-CNN中引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题（anchor就是位置和大小固定的box，可以理解成事先设置好的固定的proposal）。 具体做法： 　　• 将RPN放在最后一个卷积层的后面 　　• RPN直接训练得到候选区域 总结一下各大算法的步骤 简言之，即如本文开头所列 R-CNN（Selective Search + CNN + SVM） SPP-net（ROI Pooling） Fast R-CNN（Selective Search + CNN + ROI） Faster R-CNN（RPN + CNN + ROI）","@type":"BlogPosting","url":"https://uzzz.org/2019/08/12/793359.html","headline":"[正在进行中…] KG &amp; object detection","dateModified":"2019-08-12T00:00:00+08:00","datePublished":"2019-08-12T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/12/793359.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>[正在进行中...] KG & object detection</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p></p>
  <div class="toc">
   <h3>文章目录</h3>
   <ul>
    <li><a href="#The_More_You_Know_Using_Knowledge_Graphs_for_Image_Classification_1" rel="nofollow" data-token="b76f95f2ae55dab532c86a89987dbb7f">The More You Know: Using Knowledge Graphs for Image Classification</a></li>
    <ul>
     <li><a href="#_7" rel="nofollow" data-token="9649e63cacf5de0df011ba20401a6381">模型</a></li>
     <li><a href="#_21" rel="nofollow" data-token="298f14d72a5703bd612cb7d8a0f62d66">数据集</a></li>
     <li><a href="#case_37" rel="nofollow" data-token="2170313665bb7cece34fa8ed7bb51483">case</a></li>
    </ul>
    <li><a href="#Object_Detection_Meets_Knowledge_Graphs_40" rel="nofollow" data-token="956097f9ed5b6f719b73820974390ea6">Object Detection Meets Knowledge Graphs</a></li>
    <ul>
     <li><a href="#_55" rel="nofollow" data-token="b7ab578199e91a49e40b8af886479800">方法</a></li>
     <li><a href="#_79" rel="nofollow" data-token="cad537c652a5268635e3a3262858823d">数据集</a></li>
     <li><a href="#case_87" rel="nofollow" data-token="58f5073458ce44ebf6b575bf274b6bb2">case</a></li>
    </ul>
    <li><a href="#Tencent_MLImages_A_LargeScale_MultiLabel_Image_Database_for_Visual_Representation_Learning_98" rel="nofollow" data-token="f899ecefeb5791760dc79693558df5bd">Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning</a></li>
    <li><a href="#_104" rel="nofollow" data-token="f469f27b2c9f7fbe2a66c92a919d731b">基础</a></li>
    <ul>
     <li><a href="#RCNN_108" rel="nofollow" data-token="c88c6ff14d281e8684bac9eaa3e0bf5d">R-CNN</a></li>
     <li><a href="#SPP_Net_118" rel="nofollow" data-token="164d91d41a0206df0336443be4bfa6fd">SPP Net</a></li>
     <li><a href="#Fast_RCNN_137" rel="nofollow" data-token="d6e86956f5fb304af8406d4dae7abdf5">Fast R-CNN</a></li>
     <li><a href="#Faster_RCNN_153" rel="nofollow" data-token="68a9282fcb6c8ede7c4dbf403372cb45">Faster R-CNN</a></li>
     <li><a href="#_164" rel="nofollow" data-token="4b1e77aee67caaa87357234e14bc62df">总结一下各大算法的步骤</a></li>
    </ul>
   </ul>
  </div>
  <p></p> 
  <h1><a id="The_More_You_Know_Using_Knowledge_Graphs_for_Image_Classification_1"></a>The More You Know: Using Knowledge Graphs for Image Classification</h1> 
  <p>paper：<a href="https://arxiv.org/pdf/1612.04844.pdf" rel="nofollow">https://arxiv.org/pdf/1612.04844.pdf</a></p> 
  <p>人类和learning-based CV 算法最大的不同是：人类能够依靠背景知识在可视化世界中做推理。人可以只通过少量的样本了解到这个物品的特征、这个物品和其他物品的关系。</p> 
  <p>本文以KG作为背景知识，基于GGNN（Gated Graph Neural Network），提出Graph Search Neural Network（GSNN）进行多标签图片分类。比较GGNN，GSNN不更新整个graph上的点，1）只更新subset，因此计算效率更高， 2）利用<strong>importance network</strong>为每个结点计算重要程度来挑选subset的，因此有更强的可解释性。</p> 
  <h2><a id="_7"></a>模型</h2> 
  <p><strong>GGNN</strong><br> 1、<strong>propagation network</strong> ：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msubsup>
          <mi>
           h
          </mi>
          <mi>
           v
          </mi>
          <mrow>
           <mo>
            (
           </mo>
           <mi>
            t
           </mi>
           <mo>
            )
           </mo>
          </mrow>
         </msubsup>
        </mrow>
        <annotation encoding="application/x-tex">
         h_v^{(t)}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.16139em; vertical-align: -0.116592em;"></span><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.58341em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathit mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.116592em;"><span class=""></span></span></span></span></span></span></span></span></span></span>:表示结点<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          v
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         v
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span></span></span></span></span>在时间<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          t
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         t
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.61508em; vertical-align: 0em;"></span><span class="mord mathit">t</span></span></span></span></span>的隐层状态，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msubsup>
          <mi>
           A
          </mi>
          <mi>
           v
          </mi>
          <mi>
           T
          </mi>
         </msubsup>
        </mrow>
        <annotation encoding="application/x-tex">
         A_v^T
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.08833em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathit">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是邻接矩阵。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190705151159634.png" alt="在这里插入图片描述"><br> <strong>GSNN</strong><br> 1、首先用 Faster R-CNN得到80类的基础分类结果，将概率大于某个阈值的node拿出来作为初始的active node<br> 2、训练<strong>importance network</strong>得到对于已有的active node来说top p重要的nodes进行下一步扩展。---- 为了训练importance network，我们需要对给定的图像为每个node安排重要度。安排的原则是：如果node是ground truth concept，则重要度为1，若是一跳的，重要度为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          λ
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \lambda
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">λ</span></span></span></span></span>，若是两跳，重要度为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msup>
          <mi>
           λ
          </mi>
          <mn>
           2
          </mn>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         \lambda^2
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.814108em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>，即：靠近最终输出在扩展的时候是最重要的。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190705151101234.png" alt="在这里插入图片描述"></p> 
  <p>3、 <strong>output network</strong> 通过BCE(Binary Cross Entropy)训练。相比GGNN的<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          g
         </mi>
         <mo>
          (
         </mo>
         <msubsup>
          <mi>
           h
          </mi>
          <mi>
           v
          </mi>
          <mrow>
           <mo>
            (
           </mo>
           <mi>
            T
           </mi>
           <mo>
            )
           </mo>
          </mrow>
         </msubsup>
         <mo separator="true">
          ,
         </mo>
         <msub>
          <mi>
           x
          </mi>
          <mi>
           v
          </mi>
         </msub>
         <mo>
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         g(h_v^{(T)},x_v)
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.2948em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.58341em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.116592em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>,GSNN多了bias term <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           n
          </mi>
          <mi>
           v
          </mi>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         n_v
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，原因文中有提到。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           L
          </mi>
          <mo>
           =
          </mo>
          <mi>
           g
          </mi>
          <mo>
           (
          </mo>
          <msubsup>
           <mi>
            h
           </mi>
           <mi>
            v
           </mi>
           <mrow>
            <mo>
             (
            </mo>
            <mi>
             T
            </mi>
            <mo>
             )
            </mo>
           </mrow>
          </msubsup>
          <mo separator="true">
           ,
          </mo>
          <msub>
           <mi>
            x
           </mi>
           <mi>
            v
           </mi>
          </msub>
          <mo separator="true">
           ,
          </mo>
          <msub>
           <mi>
            n
           </mi>
           <mi>
            v
           </mi>
          </msub>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          L=g(h_v^{(T)}, x_v, n_v)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit">L</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathit mtight" style="margin-right: 0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p> 
  <h2><a id="_21"></a>数据集</h2> 
  <p>目标检测：</p> 
  <ul> 
   <li> <p>COCO</p> </li> 
   <li> <p>Visual Genome dataset：100,000张图片，每个被标记为object，attributes and object之间/object和attribute之间的relations.每张图片平均21 labels。</p> </li> 
   <li> <p>VGML：论文构建的数据集，基于Visual Genome dataset中200个最常见的object，100个最常见的attributes，还有coco中多的16个，共316个visual concepts。</p> </li> 
  </ul> 
  <p>KG：通过Visual Genome dataset + WordNet进行构建。因为Visual Genome dataset 包含了<strong>scene-level relationships between objects</strong>，但是没有包含semantic relation，因此加入wordnet进行扩充。</p> 
  <p>实验结果：<br> 1、 VG：Visual Genome graph ，WN：WordNet graph.<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812211431288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 2、训练样本数量对结果的影响<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019081221210689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 3、在coco上的效果：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812212521104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="case_37"></a>case</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019081221343035.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h1><a id="Object_Detection_Meets_Knowledge_Graphs_40"></a>Object Detection Meets Knowledge Graphs</h1> 
  <p>链接：<a href="https://www.ijcai.org/proceedings/2017/0230.pdf" rel="nofollow" data-token="502654def03977d9b862e0a6a00b0be9">https://www.ijcai.org/proceedings/2017/0230.pdf</a><br> 在原始目标检测的优化过程中添加“semantic consistency”的约束进行优化，“semantic consistency”来自于背景知识。最终的实验结果是在不降低precision值的情况下recall相比之前提升6.3。</p> 
  <p>“semantic consistency”的理解：基于“家猫可能会坐在盘子上，而熊不会”这样的背景知识，1）即使训练的时候没有样本是关于 “猫、桌子”的，测试也可能会预测出来；2）当目标检测检测出来“熊”和“桌子”时候，这和背景知识是冲突的。</p> 
  <p>方法的两个技术难点是：<br> 1）如何量化背景知识<br> 因为KG一般是通过symbolic表示，而目标检测中subsymbolic或numerical表示上操作的，一次需要量化。文中提出量化的方式是为每对concepts计算numerical表示的语义一致度。如在KG中又“cat sits on table”，说明cat and table是语义一致的概念，而熊不是。</p> 
  <blockquote> 
   <p>！！！！【这里提到“cat licks plate” and “plate placed on table”.需要看下怎么做的？？？】</p> 
  </blockquote> 
  <p>2）如何将语义一致性应用到我们的任务中<br> 基于假设：“语义一致性高的更倾向于在同一张图片中出现”。如果用<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mo>
          (
         </mo>
         <mi>
          o
         </mi>
         <mo separator="true">
          ,
         </mo>
         <mi>
          p
         </mi>
         <mo>
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         (o,p)
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathit">o</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathit">p</span><span class="mclose">)</span></span></span></span></span>表示<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          o
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         o
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">o</span></span></span></span></span>有<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          p
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         p
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathit">p</span></span></span></span></span>的概率出现在图像中，那么(cat,0.8) &amp; (table,0.9) 看起来会比(bear,0.8) &amp; (table,0.9)更合理，模型可能会将后者纠正为(bear,0.01) &amp; (table,0.9)。论文将这种约束映射为一个优化问题。</p> 
  <h2><a id="_55"></a>方法</h2> 
  <p>原始的目标检测：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
         <mo>
          =
         </mo>
         <mi>
          B
         </mi>
         <mo>
          ∗
         </mo>
         <mi>
          L
         </mi>
         <mo>
          ∈
         </mo>
         <mi mathvariant="double-struck">
          R
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         P = B * L \in \mathbb{R}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05017em;">B</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72243em; vertical-align: -0.0391em;"></span><span class="mord mathit">L</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68889em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span></span> ，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           P
          </mi>
          <mrow>
           <mi>
            b
           </mi>
           <mo separator="true">
            ,
           </mo>
           <mi>
            l
           </mi>
          </mrow>
         </msub>
         <mo>
          =
         </mo>
         <mi>
          p
         </mi>
         <mo>
          (
         </mo>
         <mi>
          l
         </mi>
         <mi mathvariant="normal">
          ∣
         </mi>
         <mi>
          b
         </mi>
         <mo>
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex">
         P_{b,l}=p(l|b)
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">b</span><span class="mpunct mtight">,</span><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="mord">∣</span><span class="mord mathit">b</span><span class="mclose">)</span></span></span></span></span>表示图像的bounding box <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          b
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         b
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span></span></span></span></span>被打标为label <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          l
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         l
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.01968em;">l</span></span></span></span></span>的概率为<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <msub>
          <mi>
           P
          </mi>
          <mrow>
           <mi>
            b
           </mi>
           <mo separator="true">
            ,
           </mo>
           <mi>
            l
           </mi>
          </mrow>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         P_{b,l}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">b</span><span class="mpunct mtight">,</span><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span><br> KG-aware目标检测：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           P
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{P}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.94677em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.94677em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span></span></span><span class="" style="top: -3.25233em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.16666em;">^</span></span></span></span></span></span></span></span></span></span>是经过“semantic consistency”纠正后的<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         P
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span></span></span></span></span>，即文章中提到的“<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           P
          </mi>
          <mo>
           ^
          </mo>
         </mover>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{P}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.94677em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.94677em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span></span></span><span class="" style="top: -3.25233em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.16666em;">^</span></span></span></span></span></span></span></span></span></span> is a knowledge-aware enhancement of <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          P
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         P
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.13889em;">P</span></span></span></span></span>”<br> 目标检测输出：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mover accent="true">
          <mi>
           l
          </mi>
          <mo>
           ^
          </mo>
         </mover>
         <mo>
          =
         </mo>
         <mi>
          a
         </mi>
         <mi>
          r
         </mi>
         <mi>
          g
         </mi>
         <mi>
          m
         </mi>
         <mi>
          a
         </mi>
         <msub>
          <mi>
           x
          </mi>
          <mi>
           l
          </mi>
         </msub>
         <msub>
          <mover accent="true">
           <mi>
            P
           </mi>
           <mo>
            ^
           </mo>
          </mover>
          <mrow>
           <mi>
            b
           </mi>
           <mo separator="true">
            ,
           </mo>
           <mi>
            l
           </mi>
          </mrow>
         </msub>
        </mrow>
        <annotation encoding="application/x-tex">
         \hat{l}=argmax_l\hat{P}_{b,l}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.95788em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.95788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span></span></span><span class="" style="top: -3.26344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.16666em;">^</span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.23288em; vertical-align: -0.286108em;"></span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit" style="margin-right: 0.03588em;">g</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.94677em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">P</span></span></span><span class="" style="top: -3.25233em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.16666em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">b</span><span class="mpunct mtight">,</span><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
  <blockquote> 
   <p>1）这里看到目标检测是需要box的，且box固定的？<br> 2）预测的结果看来是单分类的？不是，是每个box一个label</p> 
  </blockquote> 
  <p>针对上述两个技术难点：<br> 1、如何量化背景知识。Semantic Consistency，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          S
         </mi>
         <mo>
          ∈
         </mo>
         <msup>
          <mi mathvariant="double-struck">
           R
          </mi>
          <mrow>
           <mi>
            L
           </mi>
           <mo separator="true">
            ,
           </mo>
           <mi>
            L
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation encoding="application/x-tex">
         S \in \mathbb{R}^{L,L}
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.72243em; vertical-align: -0.0391em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">L</span><span class="mpunct mtight">,</span><span class="mord mathit mtight">L</span></span></span></span></span></span></span></span></span></span></span></span></span>，有“Frequency-based knowledge“和“Graph-based knowledge“两种方式计算。</p> 
  <ul> 
   <li>Frequency-based knowledge，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           N
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          N
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.10903em;">N</span></span></span></span></span>是KG中总instances数量，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           n
          </mi>
          <mo>
           (
          </mo>
          <mi>
           l
          </mi>
          <mo separator="true">
           ,
          </mo>
          <msup>
           <mi>
            l
           </mi>
           <mo mathvariant="normal">
            ′
           </mo>
          </msup>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          n(l,l&amp;#x27;)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.00189em; vertical-align: -0.25em;"></span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>是<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           l
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          l
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.01968em;">l</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msup>
           <mi>
            l
           </mi>
           <mo mathvariant="normal">
            ′
           </mo>
          </msup>
         </mrow>
         <annotation encoding="application/x-tex">
          l&amp;#x27;
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.751892em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span>共现频率<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812163023119.png" alt="在这里插入图片描述"><br> 明显这种方式不能处理KG中没有直接相连的实体对，即多跳关系的实体对。</li> 
  </ul> 
  <blockquote> 
   <p>KG中的N是总instance数量是entity数量吗？</p> 
  </blockquote> 
  <ul> 
   <li>Graph-based knowledge。“random walk with restart”的思想，会构造出从<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi>
            v
           </mi>
           <mn>
            0
           </mn>
          </msub>
         </mrow>
         <annotation encoding="application/x-tex">
          v_0
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>到<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi>
            v
           </mi>
           <mi>
            t
           </mi>
          </msub>
         </mrow>
         <annotation encoding="application/x-tex">
          v_t
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的路径<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi>
            v
           </mi>
           <mn>
            0
           </mn>
          </msub>
          <mo separator="true">
           ,
          </mo>
          <msub>
           <mi>
            v
           </mi>
           <mn>
            1
           </mn>
          </msub>
          <mo separator="true">
           ,
          </mo>
          <mi mathvariant="normal">
           .
          </mi>
          <mi mathvariant="normal">
           .
          </mi>
          <mi mathvariant="normal">
           .
          </mi>
          <msub>
           <mi>
            v
           </mi>
           <mi>
            t
           </mi>
          </msub>
         </mrow>
         <annotation encoding="application/x-tex">
          v_0,v_1,...v_t
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，让<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           p
          </mi>
          <mo>
           (
          </mo>
          <msub>
           <mi>
            v
           </mi>
           <mi>
            t
           </mi>
          </msub>
          <mo>
           =
          </mo>
          <msup>
           <mi>
            l
           </mi>
           <mo mathvariant="normal">
            ′
           </mo>
          </msup>
          <mi mathvariant="normal">
           ∣
          </mi>
          <msub>
           <mi>
            v
           </mi>
           <mn>
            0
           </mn>
          </msub>
          <mo>
           =
          </mo>
          <mi>
           l
          </mi>
          <mo separator="true">
           ;
          </mo>
          <mi>
           α
          </mi>
          <mo>
           )
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          p(v_t=l&amp;#x27;|v_0=l;\alpha)
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.00189em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathit" style="margin-right: 0.0037em;">α</span><span class="mclose">)</span></span></span></span></span>表示从<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           l
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          l
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.01968em;">l</span></span></span></span></span>到经过<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           t
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          t
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.61508em; vertical-align: 0em;"></span><span class="mord mathit">t</span></span></span></span></span>步之后到达<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msup>
           <mi>
            l
           </mi>
           <mo mathvariant="normal">
            ′
           </mo>
          </msup>
         </mrow>
         <annotation encoding="application/x-tex">
          l&amp;#x27;
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.751892em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span>的概率。经过很长的游走之后，概率<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           p
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          p
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathit">p</span></span></span></span></span>会收敛到<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
        <math>
         <semantics>
          <mrow>
           <msub>
            <mi>
             R
            </mi>
            <mrow>
             <mi>
              l
             </mi>
             <mo separator="true">
              ,
             </mo>
             <msup>
              <mi>
               l
              </mi>
              <mo mathvariant="normal">
               ′
              </mo>
             </msup>
            </mrow>
           </msub>
           <mo>
            =
           </mo>
           <munder>
            <mi>
             lim
            </mi>
            <mo>
             ⁡
            </mo>
            <mrow>
             <mi>
              t
             </mi>
             <mo>
              →
             </mo>
             <mi mathvariant="normal">
              ∞
             </mi>
            </mrow>
           </munder>
           <mi>
            p
           </mi>
           <mo>
            (
           </mo>
           <msub>
            <mi>
             v
            </mi>
            <mi>
             t
            </mi>
           </msub>
           <mo>
            =
           </mo>
           <msup>
            <mi>
             l
            </mi>
            <mo mathvariant="normal">
             ′
            </mo>
           </msup>
           <mi mathvariant="normal">
            ∣
           </mi>
           <msub>
            <mi>
             v
            </mi>
            <mn>
             0
            </mn>
           </msub>
           <mo>
            =
           </mo>
           <mi>
            l
           </mi>
           <mo separator="true">
            ;
           </mo>
           <mi>
            α
           </mi>
           <mo>
            )
           </mo>
          </mrow>
          <annotation encoding="application/x-tex">
           R_{l,l&amp;#x27;}=\lim_{t \rightarrow\infty }p(v_t=l&amp;#x27;|v_0=l;\alpha)
          </annotation>
         </semantics>
        </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.00773em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.682829em;"><span class="" style="top: -2.786em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.45em; vertical-align: -0.7em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -2.1em; margin-left: 0em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span><span class="mrel mtight">→</span><span class="mord mtight">∞</span></span></span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class=""><span class="mop">lim</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.05189em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.801892em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathit" style="margin-right: 0.01968em;">l</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathit" style="margin-right: 0.0037em;">α</span><span class="mclose">)</span></span></span></span></span></span><br> 这里<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <msub>
           <mi>
            R
           </mi>
           <mrow>
            <mi>
             l
            </mi>
            <mo separator="true">
             ,
            </mo>
            <msup>
             <mi>
              l
             </mi>
             <mo mathvariant="normal">
              ′
             </mo>
            </msup>
           </mrow>
          </msub>
          <mo>
           =
          </mo>
         </mrow>
         <annotation encoding="application/x-tex">
          R_{l,l&amp;#x27;}=
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.00773em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathit mtight" style="margin-right: 0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.682829em;"><span class="" style="top: -2.786em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span></span></span></span></span>不是对称的，上面方法是。<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           S
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          S
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.05764em;">S</span></span></span></span></span>的计算如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812165012340.png" alt="在这里插入图片描述"></li> 
  </ul> 
  <blockquote> 
   <p>和deepwalk的思想差不多，可能deepwalk是参考这个的？</p> 
  </blockquote> 
  <p>2、 如何将语义一致性应用到我们的任务中。回想上述假设：“语义一致性高的更倾向于在同一张图片中出现”，有下面的优化目标。第一项保证语义一致性高的得分近似，第二项保证经过KG纠正后的结果不应该太偏离原始目标检测出来的值。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812165913973.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p>具体的优化过程见论文。</p> 
  </blockquote> 
  <h2><a id="_79"></a>数据集</h2> 
  <p>KG：conceptNet<br> 目标检测：MSCOCO15，PASCAL07<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019081217031223.png" alt="在这里插入图片描述"><br> 在MSCOCO15上结果<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812170439363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> KF-ALL，KF-500是基于frequency-based knowledge，KG-CNet基于graph-based knowledge</p> 
  <h2><a id="case_87"></a>case</h2> 
  <p>下面的图像中，橘黄色的ground-truth label，紫色是检测出来的，左边是FRCNN，右边是KG-CNet。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812171205483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NBUkFDSF9XT05H,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>– 文中的“concept”对应KG中的“entity”</p> 
  <blockquote> 
   <p>restriction for my task:</p> 
   <ol> 
    <li>会设置bouding box数量？</li> 
    <li>最大的问题是要求目标在文中出现，即约束条件中设置了两个出现在图片中的object的出现概率差不多。训练的目标更多是让原始的object detection检测的更全一点。</li> 
   </ol> 
  </blockquote> 
  <h1><a id="Tencent_MLImages_A_LargeScale_MultiLabel_Image_Database_for_Visual_Representation_Learning_98"></a>Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning</h1> 
  <p>paper: <a href="https://arxiv.org/abs/1901.01703" rel="nofollow" data-token="0b29427224cd91024d9d605a27f7144a">https://arxiv.org/abs/1901.01703</a><br> github:<a href="https://github.com/Tencent/tencent-ml-images" rel="nofollow" data-token="542800ac3a2de94d91eebe850f5825bc">https://github.com/Tencent/tencent-ml-images</a></p> 
  <blockquote> 
   <p>为此，我们构建了一个大规模的多标签图像数据库，其中包含 18000000 个图像和 11000 个类别，我们称之为 Tencent ML-Images。我们基于大规模分布式深度学习框架，即 TFplus，在 Tencent ML-Images 上高效训练 ResNet-101 多标签输出模型，共 60 个 epoch，耗时 90 小时,128GPU。 通过 ImageNet 和 Caltech-256 上的单标签图像分类、PASCAL VOC 2007 上的对象检测、PASCAL VOC 2012 上的语义分割三个迁移学习任务，验证了 Tencent ML-Images checkpoint 的视觉表示质量良好。 ----<a href="https://blog.csdn.net/sophia_11/article/details/86326165" rel="nofollow" data-token="8790978174b6fb5d4514fd4a1bb71daa">https://blog.csdn.net/sophia_11/article/details/86326165</a></p> 
  </blockquote> 
  <h1><a id="_104"></a>基础</h1> 
  <p>建议直接看，以下都是来自于这俩篇</p> 
  <ul> 
   <li><a href="https://blog.csdn.net/v_july_v/article/details/80170182" rel="nofollow">一文读懂目标检测：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD</a>，</li> 
   <li><a href="https://zhuanlan.zhihu.com/p/31426458" rel="nofollow" data-token="262745729495f65120eafa49259e1a11">一文读懂Faster RCNN</a></li> 
  </ul> 
  <h2><a id="RCNN_108"></a>R-CNN</h2> 
  <p>Region Proposal + CNN。预先找出图中目标可能出现的位置，即候选区域（Region Proposal）。剩下的工作实际就是对候选区域进行图像分类的工作（特征提取+分类）。<br> R-CNN的简要步骤如下<br> (1) 输入测试图像<br> (2) 利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal<br> (3) 因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征</p> 
  <p>SPP Net的第一个贡献就是在最后一个卷积层后，接入了金字塔池化层，保证传到下一层全连接层的输入固定。<br> 换句话说，在普通的CNN机构中，输入图像的尺寸往往是固定的（比如224*224像素），输出则是一个固定维数的向量。SPP Net在普通的CNN结构中加入了ROI池化层（ROI Pooling），使得网络的输入图像可以是任意尺寸的，输出则不变，同样是一个固定维数的向量。</p> 
  <h2><a id="SPP_Net_118"></a>SPP Net</h2> 
  <p>R-CNN虽然不再像传统方法那样穷举，但R-CNN流程的第一步中对原始图片通过Selective Search提取的候选框region proposal多达2000个左右，而这2000个候选框每个框都需要进行CNN提特征+SVM分类，计算量很大，导致R-CNN检测速度很慢，一张图都需要47s。</p> 
  <p>有没有方法提速呢？答案是有的，这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。</p> 
  <p>但现在的问题是每个region proposal的尺度不一样，而全连接层输入必须是固定的长度，所以直接这样输入全连接层肯定是不行的。SPP Net恰好可以解决这个问题。</p> 
  <p>SPP-Net是出自2015年发表在IEEE上的论文-《Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition》。</p> 
  <p>CNN一般都含有卷积部分和全连接部分，其中，卷积层不需要固定尺寸的图像，而全连接层是需要固定大小的输入。所以当全连接层面对各种尺寸的输入数据时，就需要对输入数据进行crop（crop就是从一个大图扣出网络输入大小的patch，比如227×227），或warp（把一个边界框bounding box的内容resize成227×227）等一系列操作以统一图片的尺寸大小，比如224<em>224（ImageNet）、32</em>32(LenNet)、96*96等。</p> 
  <p>但warp/crop这种预处理，导致的问题要么被拉伸变形、要么物体不全，限制了识别精确度。没太明白？说句人话就是，一张16:9比例的图片你硬是要Resize成1:1的图片，你说图片失真不？</p> 
  <p>SPP Net的作者Kaiming He等人逆向思考，既然由于全连接FC层的存在，普通的CNN需要通过固定输入图片的大小来使得全连接层的输入固定。那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使得后面全连接层得到的输入变成固定的呢？</p> 
  <p>这个“化腐朽为神奇”的结构就是spatial pyramid pooling layer。</p> 
  <p>简言之，CNN原本只能固定输入、固定输出，CNN加上SSP之后，便能任意输入、固定输出</p> 
  <h2><a id="Fast_RCNN_137"></a>Fast R-CNN</h2> 
  <p>R-CNN与Fast R-CNN的区别有哪些呢？<br> 先说R-CNN的缺点：即使使用了Selective Search等预处理步骤来提取潜在的bounding box作为输入，但是R-CNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。</p> 
  <p>R-CNN训练过程分为了三个阶段，而Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去Region Proposal提取阶段)。</p> 
  <p>也就是说，之前R-CNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast R-CNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。</p> 
  <p>画一画重点：<br> R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。<br> 大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。<br> 解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征</p> 
  <p>原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归<br> 现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归</p> 
  <h2><a id="Faster_RCNN_153"></a>Faster R-CNN</h2> 
  <p>Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？</p> 
  <p>解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。</p> 
  <p>所以，rgbd在Fast R-CNN中引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题（anchor就是位置和大小固定的box，可以理解成事先设置好的固定的proposal）。</p> 
  <p>具体做法：<br> 　　• 将RPN放在最后一个卷积层的后面<br> 　　• RPN直接训练得到候选区域</p> 
  <h2><a id="_164"></a>总结一下各大算法的步骤</h2> 
  <p>简言之，即如本文开头所列<br> R-CNN（Selective Search + CNN + SVM）<br> SPP-net（ROI Pooling）<br> Fast R-CNN（Selective Search + CNN + ROI）<br> Faster R-CNN（RPN + CNN + ROI）</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
