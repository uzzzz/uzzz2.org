<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>ELK6.7.2搭建教程 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="ELK6.7.2搭建教程" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="一、ELK简介 &nbsp; &nbsp; &nbsp; &nbsp; ELK是三个开源软件的缩写，分别为：Elasticsearch 、 Logstash以及Kibana , 它们都是开源软件。ELK是一整套日志管理系统，对于日志的集中化管理，日志的统计和检索等都能够完美解决。 二、ELK选型 工作模式1：logstash采集、处理、转发到elasticsearch存储，在kibana进行展示&nbsp; --&nbsp;datasource-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种结构因为需要在各个服务器上部署 Logstash，而它比较消耗 CPU 和内存资源，所以比较适合计算资源丰富的服务器，否则容易造成服务器性能下降，甚至可能导致无法正常工作。 工作模式2：Beats 将搜集到的数据发送到 Logstash，经 Logstash 解析、过滤后，将其发送到 Elasticsearch 存储，并由 Kibana 呈现给用户 --&nbsp;datasource-&gt;filebeat-&gt;logstash-&gt; elasticsearch-&gt;kibana 模式特点：这种架构解决了 Logstash 在各服务器节点上占用系统资源高的问题。相比 Logstash，Beats 所占系统的 CPU 和内存几乎可以忽略不计。另外，Beats 和 Logstash 之间支持 SSL/TLS 加密传输，客户端和服务器双向认证，保证了通信安全。 因此这种架构适合对数据安全性要求较高，同时各服务器性能比较敏感的场景 工作模式3：Filebeat采集完毕直接入到kafka消息队列，进而logstash取出数据，进行处理分析输出到es，并在kibana进行展示。（filebeat版本5.0以上才支持直接输出到kafka） --datasource-&gt;filebeat-&gt;kafka-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种架构适合于日志规模比较庞大的情况。引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性。 总结：以上是目前流行的ELK收集模式，本次搭建ELK主要是收集数据量极大的日志，综合考虑，选择工作模式3进行搭建。 更多ELK工作模式，请参考文档：https://www.cnblogs.com/qingqing74647464/p/9378385.html 三、安装前的准备工作 3.1 服务器 （1）准备8台服务器，以下是服务器配置详情，及用途。 操作系统版本 IP地址 CPU核数 内存大小（G） 磁盘大小（G） 内网访问端口号 内网互通权限 是否需要访问外网 用途 Centos7.6 192.168.1.100 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master1节点及kibana Centos7.6 192.168.1.101 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master2节点 Centos7.6 192.168.1.102 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data1节点 Centos7.6 192.168.1.103 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data2节点 Centos7.6 192.168.1.104 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data3节点 Centos7.6 192.168.1.105 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.106 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.107 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 （2）安装jdk8 参考文档：https://www.cnblogs.com/shihaiming/p/5809553.html （3）关闭防火墙 查看防火墙状态：systemctl status&nbsp;firewalld.service 关闭防火墙：systemctl stop firewalld.service 禁止开机启动防火墙：systemctl disable firewalld.service 3.2 版本信息 Elasticsearch-6.7.2 logstash-6.7.2 kibana-6.7.2 filebeat-6.7.2 kibana-6.7.2 kafka_2.11-2.1.1 zookeeper-3.4.14 kafka-manager-1.3.3.7（kafka界面管理工具）可根据个人情况选用 四、Elasticsearch 4.1&nbsp;Elasticsearch简介 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 4.2&nbsp;Elasticsearch安装 4.2.1 安装 去官网下载elasticsearch的安装包：elasticsearch-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ （1）上传安装包至linux服务器 （2）解压安装包 &nbsp;[root@master1~]# tar -zxvf elasticsearch-6.7.2.tar.gz&nbsp; &nbsp;#解压安装包 4.2.2 配置 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch主要有两个配置文件，elasticsearch.yml&nbsp;文件用于配置集群节点等相关信息的，elasticsearch&nbsp;文件则是配置服务本身相关的配置，例如某个配置文件的路径以及java的一些路径配置什么的。 开始配置集群节点，在 192.168.1.100上编辑配置文件： [root@master1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-1&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.101 [root@master2 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-2&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.102 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-1&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.103 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-2&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.104 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-3&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 依此启动 [root@master1 ~]# cd /usr/elasticsearch/elasticsearch-6.7.2/bin/ [root@master1 bin]# ./elasticsearch -d 可能遇到的问题： 1、报错：can not run elasticsearch as root &nbsp; &nbsp; &nbsp; &nbsp; 使用root账户启动造成的报错，这是出于系统安全考虑设置的条件。由于ElasticSearch可以接收用户输入的脚本并且执行，为了系统安全考虑，建议创建一个单独的用户用来运行ElasticSearch。 创建elsearch用户组及elsearch用户 &nbsp; &nbsp; groupadd elsearch &nbsp; &nbsp; useradd elsearch -g elsearch -p elasticsearch 更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch &nbsp; &nbsp; cd /usr &nbsp; &nbsp; chown -R elsearch:elsearch &nbsp;elasticsearch-6.7.2 切换到elsearch用户再启动 &nbsp; &nbsp; su elsearch cd elasticsearch/bin &nbsp; &nbsp; ./elasticsearch -d 2、max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 每个进程最大同时打开文件数太小，可通过下面2个命令查看当前数量 修改/etc/security/limits.conf文件，增加配置，用户退出后重新登录生效 * &nbsp;soft &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;65536 * &nbsp;hard &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;131072 * &nbsp;soft &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited * &nbsp;hard &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited 3、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elasticsearch用户拥有的内存权限太小，至少需要262144&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;由于ES构建基于lucene, 而lucene设计强大之处在于lucene能够很好的利用操作系统内存来缓存索引数据，以提供快速的查询性能。lucene的索引文件segements是存储在单文件中的，并且不可变，对于OS来说，能够很友好地将索引文件保持在cache中，以便快速访问；因此，我们很有必要将一半的物理内存留给lucene ; 另一半的物理内存留给ES（JVM heap )。所以， 在ES内存设置方面，可以遵循以下原则： 1.当机器内存小于64G时，遵循通用的原则，50%给ES，50%留给lucene。 2.当机器内存大于64G时，遵循以下原则：&nbsp; a.如果主要的使用场景是全文检索, 那么建议给ES Heap分配 4~32G的内存即可；其它内存留给操作系统, 供lucene使用（segments cache), 以提供更快的查询性能。&nbsp; b.如果主要的使用场景是聚合或排序， 并且大多数是numerics, dates, geo_points 以及not_analyzed的字符类型， 建议分配给ES Heap分配 4~32G的内存即可，其它内存留给操作系统，供lucene使用(doc values cache)，提供快速的基于文档的聚类、排序性能。&nbsp; c.如果使用场景是聚合或排序，并且都是基于analyzed 字符数据，这时需要更多的 heap size, 建议机器上运行多ES实例，每个实例保持不超过50%的ES heap设置(但不超过32G，堆内存设置32G以下时，JVM使用对象指标压缩技巧节省空间)，50%以上留给lucene。 更多es性能调优参数，参考文档：https://www.jianshu.com/p/532b540d4c46 解决办法： 在&nbsp;&nbsp;&nbsp;/etc/sysctl.conf文件最后添加一行 vm.max_map_count=262144 执行sysctl -p 即可永久修改 参考数据（4g/4194304 &nbsp;8g/8388608）如果申请16G的内存，可适当将vm.max_map_count=4194304或8388608 4.2.3 curl查看es集群情况 依此成功启动es的各个集群节点，查看集群的状态： [root@master1&nbsp;~]# curl &#39;192.168.1.100:9200/_cluster/health?pretty&#39; { &nbsp; &quot;cluster_name&quot; : &quot;master-slave&nbsp;&quot;, &nbsp; &quot;status&quot; : &quot;green&quot;, &nbsp;# 为green则代表健康没问题，如果是yellow或者red则是集群有问题 &nbsp; &quot;timed_out&quot; : false, &nbsp;# 是否有超时 &nbsp; &quot;number_of_nodes&quot; : 5, # 集群中的节点数量 &nbsp; &quot;number_of_data_nodes&quot; : 3, # 集群中data节点的数量 &nbsp; &quot;active_primary_shards&quot; : 0, &nbsp; &quot;active_shards&quot; : 0, &nbsp; &quot;relocating_shards&quot; : 0, &nbsp; &quot;initializing_shards&quot; : 0, &nbsp; &quot;unassigned_shards&quot; : 0, &nbsp; &quot;delayed_unassigned_shards&quot; : 0, &nbsp; &quot;number_of_pending_tasks&quot; : 0, &nbsp; &quot;number_of_in_flight_fetch&quot; : 0, &nbsp; &quot;task_max_waiting_in_queue_millis&quot; : 0, &nbsp; &quot;active_shards_percent_as_number&quot; : 100.0 } 更多使用curl命令操作elasticsearch的内容，参考文档：http://zhaoyanblog.com/archives/732.html 五、kibana 5.1 kibana简介 &nbsp; &nbsp; &nbsp; &nbsp;Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 5.2 kibana安装 5.2.1 安装 去官网下载kibana的安装包：kibana-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@master1&nbsp;~]# tar -zxvf kibana-6.7.2.tar.gz 5.2.2 配置 安装完成后，对kibana进行配置： [root@master1 ~]# vim /usr/kibana/kibana-6.7.2-linux-x86_64/config/kibana.yml &nbsp;# 增加以下内容 server.port: 5601 &nbsp;# 配置kibana的端口 server.host: 192.168.1.100&nbsp; # 配置监听ip elasticsearch.hosts: [&quot;http://192.168.1.100:9200&quot;,&quot;http://192.168.1.101:9200&quot;] &nbsp;# 配置es服务器的ip，如果是集群则配置该集群中主节点的ip logging.dest: /var/log/kibana.log &nbsp;# 配置kibana的日志文件路径，不然默认是messages里记录日志 创建日志文件： [root@master-node ~]# touch /var/log/kibana.log 启动kibana服务，并检查进程和监听端口： [root@master1 ~]# cd /usr/kibana/kibana-6.7.2-linux-x86_64/bin/ [root@master1 bin]# ./kibana &amp;&nbsp; [root@master1 ~]# ps aux |grep kibana kibana &nbsp; &nbsp; 3083 36.8 &nbsp;2.9 1118668 112352 ? &nbsp; &nbsp; &nbsp;Ssl &nbsp;17:14 &nbsp; 0:03 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kibana/bin/../src/cli -c /etc/kibana/kibana.yml root &nbsp; &nbsp; &nbsp; 3095 &nbsp;0.0 &nbsp;0.0 112660 &nbsp; 964 pts/0 &nbsp; &nbsp;S+ &nbsp; 17:14 &nbsp; 0:00 grep --color=auto kibana [root@master1 ~]# netstat -lntp |grep 5601 tcp &nbsp; &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;0 192.168.1.100:5601 &nbsp; &nbsp; 0.0.0.0:* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LISTEN &nbsp; &nbsp; &nbsp;3083/node &nbsp; &nbsp; 然后在浏览器里进行访问，如：http://192.168.1.100:5601/&nbsp;，由于我们并没有安装x-pack，所以此时是没有用户名和密码的，可以直接访问的。 点击Index Patterns,创建新索引 六、Logstash 6.1&nbsp;Logstash简介 &nbsp; &nbsp; &nbsp; &nbsp; Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去 6.2 Logstash安装 6.2.1 安装 去官网下载logstash的安装包：logstash-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@logstash1 ~]# tar -zxvf logstash-6.7.2.tar.gz 6.2.2 配置 安装完之后，先不要启动服务，先配置logstash收集kafka日志： [root@logstash1 ~]# cd /usr/logstash-6.7.2/bin/ [root@logstash1 bin]# mkdir conf.d [root@logstash1 ~]# vim conf.d/first-demo.conf &nbsp;# 加入如下内容 input{ &nbsp; &nbsp; kafka { &nbsp; &nbsp; &nbsp; &nbsp; bootstrap_servers =&gt; &quot;192.168.1.105:9092,192.168.1.106:9092,192.168.1.107:9092&quot; &nbsp; &nbsp; &nbsp; &nbsp; topics =&gt; [&quot;test&quot;] &nbsp; &nbsp; &nbsp; &nbsp; group_id =&gt; &quot;consumer-test&quot; &nbsp; &nbsp; } } output { &nbsp; &nbsp; elasticsearch { &nbsp; &nbsp; &nbsp; &nbsp; hosts =&gt; [&quot;192.168.1.100:9200&quot;,&quot;192.168.1.101:9200&quot;,&quot;192.168.1.102:9200&quot;,&quot;192.168.1.103:9200&quot;,&quot;192.168.1.104:9200&quot;] &nbsp; &nbsp; &nbsp; &nbsp; index =&gt; &quot;server-test-%{+YYYY.MM.dd}&quot; &nbsp; &nbsp; } } 检测配置文件是否有错： [root@logstash1 ~]# cd /usr/logstash/bin [root@logstash1&nbsp;bin]# ./logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/syslog.conf --config.test_and_exit Sending Logstash&#39;s logs to /var/log/logstash which is now configured via log4j2.properties Configuration OK &nbsp;# 为ok则代表配置文件没有问题 [root@logstash1&nbsp;bin]#&nbsp; 命令说明： --path.settings 用于指定logstash的配置文件所在的目录 -f 指定需要被检测的配置文件的路径 --config.test_and_exit 指定检测完之后就退出，不然就会直接启动了 &nbsp; &nbsp; &nbsp; &nbsp;当然你必须要先搭建kafka集群，并创建对应topic，所以这里先不启动logstash，以上是192.168.1.105服务器的配置，根据个人需要，可在192.168.1.106、192.168.1.107服务器上安装logtash，实现logstash集群，也可以单机启动多个logstash，实现单机多节点。 编辑logstash.yml [root@logstash1 ~]$ cd /usr/logstash-6.7.2/config/ [root@logstash1 config]$ vim logstash.yml path.logs: /usr/logstash-6.7.2/logstash-data/log &nbsp;#日志路径 path.config: /usr/logstash-6.7.2/bin/conf.d/*.conf &nbsp;#配置文件路径(支持正则) path.data: /usr/logstash-6.7.2/logstash-data/data &nbsp;#logstash数据保存路径 http.host: &quot;192.168.1.105&quot; &nbsp;#主机ip 启动命令： [root@logstash1 ~]# cd /usr/logstash-6.7.2 [root@logstash1 logstash-6.7.2]# nohup ./bin/logstash -f ./bin/conf.d/first-demo.conf &gt; ./bin/nohup.out &amp; 七、kafka 7.1 安装zookeeper 7.1.1 下载 去官网下载zookeeper的安装包：zookeeper-3.4.14.tar.gz 地址：https://www-eu.apache.org/dist/zookeeper/zookeeper-3.4.14/ 7.1.2 解压 tar -zxvf&nbsp;&nbsp;zookeeper-3.4.10.tar.gz 用192.168.1.105、192.168.1.106、192.168.1.107三台服务器做kakfa集群，当前配置实例为192.168.1.105 [root@logstash1 ~]$ cd /usr/zookeeper-3.4.14 [root@logstash1 zookeeper-3.4.14]$ mkdir data [root@logstash1 zookeeper-3.4.14]$ mkdir log #在每一个数据文件目录中，新建一个myid文件，文件必须是唯一的服务标识，在后面的配置中会用到 [root@logstash1 zookeeper-3.4.14]$ echo &#39;1&#39; &gt; data/myid #复制出zoo.cfg文件: [root@logstash1 zookeeper-3.4.14]$ cp conf/zoo_sample.cfg conf/zoo.cfg 7.1.3 配置 vim zoo.cfg # The number of milliseconds of each tick &nbsp; tickTime=2000 &nbsp; # The number of ticks that the initial &nbsp;&nbsp; # synchronization phase can take &nbsp; initLimit=10 &nbsp; # The number of ticks that can pass between &nbsp;&nbsp; # sending a request and getting an acknowledgement &nbsp; syncLimit=5 &nbsp; # the directory where the snapshot is stored. &nbsp; # do not use /tmp for storage, /tmp here is just &nbsp;&nbsp; # example sakes. &nbsp; #存储路径 dataDir=/实际路径/zookeeper-cluster/data&nbsp;&nbsp; #日志路径，方便查LOG dataLogDir=/实际路径/zookeeper-cluster/log # the port at which the clients will connect &nbsp; clientPort=2181 &nbsp; # the maximum number of client connections. &nbsp; # increase this if you need to handle more clients &nbsp; #控制客户的连接数，默认数为60，太少 maxClientCnxns=300 #maxClientCnxns=60 &nbsp; # &nbsp; # Be sure to read the maintenance section of the &nbsp;&nbsp; # administrator guide before turning on autopurge. &nbsp; # &nbsp; #http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance &nbsp; # &nbsp; # The number of snapshots to retain in dataDir &nbsp; #autopurge.snapRetainCount=3 &nbsp; # Purge task interval in hours &nbsp; # Set to &quot;0&quot; to disable auto purge feature &nbsp; #autopurge.purgeInterval=1 &nbsp; #zookeeper集群地址（本机的ip填0.0.0.0） server.1=0.0.0.0:2888:3888 server.2=192.168.1.106:2888:3888 server.3=192.168.1.107:2888:3888 192.168.1.106、192.168.1.107服务器的配置类似，请参考192.168.1.105服务器配置。 7.1.4 启动 分别启动3个zookeeper服务 $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; 启动完成后查看每个服务的状态 $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status 7.2 安装kafka 7.2.1 下载 去官网下载kafka的安装包：kafka_2.11-2.1.1.tgz 地址：http://kafka.apache.org/downloads 7.2.2 解压 tar zxvf kafka_2.11-2.1.1.tgz 7.2.3 配置 以192.168.1.105为例 [root@logstash1 ~]$ cd /usr/kafka_2.11-2.1.1/config/server.properties #配置zookeeper连接,默认Kafka会使用ZooKeeper默认的/路径，这样有关Kafka的ZooKeeper配置就会散落在根路径下面，如果你有其他的应用也在使用ZooKeeper集群，查看ZooKeeper中数据可能会不直观，所以强烈建议指定一个chroot路径，直接在zookeeper.connect配置项中指定 zookeeper.connect=192.168.1.105:2181, 192.168.1.106:2181, 192.168.1.107:2181/kafka #每个Kafka Broker应该配置一个唯一的ID&nbsp; broker.id=0&nbsp; #端口号 port=9092 #如果有多个网卡地址，也可以将不同的Broker绑定到不同的网卡 &nbsp; host.name=192.168.1.105 #日志目录 log.dirs=/usr/kafka_2.11-2.1.1/logs #设置topic可删除，默认该项是被注释的，需要放开 delete.topic.enable=true #关闭自动创建topic，默认情况下Producer往一个不存在的Topic发送message时会自动创建这个Topic auto.create.topics.enable=false 7.2.4 启动 kafka_2.11-2.1.1/bin/kafka-server-start.sh kafka_2.11-2.1.1/config/server.properties &amp; 7.2.5 关闭 kafka_2.11-2.1.1/bin/kafka-server-stop.sh 7.2.6 topic 7.2.6.1 创建topic kafka_2.11-2.1.1/bin/kafka-topics.sh -topic test -create -partitions 3 -replication-factor 1 -zookeeper 192.168.1.105:2181/kafka -topic 主题名称 -partitions 分区 -replication-factor 副本 7.2.6.2 查看指定topic属性 kafka_2.11-2.1.1/bin/kafka-topics.sh -describe -zookeeper 192.168.1.105:2181/kafka -topic test 7.2.6.3 查看topic列表 kafka_2.11-2.1.1/bin/kafka-topics.sh -list -zookeeper 192.168.1.105:2181/kafka 7.2.6.4 创建生产者 kafka_2.11-2.1.1/bin/kafka-console-producer.sh -broker-list localhost:9092 -topic test 7.2.6.5 创建消费者 #重新打开一个ssh连接执行以下命令 kafka_2.11-2.1.1/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 7.2.6.6 测试 在生成者连接中输入内容.&nbsp; test&nbsp; 在消费者连接中查看是否接收到消息 7.3 kafka相关配置参数 broker.id &nbsp;整数，建议根据ip区分 &nbsp;　 log.dirs &nbsp;kafka存放消息文件的路径， &nbsp;默认/tmp/kafka-logs port &nbsp;broker用于接收producer消息的端口 &nbsp;　 zookeeper.connnect &nbsp;zookeeper连接 &nbsp;格式为 &nbsp;ip1:port,ip2:port,ip3:port message.max.bytes &nbsp;单条消息的最大长度 &nbsp;　 num.network.threads &nbsp;broker用于处理网络请求的线程数 &nbsp;如不配置默认为3，server.properties默认是2 num.io.threads &nbsp;broker用于执行网络请求的IO线程数 &nbsp;如不配置默认为8，server.properties默认是2可适当增大， queued.max.requests &nbsp;排队等候IO线程执行的requests &nbsp;默认为500 host.name &nbsp;broker的hostname &nbsp;默认null,建议写主机的ip,不然消费端不配置hosts会有麻烦 num.partitions &nbsp;topic的默认分区数 &nbsp;默认1 log.retention.hours &nbsp;消息被删除前保存多少小时 &nbsp;默认1周168小时 auto.create.topics.enable &nbsp;是否可以程序自动创建Topic &nbsp;默认true,建议false default.replication.factor &nbsp;消息备份数目 &nbsp;默认1不做复制，建议修改 num.replica.fetchers &nbsp;用于复制leader消息到follower的IO线程数 &nbsp;默认1 参考文档：https://blog.csdn.net/henianyou/article/details/75976052 至此，zookeeper以及kafka集群搭建成功。 八、filebeat 8.1 filebeat简介 &nbsp; &nbsp; &nbsp; &nbsp;beats是ELK体系中新增的一个工具，它属于一个轻量的日志采集器，以上我们使用的日志采集工具是logstash，但是logstash占用的资源比较大，没有beats轻量。 &nbsp; &nbsp; &nbsp; &nbsp;filebeat是用go编写，logstash使用ruby写的。Logstash会占用不少的jvm。 当然，也不是filebeat完全占优，filebeat也专注于采集而已，所以这也是为什么很多架构都是filebeat后面接着logstash来做信息转换。 8.2 filebeat安装 8.2.1 安装 去官网下载filebeat的安装包：filebeat-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@server ~]# tar -zxvf filebeat-6.7.2.tar.gz 说明：filebeat为日志采集工具，一般是安装在应用服务器。 8.2.2 配置 [root@server ~]# vim /usr/filebeat-6.7.2-linux-x86_64/filebeat.yml &nbsp;# 增加或者更改为以下内容 filebeat.prospectors: &nbsp;- input_type: log &nbsp;#除了&quot;log&quot;，还有&quot;stdin&quot; paths: &nbsp; &nbsp; - /tmp/*.log &nbsp; #读取文件路径 &nbsp; &nbsp;#include_lines: [&#39;ERROR&#39;] &nbsp; #只发送包含这些字样的日志 &nbsp; &nbsp;multiline: &nbsp; &nbsp;&nbsp; &nbsp;#&nbsp;&nbsp; &nbsp;多行合并 &nbsp; &nbsp; &nbsp; pattern: &#39;^\d{4}-\d{1,2}-\d{1,2}&#39; &nbsp;#日期开头的 &nbsp; &nbsp; &nbsp; negate: &nbsp;true &nbsp; &nbsp; &nbsp; match: after &nbsp; &nbsp;#after和before &nbsp; &nbsp;fields: &nbsp; &nbsp; &nbsp; beat.name: xxx.xxx.xxx.xxx &nbsp;#增加属性 &nbsp;&nbsp; &nbsp; &nbsp;log_topics: test #output.elasticsearch: &nbsp;# 先将这几句注释掉 &nbsp; # Array of hosts to connect to. # &nbsp;hosts: [&quot;localhost:9200&quot;] output.kafka: &nbsp; enabled: true &nbsp; hosts: [&quot;192.168.1.105:9092&quot;,&quot;192.168.1.106:9092&quot;,&quot;192.168.1.107:9092&quot;] &nbsp; topic: &#39;%{[fields][log_topics]}&#39; &nbsp; required_acks: 1 8.2.3 启动 [root@server ~]# cd /usr/filebeat-6.7.2-linux-x86_64 [root@server ~]# nohup ./filebeat -e -c filebeat.yml &gt; filebeat.out &amp; 九 ELK测试 9.1 启动 以上将所有组件搭建完毕，依此启动各个组件，启动顺序为：elasticsearch集群、kibana、kafka集群、logstash集群、filebeat。 9.2 验证 去kabana界面，查看对应数据是否成功收集并展示。 十 kafka-manager简介 &nbsp; &nbsp; &nbsp; &nbsp; kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容： 1、管理多个集群 2、轻松检查群集状态（主题，消费者，偏移，代理，副本分发，分区分发） 3、运行首选副本选举 4、使用选项生成分区分配以选择要使用的代理 5、运行分区重新分配（基于生成的分配） 6、使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置） 7、删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true） 8、主题列表现在指示标记为删除的主题（仅支持0.8.2+） 9、批量生成多个主题的分区分配，并可选择要使用的代理 10、批量运行重新分配多个主题的分区 11、将分区添加到现有主题 12、更新现有主题的配置 具体安装配置，此文档不做说明。 参考文档：https://www.cnblogs.com/frankdeng/p/9584870.html 最后感谢以下优秀文章的学习、借鉴： elk搭建：https://blog.51cto.com/zero01/2079879 kafka搭建：https://blog.csdn.net/makang456/article/details/78719698 logstash之grok：https://blog.csdn.net/shunzi1046/article/details/53421701 elk自动定时清理：https://blog.51cto.com/qiuyt/2053441?utm_source=oschina-app" />
<meta property="og:description" content="一、ELK简介 &nbsp; &nbsp; &nbsp; &nbsp; ELK是三个开源软件的缩写，分别为：Elasticsearch 、 Logstash以及Kibana , 它们都是开源软件。ELK是一整套日志管理系统，对于日志的集中化管理，日志的统计和检索等都能够完美解决。 二、ELK选型 工作模式1：logstash采集、处理、转发到elasticsearch存储，在kibana进行展示&nbsp; --&nbsp;datasource-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种结构因为需要在各个服务器上部署 Logstash，而它比较消耗 CPU 和内存资源，所以比较适合计算资源丰富的服务器，否则容易造成服务器性能下降，甚至可能导致无法正常工作。 工作模式2：Beats 将搜集到的数据发送到 Logstash，经 Logstash 解析、过滤后，将其发送到 Elasticsearch 存储，并由 Kibana 呈现给用户 --&nbsp;datasource-&gt;filebeat-&gt;logstash-&gt; elasticsearch-&gt;kibana 模式特点：这种架构解决了 Logstash 在各服务器节点上占用系统资源高的问题。相比 Logstash，Beats 所占系统的 CPU 和内存几乎可以忽略不计。另外，Beats 和 Logstash 之间支持 SSL/TLS 加密传输，客户端和服务器双向认证，保证了通信安全。 因此这种架构适合对数据安全性要求较高，同时各服务器性能比较敏感的场景 工作模式3：Filebeat采集完毕直接入到kafka消息队列，进而logstash取出数据，进行处理分析输出到es，并在kibana进行展示。（filebeat版本5.0以上才支持直接输出到kafka） --datasource-&gt;filebeat-&gt;kafka-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种架构适合于日志规模比较庞大的情况。引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性。 总结：以上是目前流行的ELK收集模式，本次搭建ELK主要是收集数据量极大的日志，综合考虑，选择工作模式3进行搭建。 更多ELK工作模式，请参考文档：https://www.cnblogs.com/qingqing74647464/p/9378385.html 三、安装前的准备工作 3.1 服务器 （1）准备8台服务器，以下是服务器配置详情，及用途。 操作系统版本 IP地址 CPU核数 内存大小（G） 磁盘大小（G） 内网访问端口号 内网互通权限 是否需要访问外网 用途 Centos7.6 192.168.1.100 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master1节点及kibana Centos7.6 192.168.1.101 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master2节点 Centos7.6 192.168.1.102 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data1节点 Centos7.6 192.168.1.103 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data2节点 Centos7.6 192.168.1.104 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data3节点 Centos7.6 192.168.1.105 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.106 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.107 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 （2）安装jdk8 参考文档：https://www.cnblogs.com/shihaiming/p/5809553.html （3）关闭防火墙 查看防火墙状态：systemctl status&nbsp;firewalld.service 关闭防火墙：systemctl stop firewalld.service 禁止开机启动防火墙：systemctl disable firewalld.service 3.2 版本信息 Elasticsearch-6.7.2 logstash-6.7.2 kibana-6.7.2 filebeat-6.7.2 kibana-6.7.2 kafka_2.11-2.1.1 zookeeper-3.4.14 kafka-manager-1.3.3.7（kafka界面管理工具）可根据个人情况选用 四、Elasticsearch 4.1&nbsp;Elasticsearch简介 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 4.2&nbsp;Elasticsearch安装 4.2.1 安装 去官网下载elasticsearch的安装包：elasticsearch-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ （1）上传安装包至linux服务器 （2）解压安装包 &nbsp;[root@master1~]# tar -zxvf elasticsearch-6.7.2.tar.gz&nbsp; &nbsp;#解压安装包 4.2.2 配置 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch主要有两个配置文件，elasticsearch.yml&nbsp;文件用于配置集群节点等相关信息的，elasticsearch&nbsp;文件则是配置服务本身相关的配置，例如某个配置文件的路径以及java的一些路径配置什么的。 开始配置集群节点，在 192.168.1.100上编辑配置文件： [root@master1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-1&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.101 [root@master2 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-2&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.102 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-1&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.103 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-2&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.104 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-3&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 依此启动 [root@master1 ~]# cd /usr/elasticsearch/elasticsearch-6.7.2/bin/ [root@master1 bin]# ./elasticsearch -d 可能遇到的问题： 1、报错：can not run elasticsearch as root &nbsp; &nbsp; &nbsp; &nbsp; 使用root账户启动造成的报错，这是出于系统安全考虑设置的条件。由于ElasticSearch可以接收用户输入的脚本并且执行，为了系统安全考虑，建议创建一个单独的用户用来运行ElasticSearch。 创建elsearch用户组及elsearch用户 &nbsp; &nbsp; groupadd elsearch &nbsp; &nbsp; useradd elsearch -g elsearch -p elasticsearch 更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch &nbsp; &nbsp; cd /usr &nbsp; &nbsp; chown -R elsearch:elsearch &nbsp;elasticsearch-6.7.2 切换到elsearch用户再启动 &nbsp; &nbsp; su elsearch cd elasticsearch/bin &nbsp; &nbsp; ./elasticsearch -d 2、max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 每个进程最大同时打开文件数太小，可通过下面2个命令查看当前数量 修改/etc/security/limits.conf文件，增加配置，用户退出后重新登录生效 * &nbsp;soft &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;65536 * &nbsp;hard &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;131072 * &nbsp;soft &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited * &nbsp;hard &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited 3、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elasticsearch用户拥有的内存权限太小，至少需要262144&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;由于ES构建基于lucene, 而lucene设计强大之处在于lucene能够很好的利用操作系统内存来缓存索引数据，以提供快速的查询性能。lucene的索引文件segements是存储在单文件中的，并且不可变，对于OS来说，能够很友好地将索引文件保持在cache中，以便快速访问；因此，我们很有必要将一半的物理内存留给lucene ; 另一半的物理内存留给ES（JVM heap )。所以， 在ES内存设置方面，可以遵循以下原则： 1.当机器内存小于64G时，遵循通用的原则，50%给ES，50%留给lucene。 2.当机器内存大于64G时，遵循以下原则：&nbsp; a.如果主要的使用场景是全文检索, 那么建议给ES Heap分配 4~32G的内存即可；其它内存留给操作系统, 供lucene使用（segments cache), 以提供更快的查询性能。&nbsp; b.如果主要的使用场景是聚合或排序， 并且大多数是numerics, dates, geo_points 以及not_analyzed的字符类型， 建议分配给ES Heap分配 4~32G的内存即可，其它内存留给操作系统，供lucene使用(doc values cache)，提供快速的基于文档的聚类、排序性能。&nbsp; c.如果使用场景是聚合或排序，并且都是基于analyzed 字符数据，这时需要更多的 heap size, 建议机器上运行多ES实例，每个实例保持不超过50%的ES heap设置(但不超过32G，堆内存设置32G以下时，JVM使用对象指标压缩技巧节省空间)，50%以上留给lucene。 更多es性能调优参数，参考文档：https://www.jianshu.com/p/532b540d4c46 解决办法： 在&nbsp;&nbsp;&nbsp;/etc/sysctl.conf文件最后添加一行 vm.max_map_count=262144 执行sysctl -p 即可永久修改 参考数据（4g/4194304 &nbsp;8g/8388608）如果申请16G的内存，可适当将vm.max_map_count=4194304或8388608 4.2.3 curl查看es集群情况 依此成功启动es的各个集群节点，查看集群的状态： [root@master1&nbsp;~]# curl &#39;192.168.1.100:9200/_cluster/health?pretty&#39; { &nbsp; &quot;cluster_name&quot; : &quot;master-slave&nbsp;&quot;, &nbsp; &quot;status&quot; : &quot;green&quot;, &nbsp;# 为green则代表健康没问题，如果是yellow或者red则是集群有问题 &nbsp; &quot;timed_out&quot; : false, &nbsp;# 是否有超时 &nbsp; &quot;number_of_nodes&quot; : 5, # 集群中的节点数量 &nbsp; &quot;number_of_data_nodes&quot; : 3, # 集群中data节点的数量 &nbsp; &quot;active_primary_shards&quot; : 0, &nbsp; &quot;active_shards&quot; : 0, &nbsp; &quot;relocating_shards&quot; : 0, &nbsp; &quot;initializing_shards&quot; : 0, &nbsp; &quot;unassigned_shards&quot; : 0, &nbsp; &quot;delayed_unassigned_shards&quot; : 0, &nbsp; &quot;number_of_pending_tasks&quot; : 0, &nbsp; &quot;number_of_in_flight_fetch&quot; : 0, &nbsp; &quot;task_max_waiting_in_queue_millis&quot; : 0, &nbsp; &quot;active_shards_percent_as_number&quot; : 100.0 } 更多使用curl命令操作elasticsearch的内容，参考文档：http://zhaoyanblog.com/archives/732.html 五、kibana 5.1 kibana简介 &nbsp; &nbsp; &nbsp; &nbsp;Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 5.2 kibana安装 5.2.1 安装 去官网下载kibana的安装包：kibana-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@master1&nbsp;~]# tar -zxvf kibana-6.7.2.tar.gz 5.2.2 配置 安装完成后，对kibana进行配置： [root@master1 ~]# vim /usr/kibana/kibana-6.7.2-linux-x86_64/config/kibana.yml &nbsp;# 增加以下内容 server.port: 5601 &nbsp;# 配置kibana的端口 server.host: 192.168.1.100&nbsp; # 配置监听ip elasticsearch.hosts: [&quot;http://192.168.1.100:9200&quot;,&quot;http://192.168.1.101:9200&quot;] &nbsp;# 配置es服务器的ip，如果是集群则配置该集群中主节点的ip logging.dest: /var/log/kibana.log &nbsp;# 配置kibana的日志文件路径，不然默认是messages里记录日志 创建日志文件： [root@master-node ~]# touch /var/log/kibana.log 启动kibana服务，并检查进程和监听端口： [root@master1 ~]# cd /usr/kibana/kibana-6.7.2-linux-x86_64/bin/ [root@master1 bin]# ./kibana &amp;&nbsp; [root@master1 ~]# ps aux |grep kibana kibana &nbsp; &nbsp; 3083 36.8 &nbsp;2.9 1118668 112352 ? &nbsp; &nbsp; &nbsp;Ssl &nbsp;17:14 &nbsp; 0:03 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kibana/bin/../src/cli -c /etc/kibana/kibana.yml root &nbsp; &nbsp; &nbsp; 3095 &nbsp;0.0 &nbsp;0.0 112660 &nbsp; 964 pts/0 &nbsp; &nbsp;S+ &nbsp; 17:14 &nbsp; 0:00 grep --color=auto kibana [root@master1 ~]# netstat -lntp |grep 5601 tcp &nbsp; &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;0 192.168.1.100:5601 &nbsp; &nbsp; 0.0.0.0:* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LISTEN &nbsp; &nbsp; &nbsp;3083/node &nbsp; &nbsp; 然后在浏览器里进行访问，如：http://192.168.1.100:5601/&nbsp;，由于我们并没有安装x-pack，所以此时是没有用户名和密码的，可以直接访问的。 点击Index Patterns,创建新索引 六、Logstash 6.1&nbsp;Logstash简介 &nbsp; &nbsp; &nbsp; &nbsp; Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去 6.2 Logstash安装 6.2.1 安装 去官网下载logstash的安装包：logstash-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@logstash1 ~]# tar -zxvf logstash-6.7.2.tar.gz 6.2.2 配置 安装完之后，先不要启动服务，先配置logstash收集kafka日志： [root@logstash1 ~]# cd /usr/logstash-6.7.2/bin/ [root@logstash1 bin]# mkdir conf.d [root@logstash1 ~]# vim conf.d/first-demo.conf &nbsp;# 加入如下内容 input{ &nbsp; &nbsp; kafka { &nbsp; &nbsp; &nbsp; &nbsp; bootstrap_servers =&gt; &quot;192.168.1.105:9092,192.168.1.106:9092,192.168.1.107:9092&quot; &nbsp; &nbsp; &nbsp; &nbsp; topics =&gt; [&quot;test&quot;] &nbsp; &nbsp; &nbsp; &nbsp; group_id =&gt; &quot;consumer-test&quot; &nbsp; &nbsp; } } output { &nbsp; &nbsp; elasticsearch { &nbsp; &nbsp; &nbsp; &nbsp; hosts =&gt; [&quot;192.168.1.100:9200&quot;,&quot;192.168.1.101:9200&quot;,&quot;192.168.1.102:9200&quot;,&quot;192.168.1.103:9200&quot;,&quot;192.168.1.104:9200&quot;] &nbsp; &nbsp; &nbsp; &nbsp; index =&gt; &quot;server-test-%{+YYYY.MM.dd}&quot; &nbsp; &nbsp; } } 检测配置文件是否有错： [root@logstash1 ~]# cd /usr/logstash/bin [root@logstash1&nbsp;bin]# ./logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/syslog.conf --config.test_and_exit Sending Logstash&#39;s logs to /var/log/logstash which is now configured via log4j2.properties Configuration OK &nbsp;# 为ok则代表配置文件没有问题 [root@logstash1&nbsp;bin]#&nbsp; 命令说明： --path.settings 用于指定logstash的配置文件所在的目录 -f 指定需要被检测的配置文件的路径 --config.test_and_exit 指定检测完之后就退出，不然就会直接启动了 &nbsp; &nbsp; &nbsp; &nbsp;当然你必须要先搭建kafka集群，并创建对应topic，所以这里先不启动logstash，以上是192.168.1.105服务器的配置，根据个人需要，可在192.168.1.106、192.168.1.107服务器上安装logtash，实现logstash集群，也可以单机启动多个logstash，实现单机多节点。 编辑logstash.yml [root@logstash1 ~]$ cd /usr/logstash-6.7.2/config/ [root@logstash1 config]$ vim logstash.yml path.logs: /usr/logstash-6.7.2/logstash-data/log &nbsp;#日志路径 path.config: /usr/logstash-6.7.2/bin/conf.d/*.conf &nbsp;#配置文件路径(支持正则) path.data: /usr/logstash-6.7.2/logstash-data/data &nbsp;#logstash数据保存路径 http.host: &quot;192.168.1.105&quot; &nbsp;#主机ip 启动命令： [root@logstash1 ~]# cd /usr/logstash-6.7.2 [root@logstash1 logstash-6.7.2]# nohup ./bin/logstash -f ./bin/conf.d/first-demo.conf &gt; ./bin/nohup.out &amp; 七、kafka 7.1 安装zookeeper 7.1.1 下载 去官网下载zookeeper的安装包：zookeeper-3.4.14.tar.gz 地址：https://www-eu.apache.org/dist/zookeeper/zookeeper-3.4.14/ 7.1.2 解压 tar -zxvf&nbsp;&nbsp;zookeeper-3.4.10.tar.gz 用192.168.1.105、192.168.1.106、192.168.1.107三台服务器做kakfa集群，当前配置实例为192.168.1.105 [root@logstash1 ~]$ cd /usr/zookeeper-3.4.14 [root@logstash1 zookeeper-3.4.14]$ mkdir data [root@logstash1 zookeeper-3.4.14]$ mkdir log #在每一个数据文件目录中，新建一个myid文件，文件必须是唯一的服务标识，在后面的配置中会用到 [root@logstash1 zookeeper-3.4.14]$ echo &#39;1&#39; &gt; data/myid #复制出zoo.cfg文件: [root@logstash1 zookeeper-3.4.14]$ cp conf/zoo_sample.cfg conf/zoo.cfg 7.1.3 配置 vim zoo.cfg # The number of milliseconds of each tick &nbsp; tickTime=2000 &nbsp; # The number of ticks that the initial &nbsp;&nbsp; # synchronization phase can take &nbsp; initLimit=10 &nbsp; # The number of ticks that can pass between &nbsp;&nbsp; # sending a request and getting an acknowledgement &nbsp; syncLimit=5 &nbsp; # the directory where the snapshot is stored. &nbsp; # do not use /tmp for storage, /tmp here is just &nbsp;&nbsp; # example sakes. &nbsp; #存储路径 dataDir=/实际路径/zookeeper-cluster/data&nbsp;&nbsp; #日志路径，方便查LOG dataLogDir=/实际路径/zookeeper-cluster/log # the port at which the clients will connect &nbsp; clientPort=2181 &nbsp; # the maximum number of client connections. &nbsp; # increase this if you need to handle more clients &nbsp; #控制客户的连接数，默认数为60，太少 maxClientCnxns=300 #maxClientCnxns=60 &nbsp; # &nbsp; # Be sure to read the maintenance section of the &nbsp;&nbsp; # administrator guide before turning on autopurge. &nbsp; # &nbsp; #http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance &nbsp; # &nbsp; # The number of snapshots to retain in dataDir &nbsp; #autopurge.snapRetainCount=3 &nbsp; # Purge task interval in hours &nbsp; # Set to &quot;0&quot; to disable auto purge feature &nbsp; #autopurge.purgeInterval=1 &nbsp; #zookeeper集群地址（本机的ip填0.0.0.0） server.1=0.0.0.0:2888:3888 server.2=192.168.1.106:2888:3888 server.3=192.168.1.107:2888:3888 192.168.1.106、192.168.1.107服务器的配置类似，请参考192.168.1.105服务器配置。 7.1.4 启动 分别启动3个zookeeper服务 $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; 启动完成后查看每个服务的状态 $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status 7.2 安装kafka 7.2.1 下载 去官网下载kafka的安装包：kafka_2.11-2.1.1.tgz 地址：http://kafka.apache.org/downloads 7.2.2 解压 tar zxvf kafka_2.11-2.1.1.tgz 7.2.3 配置 以192.168.1.105为例 [root@logstash1 ~]$ cd /usr/kafka_2.11-2.1.1/config/server.properties #配置zookeeper连接,默认Kafka会使用ZooKeeper默认的/路径，这样有关Kafka的ZooKeeper配置就会散落在根路径下面，如果你有其他的应用也在使用ZooKeeper集群，查看ZooKeeper中数据可能会不直观，所以强烈建议指定一个chroot路径，直接在zookeeper.connect配置项中指定 zookeeper.connect=192.168.1.105:2181, 192.168.1.106:2181, 192.168.1.107:2181/kafka #每个Kafka Broker应该配置一个唯一的ID&nbsp; broker.id=0&nbsp; #端口号 port=9092 #如果有多个网卡地址，也可以将不同的Broker绑定到不同的网卡 &nbsp; host.name=192.168.1.105 #日志目录 log.dirs=/usr/kafka_2.11-2.1.1/logs #设置topic可删除，默认该项是被注释的，需要放开 delete.topic.enable=true #关闭自动创建topic，默认情况下Producer往一个不存在的Topic发送message时会自动创建这个Topic auto.create.topics.enable=false 7.2.4 启动 kafka_2.11-2.1.1/bin/kafka-server-start.sh kafka_2.11-2.1.1/config/server.properties &amp; 7.2.5 关闭 kafka_2.11-2.1.1/bin/kafka-server-stop.sh 7.2.6 topic 7.2.6.1 创建topic kafka_2.11-2.1.1/bin/kafka-topics.sh -topic test -create -partitions 3 -replication-factor 1 -zookeeper 192.168.1.105:2181/kafka -topic 主题名称 -partitions 分区 -replication-factor 副本 7.2.6.2 查看指定topic属性 kafka_2.11-2.1.1/bin/kafka-topics.sh -describe -zookeeper 192.168.1.105:2181/kafka -topic test 7.2.6.3 查看topic列表 kafka_2.11-2.1.1/bin/kafka-topics.sh -list -zookeeper 192.168.1.105:2181/kafka 7.2.6.4 创建生产者 kafka_2.11-2.1.1/bin/kafka-console-producer.sh -broker-list localhost:9092 -topic test 7.2.6.5 创建消费者 #重新打开一个ssh连接执行以下命令 kafka_2.11-2.1.1/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 7.2.6.6 测试 在生成者连接中输入内容.&nbsp; test&nbsp; 在消费者连接中查看是否接收到消息 7.3 kafka相关配置参数 broker.id &nbsp;整数，建议根据ip区分 &nbsp;　 log.dirs &nbsp;kafka存放消息文件的路径， &nbsp;默认/tmp/kafka-logs port &nbsp;broker用于接收producer消息的端口 &nbsp;　 zookeeper.connnect &nbsp;zookeeper连接 &nbsp;格式为 &nbsp;ip1:port,ip2:port,ip3:port message.max.bytes &nbsp;单条消息的最大长度 &nbsp;　 num.network.threads &nbsp;broker用于处理网络请求的线程数 &nbsp;如不配置默认为3，server.properties默认是2 num.io.threads &nbsp;broker用于执行网络请求的IO线程数 &nbsp;如不配置默认为8，server.properties默认是2可适当增大， queued.max.requests &nbsp;排队等候IO线程执行的requests &nbsp;默认为500 host.name &nbsp;broker的hostname &nbsp;默认null,建议写主机的ip,不然消费端不配置hosts会有麻烦 num.partitions &nbsp;topic的默认分区数 &nbsp;默认1 log.retention.hours &nbsp;消息被删除前保存多少小时 &nbsp;默认1周168小时 auto.create.topics.enable &nbsp;是否可以程序自动创建Topic &nbsp;默认true,建议false default.replication.factor &nbsp;消息备份数目 &nbsp;默认1不做复制，建议修改 num.replica.fetchers &nbsp;用于复制leader消息到follower的IO线程数 &nbsp;默认1 参考文档：https://blog.csdn.net/henianyou/article/details/75976052 至此，zookeeper以及kafka集群搭建成功。 八、filebeat 8.1 filebeat简介 &nbsp; &nbsp; &nbsp; &nbsp;beats是ELK体系中新增的一个工具，它属于一个轻量的日志采集器，以上我们使用的日志采集工具是logstash，但是logstash占用的资源比较大，没有beats轻量。 &nbsp; &nbsp; &nbsp; &nbsp;filebeat是用go编写，logstash使用ruby写的。Logstash会占用不少的jvm。 当然，也不是filebeat完全占优，filebeat也专注于采集而已，所以这也是为什么很多架构都是filebeat后面接着logstash来做信息转换。 8.2 filebeat安装 8.2.1 安装 去官网下载filebeat的安装包：filebeat-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@server ~]# tar -zxvf filebeat-6.7.2.tar.gz 说明：filebeat为日志采集工具，一般是安装在应用服务器。 8.2.2 配置 [root@server ~]# vim /usr/filebeat-6.7.2-linux-x86_64/filebeat.yml &nbsp;# 增加或者更改为以下内容 filebeat.prospectors: &nbsp;- input_type: log &nbsp;#除了&quot;log&quot;，还有&quot;stdin&quot; paths: &nbsp; &nbsp; - /tmp/*.log &nbsp; #读取文件路径 &nbsp; &nbsp;#include_lines: [&#39;ERROR&#39;] &nbsp; #只发送包含这些字样的日志 &nbsp; &nbsp;multiline: &nbsp; &nbsp;&nbsp; &nbsp;#&nbsp;&nbsp; &nbsp;多行合并 &nbsp; &nbsp; &nbsp; pattern: &#39;^\d{4}-\d{1,2}-\d{1,2}&#39; &nbsp;#日期开头的 &nbsp; &nbsp; &nbsp; negate: &nbsp;true &nbsp; &nbsp; &nbsp; match: after &nbsp; &nbsp;#after和before &nbsp; &nbsp;fields: &nbsp; &nbsp; &nbsp; beat.name: xxx.xxx.xxx.xxx &nbsp;#增加属性 &nbsp;&nbsp; &nbsp; &nbsp;log_topics: test #output.elasticsearch: &nbsp;# 先将这几句注释掉 &nbsp; # Array of hosts to connect to. # &nbsp;hosts: [&quot;localhost:9200&quot;] output.kafka: &nbsp; enabled: true &nbsp; hosts: [&quot;192.168.1.105:9092&quot;,&quot;192.168.1.106:9092&quot;,&quot;192.168.1.107:9092&quot;] &nbsp; topic: &#39;%{[fields][log_topics]}&#39; &nbsp; required_acks: 1 8.2.3 启动 [root@server ~]# cd /usr/filebeat-6.7.2-linux-x86_64 [root@server ~]# nohup ./filebeat -e -c filebeat.yml &gt; filebeat.out &amp; 九 ELK测试 9.1 启动 以上将所有组件搭建完毕，依此启动各个组件，启动顺序为：elasticsearch集群、kibana、kafka集群、logstash集群、filebeat。 9.2 验证 去kabana界面，查看对应数据是否成功收集并展示。 十 kafka-manager简介 &nbsp; &nbsp; &nbsp; &nbsp; kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容： 1、管理多个集群 2、轻松检查群集状态（主题，消费者，偏移，代理，副本分发，分区分发） 3、运行首选副本选举 4、使用选项生成分区分配以选择要使用的代理 5、运行分区重新分配（基于生成的分配） 6、使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置） 7、删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true） 8、主题列表现在指示标记为删除的主题（仅支持0.8.2+） 9、批量生成多个主题的分区分配，并可选择要使用的代理 10、批量运行重新分配多个主题的分区 11、将分区添加到现有主题 12、更新现有主题的配置 具体安装配置，此文档不做说明。 参考文档：https://www.cnblogs.com/frankdeng/p/9584870.html 最后感谢以下优秀文章的学习、借鉴： elk搭建：https://blog.51cto.com/zero01/2079879 kafka搭建：https://blog.csdn.net/makang456/article/details/78719698 logstash之grok：https://blog.csdn.net/shunzi1046/article/details/53421701 elk自动定时清理：https://blog.51cto.com/qiuyt/2053441?utm_source=oschina-app" />
<link rel="canonical" href="https://uzzz.org/2019/08/13/794563.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/13/794563.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-13T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"一、ELK简介 &nbsp; &nbsp; &nbsp; &nbsp; ELK是三个开源软件的缩写，分别为：Elasticsearch 、 Logstash以及Kibana , 它们都是开源软件。ELK是一整套日志管理系统，对于日志的集中化管理，日志的统计和检索等都能够完美解决。 二、ELK选型 工作模式1：logstash采集、处理、转发到elasticsearch存储，在kibana进行展示&nbsp; --&nbsp;datasource-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种结构因为需要在各个服务器上部署 Logstash，而它比较消耗 CPU 和内存资源，所以比较适合计算资源丰富的服务器，否则容易造成服务器性能下降，甚至可能导致无法正常工作。 工作模式2：Beats 将搜集到的数据发送到 Logstash，经 Logstash 解析、过滤后，将其发送到 Elasticsearch 存储，并由 Kibana 呈现给用户 --&nbsp;datasource-&gt;filebeat-&gt;logstash-&gt; elasticsearch-&gt;kibana 模式特点：这种架构解决了 Logstash 在各服务器节点上占用系统资源高的问题。相比 Logstash，Beats 所占系统的 CPU 和内存几乎可以忽略不计。另外，Beats 和 Logstash 之间支持 SSL/TLS 加密传输，客户端和服务器双向认证，保证了通信安全。 因此这种架构适合对数据安全性要求较高，同时各服务器性能比较敏感的场景 工作模式3：Filebeat采集完毕直接入到kafka消息队列，进而logstash取出数据，进行处理分析输出到es，并在kibana进行展示。（filebeat版本5.0以上才支持直接输出到kafka） --datasource-&gt;filebeat-&gt;kafka-&gt;logstash-&gt;elasticsearch-&gt;kibana 模式特点：这种架构适合于日志规模比较庞大的情况。引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性。 总结：以上是目前流行的ELK收集模式，本次搭建ELK主要是收集数据量极大的日志，综合考虑，选择工作模式3进行搭建。 更多ELK工作模式，请参考文档：https://www.cnblogs.com/qingqing74647464/p/9378385.html 三、安装前的准备工作 3.1 服务器 （1）准备8台服务器，以下是服务器配置详情，及用途。 操作系统版本 IP地址 CPU核数 内存大小（G） 磁盘大小（G） 内网访问端口号 内网互通权限 是否需要访问外网 用途 Centos7.6 192.168.1.100 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master1节点及kibana Centos7.6 192.168.1.101 8 8 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的master2节点 Centos7.6 192.168.1.102 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data1节点 Centos7.6 192.168.1.103 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data2节点 Centos7.6 192.168.1.104 16 16 1024 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的data3节点 Centos7.6 192.168.1.105 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.106 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 Centos7.6 192.168.1.107 8 16 200 全开 同网段互通 是 内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群 （2）安装jdk8 参考文档：https://www.cnblogs.com/shihaiming/p/5809553.html （3）关闭防火墙 查看防火墙状态：systemctl status&nbsp;firewalld.service 关闭防火墙：systemctl stop firewalld.service 禁止开机启动防火墙：systemctl disable firewalld.service 3.2 版本信息 Elasticsearch-6.7.2 logstash-6.7.2 kibana-6.7.2 filebeat-6.7.2 kibana-6.7.2 kafka_2.11-2.1.1 zookeeper-3.4.14 kafka-manager-1.3.3.7（kafka界面管理工具）可根据个人情况选用 四、Elasticsearch 4.1&nbsp;Elasticsearch简介 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 4.2&nbsp;Elasticsearch安装 4.2.1 安装 去官网下载elasticsearch的安装包：elasticsearch-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ （1）上传安装包至linux服务器 （2）解压安装包 &nbsp;[root@master1~]# tar -zxvf elasticsearch-6.7.2.tar.gz&nbsp; &nbsp;#解压安装包 4.2.2 配置 &nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch主要有两个配置文件，elasticsearch.yml&nbsp;文件用于配置集群节点等相关信息的，elasticsearch&nbsp;文件则是配置服务本身相关的配置，例如某个配置文件的路径以及java的一些路径配置什么的。 开始配置集群节点，在 192.168.1.100上编辑配置文件： [root@master1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-1&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.101 [root@master2 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: master-2&nbsp; &nbsp; #节点名称 node.master: true&nbsp; &nbsp; &nbsp;#是否master节点 node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.102 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-1&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.103 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-2&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 192.168.1.104 [root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml cluster.name: master-slave&nbsp; #自定义集群名称 node.name: node-3&nbsp; &nbsp; #节点名称 node.master: false&nbsp; &nbsp; &nbsp;#是否master节点 node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点 network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个 http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口 transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口 bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区 discovery.zen.ping.unicast.hosts: [&quot;192.168.2.100:9300&quot;, &quot;192.168.2.101:9300&quot;, &quot;192.168.2.102:9300&quot;, &quot;192.168.2.103:9300&quot;, &quot;192.168.2.104:9300&quot;] 依此启动 [root@master1 ~]# cd /usr/elasticsearch/elasticsearch-6.7.2/bin/ [root@master1 bin]# ./elasticsearch -d 可能遇到的问题： 1、报错：can not run elasticsearch as root &nbsp; &nbsp; &nbsp; &nbsp; 使用root账户启动造成的报错，这是出于系统安全考虑设置的条件。由于ElasticSearch可以接收用户输入的脚本并且执行，为了系统安全考虑，建议创建一个单独的用户用来运行ElasticSearch。 创建elsearch用户组及elsearch用户 &nbsp; &nbsp; groupadd elsearch &nbsp; &nbsp; useradd elsearch -g elsearch -p elasticsearch 更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch &nbsp; &nbsp; cd /usr &nbsp; &nbsp; chown -R elsearch:elsearch &nbsp;elasticsearch-6.7.2 切换到elsearch用户再启动 &nbsp; &nbsp; su elsearch cd elasticsearch/bin &nbsp; &nbsp; ./elasticsearch -d 2、max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 每个进程最大同时打开文件数太小，可通过下面2个命令查看当前数量 修改/etc/security/limits.conf文件，增加配置，用户退出后重新登录生效 * &nbsp;soft &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;65536 * &nbsp;hard &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;131072 * &nbsp;soft &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited * &nbsp;hard &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited 3、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elasticsearch用户拥有的内存权限太小，至少需要262144&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;由于ES构建基于lucene, 而lucene设计强大之处在于lucene能够很好的利用操作系统内存来缓存索引数据，以提供快速的查询性能。lucene的索引文件segements是存储在单文件中的，并且不可变，对于OS来说，能够很友好地将索引文件保持在cache中，以便快速访问；因此，我们很有必要将一半的物理内存留给lucene ; 另一半的物理内存留给ES（JVM heap )。所以， 在ES内存设置方面，可以遵循以下原则： 1.当机器内存小于64G时，遵循通用的原则，50%给ES，50%留给lucene。 2.当机器内存大于64G时，遵循以下原则：&nbsp; a.如果主要的使用场景是全文检索, 那么建议给ES Heap分配 4~32G的内存即可；其它内存留给操作系统, 供lucene使用（segments cache), 以提供更快的查询性能。&nbsp; b.如果主要的使用场景是聚合或排序， 并且大多数是numerics, dates, geo_points 以及not_analyzed的字符类型， 建议分配给ES Heap分配 4~32G的内存即可，其它内存留给操作系统，供lucene使用(doc values cache)，提供快速的基于文档的聚类、排序性能。&nbsp; c.如果使用场景是聚合或排序，并且都是基于analyzed 字符数据，这时需要更多的 heap size, 建议机器上运行多ES实例，每个实例保持不超过50%的ES heap设置(但不超过32G，堆内存设置32G以下时，JVM使用对象指标压缩技巧节省空间)，50%以上留给lucene。 更多es性能调优参数，参考文档：https://www.jianshu.com/p/532b540d4c46 解决办法： 在&nbsp;&nbsp;&nbsp;/etc/sysctl.conf文件最后添加一行 vm.max_map_count=262144 执行sysctl -p 即可永久修改 参考数据（4g/4194304 &nbsp;8g/8388608）如果申请16G的内存，可适当将vm.max_map_count=4194304或8388608 4.2.3 curl查看es集群情况 依此成功启动es的各个集群节点，查看集群的状态： [root@master1&nbsp;~]# curl &#39;192.168.1.100:9200/_cluster/health?pretty&#39; { &nbsp; &quot;cluster_name&quot; : &quot;master-slave&nbsp;&quot;, &nbsp; &quot;status&quot; : &quot;green&quot;, &nbsp;# 为green则代表健康没问题，如果是yellow或者red则是集群有问题 &nbsp; &quot;timed_out&quot; : false, &nbsp;# 是否有超时 &nbsp; &quot;number_of_nodes&quot; : 5, # 集群中的节点数量 &nbsp; &quot;number_of_data_nodes&quot; : 3, # 集群中data节点的数量 &nbsp; &quot;active_primary_shards&quot; : 0, &nbsp; &quot;active_shards&quot; : 0, &nbsp; &quot;relocating_shards&quot; : 0, &nbsp; &quot;initializing_shards&quot; : 0, &nbsp; &quot;unassigned_shards&quot; : 0, &nbsp; &quot;delayed_unassigned_shards&quot; : 0, &nbsp; &quot;number_of_pending_tasks&quot; : 0, &nbsp; &quot;number_of_in_flight_fetch&quot; : 0, &nbsp; &quot;task_max_waiting_in_queue_millis&quot; : 0, &nbsp; &quot;active_shards_percent_as_number&quot; : 100.0 } 更多使用curl命令操作elasticsearch的内容，参考文档：http://zhaoyanblog.com/archives/732.html 五、kibana 5.1 kibana简介 &nbsp; &nbsp; &nbsp; &nbsp;Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 5.2 kibana安装 5.2.1 安装 去官网下载kibana的安装包：kibana-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@master1&nbsp;~]# tar -zxvf kibana-6.7.2.tar.gz 5.2.2 配置 安装完成后，对kibana进行配置： [root@master1 ~]# vim /usr/kibana/kibana-6.7.2-linux-x86_64/config/kibana.yml &nbsp;# 增加以下内容 server.port: 5601 &nbsp;# 配置kibana的端口 server.host: 192.168.1.100&nbsp; # 配置监听ip elasticsearch.hosts: [&quot;http://192.168.1.100:9200&quot;,&quot;http://192.168.1.101:9200&quot;] &nbsp;# 配置es服务器的ip，如果是集群则配置该集群中主节点的ip logging.dest: /var/log/kibana.log &nbsp;# 配置kibana的日志文件路径，不然默认是messages里记录日志 创建日志文件： [root@master-node ~]# touch /var/log/kibana.log 启动kibana服务，并检查进程和监听端口： [root@master1 ~]# cd /usr/kibana/kibana-6.7.2-linux-x86_64/bin/ [root@master1 bin]# ./kibana &amp;&nbsp; [root@master1 ~]# ps aux |grep kibana kibana &nbsp; &nbsp; 3083 36.8 &nbsp;2.9 1118668 112352 ? &nbsp; &nbsp; &nbsp;Ssl &nbsp;17:14 &nbsp; 0:03 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kibana/bin/../src/cli -c /etc/kibana/kibana.yml root &nbsp; &nbsp; &nbsp; 3095 &nbsp;0.0 &nbsp;0.0 112660 &nbsp; 964 pts/0 &nbsp; &nbsp;S+ &nbsp; 17:14 &nbsp; 0:00 grep --color=auto kibana [root@master1 ~]# netstat -lntp |grep 5601 tcp &nbsp; &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;0 192.168.1.100:5601 &nbsp; &nbsp; 0.0.0.0:* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LISTEN &nbsp; &nbsp; &nbsp;3083/node &nbsp; &nbsp; 然后在浏览器里进行访问，如：http://192.168.1.100:5601/&nbsp;，由于我们并没有安装x-pack，所以此时是没有用户名和密码的，可以直接访问的。 点击Index Patterns,创建新索引 六、Logstash 6.1&nbsp;Logstash简介 &nbsp; &nbsp; &nbsp; &nbsp; Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去 6.2 Logstash安装 6.2.1 安装 去官网下载logstash的安装包：logstash-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@logstash1 ~]# tar -zxvf logstash-6.7.2.tar.gz 6.2.2 配置 安装完之后，先不要启动服务，先配置logstash收集kafka日志： [root@logstash1 ~]# cd /usr/logstash-6.7.2/bin/ [root@logstash1 bin]# mkdir conf.d [root@logstash1 ~]# vim conf.d/first-demo.conf &nbsp;# 加入如下内容 input{ &nbsp; &nbsp; kafka { &nbsp; &nbsp; &nbsp; &nbsp; bootstrap_servers =&gt; &quot;192.168.1.105:9092,192.168.1.106:9092,192.168.1.107:9092&quot; &nbsp; &nbsp; &nbsp; &nbsp; topics =&gt; [&quot;test&quot;] &nbsp; &nbsp; &nbsp; &nbsp; group_id =&gt; &quot;consumer-test&quot; &nbsp; &nbsp; } } output { &nbsp; &nbsp; elasticsearch { &nbsp; &nbsp; &nbsp; &nbsp; hosts =&gt; [&quot;192.168.1.100:9200&quot;,&quot;192.168.1.101:9200&quot;,&quot;192.168.1.102:9200&quot;,&quot;192.168.1.103:9200&quot;,&quot;192.168.1.104:9200&quot;] &nbsp; &nbsp; &nbsp; &nbsp; index =&gt; &quot;server-test-%{+YYYY.MM.dd}&quot; &nbsp; &nbsp; } } 检测配置文件是否有错： [root@logstash1 ~]# cd /usr/logstash/bin [root@logstash1&nbsp;bin]# ./logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/syslog.conf --config.test_and_exit Sending Logstash&#39;s logs to /var/log/logstash which is now configured via log4j2.properties Configuration OK &nbsp;# 为ok则代表配置文件没有问题 [root@logstash1&nbsp;bin]#&nbsp; 命令说明： --path.settings 用于指定logstash的配置文件所在的目录 -f 指定需要被检测的配置文件的路径 --config.test_and_exit 指定检测完之后就退出，不然就会直接启动了 &nbsp; &nbsp; &nbsp; &nbsp;当然你必须要先搭建kafka集群，并创建对应topic，所以这里先不启动logstash，以上是192.168.1.105服务器的配置，根据个人需要，可在192.168.1.106、192.168.1.107服务器上安装logtash，实现logstash集群，也可以单机启动多个logstash，实现单机多节点。 编辑logstash.yml [root@logstash1 ~]$ cd /usr/logstash-6.7.2/config/ [root@logstash1 config]$ vim logstash.yml path.logs: /usr/logstash-6.7.2/logstash-data/log &nbsp;#日志路径 path.config: /usr/logstash-6.7.2/bin/conf.d/*.conf &nbsp;#配置文件路径(支持正则) path.data: /usr/logstash-6.7.2/logstash-data/data &nbsp;#logstash数据保存路径 http.host: &quot;192.168.1.105&quot; &nbsp;#主机ip 启动命令： [root@logstash1 ~]# cd /usr/logstash-6.7.2 [root@logstash1 logstash-6.7.2]# nohup ./bin/logstash -f ./bin/conf.d/first-demo.conf &gt; ./bin/nohup.out &amp; 七、kafka 7.1 安装zookeeper 7.1.1 下载 去官网下载zookeeper的安装包：zookeeper-3.4.14.tar.gz 地址：https://www-eu.apache.org/dist/zookeeper/zookeeper-3.4.14/ 7.1.2 解压 tar -zxvf&nbsp;&nbsp;zookeeper-3.4.10.tar.gz 用192.168.1.105、192.168.1.106、192.168.1.107三台服务器做kakfa集群，当前配置实例为192.168.1.105 [root@logstash1 ~]$ cd /usr/zookeeper-3.4.14 [root@logstash1 zookeeper-3.4.14]$ mkdir data [root@logstash1 zookeeper-3.4.14]$ mkdir log #在每一个数据文件目录中，新建一个myid文件，文件必须是唯一的服务标识，在后面的配置中会用到 [root@logstash1 zookeeper-3.4.14]$ echo &#39;1&#39; &gt; data/myid #复制出zoo.cfg文件: [root@logstash1 zookeeper-3.4.14]$ cp conf/zoo_sample.cfg conf/zoo.cfg 7.1.3 配置 vim zoo.cfg # The number of milliseconds of each tick &nbsp; tickTime=2000 &nbsp; # The number of ticks that the initial &nbsp;&nbsp; # synchronization phase can take &nbsp; initLimit=10 &nbsp; # The number of ticks that can pass between &nbsp;&nbsp; # sending a request and getting an acknowledgement &nbsp; syncLimit=5 &nbsp; # the directory where the snapshot is stored. &nbsp; # do not use /tmp for storage, /tmp here is just &nbsp;&nbsp; # example sakes. &nbsp; #存储路径 dataDir=/实际路径/zookeeper-cluster/data&nbsp;&nbsp; #日志路径，方便查LOG dataLogDir=/实际路径/zookeeper-cluster/log # the port at which the clients will connect &nbsp; clientPort=2181 &nbsp; # the maximum number of client connections. &nbsp; # increase this if you need to handle more clients &nbsp; #控制客户的连接数，默认数为60，太少 maxClientCnxns=300 #maxClientCnxns=60 &nbsp; # &nbsp; # Be sure to read the maintenance section of the &nbsp;&nbsp; # administrator guide before turning on autopurge. &nbsp; # &nbsp; #http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance &nbsp; # &nbsp; # The number of snapshots to retain in dataDir &nbsp; #autopurge.snapRetainCount=3 &nbsp; # Purge task interval in hours &nbsp; # Set to &quot;0&quot; to disable auto purge feature &nbsp; #autopurge.purgeInterval=1 &nbsp; #zookeeper集群地址（本机的ip填0.0.0.0） server.1=0.0.0.0:2888:3888 server.2=192.168.1.106:2888:3888 server.3=192.168.1.107:2888:3888 192.168.1.106、192.168.1.107服务器的配置类似，请参考192.168.1.105服务器配置。 7.1.4 启动 分别启动3个zookeeper服务 $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp; 启动完成后查看每个服务的状态 $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp; $ /usr/zookeeper-3.4.14/bin/zkServer.sh status 7.2 安装kafka 7.2.1 下载 去官网下载kafka的安装包：kafka_2.11-2.1.1.tgz 地址：http://kafka.apache.org/downloads 7.2.2 解压 tar zxvf kafka_2.11-2.1.1.tgz 7.2.3 配置 以192.168.1.105为例 [root@logstash1 ~]$ cd /usr/kafka_2.11-2.1.1/config/server.properties #配置zookeeper连接,默认Kafka会使用ZooKeeper默认的/路径，这样有关Kafka的ZooKeeper配置就会散落在根路径下面，如果你有其他的应用也在使用ZooKeeper集群，查看ZooKeeper中数据可能会不直观，所以强烈建议指定一个chroot路径，直接在zookeeper.connect配置项中指定 zookeeper.connect=192.168.1.105:2181, 192.168.1.106:2181, 192.168.1.107:2181/kafka #每个Kafka Broker应该配置一个唯一的ID&nbsp; broker.id=0&nbsp; #端口号 port=9092 #如果有多个网卡地址，也可以将不同的Broker绑定到不同的网卡 &nbsp; host.name=192.168.1.105 #日志目录 log.dirs=/usr/kafka_2.11-2.1.1/logs #设置topic可删除，默认该项是被注释的，需要放开 delete.topic.enable=true #关闭自动创建topic，默认情况下Producer往一个不存在的Topic发送message时会自动创建这个Topic auto.create.topics.enable=false 7.2.4 启动 kafka_2.11-2.1.1/bin/kafka-server-start.sh kafka_2.11-2.1.1/config/server.properties &amp; 7.2.5 关闭 kafka_2.11-2.1.1/bin/kafka-server-stop.sh 7.2.6 topic 7.2.6.1 创建topic kafka_2.11-2.1.1/bin/kafka-topics.sh -topic test -create -partitions 3 -replication-factor 1 -zookeeper 192.168.1.105:2181/kafka -topic 主题名称 -partitions 分区 -replication-factor 副本 7.2.6.2 查看指定topic属性 kafka_2.11-2.1.1/bin/kafka-topics.sh -describe -zookeeper 192.168.1.105:2181/kafka -topic test 7.2.6.3 查看topic列表 kafka_2.11-2.1.1/bin/kafka-topics.sh -list -zookeeper 192.168.1.105:2181/kafka 7.2.6.4 创建生产者 kafka_2.11-2.1.1/bin/kafka-console-producer.sh -broker-list localhost:9092 -topic test 7.2.6.5 创建消费者 #重新打开一个ssh连接执行以下命令 kafka_2.11-2.1.1/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 7.2.6.6 测试 在生成者连接中输入内容.&nbsp; test&nbsp; 在消费者连接中查看是否接收到消息 7.3 kafka相关配置参数 broker.id &nbsp;整数，建议根据ip区分 &nbsp;　 log.dirs &nbsp;kafka存放消息文件的路径， &nbsp;默认/tmp/kafka-logs port &nbsp;broker用于接收producer消息的端口 &nbsp;　 zookeeper.connnect &nbsp;zookeeper连接 &nbsp;格式为 &nbsp;ip1:port,ip2:port,ip3:port message.max.bytes &nbsp;单条消息的最大长度 &nbsp;　 num.network.threads &nbsp;broker用于处理网络请求的线程数 &nbsp;如不配置默认为3，server.properties默认是2 num.io.threads &nbsp;broker用于执行网络请求的IO线程数 &nbsp;如不配置默认为8，server.properties默认是2可适当增大， queued.max.requests &nbsp;排队等候IO线程执行的requests &nbsp;默认为500 host.name &nbsp;broker的hostname &nbsp;默认null,建议写主机的ip,不然消费端不配置hosts会有麻烦 num.partitions &nbsp;topic的默认分区数 &nbsp;默认1 log.retention.hours &nbsp;消息被删除前保存多少小时 &nbsp;默认1周168小时 auto.create.topics.enable &nbsp;是否可以程序自动创建Topic &nbsp;默认true,建议false default.replication.factor &nbsp;消息备份数目 &nbsp;默认1不做复制，建议修改 num.replica.fetchers &nbsp;用于复制leader消息到follower的IO线程数 &nbsp;默认1 参考文档：https://blog.csdn.net/henianyou/article/details/75976052 至此，zookeeper以及kafka集群搭建成功。 八、filebeat 8.1 filebeat简介 &nbsp; &nbsp; &nbsp; &nbsp;beats是ELK体系中新增的一个工具，它属于一个轻量的日志采集器，以上我们使用的日志采集工具是logstash，但是logstash占用的资源比较大，没有beats轻量。 &nbsp; &nbsp; &nbsp; &nbsp;filebeat是用go编写，logstash使用ruby写的。Logstash会占用不少的jvm。 当然，也不是filebeat完全占优，filebeat也专注于采集而已，所以这也是为什么很多架构都是filebeat后面接着logstash来做信息转换。 8.2 filebeat安装 8.2.1 安装 去官网下载filebeat的安装包：filebeat-6.7.2.tar.gz 地址：https://www.elastic.co/cn/downloads/ [root@server ~]# tar -zxvf filebeat-6.7.2.tar.gz 说明：filebeat为日志采集工具，一般是安装在应用服务器。 8.2.2 配置 [root@server ~]# vim /usr/filebeat-6.7.2-linux-x86_64/filebeat.yml &nbsp;# 增加或者更改为以下内容 filebeat.prospectors: &nbsp;- input_type: log &nbsp;#除了&quot;log&quot;，还有&quot;stdin&quot; paths: &nbsp; &nbsp; - /tmp/*.log &nbsp; #读取文件路径 &nbsp; &nbsp;#include_lines: [&#39;ERROR&#39;] &nbsp; #只发送包含这些字样的日志 &nbsp; &nbsp;multiline: &nbsp; &nbsp;&nbsp; &nbsp;#&nbsp;&nbsp; &nbsp;多行合并 &nbsp; &nbsp; &nbsp; pattern: &#39;^\\d{4}-\\d{1,2}-\\d{1,2}&#39; &nbsp;#日期开头的 &nbsp; &nbsp; &nbsp; negate: &nbsp;true &nbsp; &nbsp; &nbsp; match: after &nbsp; &nbsp;#after和before &nbsp; &nbsp;fields: &nbsp; &nbsp; &nbsp; beat.name: xxx.xxx.xxx.xxx &nbsp;#增加属性 &nbsp;&nbsp; &nbsp; &nbsp;log_topics: test #output.elasticsearch: &nbsp;# 先将这几句注释掉 &nbsp; # Array of hosts to connect to. # &nbsp;hosts: [&quot;localhost:9200&quot;] output.kafka: &nbsp; enabled: true &nbsp; hosts: [&quot;192.168.1.105:9092&quot;,&quot;192.168.1.106:9092&quot;,&quot;192.168.1.107:9092&quot;] &nbsp; topic: &#39;%{[fields][log_topics]}&#39; &nbsp; required_acks: 1 8.2.3 启动 [root@server ~]# cd /usr/filebeat-6.7.2-linux-x86_64 [root@server ~]# nohup ./filebeat -e -c filebeat.yml &gt; filebeat.out &amp; 九 ELK测试 9.1 启动 以上将所有组件搭建完毕，依此启动各个组件，启动顺序为：elasticsearch集群、kibana、kafka集群、logstash集群、filebeat。 9.2 验证 去kabana界面，查看对应数据是否成功收集并展示。 十 kafka-manager简介 &nbsp; &nbsp; &nbsp; &nbsp; kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容： 1、管理多个集群 2、轻松检查群集状态（主题，消费者，偏移，代理，副本分发，分区分发） 3、运行首选副本选举 4、使用选项生成分区分配以选择要使用的代理 5、运行分区重新分配（基于生成的分配） 6、使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置） 7、删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true） 8、主题列表现在指示标记为删除的主题（仅支持0.8.2+） 9、批量生成多个主题的分区分配，并可选择要使用的代理 10、批量运行重新分配多个主题的分区 11、将分区添加到现有主题 12、更新现有主题的配置 具体安装配置，此文档不做说明。 参考文档：https://www.cnblogs.com/frankdeng/p/9584870.html 最后感谢以下优秀文章的学习、借鉴： elk搭建：https://blog.51cto.com/zero01/2079879 kafka搭建：https://blog.csdn.net/makang456/article/details/78719698 logstash之grok：https://blog.csdn.net/shunzi1046/article/details/53421701 elk自动定时清理：https://blog.51cto.com/qiuyt/2053441?utm_source=oschina-app","@type":"BlogPosting","url":"https://uzzz.org/2019/08/13/794563.html","headline":"ELK6.7.2搭建教程","dateModified":"2019-08-13T00:00:00+08:00","datePublished":"2019-08-13T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/13/794563.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>ELK6.7.2搭建教程</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>一、ELK简介</p> 
  <p><span style="color:#3d464d;">&nbsp; &nbsp; &nbsp; &nbsp; ELK是三个开源软件的缩写，分别为：Elasticsearch 、 Logstash以及Kibana , 它们都是开源软件。ELK</span><span style="color:#3d464d;">是一整套日志管理系统，对于日志的集中化管理，日志的统计和检索等都能够完美解决。</span></p> 
  <p>二、ELK选型</p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>工作模式1</strong></span></strong><span style="color:#4b4b4b;">：logstash采集、处理、转发到elasticsearch存储，在kibana进行展示</span>&nbsp;</p> 
  <p style="margin-left:0pt;"><span style="color:#4b4b4b;">--</span>&nbsp;<strong><span style="color:#4b4b4b;"><strong>datasource-&gt;logstash-&gt;elasticsearch-&gt;kibana</strong></span></strong></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>模式特点</strong></span></strong><span style="color:#4b4b4b;">：这种结构因为需要在各个服务器上部署 Logstash，而它比较消耗 CPU 和内存资源，所以比较适合计算资源丰富的服务器，否则容易造成服务器性能下降，甚至可能导致无法正常工作。</span></p> 
  <p style="margin-left:0pt;"><img alt="" class="has" height="266" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019072511282311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70" width="571"></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>工作模式2：</strong></span></strong><span style="color:#4b4b4b;">Beats 将搜集到的数据发送到 Logstash，经 Logstash 解析、过滤后，将其发送到 Elasticsearch 存储，并由 Kibana 呈现给用户</span></p> 
  <p style="margin-left:0pt;"><span style="color:#4b4b4b;">-</span><span style="color:#4b4b4b;">-</span>&nbsp;<strong><span style="color:#4b4b4b;"><strong>datasource-&gt;filebeat-&gt;logstash-&gt; elasticsearch-&gt;kibana</strong></span></strong></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>模式特点：</strong></span></strong><span style="color:#4b4b4b;">这种架构解决了 Logstash 在各服务器节点上占用系统资源高的问题。相比 Logstash，Beats 所占系统的 CPU 和内存几乎可以忽略不计。另外，Beats 和 Logstash 之间支持 SSL/TLS 加密传输，客户端和服务器双向认证，保证了通信安全。</span></p> 
  <p style="margin-left:0pt;"><span style="color:#4b4b4b;">因此这种架构适合对数据安全性要求较高，同时各服务器性能比较敏感的场景</span></p> 
  <p style="margin-left:0pt;"><img alt="" class="has" height="247" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190725113055276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70" width="659"></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>工作模式3：</strong></span></strong><span style="color:#4b4b4b;">Filebeat采集完毕直接入到kafka消息队列，进而logstash取出数据，进行处理分析输出到es，并在kibana进行展示。</span><span style="color:#4b4b4b;">（</span><strong><span style="color:#4b4b4b;"><strong>filebeat版本5.0以上</strong></span></strong><strong><span style="color:#4b4b4b;"><strong>才支持直接输出到kafka</strong></span></strong><span style="color:#4b4b4b;">）</span></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;">--datasource-&gt;filebeat-&gt;kafka-&gt;logstash-&gt;elasticsearch-&gt;kibana</span></strong></p> 
  <p style="margin-left:0pt;"><strong><span style="color:#4b4b4b;"><strong>模式特点：这种架构适合于日志规模比较庞大的情况。引入消息队列，均衡了网络传输，从而降低了网络闭塞，尤其是丢失数据的可能性。</strong></span></strong></p> 
  <p style="margin-left:0pt;"><img alt="" class="has" height="472" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812153459725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70" width="876"></p> 
  <p style="margin-left:0pt;"><span style="color:#4b4b4b;">总结：以上是目前流行的ELK收集模式，本次搭建ELK主要是收集数据量极大的日志，综合考虑，选择工作模式3进行搭建。</span></p> 
  <p style="margin-left:0pt;">更多ELK工作模式，请参考文档：<a href="https://www.cnblogs.com/qingqing74647464/p/9378385.html" rel="nofollow" data-token="3a97230e428d45ed728d62fb291b687c">https://www.cnblogs.com/qingqing74647464/p/9378385.html</a></p> 
  <p style="margin-left:0pt;">三、安装前的准备工作</p> 
  <p style="margin-left:0pt;">3.1 服务器</p> 
  <p style="margin-left:0pt;">（1）准备8台服务器，以下是服务器配置详情，及用途。</p> 
  <table border="1" cellspacing="0">
   <tbody>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><strong><span style="color:#000000;">操作系统版本</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><strong><span style="color:#000000;">IP地址</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">CPU核数</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">内存大小（G）</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">磁盘大小（G）</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">内网访问端口号</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">内网互通权限</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><strong><span style="color:#000000;">是否需要访问外网</span></strong></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><strong><span style="color:#000000;">用途</span></strong></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.100</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">200</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的<span style="color:#ff0000;">master1</span><span style="color:#000000;">节点及kibana</span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.101</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">200</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的<span style="color:#ff0000;">master2</span><span style="color:#000000;">节点</span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.102</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">1024</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的<span style="color:#ff0000;">data1</span><span style="color:#000000;">节点</span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.103</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">1024</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的<span style="color:#ff0000;">data2</span><span style="color:#000000;">节点</span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.104</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">1024</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建elasticsearch集群的<span style="color:#ff0000;">data3</span><span style="color:#000000;">节点</span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.105</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">200</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群</span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.106</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">200</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群</span></td> 
    </tr>
    <tr>
     <td style="border-color:#000000;vertical-align:middle;width:79.8pt;"><span style="color:#000000;">Centos7.6</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:81pt;"><span style="color:#000000;">192.168.1.107</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">8</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">16</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">200</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">全开</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">同网段互通</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:48pt;"><span style="color:#000000;">是</span></td> 
     <td style="border-color:#000000;vertical-align:middle;width:180pt;"><span style="color:#000000;">内核4.4+，保证能上网，拥有root权限，用于搭建kafka集群、logstash集群</span></td> 
    </tr>
   </tbody>
  </table>
  <p>（2）安装jdk8</p> 
  <p>参考文档：<a href="https://www.cnblogs.com/shihaiming/p/5809553.html" rel="nofollow" data-token="0e10199eba18877320af68ffa9c5d3f6">https://www.cnblogs.com/shihaiming/p/5809553.html</a></p> 
  <p>（3）关闭防火墙</p> 
  <p><span style="color:#333333;">查看防火墙状态：</span><span style="color:#333333;">systemctl </span><span style="color:#333333;">status</span><span style="color:#333333;">&nbsp;firewalld.service</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">关闭防火墙：</span><span style="color:#333333;">systemctl stop firewalld.service</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">禁止开机启动防火墙：systemctl disable firewalld.service</span></p> 
  <p style="margin-left:0pt;">3.2 版本信息</p> 
  <ul>
   <li><span style="color:#333333;">Elasticsearch-</span><span style="color:#333333;">6.7.2</span></li> 
   <li><span style="color:#333333;">logstash-</span><span style="color:#333333;">6.7.2</span></li> 
   <li><span style="color:#333333;">kibana-</span><span style="color:#333333;">6.7.2</span></li> 
   <li><span style="color:#333333;">filebeat-</span><span style="color:#333333;">6.7.2</span></li> 
   <li><span style="color:#333333;">kibana-</span><span style="color:#333333;">6.7.2</span></li> 
   <li><span style="color:#333333;">kafka_2.11-2.1.1</span></li> 
   <li><span style="color:#333333;">zookeeper-3.4.14</span></li> 
   <li><span style="color:#333333;">kafka-manager-1.3.3.7（kafka界面管理工具）可根据个人情况选用</span></li> 
  </ul>
  <p>四、Elasticsearch</p> 
  <p>4.1&nbsp;<strong><strong><strong>Elasticsearch</strong></strong><strong><strong>简介</strong></strong></strong></p> 
  <p><span style="color:#3d464d;">&nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。</span></p> 
  <p>4.2&nbsp;<strong><strong><strong>Elasticsearch</strong></strong><strong><strong>安装</strong></strong></strong></p> 
  <p>4.2.1 安装</p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">去官网</span><span style="color:#3d464d;">下载elasticsearch的安装包：elasticsearch-6.7.2.tar.gz</span></p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">地址：</span><a href="https://www.elastic.co/cn/downloads/" rel="nofollow" data-token="731ada02daf726f1b2cc114b80ec0728"><u><span style="color:#0563c1;"><u>https://www.elastic.co/cn/downloads/</u></span></u></a></p> 
  <p style="margin-left:0pt;">（1）上传安装包至linux服务器</p> 
  <p style="margin-left:0pt;">（2）解压安装包</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#333333;">&nbsp;[root@master1~]</span><span style="color:#999988;"># tar -zxvf elasticsearch-6.7.2.tar.gz&nbsp; &nbsp;#解压安装包</span></p> 
  </blockquote> 
  <p style="margin-left:0pt;">4.2.2 配置</p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">&nbsp; &nbsp; &nbsp; &nbsp;Elasticsearch</span><span style="color:#3d464d;">主要有</span><span style="color:#3d464d;">两个配置文件</span><span style="color:#3d464d;">，</span><span style="color:#3d464d;">elasticsearch.yml&nbsp;文件用于配置集群节点等相关信息的，elasticsearch&nbsp;文件则是配置服务本身相关的配置，例如某个配置文件的路径以及java的一些路径配置什么的。</span></p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">开始配置集群节点，在 192.168.1.100上编辑配置文件：</span></p> 
  <blockquote> 
   <p style="margin-left:0pt;">[root@master1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml<br> cluster.name: master-slave&nbsp; #自定义集群名称<br> node.name: master-1&nbsp; &nbsp; #节点名称<br> node.master: true&nbsp; &nbsp; &nbsp;#是否master节点<br> node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点<br> network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个<br> http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口<br> transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口<br> bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区<br> discovery.zen.ping.unicast.hosts: ["192.168.2.100:9300", "192.168.2.101:9300", "192.168.2.102:9300", "192.168.2.103:9300", "192.168.2.104:9300"]</p> 
  </blockquote> 
  <p>192.168.1.101</p> 
  <blockquote> 
   <p>[root@master2 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml<br> cluster.name: master-slave&nbsp; #自定义集群名称<br> node.name: master-2&nbsp; &nbsp; #节点名称<br> node.master: true&nbsp; &nbsp; &nbsp;#是否master节点<br> node.data: false&nbsp; &nbsp; &nbsp;#是否数据节点<br> network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个<br> http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口<br> transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口<br> bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区<br> discovery.zen.ping.unicast.hosts: ["192.168.2.100:9300", "192.168.2.101:9300", "192.168.2.102:9300", "192.168.2.103:9300", "192.168.2.104:9300"]</p> 
  </blockquote> 
  <p>192.168.1.102</p> 
  <blockquote> 
   <p>[root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml<br> cluster.name: master-slave&nbsp; #自定义集群名称<br> node.name: node-1&nbsp; &nbsp; #节点名称<br> node.master: false&nbsp; &nbsp; &nbsp;#是否master节点<br> node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点<br> network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个<br> http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口<br> transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口<br> bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区<br> discovery.zen.ping.unicast.hosts: ["192.168.2.100:9300", "192.168.2.101:9300", "192.168.2.102:9300", "192.168.2.103:9300", "192.168.2.104:9300"]</p> 
  </blockquote> 
  <p>192.168.1.103</p> 
  <blockquote> 
   <p>[root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml<br> cluster.name: master-slave&nbsp; #自定义集群名称<br> node.name: node-2&nbsp; &nbsp; #节点名称<br> node.master: false&nbsp; &nbsp; &nbsp;#是否master节点<br> node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点<br> network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个<br> http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口<br> transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口<br> bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区<br> discovery.zen.ping.unicast.hosts: ["192.168.2.100:9300", "192.168.2.101:9300", "192.168.2.102:9300", "192.168.2.103:9300", "192.168.2.104:9300"]</p> 
  </blockquote> 
  <p>192.168.1.104</p> 
  <blockquote> 
   <p>[root@node1 ~]# vim /usr/elasticsearch/elasticsearch-6.7.2/config/elasticsearch.yml<br> cluster.name: master-slave&nbsp; #自定义集群名称<br> node.name: node-3&nbsp; &nbsp; #节点名称<br> node.master: false&nbsp; &nbsp; &nbsp;#是否master节点<br> node.data: true&nbsp; &nbsp; &nbsp;#是否数据节点<br> network.host: 0.0.0.0&nbsp; &nbsp; #监听地址（默认为0.0.0.0），也可以填写多个<br> http.port: 9200&nbsp; &nbsp; #es集群提供外部访问的接口<br> transport.tcp.port: 9300&nbsp; &nbsp; &nbsp;#es集群内部通信接口<br> bootstrap.memory_lock: true &nbsp;#避免es使用swap交换分区<br> discovery.zen.ping.unicast.hosts: ["192.168.2.100:9300", "192.168.2.101:9300", "192.168.2.102:9300", "192.168.2.103:9300", "192.168.2.104:9300"]</p> 
  </blockquote> 
  <p>依此启动</p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">[root@master1 ~]# cd /usr/elasticsearch/elasticsearch-6.7.2/bin/<br> [root@master1 bin]# ./elasticsearch -d</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">可能遇到的问题：</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">1、</span><span style="color:#000000;">报错：</span><span style="color:#000000;">can not run elasticsearch as root</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">&nbsp; &nbsp; &nbsp; &nbsp; 使用root账户启动造成的报错，这是出于系统安全考虑设置的条件。由于ElasticSearch可以接收用户输入的脚本并且执行，为了系统安全考虑，</span><span style="color:#333333;">建议创建一个单独的用户用来运行ElasticSearch。</span></p> 
  <p style="margin-left:0pt;"><span style="color:#333333;">创建elsearch用户组及elsearch用户<br> &nbsp; &nbsp; groupadd elsearch<br> &nbsp; &nbsp; useradd elsearch -g elsearch -p elasticsearch<br> 更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch<br> &nbsp; &nbsp; cd /usr<br> &nbsp; &nbsp; chown -R elsearch:elsearch &nbsp;elasticsearch-6.7.2<br> 切换到elsearch用户再启动<br> &nbsp; &nbsp; su elsearch cd elasticsearch/bin<br> &nbsp; &nbsp; ./elasticsearch -d</span></p> 
  <p>2、<span style="color:#000000;">max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]</span></p> 
  <blockquote> 
   <p><span style="color:#000000;">每个进程最大同时打开文件数太小，可通过下面2个命令查看当前数量<br> 修改/etc/security/limits.conf文件，增加配置，用户退出后重新登录生效<br> * &nbsp;soft &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;65536<br> * &nbsp;hard &nbsp; &nbsp;nofile &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;131072<br> * &nbsp;soft &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited<br> * &nbsp;hard &nbsp; &nbsp;memlock &nbsp; &nbsp; &nbsp; &nbsp; unlimited</span></p> 
  </blockquote> 
  <p>3、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]<br> elasticsearch用户拥有的内存权限太小，至少需要262144&nbsp; &nbsp;</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;由于ES构建基于lucene, 而lucene设计强大之处在于lucene能够很好的利用操作系统内存来缓存索引数据，以提供快速的查询性能。lucene的索引文件segements是存储在单文件中的，并且不可变，对于OS来说，能够很友好地将索引文件保持在cache中，以便快速访问；因此，我们很有必要将一半的物理内存留给lucene ; 另一半的物理内存留给ES（JVM heap )。所以， 在ES内存设置方面，可以遵循以下原则：<br> 1.当机器内存小于64G时，遵循通用的原则，50%给ES，50%留给lucene。<br> 2.当机器内存大于64G时，遵循以下原则：&nbsp;<br> a.如果主要的使用场景是全文检索, 那么建议给ES Heap分配 4~32G的内存即可；其它内存留给操作系统, 供lucene使用（segments cache), 以提供更快的查询性能。&nbsp;<br> b.如果主要的使用场景是聚合或排序， 并且大多数是numerics, dates, geo_points 以及not_analyzed的字符类型， 建议分配给ES Heap分配 4~32G的内存即可，其它内存留给操作系统，供lucene使用(doc values cache)，提供快速的基于文档的聚类、排序性能。&nbsp;<br> c.如果使用场景是聚合或排序，并且都是基于analyzed 字符数据，这时需要更多的 heap size, 建议机器上运行多ES实例，每个实例保持不超过50%的ES heap设置(但不超过32G，堆内存设置32G以下时，JVM使用对象指标压缩技巧节省空间)，50%以上留给lucene。</p> 
  <p>更多es性能调优参数，参考文档：https://www.jianshu.com/p/532b540d4c46</p> 
  <p>解决办法：<br> 在&nbsp;&nbsp;&nbsp;/etc/sysctl.conf文件最后添加一行<br> vm.max_map_count=262144<br> 执行sysctl -p<br> 即可永久修改</p> 
  <p>参考数据（4g/4194304 &nbsp;8g/8388608）如果申请16G的内存，可适当将vm.max_map_count=4194304或8388608</p> 
  <p>4.2.3 curl查看es集群情况</p> 
  <p>依此成功启动es的各个集群节点，查看集群的状态：</p> 
  <blockquote> 
   <p>[root@master1&nbsp;~]# curl '192.168.1.100:9200/_cluster/health?pretty'<br> {<br> &nbsp; "cluster_name" : "master-slave&nbsp;",<br> &nbsp; "status" : "green", &nbsp;# 为green则代表健康没问题，如果是yellow或者red则是集群有问题<br> &nbsp; "timed_out" : false, &nbsp;# 是否有超时<br> &nbsp; "number_of_nodes" : 5, # 集群中的节点数量<br> &nbsp; "number_of_data_nodes" : 3, # 集群中data节点的数量<br> &nbsp; "active_primary_shards" : 0,<br> &nbsp; "active_shards" : 0,<br> &nbsp; "relocating_shards" : 0,<br> &nbsp; "initializing_shards" : 0,<br> &nbsp; "unassigned_shards" : 0,<br> &nbsp; "delayed_unassigned_shards" : 0,<br> &nbsp; "number_of_pending_tasks" : 0,<br> &nbsp; "number_of_in_flight_fetch" : 0,<br> &nbsp; "task_max_waiting_in_queue_millis" : 0,<br> &nbsp; "active_shards_percent_as_number" : 100.0<br> }</p> 
  </blockquote> 
  <p><span style="color:#3d464d;">更多使用curl命令操作elasticsearch的内容，参考文档：</span><a href="http://zhaoyanblog.com/archives/732.html" rel="nofollow" data-token="c95a3f3ff967236bf73664e4e6ae17d9"><u><span style="color:#4285f4;"><u>http://zhaoyanblog.com/archives/732.html</u></span></u></a></p> 
  <p>五、kibana</p> 
  <p>5.1 kibana简介</p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">&nbsp; &nbsp; &nbsp; &nbsp;Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。</span></p> 
  <p>5.2 kibana安装</p> 
  <p>5.2.1 安装</p> 
  <p>去官网下载kibana的安装包：kibana-6.7.2.tar.gz<br> 地址：https://www.elastic.co/cn/downloads/<br> [root@master1&nbsp;~]# tar -zxvf kibana-6.7.2.tar.gz</p> 
  <p>5.2.2 配置</p> 
  <p>安装完成后，对kibana进行配置：</p> 
  <blockquote> 
   <p>[root@master1 ~]# vim /usr/kibana/kibana-6.7.2-linux-x86_64/config/kibana.yml &nbsp;# 增加以下内容<br> server.port: 5601 &nbsp;# 配置kibana的端口<br> server.host: 192.168.1.100&nbsp; # 配置监听ip<br> elasticsearch.hosts: ["http://192.168.1.100:9200","http://192.168.1.101:9200"] &nbsp;# 配置es服务器的ip，如果是集群则配置该集群中主节点的ip<br> logging.dest: /var/log/kibana.log &nbsp;# 配置kibana的日志文件路径，不然默认是messages里记录日志</p> 
  </blockquote> 
  <p>创建日志文件：</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#333333;">[root@master-node ~]</span><span style="color:#999988;"># touch /var/log/kibana.log</span></p> 
  </blockquote> 
  <p><span style="color:#3d464d;">启动kibana服务，并检查进程和监听端口：</span></p> 
  <blockquote> 
   <p><span style="color:#3d464d;">[root@master1 ~]# cd /usr/kibana/kibana-6.7.2-linux-x86_64/bin/<br> [root@master1 bin]# ./kibana &amp;&nbsp;<br> [root@master1 ~]# ps aux |grep kibana<br> kibana &nbsp; &nbsp; 3083 36.8 &nbsp;2.9 1118668 112352 ? &nbsp; &nbsp; &nbsp;Ssl &nbsp;17:14 &nbsp; 0:03 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kibana/bin/../src/cli -c /etc/kibana/kibana.yml<br> root &nbsp; &nbsp; &nbsp; 3095 &nbsp;0.0 &nbsp;0.0 112660 &nbsp; 964 pts/0 &nbsp; &nbsp;S+ &nbsp; 17:14 &nbsp; 0:00 grep --color=auto kibana<br> [root@master1 ~]# netstat -lntp |grep 5601<br> tcp &nbsp; &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;0 192.168.1.100:5601 &nbsp; &nbsp; 0.0.0.0:* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LISTEN &nbsp; &nbsp; &nbsp;3083/node &nbsp; &nbsp;</span></p> 
  </blockquote> 
  <p><span style="color:#3d464d;">然后在浏览器里进行访问，如：</span><a href="http://10.28.1.200:5601/" rel="nofollow" data-token="469535f880805d1e67b7136db5f5489f"><u><span style="color:#0563c1;"><u>http://192.168.1.100:5601/</u></span></u></a><span style="color:#3d464d;">&nbsp;，由于我们并没有安装x-pack，所以此时是没有用户名和密码的，可以直接访问的</span><span style="color:#3d464d;">。</span></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812170127324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p><span style="color:#3d464d;">点击Index Patterns,创建新索引</span></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019081217182456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812172233960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812172248765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190812173013736.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019081217302652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvX3JvYm90ZG9n,size_16,color_FFFFFF,t_70"></p> 
  <p>六、Logstash</p> 
  <p>6.1&nbsp;Logstash简介</p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">&nbsp; &nbsp; &nbsp; &nbsp; Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去</span></p> 
  <p>6.2 Logstash安装</p> 
  <p>6.2.1 安装</p> 
  <p>去官网下载logstash的安装包：logstash-6.7.2.tar.gz<br> 地址：https://www.elastic.co/cn/downloads/<br> [root@logstash1 ~]# tar -zxvf logstash-6.7.2.tar.gz</p> 
  <p>6.2.2 配置</p> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">安装完之后，先不要启动服务，先配置logstash收集</span><span style="color:#3d464d;">kafka</span><span style="color:#3d464d;">日志：</span></p> 
  <blockquote> 
   <p><span style="color:#3d464d;">[root@logstash1 ~]# cd /usr/logstash</span>-6.7.2<span style="color:#3d464d;">/bin/<br> [root@logstash1 bin]# mkdir conf.d<br> [root@logstash1 ~]# vim conf.d/</span>first-demo<span style="color:#3d464d;">.conf &nbsp;# 加入如下内容<br> input{<br> &nbsp; &nbsp; kafka {<br> &nbsp; &nbsp; &nbsp; &nbsp; bootstrap_servers =&gt; "192.168.1.105:9092,192.168.1.106:9092,192.168.1.107:9092"<br> &nbsp; &nbsp; &nbsp; &nbsp; topics =&gt; ["test"]<br> &nbsp; &nbsp; &nbsp; &nbsp; group_id =&gt; "consumer-test"<br> &nbsp; &nbsp; }<br> }</span></p> 
   <p><span style="color:#3d464d;">output {<br> &nbsp; &nbsp; elasticsearch {<br> &nbsp; &nbsp; &nbsp; &nbsp; hosts =&gt; ["192.168.1.100:9200","192.168.1.101:9200","192.168.1.102:9200","192.168.1.103:9200","192.168.1.104:9200"]<br> &nbsp; &nbsp; &nbsp; &nbsp; index =&gt; "server-test-%{+YYYY.MM.dd}"<br> &nbsp; &nbsp; }<br> }</span></p> 
  </blockquote> 
  <p style="margin-left:0pt;"><span style="color:#3d464d;">检测配置文件是否有错：</span></p> 
  <blockquote> 
   <p>[root@<span style="color:#3d464d;">logstash1 ~</span>]# cd /usr/logstash/bin<br> [root@<span style="color:#3d464d;">logstash1</span>&nbsp;bin]# ./logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/syslog.conf --config.test_and_exit<br> Sending Logstash's logs to /var/log/logstash which is now configured via log4j2.properties<br> Configuration OK &nbsp;# 为ok则代表配置文件没有问题<br> [root@<span style="color:#3d464d;">logstash1</span>&nbsp;bin]#&nbsp;</p> 
  </blockquote> 
  <p>命令说明：<br> --path.settings 用于指定logstash的配置文件所在的目录<br> -f 指定需要被检测的配置文件的路径<br> --config.test_and_exit 指定检测完之后就退出，不然就会直接启动了</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;当然你必须要先搭建kafka集群，并创建对应topic，所以这里先不启动logstash，以上是192.168.1.105服务器的配置，根据个人需要，可在192.168.1.106、192.168.1.107服务器上安装logtash，实现logstash集群，也可以单机启动多个logstash，实现单机多节点。</p> 
  <p>编辑logstash.yml</p> 
  <blockquote> 
   <p>[root@<span style="color:#3d464d;">logstash1 </span>~]$ cd /usr/logstash-6.7.2/config/<br> [root@<span style="color:#3d464d;">logstash1 </span>config]$ vim logstash.yml<br> path.logs: /usr/logstash-6.7.2/logstash-data/log &nbsp;#日志路径<br> path.config: /usr/logstash-6.7.2/bin/conf.d/*.conf &nbsp;#配置文件路径(支持正则)<br> path.data: /usr/logstash-6.7.2/logstash-data/data &nbsp;#logstash数据保存路径<br> http.host: "192.168.1.105" &nbsp;#主机ip</p> 
  </blockquote> 
  <p>启动命令：</p> 
  <blockquote> 
   <p>[root@<span style="color:#3d464d;">logstash1 ~</span>]# cd /usr/logstash-6.7.2<br> [root@<span style="color:#3d464d;">logstash1 </span>logstash-6.7.2]# nohup ./bin/logstash -f ./bin/conf.d/first-demo.conf &gt; ./bin/nohup.out &amp;</p> 
  </blockquote> 
  <p style="margin-left:0pt;">七、kafka</p> 
  <p>7.1 安装zookeeper</p> 
  <p>7.1.1 下载</p> 
  <p>去官网下载zookeeper的安装包：zookeeper-3.4.14.tar.gz<br> 地址：https://www-eu.apache.org/dist/zookeeper/zookeeper-3.4.14/</p> 
  <p>7.1.2 解压</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">tar -</span><span style="color:#000000;">zxvf</span><span style="color:#000000;">&nbsp;&nbsp;zookeeper-</span><span style="color:#000000;">3.4.10.tar.gz</span></p> 
  </blockquote> 
  <p>用192.168.1.105、192.168.1.106、192.168.1.107三台服务器做kakfa集群，当前配置实例为192.168.1.105</p> 
  <p>[root@logstash1 ~]$ cd /usr/zookeeper-3.4.14<br> [root@logstash1 zookeeper-3.4.14]$ mkdir data<br> [root@logstash1 zookeeper-3.4.14]$ mkdir log<br> #在每一个数据文件目录中，新建一个myid文件，文件必须是唯一的服务标识，在后面的配置中会用到<br> [root@logstash1 zookeeper-3.4.14]$ echo '1' &gt; data/myid<br> #复制出zoo.cfg文件:<br> [root@logstash1 zookeeper-3.4.14]$ cp conf/zoo_sample.cfg conf/zoo.cfg</p> 
  <p>7.1.3 配置</p> 
  <p>vim zoo.cfg</p> 
  <blockquote> 
   <p># The number of milliseconds of each tick &nbsp;<br> tickTime=2000 &nbsp;<br> # The number of ticks that the initial &nbsp;&nbsp;<br> # synchronization phase can take &nbsp;<br> initLimit=10 &nbsp;<br> # The number of ticks that can pass between &nbsp;&nbsp;<br> # sending a request and getting an acknowledgement &nbsp;<br> syncLimit=5 &nbsp;<br> # the directory where the snapshot is stored. &nbsp;<br> # do not use /tmp for storage, /tmp here is just &nbsp;&nbsp;<br> # example sakes. &nbsp;<br> #存储路径<br> dataDir=/实际路径/zookeeper-cluster/data&nbsp;&nbsp;<br> #日志路径，方便查LOG<br> dataLogDir=/实际路径/zookeeper-cluster/log<br> # the port at which the clients will connect &nbsp;<br> clientPort=2181 &nbsp;<br> # the maximum number of client connections. &nbsp;<br> # increase this if you need to handle more clients &nbsp;<br> #控制客户的连接数，默认数为60，太少<br> maxClientCnxns=300<br> #maxClientCnxns=60 &nbsp;<br> # &nbsp;<br> # Be sure to read the maintenance section of the &nbsp;&nbsp;<br> # administrator guide before turning on autopurge. &nbsp;<br> # &nbsp;<br> #http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance &nbsp;<br> # &nbsp;<br> # The number of snapshots to retain in dataDir &nbsp;<br> #autopurge.snapRetainCount=3 &nbsp;<br> # Purge task interval in hours &nbsp;<br> # Set to "0" to disable auto purge feature &nbsp;<br> #autopurge.purgeInterval=1 &nbsp;<br> #zookeeper集群地址（本机的ip填0.0.0.0）<br> server.1=0.0.0.0:2888:3888<br> server.2=192.168.1.106:2888:3888<br> server.3=192.168.1.107:2888:3888</p> 
  </blockquote> 
  <p>192.168.1.106、192.168.1.107服务器的配置类似，请参考192.168.1.105服务器配置。</p> 
  <p>7.1.4 启动</p> 
  <p>分别启动3个zookeeper服务</p> 
  <blockquote> 
   <p>$ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp;<br> $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp;<br> $ /usr/zookeeper-3.4.14/bin/zkServer.sh start&nbsp;</p> 
  </blockquote> 
  <p>启动完成后查看每个服务的状态</p> 
  <blockquote> 
   <p>$ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp;<br> $ /usr/zookeeper-3.4.14/bin/zkServer.sh status &nbsp;<br> $ /usr/zookeeper-3.4.14/bin/zkServer.sh status</p> 
  </blockquote> 
  <p>7.2 安装kafka</p> 
  <p>7.2.1 下载</p> 
  <p>去官网下载kafka的安装包：kafka_2.11-2.1.1.tgz<br> 地址：http://kafka.apache.org/downloads</p> 
  <p>7.2.2 解压</p> 
  <blockquote> 
   <p style="margin-left:0pt;">tar zxvf kafka_2.11-2.1.1.tgz</p> 
  </blockquote> 
  <p>7.2.3 配置</p> 
  <p>以192.168.1.105为例</p> 
  <blockquote> 
   <p style="margin-left:0pt;">[root@logstash1 ~]$ cd /usr/kafka_2.11-2.1.1/config/server.properties<br> #配置zookeeper连接,默认Kafka会使用ZooKeeper默认的/路径，这样有关Kafka的ZooKeeper配置就会散落在根路径下面，如果你有其他的应用也在使用ZooKeeper集群，查看ZooKeeper中数据可能会不直观，所以强烈建议指定一个chroot路径，直接在zookeeper.connect配置项中指定<br> zookeeper.connect=192.168.1.105:2181, 192.168.1.106:2181, 192.168.1.107:2181/kafka<br> #每个Kafka Broker应该配置一个唯一的ID&nbsp;<br> broker.id=0&nbsp;<br> #端口号<br> port=9092<br> #如果有多个网卡地址，也可以将不同的Broker绑定到不同的网卡 &nbsp;<br> host.name=192.168.1.105<br> #日志目录<br> log.dirs=/usr/kafka_2.11-2.1.1/logs<br> #设置topic可删除，默认该项是被注释的，需要放开<br> delete.topic.enable=true<br> #关闭自动创建topic，默认情况下Producer往一个不存在的Topic发送message时会自动创建这个Topic<br> auto.create.topics.enable=false</p> 
  </blockquote> 
  <p>7.2.4 启动</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1/bin/kafka-server-start.sh kafka_2.11-2.1.1/config/server.properties &amp;</span></p> 
  </blockquote> 
  <p>7.2.5 关闭</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1/bin/kafka-server-stop.sh</span></p> 
  </blockquote> 
  <p>7.2.6 topic</p> 
  <p>7.2.6.1 创建topic</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1/bin/kafka-topics.sh -topic test -create -partitions 3 -replication-factor 1 -zookeeper 192.168.1.105:2181/kafka</span></p> 
  </blockquote> 
  <p>-topic 主题名称<br> -partitions 分区<br> -replication-factor 副本</p> 
  <p>7.2.6.2 查看指定topic属性</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1/bin/kafka-topics.sh -describe -zookeeper 192.168.1.105:2181/kafka -topic test</span></p> 
  </blockquote> 
  <p>7.2.6.3 查看topic列表</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1/bin/kafka-topics.sh -list -zookeeper 192.168.1.105:2181/kafka</span></p> 
  </blockquote> 
  <p>7.2.6.4 创建生产者</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1</span><span style="color:#000000;">/bin/kafka-console-producer.sh -broker-list localhost:9092 -topic test</span></p> 
  </blockquote> 
  <p>7.2.6.5 创建消费者</p> 
  <p style="margin-left:0pt;">#重新打开一个ssh连接执行以下命令</p> 
  <blockquote> 
   <p style="margin-left:0pt;"><span style="color:#000000;">kafka_2.11-2.1.1</span><span style="color:#000000;">/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span></p> 
  </blockquote> 
  <p>7.2.6.6 测试</p> 
  <p>在生成者连接中输入内容.&nbsp;<br> test&nbsp;<br> 在消费者连接中查看是否接收到消息</p> 
  <p>7.3 kafka相关配置参数</p> 
  <blockquote> 
   <p>broker.id &nbsp;整数，建议根据ip区分 &nbsp;　<br> log.dirs &nbsp;kafka存放消息文件的路径， &nbsp;默认/tmp/kafka-logs<br> port &nbsp;broker用于接收producer消息的端口 &nbsp;　<br> zookeeper.connnect &nbsp;zookeeper连接 &nbsp;格式为 &nbsp;ip1:port,ip2:port,ip3:port<br> message.max.bytes &nbsp;单条消息的最大长度 &nbsp;　<br> num.network.threads &nbsp;broker用于处理网络请求的线程数 &nbsp;如不配置默认为3，server.properties默认是2<br> num.io.threads &nbsp;broker用于执行网络请求的IO线程数 &nbsp;如不配置默认为8，server.properties默认是2可适当增大，<br> queued.max.requests &nbsp;排队等候IO线程执行的requests &nbsp;默认为500<br> host.name &nbsp;broker的hostname &nbsp;默认null,建议写主机的ip,不然消费端不配置hosts会有麻烦<br> num.partitions &nbsp;topic的默认分区数 &nbsp;默认1<br> log.retention.hours &nbsp;消息被删除前保存多少小时 &nbsp;默认1周168小时<br> auto.create.topics.enable &nbsp;是否可以程序自动创建Topic &nbsp;默认true,建议false<br> default.replication.factor &nbsp;消息备份数目 &nbsp;默认1不做复制，建议修改<br> num.replica.fetchers &nbsp;用于复制leader消息到follower的IO线程数 &nbsp;默认1</p> 
  </blockquote> 
  <p style="margin-left:0pt;">参考文档：<a href="https://blog.csdn.net/henianyou/article/details/75976052" rel="nofollow" data-token="9bbf70755defc071dc1cc5ef445ab869"><u><span style="color:#0563c1;"><u>https://blog.csdn.net/henianyou/article/details/75976052</u></span></u></a></p> 
  <p>至此，zookeeper以及kafka集群搭建成功。</p> 
  <p>八、filebeat</p> 
  <p>8.1 filebeat简介</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;beats是ELK体系中新增的一个工具，它属于一个轻量的日志采集器，以上我们使用的日志采集工具是logstash，但是logstash占用的资源比较大，没有beats轻量。<br> &nbsp; &nbsp; &nbsp; &nbsp;filebeat是用go编写，logstash使用ruby写的。Logstash会占用不少的jvm。<br> 当然，也不是filebeat完全占优，filebeat也专注于采集而已，所以这也是为什么很多架构都是filebeat后面接着logstash来做信息转换。</p> 
  <p>8.2 filebeat安装</p> 
  <p>8.2.1 安装</p> 
  <p>去官网下载filebeat的安装包：filebeat-6.7.2.tar.gz<br> 地址：https://www.elastic.co/cn/downloads/<br> [root@server ~]# tar -zxvf filebeat-6.7.2.tar.gz</p> 
  <p>说明：filebeat为日志采集工具，一般是安装在应用服务器。</p> 
  <p>8.2.2 配置</p> 
  <blockquote> 
   <p>[root@server ~]# vim /usr/filebeat-6.7.2-linux-x86_64/filebeat.yml &nbsp;# 增加或者更改为以下内容<br> filebeat.prospectors:<br> &nbsp;- input_type: log &nbsp;#除了"log"，还有"stdin"<br> paths:<br> &nbsp; &nbsp; - /tmp/*.log &nbsp; #读取文件路径<br> &nbsp; &nbsp;#include_lines: ['ERROR'] &nbsp; #只发送包含这些字样的日志<br> &nbsp; &nbsp;multiline: &nbsp; &nbsp;&nbsp; &nbsp;#&nbsp;&nbsp; &nbsp;多行合并<br> &nbsp; &nbsp; &nbsp; pattern: '^\d{4}-\d{1,2}-\d{1,2}' &nbsp;#日期开头的<br> &nbsp; &nbsp; &nbsp; negate: &nbsp;true<br> &nbsp; &nbsp; &nbsp; match: after &nbsp; &nbsp;#after和before<br> &nbsp; &nbsp;fields:<br> &nbsp; &nbsp; &nbsp; beat.name: xxx.xxx.xxx.xxx &nbsp;#增加属性<br> &nbsp;&nbsp; &nbsp; &nbsp;log_topics: test<br> #output.elasticsearch: &nbsp;# 先将这几句注释掉<br> &nbsp; # Array of hosts to connect to.<br> # &nbsp;hosts: ["localhost:9200"]<br> output.kafka:<br> &nbsp; enabled: true<br> &nbsp; hosts: ["192.168.1.105:9092","192.168.1.106:9092","192.168.1.107:9092"]<br> &nbsp; topic: '%{[fields][log_topics]}'<br> &nbsp; required_acks: 1</p> 
  </blockquote> 
  <p>8.2.3 启动</p> 
  <blockquote> 
   <p>[root@server ~]# cd /usr/filebeat-6.7.2-linux-x86_64<br> [root@server ~]# nohup ./filebeat -e -c filebeat.yml &gt; filebeat.out &amp;</p> 
  </blockquote> 
  <p>九 ELK测试</p> 
  <p>9.1 启动</p> 
  <p>以上将所有组件搭建完毕，依此启动各个组件，启动顺序为：elasticsearch集群、kibana、kafka集群、logstash集群、filebeat。</p> 
  <p>9.2 验证</p> 
  <p>去kabana界面，查看对应数据是否成功收集并展示。</p> 
  <p>十 kafka-manager简介</p> 
  <p style="margin-left:0pt;"><span style="color:#000000;">&nbsp; &nbsp; &nbsp; &nbsp; kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容：</span></p> 
  <p style="margin-left:0pt;"><span style="color:#000000;">1、管理多个集群<br> 2、轻松检查群集状态（主题，消费者，偏移，代理，副本分发，分区分发）<br> 3、运行首选副本选举<br> 4、使用选项生成分区分配以选择要使用的代理<br> 5、运行分区重新分配（基于生成的分配）<br> 6、使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置）<br> 7、删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true）<br> 8、主题列表现在指示标记为删除的主题（仅支持0.8.2+）<br> 9、批量生成多个主题的分区分配，并可选择要使用的代理<br> 10、批量运行重新分配多个主题的分区<br> 11、将分区添加到现有主题<br> 12、更新现有主题的配置</span></p> 
  <p style="margin-left:0pt;">具体安装配置，此文档不做说明。<br> 参考文档：https://www.cnblogs.com/frankdeng/p/9584870.html</p> 
  <p style="margin-left:0pt;">最后感谢以下优秀文章的学习、借鉴：</p> 
  <p style="margin-left:0pt;">elk搭建：<a href="https://blog.51cto.com/zero01/2079879" rel="nofollow" data-token="869204d149062572f69c847d60c1d2e7">https://blog.51cto.com/zero01/2079879</a></p> 
  <p style="margin-left:0pt;">kafka搭建：<a href="https://blog.csdn.net/makang456/article/details/78719698" rel="nofollow" data-token="2916fe8d47e035d18bdcd36d7fb74ba2">https://blog.csdn.net/makang456/article/details/78719698</a></p> 
  <p style="margin-left:0pt;">logstash之grok：<a href="https://blog.csdn.net/shunzi1046/article/details/53421701" rel="nofollow" data-token="e4af22ecf2883e64de8a3295fb7d3022">https://blog.csdn.net/shunzi1046/article/details/53421701</a></p> 
  <p style="margin-left:0pt;">elk自动定时清理：<a href="https://blog.51cto.com/qiuyt/2053441?utm_source=oschina-app" rel="nofollow" data-token="191d18938678e1607008704c64ccc107">https://blog.51cto.com/qiuyt/2053441?utm_source=oschina-app</a></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
