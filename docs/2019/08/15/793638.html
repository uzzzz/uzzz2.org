<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>客户端配置Hadoop并运用SLURM GPU集群与HDFS文件系统 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="客户端配置Hadoop并运用SLURM GPU集群与HDFS文件系统" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目的：运算量巨大的时候，需要使用SLURM的GPU集群来运行实验。每个SLURM集群的配置方法不一样，但是流程大致相同。下面为我配置SLURM集群的方法，亲测有效 目录 一、客户端部署 1.1 下载 1.2 安装 1.3 help 二、环境配置 2.1 python与torch配置 2.2 配置汇总 三、运用 3.1 进入文件夹 3.2 目录结构 3.3 拷入文件 3.4 路径地址 3.5 三个sh文件 四、hadoop数据服务器文件操作 4.1 submit.sh 4.2 下载与安装 4.3 afs agent 4.4 配套hadoop 4.5 参考 五、运行集群 5.1 提交任务 5.2 查看队列情况 5.3 删除操作 六、结果查看及文件传输 &nbsp; 一、客户端部署 1.1 下载 （根据平台下载相应的客户端） wget -e &quot;http_proxy**&quot; http://**/slurm-client-install.sh 下载位置，找个相对大一点的盘， df -h -l &nbsp; /dev/sdb1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.6T&nbsp; 1.8G&nbsp; 3.6T&nbsp;&nbsp; 1% /home/ssd1 $ cd /home/ssd1/ $ pwd /home/ssd1 $ wget -e &quot;http_proxy=****.cp**:8888&quot; http://**/slurm-client-v2.5/slurm-client-install.sh 下载之后看到其为： #DO NOT USE OPTION -prefix if [ &quot;$1&quot; = &quot;-prefix&quot; ];then ******=$2 else ******=~/.****** fi INSTALL_ROOT=${******}/ wget -e &quot;xxxxxxxx/slurm-client-v2.5/slurm-client-v2.5.tar.gz mkdir -p ${INSTALL_ROOT} tar zxvf slurm-client-v2.5.tar.gz -C ${INSTALL_ROOT} grep &#39;#****** use&#39; ~/.bashrc &gt;/dev/null 2&gt;&amp;1 if [ $? -ne 0 ]; then echo &#39;#******use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}&quot; &gt;&gt;~/.bashrc else sed -i &#39;/******use/,+1d&#39; ~/.bashrc echo &#39;#****** use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}&quot; &gt;&gt;~/.bashrc 不让运用-prefix选项 1.2 安装 sh slurm-client-install.sh 会下载和安装一堆选项 输入下面命令行看token测试命令是否安装成功 tokenapply tokenapply bash: tokenapply: command not found 安装脚本会自动将安装目录写入到~/.bashrc中 如果提示找不到命令，请手动source ~/.bashrc 执行2后，如果还提示找不到命令，请尝试退出机器然后重新登录机器 [ssd1]$ source ~/.bashrc [ssd1]$ tokenapply ======================================================= xxx Client is updating Version: 2.6 ------------------------------------------------------- [Total Size]:2.00 MB [██████████████████████████████████████████████████] 100% your client is not new, we have already update it for you Client updated done. ======================================================= ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(*****@*****.com) ====================================================================== 1.3 help [~]$ tokenapply -h usage: client.py [-h] [-v] [-s SUBMITTER] optional arguments: -h, --help show this help message and exit -v, --version version info -s SUBMITTER, --submitter SUBMITTER the prefix of your mailbox 二、环境配置 2.1 python与torch配置 把相应的环境配置好。 python 位置：/home/xingxiangrui/env/bin/python cuda位置： export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin client位置 2.2 配置汇总 [bin]$ ls deljob showframework showjob shownode showquota submit tokenapply tokenclean tokenconfig tokenquery [bin]$ ./tokenapply deljob showjob showquota tokenapply tokenconfig showframework shownode submit tokenclean tokenquery [bin]$ ./tokenapply ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(**@**.com) ====================================================================== [bin]$ ./tokenconfig Please input the token: ak: *** sk: *** ================================================== Config token successfully ================================================== 三、运用 3.1 进入文件夹 注意是程序运行的文件夹，可以参考： 3.2 目录结构 submit.sh 调用qsub_f提交任务的脚本 bin 任务的可执行文件及相关文件 data 本机训练数据所在目标文件夹 job.sh 任务执行脚本 log 存放运行日志（任务运行结束后会上传到 hadoop 中） output 存放输出（任务运行结束后会上传到 hadoop 中） common.conf 环境变量配置，训练脚本配置可以统一在conf里 3.3 拷入文件 文件运行之前需要确保可以本地运行 env环境拷入，先把之前的删掉。rm -rf cp -r /home/xingxiangrui/env/* env/ cp -rf /home/xingxiangrui/env/ . 两个文件需要拷入，submit.sh&nbsp;&nbsp; ， job.sh 3.4 路径地址 submit.sh,&nbsp; job.sh,&nbsp; run.sh都要改 路径 /home/xingxiangrui/.******/software-install** MPI地址：&nbsp; /home/xingxiangruisoftware-install/openmpi-1.8.5/bin/mpirun OpenMPI是一种高性能消息传递库，OpenMPI能够从高性能社区中获得专业技术、工业技术和资源支持 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin 3.5 三个sh文件 job.sh，设定服务器工作，注意下面的MPIRUN直接要用绝对路径，直接mpirun即可。 # !!! Only Runing on master node # 1. Set the env for multi-node training MPIRUN=&quot;mpirun --bind-to none&quot; IPLIST=`cat nodelist-${SLURM_JOB_ID} | xargs | sed &#39;s/ /,/g&#39;` IP0=`echo $IPLIST | awk -F&#39;,&#39; &#39;{print $1}&#39; | sed &#39;s/ //g&#39;` echo &quot;==== GLOBAL INFO ====&quot; | tee -a screen.log echo &quot;IPLIST: $IPLIST&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;====================&quot; | tee -a screen.log # 2. Trigger on master node $MPIRUN -x IP0=$IP0 sh run.sh submit.sh 将任务提交服务器 ******_CLIENT_BIN=/**/bin/ ${******_CLIENT_BIN}/submit \ --hdfs hdfs://** \ --hdfs-user ** \ --hdfs-passwd *** \ --hdfs-path /app**/**** \ --file-dir ./ \ --job-name *** \ --queue-name *** \ --num-nodes 1 \ --num-task-pernode 1 \ --gpu-pnode 8 \ --submitter ***\ --time-limit 0 \ --job-script ./job.sh run.sh # 2. Get node env NODE_IP=`hostname -i` NODE_RANK=${OMPI_COMM_WORLD_RANK} echo &quot;==== NODE INFO ====&quot; | tee -a screen.log echo &quot;NODE_RNAK: $NODE_RANK&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;NODE_IP: $NODE_IP&quot; | tee -a screen.log echo &quot;===================&quot; | tee -a screen.log # 3. Run training PYTHON=./torch/bin/python export LD_LIBRARY_PATH=/home/work/cuda-8.0/lib64:$LD_LIBRARY_PATH #sh train_**_nls.sh #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50**.py --gpus 1 --resume_from ./work_dirs/cascade_rcnn_senet50_**_nls/epoch_288_93.4.pth #../env/bin/python ../tools/train.py ../configs/retinanet_seresnet101_fpn_1x_**nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_mobilenetv2_clstest_nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50_slim_clstest_nls.py --gpus 4 --validate #../tools/dist_train.sh ../configs/dcn/cascade_rcnn_seresnet_50_mdpool_**s.py 4 ./torch/bin/python train_se_clsgat.py 四、hadoop数据服务器文件操作 ls，cp，mkdir等等 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。 Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。 4.1 submit.sh 目的是在此程序中更改相应的hdfs path &nbsp;--******-path /app***tmp/$TIME \ ******-path要通过hadoop客户端建立，使用手册如下 4.2 下载与安装 2018-05-07 client 1.6.4 最新版本，支持afs和hdfs wget -O output.tar.gz --header &quot;***-************&quot; 解压 路径/home******/bin 运行 ./hadoop 4.3 afs agent 下载并使用。 #启动afs_agent cd output &amp;&amp; sh start_agent.sh #停止afs_agent cd output &amp;&amp; sh stop_agent.sh #检查afs_agent是否运行，看进程存在即可 ps -ef|grep bin/afs_agent|grep -v grep &nbsp;路径：/home/xingxiangrui/hadoop-client/afs_agent/bin 4.4 配套hadoop 运行 ./hadoop 过于复杂，直接在submit.sh中更改相应的命令行即可。（直接运行不可，会报错） []$ source submit.sh Notes: &#39;submitter&#39; parameter has been removed, the submission will ignore this parameter. cat: ./torch/lib/python3.5/site-packages/zmq/ssh: Is a directory Error: /app/mmt-vis/xingxiangrui/se_cls_gat_on_coco is not a directory! 4.5 参考 &nbsp;~/.******/software-install/******/tools/hadoop-v2/hadoop/bin/hadoop fs -D fs.default.name=afs://****** -D hadoop.job.ugi=******,******-D dfs.replication=1 -D fs.afs.impl=org.apache.hadoop.fs.DFileSystem -ls&nbsp; /user/******/******/ 五、运行集群 5.1 提交任务 直接提交 ******_CLIENT_BIN=/******/bin/ ${******_CLIENT_BIN}/submit \ --hdfs afs:****** \ --hdfs-user ******\ --hdfs-passwd ******\ --hdfs-path ****** \ --file-dir ./ \ --job-name ******\ --queue-name ******-p40-2-8 \ --num-nodes 1 \ --num-task-pernode 1 \ --gpu-pnode 8 \ --submitter ******\ --time-limit 0 \ --job-script ./job.sh source submit.sh 可以将gpu-pnode设为1，表示节点的个数。 注意地址要在三级目录之后再建 同时注意，相应的用户名与密码要改为上面的这些模式 5.2 查看队列情况 showjob -p ****** 查看相应的集群上的队列 查看相应的工作 show -j&nbsp;&nbsp; &lt;job ID&gt; []$ showjob -p ****** QueueName: ****** ======================================================================================================================== JobId JobName Submitter RunningTime TotalGpus Status GpuUtil ======================================================================================================================== ... ... ]$ showjob -j ****** ============================================================================================================== Job Information ============================================================================================================== ... ... &nbsp; 5.3 删除操作 # 1. 命令 deljob -j JOBID &nbsp; # 2. 举例 # deljob -j ****** 删除之后相应status变为 CANCELLED 六、结果查看及文件传输 相关命令行。 服务器上cp，mv 等等，用到后续来更新。与文件系统有关。 &nbsp;" />
<meta property="og:description" content="目的：运算量巨大的时候，需要使用SLURM的GPU集群来运行实验。每个SLURM集群的配置方法不一样，但是流程大致相同。下面为我配置SLURM集群的方法，亲测有效 目录 一、客户端部署 1.1 下载 1.2 安装 1.3 help 二、环境配置 2.1 python与torch配置 2.2 配置汇总 三、运用 3.1 进入文件夹 3.2 目录结构 3.3 拷入文件 3.4 路径地址 3.5 三个sh文件 四、hadoop数据服务器文件操作 4.1 submit.sh 4.2 下载与安装 4.3 afs agent 4.4 配套hadoop 4.5 参考 五、运行集群 5.1 提交任务 5.2 查看队列情况 5.3 删除操作 六、结果查看及文件传输 &nbsp; 一、客户端部署 1.1 下载 （根据平台下载相应的客户端） wget -e &quot;http_proxy**&quot; http://**/slurm-client-install.sh 下载位置，找个相对大一点的盘， df -h -l &nbsp; /dev/sdb1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.6T&nbsp; 1.8G&nbsp; 3.6T&nbsp;&nbsp; 1% /home/ssd1 $ cd /home/ssd1/ $ pwd /home/ssd1 $ wget -e &quot;http_proxy=****.cp**:8888&quot; http://**/slurm-client-v2.5/slurm-client-install.sh 下载之后看到其为： #DO NOT USE OPTION -prefix if [ &quot;$1&quot; = &quot;-prefix&quot; ];then ******=$2 else ******=~/.****** fi INSTALL_ROOT=${******}/ wget -e &quot;xxxxxxxx/slurm-client-v2.5/slurm-client-v2.5.tar.gz mkdir -p ${INSTALL_ROOT} tar zxvf slurm-client-v2.5.tar.gz -C ${INSTALL_ROOT} grep &#39;#****** use&#39; ~/.bashrc &gt;/dev/null 2&gt;&amp;1 if [ $? -ne 0 ]; then echo &#39;#******use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}&quot; &gt;&gt;~/.bashrc else sed -i &#39;/******use/,+1d&#39; ~/.bashrc echo &#39;#****** use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}&quot; &gt;&gt;~/.bashrc 不让运用-prefix选项 1.2 安装 sh slurm-client-install.sh 会下载和安装一堆选项 输入下面命令行看token测试命令是否安装成功 tokenapply tokenapply bash: tokenapply: command not found 安装脚本会自动将安装目录写入到~/.bashrc中 如果提示找不到命令，请手动source ~/.bashrc 执行2后，如果还提示找不到命令，请尝试退出机器然后重新登录机器 [ssd1]$ source ~/.bashrc [ssd1]$ tokenapply ======================================================= xxx Client is updating Version: 2.6 ------------------------------------------------------- [Total Size]:2.00 MB [██████████████████████████████████████████████████] 100% your client is not new, we have already update it for you Client updated done. ======================================================= ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(*****@*****.com) ====================================================================== 1.3 help [~]$ tokenapply -h usage: client.py [-h] [-v] [-s SUBMITTER] optional arguments: -h, --help show this help message and exit -v, --version version info -s SUBMITTER, --submitter SUBMITTER the prefix of your mailbox 二、环境配置 2.1 python与torch配置 把相应的环境配置好。 python 位置：/home/xingxiangrui/env/bin/python cuda位置： export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin client位置 2.2 配置汇总 [bin]$ ls deljob showframework showjob shownode showquota submit tokenapply tokenclean tokenconfig tokenquery [bin]$ ./tokenapply deljob showjob showquota tokenapply tokenconfig showframework shownode submit tokenclean tokenquery [bin]$ ./tokenapply ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(**@**.com) ====================================================================== [bin]$ ./tokenconfig Please input the token: ak: *** sk: *** ================================================== Config token successfully ================================================== 三、运用 3.1 进入文件夹 注意是程序运行的文件夹，可以参考： 3.2 目录结构 submit.sh 调用qsub_f提交任务的脚本 bin 任务的可执行文件及相关文件 data 本机训练数据所在目标文件夹 job.sh 任务执行脚本 log 存放运行日志（任务运行结束后会上传到 hadoop 中） output 存放输出（任务运行结束后会上传到 hadoop 中） common.conf 环境变量配置，训练脚本配置可以统一在conf里 3.3 拷入文件 文件运行之前需要确保可以本地运行 env环境拷入，先把之前的删掉。rm -rf cp -r /home/xingxiangrui/env/* env/ cp -rf /home/xingxiangrui/env/ . 两个文件需要拷入，submit.sh&nbsp;&nbsp; ， job.sh 3.4 路径地址 submit.sh,&nbsp; job.sh,&nbsp; run.sh都要改 路径 /home/xingxiangrui/.******/software-install** MPI地址：&nbsp; /home/xingxiangruisoftware-install/openmpi-1.8.5/bin/mpirun OpenMPI是一种高性能消息传递库，OpenMPI能够从高性能社区中获得专业技术、工业技术和资源支持 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin 3.5 三个sh文件 job.sh，设定服务器工作，注意下面的MPIRUN直接要用绝对路径，直接mpirun即可。 # !!! Only Runing on master node # 1. Set the env for multi-node training MPIRUN=&quot;mpirun --bind-to none&quot; IPLIST=`cat nodelist-${SLURM_JOB_ID} | xargs | sed &#39;s/ /,/g&#39;` IP0=`echo $IPLIST | awk -F&#39;,&#39; &#39;{print $1}&#39; | sed &#39;s/ //g&#39;` echo &quot;==== GLOBAL INFO ====&quot; | tee -a screen.log echo &quot;IPLIST: $IPLIST&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;====================&quot; | tee -a screen.log # 2. Trigger on master node $MPIRUN -x IP0=$IP0 sh run.sh submit.sh 将任务提交服务器 ******_CLIENT_BIN=/**/bin/ ${******_CLIENT_BIN}/submit \ --hdfs hdfs://** \ --hdfs-user ** \ --hdfs-passwd *** \ --hdfs-path /app**/**** \ --file-dir ./ \ --job-name *** \ --queue-name *** \ --num-nodes 1 \ --num-task-pernode 1 \ --gpu-pnode 8 \ --submitter ***\ --time-limit 0 \ --job-script ./job.sh run.sh # 2. Get node env NODE_IP=`hostname -i` NODE_RANK=${OMPI_COMM_WORLD_RANK} echo &quot;==== NODE INFO ====&quot; | tee -a screen.log echo &quot;NODE_RNAK: $NODE_RANK&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;NODE_IP: $NODE_IP&quot; | tee -a screen.log echo &quot;===================&quot; | tee -a screen.log # 3. Run training PYTHON=./torch/bin/python export LD_LIBRARY_PATH=/home/work/cuda-8.0/lib64:$LD_LIBRARY_PATH #sh train_**_nls.sh #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50**.py --gpus 1 --resume_from ./work_dirs/cascade_rcnn_senet50_**_nls/epoch_288_93.4.pth #../env/bin/python ../tools/train.py ../configs/retinanet_seresnet101_fpn_1x_**nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_mobilenetv2_clstest_nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50_slim_clstest_nls.py --gpus 4 --validate #../tools/dist_train.sh ../configs/dcn/cascade_rcnn_seresnet_50_mdpool_**s.py 4 ./torch/bin/python train_se_clsgat.py 四、hadoop数据服务器文件操作 ls，cp，mkdir等等 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。 Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。 4.1 submit.sh 目的是在此程序中更改相应的hdfs path &nbsp;--******-path /app***tmp/$TIME \ ******-path要通过hadoop客户端建立，使用手册如下 4.2 下载与安装 2018-05-07 client 1.6.4 最新版本，支持afs和hdfs wget -O output.tar.gz --header &quot;***-************&quot; 解压 路径/home******/bin 运行 ./hadoop 4.3 afs agent 下载并使用。 #启动afs_agent cd output &amp;&amp; sh start_agent.sh #停止afs_agent cd output &amp;&amp; sh stop_agent.sh #检查afs_agent是否运行，看进程存在即可 ps -ef|grep bin/afs_agent|grep -v grep &nbsp;路径：/home/xingxiangrui/hadoop-client/afs_agent/bin 4.4 配套hadoop 运行 ./hadoop 过于复杂，直接在submit.sh中更改相应的命令行即可。（直接运行不可，会报错） []$ source submit.sh Notes: &#39;submitter&#39; parameter has been removed, the submission will ignore this parameter. cat: ./torch/lib/python3.5/site-packages/zmq/ssh: Is a directory Error: /app/mmt-vis/xingxiangrui/se_cls_gat_on_coco is not a directory! 4.5 参考 &nbsp;~/.******/software-install/******/tools/hadoop-v2/hadoop/bin/hadoop fs -D fs.default.name=afs://****** -D hadoop.job.ugi=******,******-D dfs.replication=1 -D fs.afs.impl=org.apache.hadoop.fs.DFileSystem -ls&nbsp; /user/******/******/ 五、运行集群 5.1 提交任务 直接提交 ******_CLIENT_BIN=/******/bin/ ${******_CLIENT_BIN}/submit \ --hdfs afs:****** \ --hdfs-user ******\ --hdfs-passwd ******\ --hdfs-path ****** \ --file-dir ./ \ --job-name ******\ --queue-name ******-p40-2-8 \ --num-nodes 1 \ --num-task-pernode 1 \ --gpu-pnode 8 \ --submitter ******\ --time-limit 0 \ --job-script ./job.sh source submit.sh 可以将gpu-pnode设为1，表示节点的个数。 注意地址要在三级目录之后再建 同时注意，相应的用户名与密码要改为上面的这些模式 5.2 查看队列情况 showjob -p ****** 查看相应的集群上的队列 查看相应的工作 show -j&nbsp;&nbsp; &lt;job ID&gt; []$ showjob -p ****** QueueName: ****** ======================================================================================================================== JobId JobName Submitter RunningTime TotalGpus Status GpuUtil ======================================================================================================================== ... ... ]$ showjob -j ****** ============================================================================================================== Job Information ============================================================================================================== ... ... &nbsp; 5.3 删除操作 # 1. 命令 deljob -j JOBID &nbsp; # 2. 举例 # deljob -j ****** 删除之后相应status变为 CANCELLED 六、结果查看及文件传输 相关命令行。 服务器上cp，mv 等等，用到后续来更新。与文件系统有关。 &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/08/15/793638.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/15/793638.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-15T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目的：运算量巨大的时候，需要使用SLURM的GPU集群来运行实验。每个SLURM集群的配置方法不一样，但是流程大致相同。下面为我配置SLURM集群的方法，亲测有效 目录 一、客户端部署 1.1 下载 1.2 安装 1.3 help 二、环境配置 2.1 python与torch配置 2.2 配置汇总 三、运用 3.1 进入文件夹 3.2 目录结构 3.3 拷入文件 3.4 路径地址 3.5 三个sh文件 四、hadoop数据服务器文件操作 4.1 submit.sh 4.2 下载与安装 4.3 afs agent 4.4 配套hadoop 4.5 参考 五、运行集群 5.1 提交任务 5.2 查看队列情况 5.3 删除操作 六、结果查看及文件传输 &nbsp; 一、客户端部署 1.1 下载 （根据平台下载相应的客户端） wget -e &quot;http_proxy**&quot; http://**/slurm-client-install.sh 下载位置，找个相对大一点的盘， df -h -l &nbsp; /dev/sdb1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.6T&nbsp; 1.8G&nbsp; 3.6T&nbsp;&nbsp; 1% /home/ssd1 $ cd /home/ssd1/ $ pwd /home/ssd1 $ wget -e &quot;http_proxy=****.cp**:8888&quot; http://**/slurm-client-v2.5/slurm-client-install.sh 下载之后看到其为： #DO NOT USE OPTION -prefix if [ &quot;$1&quot; = &quot;-prefix&quot; ];then ******=$2 else ******=~/.****** fi INSTALL_ROOT=${******}/ wget -e &quot;xxxxxxxx/slurm-client-v2.5/slurm-client-v2.5.tar.gz mkdir -p ${INSTALL_ROOT} tar zxvf slurm-client-v2.5.tar.gz -C ${INSTALL_ROOT} grep &#39;#****** use&#39; ~/.bashrc &gt;/dev/null 2&gt;&amp;1 if [ $? -ne 0 ]; then echo &#39;#******use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\\${PATH}&quot; &gt;&gt;~/.bashrc else sed -i &#39;/******use/,+1d&#39; ~/.bashrc echo &#39;#****** use&#39; &gt;&gt;~/.bashrc echo &quot;export PATH=${INSTALL_ROOT}/software-install/bin:\\${PATH}&quot; &gt;&gt;~/.bashrc 不让运用-prefix选项 1.2 安装 sh slurm-client-install.sh 会下载和安装一堆选项 输入下面命令行看token测试命令是否安装成功 tokenapply tokenapply bash: tokenapply: command not found 安装脚本会自动将安装目录写入到~/.bashrc中 如果提示找不到命令，请手动source ~/.bashrc 执行2后，如果还提示找不到命令，请尝试退出机器然后重新登录机器 [ssd1]$ source ~/.bashrc [ssd1]$ tokenapply ======================================================= xxx Client is updating Version: 2.6 ------------------------------------------------------- [Total Size]:2.00 MB [██████████████████████████████████████████████████] 100% your client is not new, we have already update it for you Client updated done. ======================================================= ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(*****@*****.com) ====================================================================== 1.3 help [~]$ tokenapply -h usage: client.py [-h] [-v] [-s SUBMITTER] optional arguments: -h, --help show this help message and exit -v, --version version info -s SUBMITTER, --submitter SUBMITTER the prefix of your mailbox 二、环境配置 2.1 python与torch配置 把相应的环境配置好。 python 位置：/home/xingxiangrui/env/bin/python cuda位置： export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin client位置 2.2 配置汇总 [bin]$ ls deljob showframework showjob shownode showquota submit tokenapply tokenclean tokenconfig tokenquery [bin]$ ./tokenapply deljob showjob showquota tokenapply tokenconfig showframework shownode submit tokenclean tokenquery [bin]$ ./tokenapply ====================================================================== Apply token successfully, the information about your token has been sent to mailbox(**@**.com) ====================================================================== [bin]$ ./tokenconfig Please input the token: ak: *** sk: *** ================================================== Config token successfully ================================================== 三、运用 3.1 进入文件夹 注意是程序运行的文件夹，可以参考： 3.2 目录结构 submit.sh 调用qsub_f提交任务的脚本 bin 任务的可执行文件及相关文件 data 本机训练数据所在目标文件夹 job.sh 任务执行脚本 log 存放运行日志（任务运行结束后会上传到 hadoop 中） output 存放输出（任务运行结束后会上传到 hadoop 中） common.conf 环境变量配置，训练脚本配置可以统一在conf里 3.3 拷入文件 文件运行之前需要确保可以本地运行 env环境拷入，先把之前的删掉。rm -rf cp -r /home/xingxiangrui/env/* env/ cp -rf /home/xingxiangrui/env/ . 两个文件需要拷入，submit.sh&nbsp;&nbsp; ， job.sh 3.4 路径地址 submit.sh,&nbsp; job.sh,&nbsp; run.sh都要改 路径 /home/xingxiangrui/.******/software-install** MPI地址：&nbsp; /home/xingxiangruisoftware-install/openmpi-1.8.5/bin/mpirun OpenMPI是一种高性能消息传递库，OpenMPI能够从高性能社区中获得专业技术、工业技术和资源支持 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64 export PATH=$PATH:/home/work/cuda-8.0/bin 3.5 三个sh文件 job.sh，设定服务器工作，注意下面的MPIRUN直接要用绝对路径，直接mpirun即可。 # !!! Only Runing on master node # 1. Set the env for multi-node training MPIRUN=&quot;mpirun --bind-to none&quot; IPLIST=`cat nodelist-${SLURM_JOB_ID} | xargs | sed &#39;s/ /,/g&#39;` IP0=`echo $IPLIST | awk -F&#39;,&#39; &#39;{print $1}&#39; | sed &#39;s/ //g&#39;` echo &quot;==== GLOBAL INFO ====&quot; | tee -a screen.log echo &quot;IPLIST: $IPLIST&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;====================&quot; | tee -a screen.log # 2. Trigger on master node $MPIRUN -x IP0=$IP0 sh run.sh submit.sh 将任务提交服务器 ******_CLIENT_BIN=/**/bin/ ${******_CLIENT_BIN}/submit \\ --hdfs hdfs://** \\ --hdfs-user ** \\ --hdfs-passwd *** \\ --hdfs-path /app**/**** \\ --file-dir ./ \\ --job-name *** \\ --queue-name *** \\ --num-nodes 1 \\ --num-task-pernode 1 \\ --gpu-pnode 8 \\ --submitter ***\\ --time-limit 0 \\ --job-script ./job.sh run.sh # 2. Get node env NODE_IP=`hostname -i` NODE_RANK=${OMPI_COMM_WORLD_RANK} echo &quot;==== NODE INFO ====&quot; | tee -a screen.log echo &quot;NODE_RNAK: $NODE_RANK&quot; | tee -a screen.log echo &quot;IP0: $IP0&quot; | tee -a screen.log echo &quot;NODE_IP: $NODE_IP&quot; | tee -a screen.log echo &quot;===================&quot; | tee -a screen.log # 3. Run training PYTHON=./torch/bin/python export LD_LIBRARY_PATH=/home/work/cuda-8.0/lib64:$LD_LIBRARY_PATH #sh train_**_nls.sh #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50**.py --gpus 1 --resume_from ./work_dirs/cascade_rcnn_senet50_**_nls/epoch_288_93.4.pth #../env/bin/python ../tools/train.py ../configs/retinanet_seresnet101_fpn_1x_**nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_mobilenetv2_clstest_nls.py --gpus 4 #../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50_slim_clstest_nls.py --gpus 4 --validate #../tools/dist_train.sh ../configs/dcn/cascade_rcnn_seresnet_50_mdpool_**s.py 4 ./torch/bin/python train_se_clsgat.py 四、hadoop数据服务器文件操作 ls，cp，mkdir等等 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。 Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。 4.1 submit.sh 目的是在此程序中更改相应的hdfs path &nbsp;--******-path /app***tmp/$TIME \\ ******-path要通过hadoop客户端建立，使用手册如下 4.2 下载与安装 2018-05-07 client 1.6.4 最新版本，支持afs和hdfs wget -O output.tar.gz --header &quot;***-************&quot; 解压 路径/home******/bin 运行 ./hadoop 4.3 afs agent 下载并使用。 #启动afs_agent cd output &amp;&amp; sh start_agent.sh #停止afs_agent cd output &amp;&amp; sh stop_agent.sh #检查afs_agent是否运行，看进程存在即可 ps -ef|grep bin/afs_agent|grep -v grep &nbsp;路径：/home/xingxiangrui/hadoop-client/afs_agent/bin 4.4 配套hadoop 运行 ./hadoop 过于复杂，直接在submit.sh中更改相应的命令行即可。（直接运行不可，会报错） []$ source submit.sh Notes: &#39;submitter&#39; parameter has been removed, the submission will ignore this parameter. cat: ./torch/lib/python3.5/site-packages/zmq/ssh: Is a directory Error: /app/mmt-vis/xingxiangrui/se_cls_gat_on_coco is not a directory! 4.5 参考 &nbsp;~/.******/software-install/******/tools/hadoop-v2/hadoop/bin/hadoop fs -D fs.default.name=afs://****** -D hadoop.job.ugi=******,******-D dfs.replication=1 -D fs.afs.impl=org.apache.hadoop.fs.DFileSystem -ls&nbsp; /user/******/******/ 五、运行集群 5.1 提交任务 直接提交 ******_CLIENT_BIN=/******/bin/ ${******_CLIENT_BIN}/submit \\ --hdfs afs:****** \\ --hdfs-user ******\\ --hdfs-passwd ******\\ --hdfs-path ****** \\ --file-dir ./ \\ --job-name ******\\ --queue-name ******-p40-2-8 \\ --num-nodes 1 \\ --num-task-pernode 1 \\ --gpu-pnode 8 \\ --submitter ******\\ --time-limit 0 \\ --job-script ./job.sh source submit.sh 可以将gpu-pnode设为1，表示节点的个数。 注意地址要在三级目录之后再建 同时注意，相应的用户名与密码要改为上面的这些模式 5.2 查看队列情况 showjob -p ****** 查看相应的集群上的队列 查看相应的工作 show -j&nbsp;&nbsp; &lt;job ID&gt; []$ showjob -p ****** QueueName: ****** ======================================================================================================================== JobId JobName Submitter RunningTime TotalGpus Status GpuUtil ======================================================================================================================== ... ... ]$ showjob -j ****** ============================================================================================================== Job Information ============================================================================================================== ... ... &nbsp; 5.3 删除操作 # 1. 命令 deljob -j JOBID &nbsp; # 2. 举例 # deljob -j ****** 删除之后相应status变为 CANCELLED 六、结果查看及文件传输 相关命令行。 服务器上cp，mv 等等，用到后续来更新。与文件系统有关。 &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/08/15/793638.html","headline":"客户端配置Hadoop并运用SLURM GPU集群与HDFS文件系统","dateModified":"2019-08-15T00:00:00+08:00","datePublished":"2019-08-15T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/15/793638.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>客户端配置Hadoop并运用SLURM GPU集群与HDFS文件系统</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>目的：运算量巨大的时候，需要使用SLURM的GPU集群来运行实验。每个SLURM集群的配置方法不一样，但是流程大致相同。下面为我配置SLURM集群的方法，亲测有效</p> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="%E4%B8%80%E3%80%81%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%83%A8%E7%BD%B2-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%83%A8%E7%BD%B2" rel="nofollow" data-token="3a8850fceb14c3a5b81a1cf76265d740">一、客户端部署</a></p> 
  <p id="1.1%20%E4%B8%8B%E8%BD%BD-toc" style="margin-left:40px;"><a href="#1.1%20%E4%B8%8B%E8%BD%BD" rel="nofollow" data-token="476eecfcf6ad53ae4112c870f5a65cee">1.1 下载</a></p> 
  <p id="1.2%20%E5%AE%89%E8%A3%85-toc" style="margin-left:40px;"><a href="#1.2%20%E5%AE%89%E8%A3%85" rel="nofollow" data-token="b7fe07d61082d0c0b817614cb521c030">1.2 安装</a></p> 
  <p id="1.3%20help-toc" style="margin-left:40px;"><a href="#1.3%20help" rel="nofollow" data-token="396c60b46dad3417cbd38fe839dc67fb">1.3 help</a></p> 
  <p id="%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE" rel="nofollow" data-token="04404f4e33c43bc7f591e6c9eb093f52">二、环境配置</a></p> 
  <p id="2.1%20python%E4%B8%8Etorch%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#2.1%20python%E4%B8%8Etorch%E9%85%8D%E7%BD%AE" rel="nofollow" data-token="09848707ec09e040be56477496634c7e">2.1 python与torch配置</a></p> 
  <p id="2.2%20%E9%85%8D%E7%BD%AE%E6%B1%87%E6%80%BB-toc" style="margin-left:40px;"><a href="#2.2%20%E9%85%8D%E7%BD%AE%E6%B1%87%E6%80%BB" rel="nofollow" data-token="957b8cdd423fb9e7d356db91a4816061">2.2 配置汇总</a></p> 
  <p id="%E4%B8%89%E3%80%81%E8%BF%90%E7%94%A8-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E8%BF%90%E7%94%A8" rel="nofollow" data-token="b6cd41f849e9d5fb34445aedefab5b83">三、运用</a></p> 
  <p id="3.1%20%E8%BF%9B%E5%85%A5%E6%96%87%E4%BB%B6%E5%A4%B9-toc" style="margin-left:40px;"><a href="#3.1%20%E8%BF%9B%E5%85%A5%E6%96%87%E4%BB%B6%E5%A4%B9" rel="nofollow" data-token="7cbb8031a52d94f78885eb4ea043f2af">3.1 进入文件夹</a></p> 
  <p id="h3-3-1--toc" style="margin-left:80px;"><a href="#h3-3-1-" rel="nofollow" data-token="7e2607f765a02a54d3da4c3c3910f136">3.2 目录结构</a></p> 
  <p id="3.3%20%E6%8B%B7%E5%85%A5%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><a href="#3.3%20%E6%8B%B7%E5%85%A5%E6%96%87%E4%BB%B6" rel="nofollow" data-token="98f6bee9a779c0ac70911c88717184dd">3.3 拷入文件</a></p> 
  <p id="3.4%20%E8%B7%AF%E5%BE%84%E5%9C%B0%E5%9D%80-toc" style="margin-left:40px;"><a href="#3.4%20%E8%B7%AF%E5%BE%84%E5%9C%B0%E5%9D%80" rel="nofollow" data-token="e3c0eb448c657e661ba3c613f0bf20cc">3.4 路径地址</a></p> 
  <p id="3.5%20%E4%B8%89%E4%B8%AAsh%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><a href="#3.5%20%E4%B8%89%E4%B8%AAsh%E6%96%87%E4%BB%B6" rel="nofollow" data-token="2930badd261bab5d587b54a5310355cf">3.5 三个sh文件</a></p> 
  <p id="%E5%9B%9B%E3%80%81%E5%BB%BA%E7%AB%8Bhandoop%E5%AE%A2%E6%88%B7%E7%AB%AF-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%BB%BA%E7%AB%8Bhandoop%E5%AE%A2%E6%88%B7%E7%AB%AF" rel="nofollow" data-token="9da6239a7014aa8eeae3efe2422ad4fe">四、hadoop数据服务器文件操作</a></p> 
  <p id="4.1%20submit.sh-toc" style="margin-left:40px;"><a href="#4.1%20submit.sh" rel="nofollow" data-token="21fb4b16112f3435f5a8d71cf7561ce2">4.1 submit.sh</a></p> 
  <p id="4.2%20%E4%B8%8B%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85-toc" style="margin-left:40px;"><a href="#4.2%20%E4%B8%8B%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85" rel="nofollow" data-token="d9b6b053a4ac561fa3f25fee632fe738">4.2 下载与安装</a></p> 
  <p id="4.3%20afs%20agent-toc" style="margin-left:40px;"><a href="#4.3%20afs%20agent" rel="nofollow" data-token="5c7d4e9891bd19b1994346183c575eb6">4.3 afs agent</a></p> 
  <p id="4.4%20%E9%85%8D%E5%A5%97hadoop-toc" style="margin-left:40px;"><a href="#4.4%20%E9%85%8D%E5%A5%97hadoop" rel="nofollow" data-token="0591462db2868455aec75d612784e269">4.4 配套hadoop</a></p> 
  <p id="4.5%20%E5%8F%82%E8%80%83-toc" style="margin-left:40px;"><a href="#4.5%20%E5%8F%82%E8%80%83" rel="nofollow" data-token="a7fc911b974bbd8cae7cd63162a386f5">4.5 参考</a></p> 
  <p id="%E4%BA%94%E3%80%81%E8%BF%90%E8%A1%8C%E9%9B%86%E7%BE%A4-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E8%BF%90%E8%A1%8C%E9%9B%86%E7%BE%A4" rel="nofollow" data-token="bb693b1b0c1f5a51f6f75e82a88077a9">五、运行集群</a></p> 
  <p id="5.1%20%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1-toc" style="margin-left:40px;"><a href="#5.1%20%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1" rel="nofollow" data-token="6e965962636e7f4ece7b97cdd64e3009">5.1 提交任务</a></p> 
  <p id="5.2%20%E6%9F%A5%E7%9C%8B%E9%98%9F%E5%88%97%E6%83%85%E5%86%B5-toc" style="margin-left:40px;"><a href="#5.2%20%E6%9F%A5%E7%9C%8B%E9%98%9F%E5%88%97%E6%83%85%E5%86%B5" rel="nofollow" data-token="009c3f7c86aeff520aa43807ed2d52ad">5.2 查看队列情况</a></p> 
  <p id="h3-5-2--toc" style="margin-left:40px;"><a href="#h3-5-2-" rel="nofollow" data-token="ed0656e5619e10e02623e612157428f4">5.3 删除操作</a></p> 
  <p id="%E5%85%AD%E3%80%81%E7%BB%93%E6%9E%9C%E6%9F%A5%E7%9C%8B%E5%8F%8A%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93-toc" style="margin-left:40px;"><a href="#%E5%85%AD%E3%80%81%E7%BB%93%E6%9E%9C%E6%9F%A5%E7%9C%8B%E5%8F%8A%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93" rel="nofollow" data-token="7410e5848a21ff791d734c9671dd9a85">六、结果查看及文件传输</a></p> 
  <hr id="hr-toc">
  <p>&nbsp;</p> 
  <h1 id="%E4%B8%80%E3%80%81%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%83%A8%E7%BD%B2">一、客户端部署</h1> 
  <h2 id="1.1%20%E4%B8%8B%E8%BD%BD">1.1 下载</h2> 
  <p>（根据平台下载相应的客户端）</p> 
  <p><code>wget -e "http_proxy**" http://**/slurm-client-install.sh</code></p> 
  <p>下载位置，找个相对大一点的盘， df -h -l</p> 
  <p>&nbsp; /dev/sdb1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.6T&nbsp; 1.8G&nbsp; 3.6T&nbsp;&nbsp; 1% /home/ssd1</p> 
  <pre class="has">
<code class="language-bash">$ cd /home/ssd1/
$ pwd
/home/ssd1
$ wget -e "http_proxy=****.cp**:8888" http://**/slurm-client-v2.5/slurm-client-install.sh</code></pre> 
  <p>下载之后看到其为：</p> 
  <pre class="has">
<code class="language-bash">#DO NOT USE OPTION -prefix
if [ "$1" = "-prefix" ];then
    ******=$2
else
    ******=~/.******
fi
INSTALL_ROOT=${******}/

wget -e "xxxxxxxx/slurm-client-v2.5/slurm-client-v2.5.tar.gz
mkdir -p ${INSTALL_ROOT}
tar zxvf slurm-client-v2.5.tar.gz -C ${INSTALL_ROOT}

grep '#****** use' ~/.bashrc &gt;/dev/null 2&gt;&amp;1
if [ $? -ne 0 ]; then
    echo '#******use' &gt;&gt;~/.bashrc
    echo "export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}" &gt;&gt;~/.bashrc
else
    sed -i '/******use/,+1d' ~/.bashrc
    echo '#****** use' &gt;&gt;~/.bashrc
        echo "export PATH=${INSTALL_ROOT}/software-install/bin:\${PATH}" &gt;&gt;~/.bashrc</code></pre> 
  <p>不让运用-prefix选项</p> 
  <h2 id="1.2%20%E5%AE%89%E8%A3%85">1.2 安装</h2> 
  <p><code>sh slurm-client-install.sh</code></p> 
  <p><code>会下载和安装一堆选项</code></p> 
  <p><code>输入下面命令行看token测试命令是否安装成功</code></p> 
  <p><code>tokenapply </code></p> 
  <pre class="has">
<code class="language-bash">tokenapply
bash: tokenapply: command not found</code></pre> 
  <ol>
   <li>安装脚本会自动将安装目录写入到<code>~/.bashrc</code>中</li> 
   <li>如果提示找不到命令，请手动<code>source ~/.bashrc</code></li> 
   <li>执行2后，如果还提示找不到命令，请尝试退出机器然后重新登录机器</li> 
  </ol>
  <pre class="has">
<code class="language-bash">[ssd1]$ source ~/.bashrc
[ssd1]$ tokenapply
=======================================================
           xxx Client is updating
           Version: 2.6
-------------------------------------------------------
[Total Size]:2.00 MB
[██████████████████████████████████████████████████] 100%
your client is not new, we have already update it for you

Client updated done.
=======================================================

======================================================================
Apply token successfully, the information about your token
has been sent to mailbox(*****@*****.com)
======================================================================</code></pre> 
  <h2 id="1.3%20help"><code>1.3 help</code></h2> 
  <pre class="has">
<code class="language-bash">[~]$ tokenapply -h
usage: client.py [-h] [-v] [-s SUBMITTER]

optional arguments:
  -h, --help            show this help message and exit
  -v, --version         version info
  -s SUBMITTER, --submitter SUBMITTER
                        the prefix of your mailbox</code></pre> 
  <h1 id="%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">二、环境配置</h1> 
  <h2 id="2.1%20python%E4%B8%8Etorch%E9%85%8D%E7%BD%AE">2.1 python与torch配置</h2> 
  <p>把相应的环境配置好。</p> 
  <p>python 位置：/home/xingxiangrui/env/bin/python</p> 
  <p>cuda位置：</p> 
  <p>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64<br> export PATH=$PATH:/home/work/cuda-8.0/bin</p> 
  <p>client位置</p> 
  <h2 id="2.2%20%E9%85%8D%E7%BD%AE%E6%B1%87%E6%80%BB">2.2 配置汇总</h2> 
  <pre class="has">
<code class="language-bash">[bin]$ ls
deljob  showframework  showjob  shownode  showquota  submit  tokenapply  tokenclean  tokenconfig  tokenquery
[bin]$ ./tokenapply
deljob         showjob        showquota      tokenapply     tokenconfig
showframework  shownode       submit         tokenclean     tokenquery
[bin]$ ./tokenapply
======================================================================
Apply token successfully, the information about your token
has been sent to mailbox(**@**.com)
======================================================================
[bin]$ ./tokenconfig
Please input the token:
ak: ***
sk: ***
==================================================
Config token successfully
==================================================</code></pre> 
  <h1 id="%E4%B8%89%E3%80%81%E8%BF%90%E7%94%A8">三、运用</h1> 
  <h2 id="3.1%20%E8%BF%9B%E5%85%A5%E6%96%87%E4%BB%B6%E5%A4%B9">3.1 进入文件夹</h2> 
  <p>注意是程序运行的文件夹，可以参考：</p> 
  <h3 id="h3-3-1-">3.2 目录结构</h3> 
  <table>
   <tbody>
    <tr>
     <td>submit.sh</td> 
     <td>调用qsub_f提交任务的脚本</td> 
    </tr>
    <tr>
     <td>bin</td> 
     <td>任务的可执行文件及相关文件</td> 
    </tr>
    <tr>
     <td>data</td> 
     <td>本机训练数据所在目标文件夹</td> 
    </tr>
    <tr>
     <td>job.sh</td> 
     <td>任务执行脚本</td> 
    </tr>
    <tr>
     <td>log</td> 
     <td>存放运行日志（任务运行结束后会上传到 hadoop 中）</td> 
    </tr>
    <tr>
     <td>output</td> 
     <td>存放输出（任务运行结束后会上传到 hadoop 中）</td> 
    </tr>
    <tr>
     <td>common.conf</td> 
     <td>环境变量配置，训练脚本配置可以统一在conf里</td> 
    </tr>
   </tbody>
  </table>
  <h2 id="3.3%20%E6%8B%B7%E5%85%A5%E6%96%87%E4%BB%B6">3.3 拷入文件</h2> 
  <p>文件运行之前需要确保可以本地运行</p> 
  <p>env环境拷入，先把之前的删掉。rm -rf</p> 
  <p>cp -r /home/xingxiangrui/env/* env/</p> 
  <p>cp -rf /home/xingxiangrui/env/ .</p> 
  <p>两个文件需要拷入，submit.sh&nbsp;&nbsp; ， job.sh</p> 
  <h2 id="3.4%20%E8%B7%AF%E5%BE%84%E5%9C%B0%E5%9D%80">3.4 路径地址</h2> 
  <p>submit.sh,&nbsp; job.sh,&nbsp; run.sh都要改</p> 
  <p>路径 /home/xingxiangrui/.<strong>******</strong>/software-install**</p> 
  <p>MPI地址：&nbsp; /home/xingxiangruisoftware-install/openmpi-1.8.5/bin/mpirun</p> 
  <p>OpenMPI是一种高性能消息传递库，OpenMPI能够从高性能社区中获得专业技术、工业技术和资源支持</p> 
  <p>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/work/cuda-8.0/lib64<br> export PATH=$PATH:/home/work/cuda-8.0/bin</p> 
  <h2 id="3.5%20%E4%B8%89%E4%B8%AAsh%E6%96%87%E4%BB%B6">3.5 三个sh文件</h2> 
  <p>job.sh，设定服务器工作，注意下面的MPIRUN直接要用绝对路径，直接mpirun即可。</p> 
  <pre class="has">
<code class="language-bash"># !!! Only Runing on master node

# 1. Set the env for multi-node training
MPIRUN="mpirun --bind-to none"
IPLIST=`cat nodelist-${SLURM_JOB_ID} | xargs | sed 's/ /,/g'`
IP0=`echo $IPLIST | awk -F',' '{print $1}' | sed 's/ //g'`

echo "==== GLOBAL INFO ====" | tee -a screen.log
echo "IPLIST: $IPLIST"       | tee -a screen.log
echo "IP0: $IP0"             | tee -a screen.log
echo "===================="  | tee -a screen.log

# 2. Trigger on master node
$MPIRUN -x IP0=$IP0 sh run.sh</code></pre> 
  <p>submit.sh 将任务提交服务器</p> 
  <pre class="has">
<code class="language-python">******_CLIENT_BIN=/**/bin/

${******_CLIENT_BIN}/submit \
    --hdfs hdfs://** \
    --hdfs-user ** \
    --hdfs-passwd *** \
    --hdfs-path /app**/**** \
    --file-dir ./ \
    --job-name *** \
    --queue-name *** \
    --num-nodes 1 \
    --num-task-pernode 1 \
    --gpu-pnode 8 \
    --submitter ***\
    --time-limit 0 \
    --job-script ./job.sh</code></pre> 
  <p>run.sh</p> 
  <pre class="has">
<code class="language-bash"># 2. Get node env
NODE_IP=`hostname -i`
NODE_RANK=${OMPI_COMM_WORLD_RANK}
echo "==== NODE INFO ===="     | tee -a screen.log
echo "NODE_RNAK: $NODE_RANK"   | tee -a screen.log
echo "IP0: $IP0"               | tee -a screen.log
echo "NODE_IP: $NODE_IP"       | tee -a screen.log
echo "==================="     | tee -a screen.log

# 3. Run training
PYTHON=./torch/bin/python
export LD_LIBRARY_PATH=/home/work/cuda-8.0/lib64:$LD_LIBRARY_PATH

#sh train_**_nls.sh
#../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50**.py --gpus 1 --resume_from ./work_dirs/cascade_rcnn_senet50_**_nls/epoch_288_93.4.pth
#../env/bin/python ../tools/train.py ../configs/retinanet_seresnet101_fpn_1x_**nls.py --gpus 4
#../env/bin/python ../tools/train.py ../configs/cascade_rcnn_mobilenetv2_clstest_nls.py --gpus 4
#../env/bin/python ../tools/train.py ../configs/cascade_rcnn_seresnet_50_slim_clstest_nls.py --gpus 4 --validate
#../tools/dist_train.sh ../configs/dcn/cascade_rcnn_seresnet_50_mdpool_**s.py 4

./torch/bin/python train_se_clsgat.py</code></pre> 
  <h1 id="%E5%9B%9B%E3%80%81%E5%BB%BA%E7%AB%8Bhandoop%E5%AE%A2%E6%88%B7%E7%AB%AF">四、hadoop数据服务器文件操作</h1> 
  <p>ls，cp，mkdir等等</p> 
  <p>Hadoop实现了一个<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/1250388" rel="nofollow" data-token="37e166fc85bb8cd2483f2c75dc8eab0e">分布式文件系统</a>（Hadoop Distributed File System），简称HDFS。HDFS有高<a href="https://baike.baidu.com/item/%E5%AE%B9%E9%94%99%E6%80%A7/9131391" rel="nofollow" data-token="5ec36c311db46f73435e3ec9a1b03974">容错性</a>的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问<a href="https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/5985445" rel="nofollow" data-token="44832b49ba310201ee1e6da141fdf9e0">应用程序</a>的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。</p> 
  <p>Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。</p> 
  <h2 id="4.1%20submit.sh">4.1 submit.sh</h2> 
  <p>目的是在此程序中更改相应的hdfs path</p> 
  <p>&nbsp;--<strong>******</strong>-path /app***tmp/$TIME \</p> 
  <p><strong>******</strong>-path要通过hadoop客户端建立，使用手册如下</p> 
  <h2 id="4.2%20%E4%B8%8B%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85">4.2 下载与安装</h2> 
  <table>
   <tbody>
    <tr>
     <td colspan="1"><strong>2018-05-07</strong></td> 
     <td colspan="1"><strong>client 1.6.4</strong></td> 
     <td colspan="1"><strong>最新版本，支持afs和hdfs</strong></td> 
     <td colspan="1"><strong>wget -O output.tar.gz --header "</strong>***<strong>-************" </strong></td> 
    </tr>
   </tbody>
  </table>
  <p>解压</p> 
  <p>路径/home<strong>******/bin</strong></p> 
  <p>运行 ./hadoop</p> 
  <h2 id="4.3%20afs%20agent">4.3 afs agent</h2> 
  <p>下载并使用。</p> 
  <pre class="has">
<code class="language-bash">#启动afs_agent
cd output &amp;&amp; sh start_agent.sh
 
#停止afs_agent
cd output &amp;&amp; sh stop_agent.sh
  
#检查afs_agent是否运行，看进程存在即可
ps -ef|grep bin/afs_agent|grep -v grep</code></pre> 
  <p>&nbsp;路径：/home/xingxiangrui/hadoop-client/afs_agent/bin</p> 
  <h2 id="4.4%20%E9%85%8D%E5%A5%97hadoop">4.4 配套hadoop</h2> 
  <p>运行 ./hadoop</p> 
  <p>过于复杂，直接在submit.sh中更改相应的命令行即可。（直接运行不可，会报错）</p> 
  <pre class="has">
<code class="language-bash">[]$ source submit.sh
Notes: 'submitter' parameter has been removed, the submission will ignore this parameter.
cat: ./torch/lib/python3.5/site-packages/zmq/ssh: Is a directory
Error: /app/mmt-vis/xingxiangrui/se_cls_gat_on_coco is not a directory!</code></pre> 
  <h2 id="4.5%20%E5%8F%82%E8%80%83">4.5 参考</h2> 
  <p>&nbsp;~/.<strong>******</strong>/software-install/<strong>******</strong>/tools/hadoop-v2/hadoop/bin/hadoop fs -D fs.default.name=afs://<strong>******</strong> -D hadoop.job.ugi=<strong>******</strong>,<strong>******</strong>-D dfs.replication=1 -D fs.afs.impl=org.apache.hadoop.fs.DFileSystem -ls&nbsp; /user/<strong>******</strong>/<strong>******</strong>/</p> 
  <h1 id="%E4%BA%94%E3%80%81%E8%BF%90%E8%A1%8C%E9%9B%86%E7%BE%A4">五、运行集群</h1> 
  <h2 id="5.1%20%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1">5.1 提交任务</h2> 
  <p>直接提交</p> 
  <pre class="has">
<code class="language-bash">******_CLIENT_BIN=/******/bin/

${******_CLIENT_BIN}/submit \
    --hdfs afs:****** \
    --hdfs-user ******\
    --hdfs-passwd ******\
    --hdfs-path ****** \
    --file-dir ./ \
    --job-name ******\
    --queue-name ******-p40-2-8 \
    --num-nodes 1 \
    --num-task-pernode 1 \
    --gpu-pnode 8 \
    --submitter ******\
    --time-limit 0 \
    --job-script ./job.sh</code></pre> 
  <p>source submit.sh</p> 
  <p>可以将gpu-pnode设为1，表示节点的个数。</p> 
  <p>注意地址要在三级目录之后再建</p> 
  <p>同时注意，相应的用户名与密码要改为上面的这些模式</p> 
  <h2 id="5.2%20%E6%9F%A5%E7%9C%8B%E9%98%9F%E5%88%97%E6%83%85%E5%86%B5">5.2 查看队列情况</h2> 
  <p>showjob -p <strong>******</strong></p> 
  <p>查看相应的集群上的队列</p> 
  <p>查看相应的工作 show -j&nbsp;&nbsp; &lt;job ID&gt;</p> 
  <pre class="has">
<code class="language-bash">[]$ showjob -p ******
QueueName: ******
========================================================================================================================
  JobId           JobName                        Submitter       RunningTime     TotalGpus  Status     GpuUtil
========================================================================================================================
...
...
]$ showjob -j ******
==============================================================================================================
                                              Job Information
==============================================================================================================
...
...</code></pre> 
  <p>&nbsp;</p> 
  <h2 id="h3-5-2-">5.3 删除操作</h2> 
  <ol>
   <li><code># 1. 命令</code></li> 
   <li><code>deljob -j JOBID</code></li> 
   <li>&nbsp;</li> 
   <li><code># 2. 举例</code></li> 
   <li><code># deljob -j </code><strong>******</strong></li> 
  </ol>
  <p>删除之后相应status变为 CANCELLED</p> 
  <p><img alt="" class="has" height="146" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019052719061483.png" width="410"></p> 
  <h2 id="%E5%85%AD%E3%80%81%E7%BB%93%E6%9E%9C%E6%9F%A5%E7%9C%8B%E5%8F%8A%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93">六、结果查看及文件传输</h2> 
  <p>相关命令行。</p> 
  <p>服务器上cp，mv 等等，用到后续来更新。与文件系统有关。</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
