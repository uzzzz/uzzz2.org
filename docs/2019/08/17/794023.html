<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>pytorch 数据工程（待更新） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="pytorch 数据工程（待更新）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 1、爬取图像 2、转换为png图像 3、划分训练集、验证集和测试集 4、数据增强 1、爬取图像 # -*- coding: utf-8 -*- import requests import time import os import sys import importlib import json importlib.reload(sys) def getManyPages(keyword,pages): params=[] for i in range(30,30*pages+30,30): params.append({ &#39;tn&#39;: &#39;resultjson_com&#39;, &#39;ipn&#39;: &#39;rj&#39;, &#39;ct&#39;: 201326592, &#39;is&#39;: &#39;&#39;, &#39;fp&#39;: &#39;result&#39;, &#39;queryWord&#39;: keyword, &#39;cl&#39;: 2, &#39;lm&#39;: -1, &#39;ie&#39;: &#39;utf-8&#39;, &#39;oe&#39;: &#39;utf-8&#39;, &#39;adpicid&#39;: &#39;&#39;, &#39;st&#39;: -1, &#39;z&#39;: &#39;&#39;, &#39;ic&#39;: 0, &#39;word&#39;: keyword, &#39;s&#39;: &#39;&#39;, &#39;se&#39;: &#39;&#39;, &#39;tab&#39;: &#39;&#39;, &#39;width&#39;: &#39;&#39;, &#39;height&#39;: &#39;&#39;, &#39;face&#39;: 0, &#39;istype&#39;: 2, &#39;qc&#39;: &#39;&#39;, &#39;nc&#39;: 1, &#39;fr&#39;: &#39;&#39;, &#39;pn&#39;: i, &#39;rn&#39;: 30, &#39;gsm&#39;: &#39;1e&#39;, &#39;1488942260214&#39;: &#39;&#39; }) url = &#39;https://image.baidu.com/search/acjson&#39; urls = [] for i in params: try: urls.append(requests.get(url, params=i).json().get(&#39;data&#39;)) except json.decoder.JSONDecodeError: print(&quot;解析出错&quot;) return urls def getImg(dataList, localPath): if not os.path.exists(localPath): os.mkdir(localPath) x = 1 for list in dataList: for i in list: if i.get(&#39;thumbURL&#39;) != None: print(&#39;正在下载：%s&#39; % i.get(&#39;thumbURL&#39;)) ir = requests.get(i.get(&#39;thumbURL&#39;)) string = localPath + &#39;/&#39; + &#39;%04d.jpg&#39; % x with open(string, &#39;wb&#39;) as f: f.write(ir.content) x += 1 time.sleep(0.5) else: print(&#39;图片链接不存在&#39;) if __name__ == &#39;__main__&#39;: keyword = input(&quot;输入关键词：&quot;) dataList = getManyPages(keyword, 100) getImg(dataList,&#39;E:\\darknet-master\\Complied-darknet-master\\darknet-master\\data\\Mydata\\&#39;+keyword) 参考资料：http://www.mamicode.com/info-detail-2185644.html &nbsp; 2、转换为png图像 把 cifar-10 的测试集转换成了 png 图片，充当实验的原始数据。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jun 27 11:09:32 2019 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 import numpy as np import os savePath = &#39;.\\data_batch1&#39; srcPath=&#39;data_batch_1&#39; filepath = savePath.strip() #去掉.\符号 isExists=os.path.exists(filepath) if not isExists: os.makedirs(filepath) print(filepath+&#39;创建成功&#39;) else: print(filepath+&#39;目录已存在&#39;) def unpickle(srcPath): import pickle with open(srcPath, &#39;rb&#39;) as fo: dict = pickle.load(fo, encoding=&#39;bytes&#39;) return dict dict1 = unpickle(srcPath) for i in range(dict1[b&#39;data&#39;].shape[0]): img = dict1[b&#39;data&#39;][i] img = np.reshape(img, (3, 32,32)) #转为三维图片数组 img = img.transpose((1,2,0)) #通道转换为CV2的要求形式，CV是BGR img_name = str(dict1[b&#39;filenames&#39;][i]) #图片的名字 img_label = str(dict1[b&#39;labels&#39;][i]) #图片的标签 cv2.imwrite(&quot;.\\cifarData\\&quot;+img_label+&quot;\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1],img)#保存 print(&quot;.\\cifarData\\&quot;+img_label+&quot;\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1]) 3、划分训练集、验证集和测试集 &nbsp; &nbsp; &nbsp; 将上述数据分为实验所需的训练集、验证集和测试集。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jul 25 14:41:01 2019 @author: xiaoxiaoke &quot;&quot;&quot; import random import numpy as np import glob import shutil #提供了多个针对文件或文件集合的高等级操作 datapath=&quot;F:\DeepLearning\pytorch\cifar10-master\cifar-10-batches-py\data_batch1\\&quot; imgs_list = glob.glob(datapath+&#39;/*.png&#39;) imageSum=len(imgs_list) items = np.arange(imageSum) numImage=np.random.shuffle(imgs_list) rateTrain=int(0.7*imageSum) rateVaild=int(0.85*imageSum) #创建文件夹 trainPath=datapath+&#39;trainPath&#39; testPath=datapath+&#39;testPath&#39; vaildPath=datapath+&#39;vaildPath&#39; if not os.path.exists(trainPath): os.makedirs(trainPath) if not os.path.exists(testPath): os.makedirs(testPath) if not os.path.exists(vaildPath): os.makedirs(vaildPath) for i in range(imageSum): if i&lt;rateTrain: shutil.copy(imgs_list[i], trainPath) elif i&lt;rateVaild: shutil.copy(imgs_list[i], testPath) else: shutil.copy(imgs_list[i], vaildPath) 4、数据增强 &nbsp;常见的数据增强技术： 1、标准化（减去均均值，除以标准差,均值为0，标准差为1） 2、归一化（除以255，像素值归一化至[0 1]） 3、裁剪（中心裁剪、随机裁剪、随机长宽比裁剪、上下左右中心裁剪、填充、resize） 4、旋转（随机旋转） 5、镜像翻转(依照概率P水平翻转、垂直翻转) 6、变换（修改亮度、饱和度和对比度、线性变换、转为灰度图、仿射变换） 上述操作的按照一定概率随机排列和关闭。 标准化和归一化的目标在于：去除不同维度上的量纲影响，有利于模型的快速收敛。&nbsp; 计算某一个文件夹下的图像的均值： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Mon Jul 8 14:07:52 2019 计算图像的均值，应当计算图像在各类变换以后的均值 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 as cv import numpy as np import os import sys import matplotlib .pyplot as plt def computeMeanDirImage(trainPath,width,height): matSum=np.zeros([width,height,3]) cv.namedWindow(&quot;image&quot;,0) cv.resizeWindow(&quot;image&quot;,400,400) for root, dirs, files in os.walk(trainPath): print(root,dirs) matSum=np.zeros((width,height,3)) for imageNum in range(0,len(os.listdir(root))): #range(0,100): print(files[imageNum]) matImage=cv.imread(trainPath+files[imageNum]) if matImage.shape[2]!=3: print(&quot;The image is gray!&quot;); return 0 matImageNp = np.array(matImage) matSum=matSum+matImageNp; cv.imshow(&quot;image&quot;,matImage) cv.waitKey(100) avergeMatFloat=matSum/len(os.listdir(root)); avergeMatInt=avergeMatFloat.astype(np.int16) sc = plt.imshow(avergeMatInt) sc.set_cmap(&#39;hot&#39;)# 这里可以设置多种模式 return avergeMatFloat &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="目录 1、爬取图像 2、转换为png图像 3、划分训练集、验证集和测试集 4、数据增强 1、爬取图像 # -*- coding: utf-8 -*- import requests import time import os import sys import importlib import json importlib.reload(sys) def getManyPages(keyword,pages): params=[] for i in range(30,30*pages+30,30): params.append({ &#39;tn&#39;: &#39;resultjson_com&#39;, &#39;ipn&#39;: &#39;rj&#39;, &#39;ct&#39;: 201326592, &#39;is&#39;: &#39;&#39;, &#39;fp&#39;: &#39;result&#39;, &#39;queryWord&#39;: keyword, &#39;cl&#39;: 2, &#39;lm&#39;: -1, &#39;ie&#39;: &#39;utf-8&#39;, &#39;oe&#39;: &#39;utf-8&#39;, &#39;adpicid&#39;: &#39;&#39;, &#39;st&#39;: -1, &#39;z&#39;: &#39;&#39;, &#39;ic&#39;: 0, &#39;word&#39;: keyword, &#39;s&#39;: &#39;&#39;, &#39;se&#39;: &#39;&#39;, &#39;tab&#39;: &#39;&#39;, &#39;width&#39;: &#39;&#39;, &#39;height&#39;: &#39;&#39;, &#39;face&#39;: 0, &#39;istype&#39;: 2, &#39;qc&#39;: &#39;&#39;, &#39;nc&#39;: 1, &#39;fr&#39;: &#39;&#39;, &#39;pn&#39;: i, &#39;rn&#39;: 30, &#39;gsm&#39;: &#39;1e&#39;, &#39;1488942260214&#39;: &#39;&#39; }) url = &#39;https://image.baidu.com/search/acjson&#39; urls = [] for i in params: try: urls.append(requests.get(url, params=i).json().get(&#39;data&#39;)) except json.decoder.JSONDecodeError: print(&quot;解析出错&quot;) return urls def getImg(dataList, localPath): if not os.path.exists(localPath): os.mkdir(localPath) x = 1 for list in dataList: for i in list: if i.get(&#39;thumbURL&#39;) != None: print(&#39;正在下载：%s&#39; % i.get(&#39;thumbURL&#39;)) ir = requests.get(i.get(&#39;thumbURL&#39;)) string = localPath + &#39;/&#39; + &#39;%04d.jpg&#39; % x with open(string, &#39;wb&#39;) as f: f.write(ir.content) x += 1 time.sleep(0.5) else: print(&#39;图片链接不存在&#39;) if __name__ == &#39;__main__&#39;: keyword = input(&quot;输入关键词：&quot;) dataList = getManyPages(keyword, 100) getImg(dataList,&#39;E:\\darknet-master\\Complied-darknet-master\\darknet-master\\data\\Mydata\\&#39;+keyword) 参考资料：http://www.mamicode.com/info-detail-2185644.html &nbsp; 2、转换为png图像 把 cifar-10 的测试集转换成了 png 图片，充当实验的原始数据。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jun 27 11:09:32 2019 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 import numpy as np import os savePath = &#39;.\\data_batch1&#39; srcPath=&#39;data_batch_1&#39; filepath = savePath.strip() #去掉.\符号 isExists=os.path.exists(filepath) if not isExists: os.makedirs(filepath) print(filepath+&#39;创建成功&#39;) else: print(filepath+&#39;目录已存在&#39;) def unpickle(srcPath): import pickle with open(srcPath, &#39;rb&#39;) as fo: dict = pickle.load(fo, encoding=&#39;bytes&#39;) return dict dict1 = unpickle(srcPath) for i in range(dict1[b&#39;data&#39;].shape[0]): img = dict1[b&#39;data&#39;][i] img = np.reshape(img, (3, 32,32)) #转为三维图片数组 img = img.transpose((1,2,0)) #通道转换为CV2的要求形式，CV是BGR img_name = str(dict1[b&#39;filenames&#39;][i]) #图片的名字 img_label = str(dict1[b&#39;labels&#39;][i]) #图片的标签 cv2.imwrite(&quot;.\\cifarData\\&quot;+img_label+&quot;\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1],img)#保存 print(&quot;.\\cifarData\\&quot;+img_label+&quot;\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1]) 3、划分训练集、验证集和测试集 &nbsp; &nbsp; &nbsp; 将上述数据分为实验所需的训练集、验证集和测试集。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jul 25 14:41:01 2019 @author: xiaoxiaoke &quot;&quot;&quot; import random import numpy as np import glob import shutil #提供了多个针对文件或文件集合的高等级操作 datapath=&quot;F:\DeepLearning\pytorch\cifar10-master\cifar-10-batches-py\data_batch1\\&quot; imgs_list = glob.glob(datapath+&#39;/*.png&#39;) imageSum=len(imgs_list) items = np.arange(imageSum) numImage=np.random.shuffle(imgs_list) rateTrain=int(0.7*imageSum) rateVaild=int(0.85*imageSum) #创建文件夹 trainPath=datapath+&#39;trainPath&#39; testPath=datapath+&#39;testPath&#39; vaildPath=datapath+&#39;vaildPath&#39; if not os.path.exists(trainPath): os.makedirs(trainPath) if not os.path.exists(testPath): os.makedirs(testPath) if not os.path.exists(vaildPath): os.makedirs(vaildPath) for i in range(imageSum): if i&lt;rateTrain: shutil.copy(imgs_list[i], trainPath) elif i&lt;rateVaild: shutil.copy(imgs_list[i], testPath) else: shutil.copy(imgs_list[i], vaildPath) 4、数据增强 &nbsp;常见的数据增强技术： 1、标准化（减去均均值，除以标准差,均值为0，标准差为1） 2、归一化（除以255，像素值归一化至[0 1]） 3、裁剪（中心裁剪、随机裁剪、随机长宽比裁剪、上下左右中心裁剪、填充、resize） 4、旋转（随机旋转） 5、镜像翻转(依照概率P水平翻转、垂直翻转) 6、变换（修改亮度、饱和度和对比度、线性变换、转为灰度图、仿射变换） 上述操作的按照一定概率随机排列和关闭。 标准化和归一化的目标在于：去除不同维度上的量纲影响，有利于模型的快速收敛。&nbsp; 计算某一个文件夹下的图像的均值： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Mon Jul 8 14:07:52 2019 计算图像的均值，应当计算图像在各类变换以后的均值 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 as cv import numpy as np import os import sys import matplotlib .pyplot as plt def computeMeanDirImage(trainPath,width,height): matSum=np.zeros([width,height,3]) cv.namedWindow(&quot;image&quot;,0) cv.resizeWindow(&quot;image&quot;,400,400) for root, dirs, files in os.walk(trainPath): print(root,dirs) matSum=np.zeros((width,height,3)) for imageNum in range(0,len(os.listdir(root))): #range(0,100): print(files[imageNum]) matImage=cv.imread(trainPath+files[imageNum]) if matImage.shape[2]!=3: print(&quot;The image is gray!&quot;); return 0 matImageNp = np.array(matImage) matSum=matSum+matImageNp; cv.imshow(&quot;image&quot;,matImage) cv.waitKey(100) avergeMatFloat=matSum/len(os.listdir(root)); avergeMatInt=avergeMatFloat.astype(np.int16) sc = plt.imshow(avergeMatInt) sc.set_cmap(&#39;hot&#39;)# 这里可以设置多种模式 return avergeMatFloat &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<link rel="canonical" href="https://uzzz.org/2019/08/17/794023.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/17/794023.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 1、爬取图像 2、转换为png图像 3、划分训练集、验证集和测试集 4、数据增强 1、爬取图像 # -*- coding: utf-8 -*- import requests import time import os import sys import importlib import json importlib.reload(sys) def getManyPages(keyword,pages): params=[] for i in range(30,30*pages+30,30): params.append({ &#39;tn&#39;: &#39;resultjson_com&#39;, &#39;ipn&#39;: &#39;rj&#39;, &#39;ct&#39;: 201326592, &#39;is&#39;: &#39;&#39;, &#39;fp&#39;: &#39;result&#39;, &#39;queryWord&#39;: keyword, &#39;cl&#39;: 2, &#39;lm&#39;: -1, &#39;ie&#39;: &#39;utf-8&#39;, &#39;oe&#39;: &#39;utf-8&#39;, &#39;adpicid&#39;: &#39;&#39;, &#39;st&#39;: -1, &#39;z&#39;: &#39;&#39;, &#39;ic&#39;: 0, &#39;word&#39;: keyword, &#39;s&#39;: &#39;&#39;, &#39;se&#39;: &#39;&#39;, &#39;tab&#39;: &#39;&#39;, &#39;width&#39;: &#39;&#39;, &#39;height&#39;: &#39;&#39;, &#39;face&#39;: 0, &#39;istype&#39;: 2, &#39;qc&#39;: &#39;&#39;, &#39;nc&#39;: 1, &#39;fr&#39;: &#39;&#39;, &#39;pn&#39;: i, &#39;rn&#39;: 30, &#39;gsm&#39;: &#39;1e&#39;, &#39;1488942260214&#39;: &#39;&#39; }) url = &#39;https://image.baidu.com/search/acjson&#39; urls = [] for i in params: try: urls.append(requests.get(url, params=i).json().get(&#39;data&#39;)) except json.decoder.JSONDecodeError: print(&quot;解析出错&quot;) return urls def getImg(dataList, localPath): if not os.path.exists(localPath): os.mkdir(localPath) x = 1 for list in dataList: for i in list: if i.get(&#39;thumbURL&#39;) != None: print(&#39;正在下载：%s&#39; % i.get(&#39;thumbURL&#39;)) ir = requests.get(i.get(&#39;thumbURL&#39;)) string = localPath + &#39;/&#39; + &#39;%04d.jpg&#39; % x with open(string, &#39;wb&#39;) as f: f.write(ir.content) x += 1 time.sleep(0.5) else: print(&#39;图片链接不存在&#39;) if __name__ == &#39;__main__&#39;: keyword = input(&quot;输入关键词：&quot;) dataList = getManyPages(keyword, 100) getImg(dataList,&#39;E:\\\\darknet-master\\\\Complied-darknet-master\\\\darknet-master\\\\data\\\\Mydata\\\\&#39;+keyword) 参考资料：http://www.mamicode.com/info-detail-2185644.html &nbsp; 2、转换为png图像 把 cifar-10 的测试集转换成了 png 图片，充当实验的原始数据。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jun 27 11:09:32 2019 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 import numpy as np import os savePath = &#39;.\\\\data_batch1&#39; srcPath=&#39;data_batch_1&#39; filepath = savePath.strip() #去掉.\\符号 isExists=os.path.exists(filepath) if not isExists: os.makedirs(filepath) print(filepath+&#39;创建成功&#39;) else: print(filepath+&#39;目录已存在&#39;) def unpickle(srcPath): import pickle with open(srcPath, &#39;rb&#39;) as fo: dict = pickle.load(fo, encoding=&#39;bytes&#39;) return dict dict1 = unpickle(srcPath) for i in range(dict1[b&#39;data&#39;].shape[0]): img = dict1[b&#39;data&#39;][i] img = np.reshape(img, (3, 32,32)) #转为三维图片数组 img = img.transpose((1,2,0)) #通道转换为CV2的要求形式，CV是BGR img_name = str(dict1[b&#39;filenames&#39;][i]) #图片的名字 img_label = str(dict1[b&#39;labels&#39;][i]) #图片的标签 cv2.imwrite(&quot;.\\\\cifarData\\\\&quot;+img_label+&quot;\\\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1],img)#保存 print(&quot;.\\\\cifarData\\\\&quot;+img_label+&quot;\\\\&quot;+img_label+&quot;_&quot;+img_name[2:len(img_name)-1]) 3、划分训练集、验证集和测试集 &nbsp; &nbsp; &nbsp; 将上述数据分为实验所需的训练集、验证集和测试集。 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jul 25 14:41:01 2019 @author: xiaoxiaoke &quot;&quot;&quot; import random import numpy as np import glob import shutil #提供了多个针对文件或文件集合的高等级操作 datapath=&quot;F:\\DeepLearning\\pytorch\\cifar10-master\\cifar-10-batches-py\\data_batch1\\\\&quot; imgs_list = glob.glob(datapath+&#39;/*.png&#39;) imageSum=len(imgs_list) items = np.arange(imageSum) numImage=np.random.shuffle(imgs_list) rateTrain=int(0.7*imageSum) rateVaild=int(0.85*imageSum) #创建文件夹 trainPath=datapath+&#39;trainPath&#39; testPath=datapath+&#39;testPath&#39; vaildPath=datapath+&#39;vaildPath&#39; if not os.path.exists(trainPath): os.makedirs(trainPath) if not os.path.exists(testPath): os.makedirs(testPath) if not os.path.exists(vaildPath): os.makedirs(vaildPath) for i in range(imageSum): if i&lt;rateTrain: shutil.copy(imgs_list[i], trainPath) elif i&lt;rateVaild: shutil.copy(imgs_list[i], testPath) else: shutil.copy(imgs_list[i], vaildPath) 4、数据增强 &nbsp;常见的数据增强技术： 1、标准化（减去均均值，除以标准差,均值为0，标准差为1） 2、归一化（除以255，像素值归一化至[0 1]） 3、裁剪（中心裁剪、随机裁剪、随机长宽比裁剪、上下左右中心裁剪、填充、resize） 4、旋转（随机旋转） 5、镜像翻转(依照概率P水平翻转、垂直翻转) 6、变换（修改亮度、饱和度和对比度、线性变换、转为灰度图、仿射变换） 上述操作的按照一定概率随机排列和关闭。 标准化和归一化的目标在于：去除不同维度上的量纲影响，有利于模型的快速收敛。&nbsp; 计算某一个文件夹下的图像的均值： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Mon Jul 8 14:07:52 2019 计算图像的均值，应当计算图像在各类变换以后的均值 @author: xiaoxiaoke &quot;&quot;&quot; import cv2 as cv import numpy as np import os import sys import matplotlib .pyplot as plt def computeMeanDirImage(trainPath,width,height): matSum=np.zeros([width,height,3]) cv.namedWindow(&quot;image&quot;,0) cv.resizeWindow(&quot;image&quot;,400,400) for root, dirs, files in os.walk(trainPath): print(root,dirs) matSum=np.zeros((width,height,3)) for imageNum in range(0,len(os.listdir(root))): #range(0,100): print(files[imageNum]) matImage=cv.imread(trainPath+files[imageNum]) if matImage.shape[2]!=3: print(&quot;The image is gray!&quot;); return 0 matImageNp = np.array(matImage) matSum=matSum+matImageNp; cv.imshow(&quot;image&quot;,matImage) cv.waitKey(100) avergeMatFloat=matSum/len(os.listdir(root)); avergeMatInt=avergeMatFloat.astype(np.int16) sc = plt.imshow(avergeMatInt) sc.set_cmap(&#39;hot&#39;)# 这里可以设置多种模式 return avergeMatFloat &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"https://uzzz.org/2019/08/17/794023.html","headline":"pytorch 数据工程（待更新）","dateModified":"2019-08-17T00:00:00+08:00","datePublished":"2019-08-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/17/794023.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>pytorch 数据工程（待更新）</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="1%E3%80%81%E7%88%AC%E5%8F%96%E5%9B%BE%E5%83%8F-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E7%88%AC%E5%8F%96%E5%9B%BE%E5%83%8F" rel="nofollow" data-token="0b68204e331150a88bd7377da435fb21">1、爬取图像</a></p> 
  <p id="1%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%BApng%E5%9B%BE%E5%83%8F-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%BApng%E5%9B%BE%E5%83%8F" rel="nofollow" data-token="e41dae57a2b745b93143b59aa65bc9e8">2、转换为png图像</a></p> 
  <p id="2%E3%80%81%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86" rel="nofollow" data-token="976adc6a6797265b076bd38d11539c95">3、划分训练集、验证集和测试集</a></p> 
  <p id="3%E3%80%81%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-toc" style="margin-left:40px;"><a href="#3%E3%80%81%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA" rel="nofollow" data-token="d7b1707a4fcde79964585c0015834680">4、数据增强</a></p> 
  <hr id="hr-toc">
  <h2 id="1%E3%80%81%E7%88%AC%E5%8F%96%E5%9B%BE%E5%83%8F"><strong>1、爬取图像</strong></h2> 
  <pre class="has">
<code># -*- coding: utf-8 -*-

import requests
import time
import os
import sys
import importlib
import json
importlib.reload(sys)


def getManyPages(keyword,pages):
    params=[]
    for i in range(30,30*pages+30,30):
        params.append({
                      'tn': 'resultjson_com',
                      'ipn': 'rj',
                      'ct': 201326592,
                      'is': '',
                      'fp': 'result',
                      'queryWord': keyword,
                      'cl': 2,
                      'lm': -1,
                      'ie': 'utf-8',
                      'oe': 'utf-8',
                      'adpicid': '',
                      'st': -1,
                      'z': '',
                      'ic': 0,
                      'word': keyword,
                      's': '',
                      'se': '',
                      'tab': '',
                      'width': '',
                      'height': '',
                      'face': 0,
                      'istype': 2,
                      'qc': '',
                      'nc': 1,
                      'fr': '',
                      'pn': i,
                      'rn': 30,
                      'gsm': '1e',
                      '1488942260214': ''
                  })
    url = 'https://image.baidu.com/search/acjson'
    urls = []
    for i in params:
         try:
            urls.append(requests.get(url, params=i).json().get('data'))
         except json.decoder.JSONDecodeError:
            print("解析出错")
    return urls


def getImg(dataList, localPath):
    if not os.path.exists(localPath):
        os.mkdir(localPath)

    x = 1
    for list in dataList:
        for i in list:
            if i.get('thumbURL') != None:
                print('正在下载：%s' % i.get('thumbURL'))
                ir = requests.get(i.get('thumbURL'))
                string = localPath + '/' + '%04d.jpg' % x
                with open(string, 'wb') as f:
                    f.write(ir.content)
                x += 1
                time.sleep(0.5)
            else:
                print('图片链接不存在')

if __name__ == '__main__':
    keyword = input("输入关键词：")
    dataList = getManyPages(keyword, 100)
    getImg(dataList,'E:\\darknet-master\\Complied-darknet-master\\darknet-master\\data\\Mydata\\'+keyword)
        
</code></pre> 
  <p>参考资料：<a href="http://www.mamicode.com/info-detail-2185644.html" rel="nofollow" data-token="554534801c8b275baf4675499d9f6067">http://www.mamicode.com/info-detail-2185644.html</a></p> 
  <p>&nbsp;</p> 
  <h2 id="1%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%BApng%E5%9B%BE%E5%83%8F"><strong>2、转换为png图像</strong></h2> 
  <p>把 cifar-10 的测试集转换成了 png 图片，充当实验的原始数据。</p> 
  <pre class="has">
<code># -*- coding: utf-8 -*-
"""
Created on Thu Jun 27 11:09:32 2019

@author: xiaoxiaoke
"""
import cv2
import numpy as np
import os

savePath = '.\\data_batch1' 
srcPath='data_batch_1'

filepath = savePath.strip()    #去掉.\符号
isExists=os.path.exists(filepath)
if not isExists:
        os.makedirs(filepath) 
        print(filepath+'创建成功')
else:
        print(filepath+'目录已存在')
       
def unpickle(srcPath):
    import pickle
    with open(srcPath, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict
dict1 = unpickle(srcPath)

for i in range(dict1[b'data'].shape[0]):
    img = dict1[b'data'][i]
    img = np.reshape(img, (3, 32,32))      #转为三维图片数组
    img = img.transpose((1,2,0))           #通道转换为CV2的要求形式，CV是BGR
    img_name = str(dict1[b'filenames'][i]) #图片的名字
    img_label = str(dict1[b'labels'][i])   #图片的标签
    cv2.imwrite(".\\cifarData\\"+img_label+"\\"+img_label+"_"+img_name[2:len(img_name)-1],img)#保存
    print(".\\cifarData\\"+img_label+"\\"+img_label+"_"+img_name[2:len(img_name)-1])
    </code></pre> 
  <h2 id="2%E3%80%81%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86"><strong>3、划分训练集、验证集和测试集</strong></h2> 
  <p>&nbsp; &nbsp; &nbsp; 将上述数据分为实验所需的训练集、验证集和测试集。</p> 
  <pre class="has">
<code># -*- coding: utf-8 -*-
"""
Created on Thu Jul 25 14:41:01 2019

@author: xiaoxiaoke 
"""
import random
import numpy as np
import glob
import shutil #提供了多个针对文件或文件集合的高等级操作

datapath="F:\DeepLearning\pytorch\cifar10-master\cifar-10-batches-py\data_batch1\\"

imgs_list = glob.glob(datapath+'/*.png')
imageSum=len(imgs_list)
items = np.arange(imageSum)
numImage=np.random.shuffle(imgs_list)

rateTrain=int(0.7*imageSum)
rateVaild=int(0.85*imageSum)

#创建文件夹
trainPath=datapath+'trainPath'
testPath=datapath+'testPath'
vaildPath=datapath+'vaildPath'

if not os.path.exists(trainPath):
    os.makedirs(trainPath) 
if not os.path.exists(testPath):
    os.makedirs(testPath) 
if not os.path.exists(vaildPath):
    os.makedirs(vaildPath) 

for i in range(imageSum):
    if i&lt;rateTrain:
        shutil.copy(imgs_list[i], trainPath)
    elif i&lt;rateVaild:
        shutil.copy(imgs_list[i], testPath)
    else:
        shutil.copy(imgs_list[i], vaildPath)
        </code></pre> 
  <h2 id="3%E3%80%81%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><strong>4、数据增强</strong></h2> 
  <p>&nbsp;常见的数据增强技术：</p> 
  <p style="text-indent:50px;">1、标准化（减去均均值，除以标准差,均值为0，标准差为1）</p> 
  <p style="text-indent:50px;">2、归一化（除以255，像素值归一化至[0 1]）</p> 
  <p style="text-indent:50px;">3、裁剪（中心裁剪、随机裁剪、随机长宽比裁剪、上下左右中心裁剪、填充、resize）</p> 
  <p style="text-indent:50px;">4、旋转（随机旋转）</p> 
  <p style="text-indent:50px;">5、镜像翻转(依照概率P水平翻转、垂直翻转)</p> 
  <p style="text-indent:50px;">6、变换（修改亮度、饱和度和对比度、线性变换、转为灰度图、仿射变换）</p> 
  <p style="text-indent:50px;">上述操作的按照一定概率随机排列和关闭。</p> 
  <p>标准化和归一化的目标在于：去除不同维度上的量纲影响，有利于模型的快速收敛。&nbsp;</p> 
  <p>计算某一个文件夹下的图像的均值：</p> 
  <pre class="has">
<code># -*- coding: utf-8 -*-
"""
Created on Mon Jul  8 14:07:52 2019
计算图像的均值，应当计算图像在各类变换以后的均值
@author: xiaoxiaoke 
"""
import cv2 as cv
import numpy as np
import os
import sys
import matplotlib .pyplot as plt

def computeMeanDirImage(trainPath,width,height):
    matSum=np.zeros([width,height,3])
    cv.namedWindow("image",0)
    cv.resizeWindow("image",400,400)
    for root, dirs, files in os.walk(trainPath):
        print(root,dirs)
       
        matSum=np.zeros((width,height,3))
        for imageNum in range(0,len(os.listdir(root))):     #range(0,100): 
            print(files[imageNum])
            matImage=cv.imread(trainPath+files[imageNum])
            if matImage.shape[2]!=3:
                print("The image is gray!");
                return 0
            matImageNp = np.array(matImage) 
            matSum=matSum+matImageNp;
            cv.imshow("image",matImage)
            cv.waitKey(100)
            
    avergeMatFloat=matSum/len(os.listdir(root));
    avergeMatInt=avergeMatFloat.astype(np.int16)
    sc = plt.imshow(avergeMatInt)
    sc.set_cmap('hot')# 这里可以设置多种模式

    return avergeMatFloat</code></pre> 
  <p>&nbsp;</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
