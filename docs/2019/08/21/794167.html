<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>数据分析/挖掘笔记 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="数据分析/挖掘笔记" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="流程： 数据获取-》探索分析与可视化-》预处理理论-》分析建模-》模型评估 数据获取手段- 1.数据仓库 数据库面向业务存储，仓库面向主题存储 数据库针对应用（OLTP），仓库针对分析（OLAP） 数据库组织规范，仓库冗余大 2.监测与抓取 Python常用工具 urllib,urllib2,requests,scrapy 3.填写，埋点，日志 用户填写信息 APP或网页埋点（特定流程的信息记录点） 操作日志 4.竞赛网站 kaggle 阿里云 天池 探索分析与可视化 理论铺垫 集中趋势：均值，中位数与分位数，众数 .mean() #均值 .median() #中位数 .quantile(q=0.25) #分位数 .mode() #众数 可能会有多个 离中趋势：标准差，方差 √ .std() #标准差 .var() #方差 .sum() #求和 数据分布：偏态与峰态，正态分布与三大分布 .skew() #偏态系数 .kurt() #峰态系数 抽样理论：抽样误差，抽样精度 .sample() #抽样 异常值分析： 判断某列有多少异常值： sl = data[&quot;col&quot;] sl[ sl.isnull() ] 有异常值数据的其他信息： data[ data[&quot;col&quot;].isnull() ] 判断某特征各个值数量的多少 col.value_counts(normalize=True).sort_index() 对比分析 结构分析： 静态分析：看各部分所占比例 动态分析：时间轴，看变化趋势 np.histogram(data.values, bins=np.arange(0.0, 1.1, 0.1)) #value值 从0到1.1，每隔0.1有多少个 数据预处理 特征工程 数据和特征决定了机器学习的上限 异常值处理 识别异常值 fillna() 删除某一列的空值 data.dropna(subset=[“B”]) .interpolate() 插值函数 df[ [True if item.startwith(“f”）else False for item in list(df[“F”].values) ]] 保留以f开头的选项 标注：标签，label 特征选择： from sklearn.svm import SVR from sklearn.tree import DecisionTreeRegressor X=df.loc[:,[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;]] Y=df.loc[:,&quot;D&quot;] from sklearn.feature_selection import SelectKBest,RFE,SelectFormModel skb=SelectBest(k=2) skb.fit(X,Y) skb.transform(X) rfe=RFE(estimator=SVR(kernal=&quot;linear&quot;),n_features_to_select=2,step=1) rfe.fit_transform(X,Y) sfm=SelectFormModel(estimator=DecisionTreeRegressor(),threshold=0.1) sfm.fit_transform(X,Y) 机器学习与建模 机器学习：计算机以数据为基础，进行归纳与总结 监督学习（分类/回归） 非监督学习（聚类/关联） 半监督学习 训练集：用来训练和拟合模型 验证集：纠偏或改正预测 测试集：模型泛化能力的考量（泛化：对未知数据的预测能力） KNN 朴素贝叶斯 决策树 支持向量机 集成方法 欧式距离 ：（直线距离） 曼哈顿距离：（各个维度距离累加） 明可夫斯基距离 K-nearest neighbors from sklearn.neighbors import Nearest Neighbors ,KNeighborsClassifier knn_clf = KNeighborsClassifier(n_neighbors=5) knn_clf.fit(X_train,Y_train) Y_pred = knn_clf.predict(X_validation) from sklearn.metrics import accuracy_score,recall_score,f1_score print(&quot;ACC:&quot;, accuracy_score(Y_validation,Y_pred)) print(&quot;REC:&quot;, recall_score(Y_validation,Y_pred)) print(&quot;F-Score:&quot;, f1_score(Y_validation,Y_pred)) 朴素贝叶斯 概率：p(a) 条件概率p(a|b) 联合概率p（a,b）" />
<meta property="og:description" content="流程： 数据获取-》探索分析与可视化-》预处理理论-》分析建模-》模型评估 数据获取手段- 1.数据仓库 数据库面向业务存储，仓库面向主题存储 数据库针对应用（OLTP），仓库针对分析（OLAP） 数据库组织规范，仓库冗余大 2.监测与抓取 Python常用工具 urllib,urllib2,requests,scrapy 3.填写，埋点，日志 用户填写信息 APP或网页埋点（特定流程的信息记录点） 操作日志 4.竞赛网站 kaggle 阿里云 天池 探索分析与可视化 理论铺垫 集中趋势：均值，中位数与分位数，众数 .mean() #均值 .median() #中位数 .quantile(q=0.25) #分位数 .mode() #众数 可能会有多个 离中趋势：标准差，方差 √ .std() #标准差 .var() #方差 .sum() #求和 数据分布：偏态与峰态，正态分布与三大分布 .skew() #偏态系数 .kurt() #峰态系数 抽样理论：抽样误差，抽样精度 .sample() #抽样 异常值分析： 判断某列有多少异常值： sl = data[&quot;col&quot;] sl[ sl.isnull() ] 有异常值数据的其他信息： data[ data[&quot;col&quot;].isnull() ] 判断某特征各个值数量的多少 col.value_counts(normalize=True).sort_index() 对比分析 结构分析： 静态分析：看各部分所占比例 动态分析：时间轴，看变化趋势 np.histogram(data.values, bins=np.arange(0.0, 1.1, 0.1)) #value值 从0到1.1，每隔0.1有多少个 数据预处理 特征工程 数据和特征决定了机器学习的上限 异常值处理 识别异常值 fillna() 删除某一列的空值 data.dropna(subset=[“B”]) .interpolate() 插值函数 df[ [True if item.startwith(“f”）else False for item in list(df[“F”].values) ]] 保留以f开头的选项 标注：标签，label 特征选择： from sklearn.svm import SVR from sklearn.tree import DecisionTreeRegressor X=df.loc[:,[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;]] Y=df.loc[:,&quot;D&quot;] from sklearn.feature_selection import SelectKBest,RFE,SelectFormModel skb=SelectBest(k=2) skb.fit(X,Y) skb.transform(X) rfe=RFE(estimator=SVR(kernal=&quot;linear&quot;),n_features_to_select=2,step=1) rfe.fit_transform(X,Y) sfm=SelectFormModel(estimator=DecisionTreeRegressor(),threshold=0.1) sfm.fit_transform(X,Y) 机器学习与建模 机器学习：计算机以数据为基础，进行归纳与总结 监督学习（分类/回归） 非监督学习（聚类/关联） 半监督学习 训练集：用来训练和拟合模型 验证集：纠偏或改正预测 测试集：模型泛化能力的考量（泛化：对未知数据的预测能力） KNN 朴素贝叶斯 决策树 支持向量机 集成方法 欧式距离 ：（直线距离） 曼哈顿距离：（各个维度距离累加） 明可夫斯基距离 K-nearest neighbors from sklearn.neighbors import Nearest Neighbors ,KNeighborsClassifier knn_clf = KNeighborsClassifier(n_neighbors=5) knn_clf.fit(X_train,Y_train) Y_pred = knn_clf.predict(X_validation) from sklearn.metrics import accuracy_score,recall_score,f1_score print(&quot;ACC:&quot;, accuracy_score(Y_validation,Y_pred)) print(&quot;REC:&quot;, recall_score(Y_validation,Y_pred)) print(&quot;F-Score:&quot;, f1_score(Y_validation,Y_pred)) 朴素贝叶斯 概率：p(a) 条件概率p(a|b) 联合概率p（a,b）" />
<link rel="canonical" href="https://uzzz.org/2019/08/21/794167.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/21/794167.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"流程： 数据获取-》探索分析与可视化-》预处理理论-》分析建模-》模型评估 数据获取手段- 1.数据仓库 数据库面向业务存储，仓库面向主题存储 数据库针对应用（OLTP），仓库针对分析（OLAP） 数据库组织规范，仓库冗余大 2.监测与抓取 Python常用工具 urllib,urllib2,requests,scrapy 3.填写，埋点，日志 用户填写信息 APP或网页埋点（特定流程的信息记录点） 操作日志 4.竞赛网站 kaggle 阿里云 天池 探索分析与可视化 理论铺垫 集中趋势：均值，中位数与分位数，众数 .mean() #均值 .median() #中位数 .quantile(q=0.25) #分位数 .mode() #众数 可能会有多个 离中趋势：标准差，方差 √ .std() #标准差 .var() #方差 .sum() #求和 数据分布：偏态与峰态，正态分布与三大分布 .skew() #偏态系数 .kurt() #峰态系数 抽样理论：抽样误差，抽样精度 .sample() #抽样 异常值分析： 判断某列有多少异常值： sl = data[&quot;col&quot;] sl[ sl.isnull() ] 有异常值数据的其他信息： data[ data[&quot;col&quot;].isnull() ] 判断某特征各个值数量的多少 col.value_counts(normalize=True).sort_index() 对比分析 结构分析： 静态分析：看各部分所占比例 动态分析：时间轴，看变化趋势 np.histogram(data.values, bins=np.arange(0.0, 1.1, 0.1)) #value值 从0到1.1，每隔0.1有多少个 数据预处理 特征工程 数据和特征决定了机器学习的上限 异常值处理 识别异常值 fillna() 删除某一列的空值 data.dropna(subset=[“B”]) .interpolate() 插值函数 df[ [True if item.startwith(“f”）else False for item in list(df[“F”].values) ]] 保留以f开头的选项 标注：标签，label 特征选择： from sklearn.svm import SVR from sklearn.tree import DecisionTreeRegressor X=df.loc[:,[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;]] Y=df.loc[:,&quot;D&quot;] from sklearn.feature_selection import SelectKBest,RFE,SelectFormModel skb=SelectBest(k=2) skb.fit(X,Y) skb.transform(X) rfe=RFE(estimator=SVR(kernal=&quot;linear&quot;),n_features_to_select=2,step=1) rfe.fit_transform(X,Y) sfm=SelectFormModel(estimator=DecisionTreeRegressor(),threshold=0.1) sfm.fit_transform(X,Y) 机器学习与建模 机器学习：计算机以数据为基础，进行归纳与总结 监督学习（分类/回归） 非监督学习（聚类/关联） 半监督学习 训练集：用来训练和拟合模型 验证集：纠偏或改正预测 测试集：模型泛化能力的考量（泛化：对未知数据的预测能力） KNN 朴素贝叶斯 决策树 支持向量机 集成方法 欧式距离 ：（直线距离） 曼哈顿距离：（各个维度距离累加） 明可夫斯基距离 K-nearest neighbors from sklearn.neighbors import Nearest Neighbors ,KNeighborsClassifier knn_clf = KNeighborsClassifier(n_neighbors=5) knn_clf.fit(X_train,Y_train) Y_pred = knn_clf.predict(X_validation) from sklearn.metrics import accuracy_score,recall_score,f1_score print(&quot;ACC:&quot;, accuracy_score(Y_validation,Y_pred)) print(&quot;REC:&quot;, recall_score(Y_validation,Y_pred)) print(&quot;F-Score:&quot;, f1_score(Y_validation,Y_pred)) 朴素贝叶斯 概率：p(a) 条件概率p(a|b) 联合概率p（a,b）","@type":"BlogPosting","url":"https://uzzz.org/2019/08/21/794167.html","headline":"数据分析/挖掘笔记","dateModified":"2019-08-21T00:00:00+08:00","datePublished":"2019-08-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/21/794167.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>数据分析/挖掘笔记</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p><strong>流程：</strong><br> 数据获取-》探索分析与可视化-》预处理理论-》分析建模-》模型评估</p> 
  <p><strong>数据获取手段-</strong><br> 1.数据仓库<br> 数据库面向业务存储，仓库面向主题存储<br> 数据库针对应用（OLTP），仓库针对分析（OLAP）<br> 数据库组织规范，仓库冗余大</p> 
  <p>2.监测与抓取<br> Python常用工具<br> urllib,urllib2,requests,scrapy</p> 
  <p>3.填写，埋点，日志<br> 用户填写信息<br> APP或网页埋点（特定流程的信息记录点）<br> 操作日志</p> 
  <p>4.竞赛网站<br> kaggle<br> 阿里云 天池</p> 
  <p><strong>探索分析与可视化</strong><br> 理论铺垫<br> <strong>集中趋势</strong>：均值，中位数与分位数，众数</p> 
  <pre><code>.mean()       #均值
.median()      #中位数
.quantile(q=0.25)   #分位数
.mode()      #众数  可能会有多个
</code></pre> 
  <p><strong>离中趋势</strong>：标准差，方差 √</p> 
  <pre><code>.std()      #标准差
.var()       #方差
.sum()       #求和
</code></pre> 
  <p><strong>数据分布</strong>：偏态与峰态，正态分布与三大分布<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190608235916753.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <pre><code>.skew()       #偏态系数
.kurt()        #峰态系数
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190608235824305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>抽样理论</strong>：抽样误差，抽样精度</p> 
  <pre><code>.sample()         #抽样
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190609000006772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190608235703571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190608235752729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>异常值分析：</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190610160047561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <pre><code>判断某列有多少异常值：
sl = data["col"]         sl[ sl.isnull() ]
有异常值数据的其他信息：  data[ data["col"].isnull() ]

判断某特征各个值数量的多少
col.value_counts(normalize=True).sort_index()
</code></pre> 
  <p><strong>对比分析</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190610160750625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>结构分析：</strong><br> 静态分析：看各部分所占比例<br> 动态分析：时间轴，看变化趋势</p> 
  <pre><code>np.histogram(data.values, bins=np.arange(0.0, 1.1, 0.1))  #value值 从0到1.1，每隔0.1有多少个
</code></pre> 
  <p><strong>数据预处理</strong><br> 特征工程<br> 数据和特征决定了机器学习的上限<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190611143151256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MDc2ODM2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 异常值处理<br> 识别异常值<br> fillna()<br> 删除某一列的空值 data.dropna(subset=[“B”])<br> .interpolate() 插值函数<br> df[ [True if item.startwith(“f”）else False for item in list(df[“F”].values) ]] 保留以f开头的选项</p> 
  <p>标注：标签，label<br> 特征选择：</p> 
  <pre><code>from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
X=df.loc[:,["A","B","C"]]
Y=df.loc[:,"D"]
from sklearn.feature_selection import SelectKBest,RFE,SelectFormModel
skb=SelectBest(k=2)
skb.fit(X,Y)
skb.transform(X)

rfe=RFE(estimator=SVR(kernal="linear"),n_features_to_select=2,step=1)
rfe.fit_transform(X,Y)

sfm=SelectFormModel(estimator=DecisionTreeRegressor(),threshold=0.1)
sfm.fit_transform(X,Y)
</code></pre> 
  <p><strong>机器学习与建模</strong><br> <em>机器学习：计算机以数据为基础，进行归纳与总结</em><br> 监督学习（分类/回归）<br> 非监督学习（聚类/关联）<br> 半监督学习</p> 
  <p>训练集：用来训练和拟合模型<br> 验证集：纠偏或改正预测<br> 测试集：模型泛化能力的考量（泛化：对未知数据的预测能力）</p> 
  <p>KNN 朴素贝叶斯 决策树 支持向量机 集成方法</p> 
  <p>欧式距离 ：（直线距离）<br> 曼哈顿距离：（各个维度距离累加）<br> 明可夫斯基距离</p> 
  <p>K-nearest neighbors</p> 
  <pre><code>from sklearn.neighbors import Nearest Neighbors ,KNeighborsClassifier
knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train,Y_train)
Y_pred = knn_clf.predict(X_validation)
from sklearn.metrics import accuracy_score,recall_score,f1_score
print("ACC:", accuracy_score(Y_validation,Y_pred))
print("REC:", recall_score(Y_validation,Y_pred))
print("F-Score:", f1_score(Y_validation,Y_pred))
</code></pre> 
  <p>朴素贝叶斯<br> 概率：p(a)<br> 条件概率p(a|b) 联合概率p（a,b）</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
