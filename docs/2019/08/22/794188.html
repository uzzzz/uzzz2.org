<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>虚拟机上的Hadoop伪分布式和完全分布式的搭建 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="虚拟机上的Hadoop伪分布式和完全分布式的搭建" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 一、Hadoop 1.Hadoop的组成 1.1HDFS架构概述 1.2YARN架构概述 1.3MapReduce架构概述 二、Hadoop的搭建 1.运行环境 1.1安装JDK 1.2安装Hadoop 2.伪分布式运行模式 2.1配置文件说明 2.2启动HDFS并运行MapReduce程序 2.3启动YARN并运行MapReduce程序 2.4配置历史服务器 2.5配置日志的聚集 3.完全分布式运行模式 3.1虚拟机准备 3.2编写集群分发脚本 3.3集群配置 集群启动/停止方式总结 一、Hadoop 1.Hadoop的组成 简单了解一下Hadoop2.x时代的组成： HDFS 负责数据存储 Yarn 负责资源调度 MapReduce 负责计算 Common 辅助工具 1.1HDFS架构概述 HDFS(Hadoop Distributed File System) （1）NameNode (nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和块所在的DataNode等。 （2）DataNode (dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 （3）Secondary NameNode (2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 1.2YARN架构概述 ResourceManager（RM）主要作用如下： （1）处理客户端请求 （2）监控NodeManager （3）启动或监控ApplicationMaster （4）资源的分配与调度 NodeManger（NM）主要作用如下： （1）管理单个节点上的资源 （2）处理来自ResourceManager的命令 （3）处理来自ApplicationMaster的命令 ApplicationMaster（AM）作用如下： （1）负责数据的切分 （2）为应用程序申请资源并分配给内部的任务。 （3）任务的监控与容错。 Container Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。 1.3MapReduce架构概述 MapReduce 将计算过程分为两个阶段：Map和Reduce： （1）Map阶段并行处理输入数据。 （2）Reduce阶段对Map结果进行汇总 二、Hadoop的搭建 1.运行环境 前期准备这一部分看需求进行配置 修改 vim /etc/udev/rules.d/70-persistent-net.rules , 拷贝mac地址 修改 vim /etc/sysconfig/network-scripts/ifcfg-eth0 , 修改mac地址以及IP地址 修改 vim /etc/sysconfig/network 修改主机名 修改 vim /etc/hosts ,配置 IP与主机名的映射. 修改主机名 vim /etc/sysconfig/network 配置IP与主机名的映射： vim /etc/hosts 添加如下内容： 192.168.17.101 hadoop101 192.168.17.102 hadoop102 192.168.17.103 hadoop103 192.168.17.104 hadoop104 关闭防火墙 查看防火墙状态： service iptables status 临时关闭防火墙： service iptables stop 开机时关闭防火墙： chkconfig iptables off 创建Linux用户 这里添加了名为 fseast 的新用户： useradd fseast passwd fseast 配置Linux用户具有root权限 对/etc/sudoers文件添加： fseast ALL=(ALL) NOPASSWD:ALL 接下来的操作都将使用fseast用户操作 创建文件夹 在/opt下创建 software 和 module 两个目录，一个存放软件包，一个放解压后的文件。（使用fseast用户创建要使用sudo） 改变这两个目录所有者： chown fseast:fseast 目录 关闭图形化界面： 修改 /etc/inittab id:3:initdefault: 1.1安装JDK 这里使用的Linux版本是Centos6.8， JDK版本是1.8， Hadoop版本是2.7.2 安装JDK 先把软件包上传到software 目录 解压： tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/ 配置环境变量： 在/etc/profile文件加上： #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 export PATH=$PATH:$JAVA_HOME/bin 使其生效： source /etc/profile 测试jdk是否安装成功： java -version 1.2安装Hadoop Hadoop下载地址： https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/ 上传安装包到software，解压： tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/ 解压后查看目录结构： （1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本 （2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件 （3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能） （4）sbin目录：存放启动或停止Hadoop相关服务的脚本 （5）share目录：存放Hadoop的依赖jar包、文档、和官方案例 将Hadoop添加到环境变量： 在/etc/profile文件添加： export HADOOP_HOME=/opt/module/hadoop-2.7.2 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 使其生效： source /etc/profile 测试是否安装成功： hadoop version 2.伪分布式运行模式 2.1配置文件说明 Hadoop配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。 （1）默认配置文件： （2）自定义配置文件: core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。 2.2启动HDFS并运行MapReduce程序 (1). 修改配置文件： 进入/opt/module/hadoop-2.7.2/etc/hadoop 目录 （a）配置：hadoop-env.sh 修改改配置文件的JAVA_HOME路径（其实单台节点不配JAVA_HOME也可以读的到该变量）： export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置：core-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; （c）配置：hdfs-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; (2). 启动集群 （a）格式化NameNode（第一次启动时格式化，以后就不要总格式化，原因下面说） bin/hdfs namenode -format （b）启动NameNode hadoop-daemon.sh start namenode （c）启动DataNode hadoop-daemon.sh start datanode (3). 查看集群 （a）查看是否启动成功 [fseast@hadoop101 hadoop-2.7.2]$ jps 5203 DataNode 5353 Jps 5102 NameNode （b）web端查看HDFS文件系统 http://hadoop101:50070/ 使用hadoop101的话需要配置Windows的hosts文件。 成功进入： （c）查看产生的Log日志 要习惯根据日志提示信息去分析问题、解决Bug。 这里日志文件目录为：/opt/module/hadoop-2.7.2/logs (4). 操作集群： （a）在HDFS文件系统上创建一个input文件夹 hdfs dfs -mkdir -p /user/fseast/input （b）将测试文件内容上传到文件系统上 先在本地创建一个文件wc.input，并写入一些单词，然后上传到文件系统上： hdfs dfs -put wc.input /user/fseast/input （c）运行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input/ /user/fseast/output 这个 /user/fseast/output目录不用提前在HDFS创建。 （d）查看输出结果 hdfs dfs -cat /user/fseast/output/* 浏览器查看： 【为什么不能重复格式化NameNode？】 Hadoop的NameNode和DataNode有对应的clusterID，NameNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/VERSION文件中，DataNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/VERSION文件中，正常情况下这NameNode和DataNode的cID要一致。当重复格式化NameNode的时候，会导致NameNode的clusterID与DataNode的clusterID不一致。启动的时候便会出现问题。 所以，以后一定要格式化的时候，先关闭进程，删除/opt/module/hadoop-2.7.2下的data和logs这两个目录。 我截了NameNode的clusterID与DataNode的clusterID： 2.3启动YARN并运行MapReduce程序 （1）配置集群 （a）配置yarn-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置yarn-site.xml &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop101&lt;/value&gt; &lt;/property&gt; （c）配置：mapred-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （d）配置： (对mapred-site.xml.template复制一份并重新命名为) mapred-site.xml &lt;!-- 指定MR运行在YARN上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 切记上面的配置都要在 &lt;configuration&gt;&lt;/configuration&gt; 内 （2）启动集群 （a）启动前必须保证NameNode和DataNode已经启动 （b）启动ResourceManager yarn-daemon.sh start resourcemanager （c）启动NodeManager yarn-daemon.sh start nodemanager 截图： （3）集群操作 （a）YARN的浏览器页面查看：http://hadoop101:8088 如图所示： （b）删除文件系统上的output文件 hdfs dfs -rm -R /user/fseast/output （c）执行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 执行MapReduce程序的时候，如果你一直刷新页面，就可以看的到变化： 2.4配置历史服务器 为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下： 配置mapred-site.xml: &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop101:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop101:19888&lt;/value&gt; &lt;/property&gt; 启动历史服务器 mr-jobhistory-daemon.sh start historyserver 查看历史服务器是否启动： 查看JobHistory：http://hadoop101:19888/jobhistory 如图所示： 点击上方圈起来的位置： 再点击圈起来的地方： 他说没有开启聚集，那就开启一下日志的聚集： 2.5配置日志的聚集 配置yarn-site.xml: &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; 关闭NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh stop historyserver 启动NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh start resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh start nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh start historyserver 删除HDFS上已经存在的输出文件 hdfs dfs -rm -R /user/fseast/output 执行WordCount程序 [fseast@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 再按照上面，查看日志， 先进JobHistory，http://hadoop101:19888/jobhistory 3.完全分布式运行模式 3.1虚拟机准备 再准备三台虚拟机：hadoop102、hadoop103、hadoop104，修改主机名，IP地址，配置/etc/hosts文件， 3.2编写集群分发脚本 scp（secure copy）安全拷贝 把上面安装好的jdk和Hadoop发送到新建的三台虚拟机(记得先停掉hadoop的那些进程)： [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop102:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop103:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop104:/opt/ 改变传过去目录的所有者： [fseast@hadoop102 opt]$ sudo chown fseast:fseast -R module/ rsync 远程同步工具 rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。 实例： 把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录： [fseast@hadoop101 opt]$ sudo rsync -av /opt/software/ hadoop102:/opt/software 拷贝环境变量配置文件： [fseast@hadoop101 etc]$ sudo rsync -av /etc/profile hadoop102:/etc/profile 使环境变量生效：source /etc/profile 脚本实现： 目的：后面在hadoop102节点上修改了某些文件时，不需要一个个传到另外两个节点，启动 shell 脚本时加上参数即可： （a）在/home/fseast目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下： [fseast@hadoop102 ~]$ mkdir bin [fseast@hadoop102 ~]$ cd bin/ [fseast@hadoop102 bin]$ touch xsync [fseast@hadoop102 bin]$ vim xsync 在该文件中编写如下代码： #!/bin/bash #1 获取输入参数个数，如果没有参数，直接退出 pcount=$# if ((pcount==0)); then echo no args; exit; fi #2 获取文件名称 p1=$1 fname=`basename $p1` echo fname=$fname #3 获取上级目录到绝对路径 pdir=`cd -P $(dirname $p1); pwd` echo pdir=$pdir #4 获取当前用户名称 user=`whoami` #5 循环 for((host=103; host&lt;105; host++)); do echo ------------------- hadoop$host -------------- rsync -av $pdir/$fname $user@hadoop$host:$pdir done （b）修改脚本 xsync 具有执行权限 [fseast@hadoop102 bin]$ chmod 777 xsync （c）调用脚本形式：xsync 文件名称 如： 把/home/fseast/bin同步到其他两台节点： [fseast@hadoop102 bin]$ xsync /home/fseast/bin 注意：如果将xsync放到/home/fseast/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。出现不能使用的情况，大多是全局变量PATH没有/home/fseast/bin路径。 3.3集群配置 以下的完全分布式配置是完整的配置，也就是默认没有配置伪分布式情况下的。 配置文件三个.env结尾的文件都只是配了 JAVA_HOME ，所以也可不配，只需要在/home/fseast/.bashrc文件中加上 source /etc/profile NameNode，ResourceManager，SecondaryNameNode三个节点比较耗资源，最好不要放在同一台机器。 集群部署规划 SSH免密登录配置 (1) 生成公钥和私钥： [fseast@hadoop102 ~]$ ssh-keygen -t rsa 然后按三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥） (2) 将公钥拷贝到要免密登录的目标机器上 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop102 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop103 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop104 在hadoop103也要做相同操作，这里hadoop104可以操作也可以不做。 配置集群 配置集群的文件在hadoop102节点配置，配置完后再使用上面的脚本同步就好。 这里是按照没有配伪分布式情况下的配置文件，在前面配过伪分布式那么有些配过了那就不需要重复配了。 所用需要配置的文件都在目录： /opt/module/hadoop-2.7.2/etc/hadoop/slaves （1）核心配置文件 配置core-site.xml（伪分布式配过，只需要修改NameNode的节点名即可。）： &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop102:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; （2）HDFS配置文件 配置hadoop-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置hdfs-site.xml（副本数量伪分布式配过，不过需要修改）： &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt; &lt;/property&gt; （3）YARN配置文件 配置yarn-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置yarn-site.xml（伪分布式配过，需要修改ResourceManager的地址，前面配的日志聚集也可保留）： &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt; &lt;/property&gt; （4）MapReduce配置文件 配置mapred-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置mapred-site.xml（伪分布配过，没配过的需要复制mapred-site.xml.template文件并改名为mapred-site.xml再配置）： &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop102:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop102:19888&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定MR运行在Yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; （5）配置slaves（没有配过）： 为了群起集群的时候，知道哪台节点是从节点 hadoop102 hadoop103 hadoop104 在集群上分发配置好的Hadoop配置文件 [fseast@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/ 群起集群 （1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） hdfs namenode -format （2）启动HDFS 在hadoop102（NameNode）执行： start-dfs.sh （3）启动YARN 在hadoop103（ResourceManager）执行： start-yarn.sh （4）Web端查看SecondaryNameNode： http://hadoop104:50090 集群启动/停止方式总结 各个服务组件逐一启动/停止 （1）分别启动/停止HDFS组件 hadoop-daemon.sh start / stop namenode / datanode / secondarynamenode hadoop-daemon.sh start / stop datanode hadoop-daemon.sh start / stop secondarynamenode （2）启动/停止YARN yarn-daemon.sh start / stop resourcemanager yarn-daemon.sh start / stop nodemanager 各个模块分开启动/停止（配置ssh是前提） （1）整体启动/停止HDFS start-dfs.sh / stop-dfs.sh （2）整体启动/停止YARN start-yarn.sh / stop-yarn.sh 下一篇：阿里云服务器上的Hadoop伪分布式和完全分布式的搭建" />
<meta property="og:description" content="目录 一、Hadoop 1.Hadoop的组成 1.1HDFS架构概述 1.2YARN架构概述 1.3MapReduce架构概述 二、Hadoop的搭建 1.运行环境 1.1安装JDK 1.2安装Hadoop 2.伪分布式运行模式 2.1配置文件说明 2.2启动HDFS并运行MapReduce程序 2.3启动YARN并运行MapReduce程序 2.4配置历史服务器 2.5配置日志的聚集 3.完全分布式运行模式 3.1虚拟机准备 3.2编写集群分发脚本 3.3集群配置 集群启动/停止方式总结 一、Hadoop 1.Hadoop的组成 简单了解一下Hadoop2.x时代的组成： HDFS 负责数据存储 Yarn 负责资源调度 MapReduce 负责计算 Common 辅助工具 1.1HDFS架构概述 HDFS(Hadoop Distributed File System) （1）NameNode (nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和块所在的DataNode等。 （2）DataNode (dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 （3）Secondary NameNode (2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 1.2YARN架构概述 ResourceManager（RM）主要作用如下： （1）处理客户端请求 （2）监控NodeManager （3）启动或监控ApplicationMaster （4）资源的分配与调度 NodeManger（NM）主要作用如下： （1）管理单个节点上的资源 （2）处理来自ResourceManager的命令 （3）处理来自ApplicationMaster的命令 ApplicationMaster（AM）作用如下： （1）负责数据的切分 （2）为应用程序申请资源并分配给内部的任务。 （3）任务的监控与容错。 Container Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。 1.3MapReduce架构概述 MapReduce 将计算过程分为两个阶段：Map和Reduce： （1）Map阶段并行处理输入数据。 （2）Reduce阶段对Map结果进行汇总 二、Hadoop的搭建 1.运行环境 前期准备这一部分看需求进行配置 修改 vim /etc/udev/rules.d/70-persistent-net.rules , 拷贝mac地址 修改 vim /etc/sysconfig/network-scripts/ifcfg-eth0 , 修改mac地址以及IP地址 修改 vim /etc/sysconfig/network 修改主机名 修改 vim /etc/hosts ,配置 IP与主机名的映射. 修改主机名 vim /etc/sysconfig/network 配置IP与主机名的映射： vim /etc/hosts 添加如下内容： 192.168.17.101 hadoop101 192.168.17.102 hadoop102 192.168.17.103 hadoop103 192.168.17.104 hadoop104 关闭防火墙 查看防火墙状态： service iptables status 临时关闭防火墙： service iptables stop 开机时关闭防火墙： chkconfig iptables off 创建Linux用户 这里添加了名为 fseast 的新用户： useradd fseast passwd fseast 配置Linux用户具有root权限 对/etc/sudoers文件添加： fseast ALL=(ALL) NOPASSWD:ALL 接下来的操作都将使用fseast用户操作 创建文件夹 在/opt下创建 software 和 module 两个目录，一个存放软件包，一个放解压后的文件。（使用fseast用户创建要使用sudo） 改变这两个目录所有者： chown fseast:fseast 目录 关闭图形化界面： 修改 /etc/inittab id:3:initdefault: 1.1安装JDK 这里使用的Linux版本是Centos6.8， JDK版本是1.8， Hadoop版本是2.7.2 安装JDK 先把软件包上传到software 目录 解压： tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/ 配置环境变量： 在/etc/profile文件加上： #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 export PATH=$PATH:$JAVA_HOME/bin 使其生效： source /etc/profile 测试jdk是否安装成功： java -version 1.2安装Hadoop Hadoop下载地址： https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/ 上传安装包到software，解压： tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/ 解压后查看目录结构： （1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本 （2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件 （3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能） （4）sbin目录：存放启动或停止Hadoop相关服务的脚本 （5）share目录：存放Hadoop的依赖jar包、文档、和官方案例 将Hadoop添加到环境变量： 在/etc/profile文件添加： export HADOOP_HOME=/opt/module/hadoop-2.7.2 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 使其生效： source /etc/profile 测试是否安装成功： hadoop version 2.伪分布式运行模式 2.1配置文件说明 Hadoop配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。 （1）默认配置文件： （2）自定义配置文件: core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。 2.2启动HDFS并运行MapReduce程序 (1). 修改配置文件： 进入/opt/module/hadoop-2.7.2/etc/hadoop 目录 （a）配置：hadoop-env.sh 修改改配置文件的JAVA_HOME路径（其实单台节点不配JAVA_HOME也可以读的到该变量）： export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置：core-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; （c）配置：hdfs-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; (2). 启动集群 （a）格式化NameNode（第一次启动时格式化，以后就不要总格式化，原因下面说） bin/hdfs namenode -format （b）启动NameNode hadoop-daemon.sh start namenode （c）启动DataNode hadoop-daemon.sh start datanode (3). 查看集群 （a）查看是否启动成功 [fseast@hadoop101 hadoop-2.7.2]$ jps 5203 DataNode 5353 Jps 5102 NameNode （b）web端查看HDFS文件系统 http://hadoop101:50070/ 使用hadoop101的话需要配置Windows的hosts文件。 成功进入： （c）查看产生的Log日志 要习惯根据日志提示信息去分析问题、解决Bug。 这里日志文件目录为：/opt/module/hadoop-2.7.2/logs (4). 操作集群： （a）在HDFS文件系统上创建一个input文件夹 hdfs dfs -mkdir -p /user/fseast/input （b）将测试文件内容上传到文件系统上 先在本地创建一个文件wc.input，并写入一些单词，然后上传到文件系统上： hdfs dfs -put wc.input /user/fseast/input （c）运行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input/ /user/fseast/output 这个 /user/fseast/output目录不用提前在HDFS创建。 （d）查看输出结果 hdfs dfs -cat /user/fseast/output/* 浏览器查看： 【为什么不能重复格式化NameNode？】 Hadoop的NameNode和DataNode有对应的clusterID，NameNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/VERSION文件中，DataNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/VERSION文件中，正常情况下这NameNode和DataNode的cID要一致。当重复格式化NameNode的时候，会导致NameNode的clusterID与DataNode的clusterID不一致。启动的时候便会出现问题。 所以，以后一定要格式化的时候，先关闭进程，删除/opt/module/hadoop-2.7.2下的data和logs这两个目录。 我截了NameNode的clusterID与DataNode的clusterID： 2.3启动YARN并运行MapReduce程序 （1）配置集群 （a）配置yarn-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置yarn-site.xml &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop101&lt;/value&gt; &lt;/property&gt; （c）配置：mapred-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （d）配置： (对mapred-site.xml.template复制一份并重新命名为) mapred-site.xml &lt;!-- 指定MR运行在YARN上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 切记上面的配置都要在 &lt;configuration&gt;&lt;/configuration&gt; 内 （2）启动集群 （a）启动前必须保证NameNode和DataNode已经启动 （b）启动ResourceManager yarn-daemon.sh start resourcemanager （c）启动NodeManager yarn-daemon.sh start nodemanager 截图： （3）集群操作 （a）YARN的浏览器页面查看：http://hadoop101:8088 如图所示： （b）删除文件系统上的output文件 hdfs dfs -rm -R /user/fseast/output （c）执行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 执行MapReduce程序的时候，如果你一直刷新页面，就可以看的到变化： 2.4配置历史服务器 为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下： 配置mapred-site.xml: &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop101:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop101:19888&lt;/value&gt; &lt;/property&gt; 启动历史服务器 mr-jobhistory-daemon.sh start historyserver 查看历史服务器是否启动： 查看JobHistory：http://hadoop101:19888/jobhistory 如图所示： 点击上方圈起来的位置： 再点击圈起来的地方： 他说没有开启聚集，那就开启一下日志的聚集： 2.5配置日志的聚集 配置yarn-site.xml: &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; 关闭NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh stop historyserver 启动NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh start resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh start nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh start historyserver 删除HDFS上已经存在的输出文件 hdfs dfs -rm -R /user/fseast/output 执行WordCount程序 [fseast@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 再按照上面，查看日志， 先进JobHistory，http://hadoop101:19888/jobhistory 3.完全分布式运行模式 3.1虚拟机准备 再准备三台虚拟机：hadoop102、hadoop103、hadoop104，修改主机名，IP地址，配置/etc/hosts文件， 3.2编写集群分发脚本 scp（secure copy）安全拷贝 把上面安装好的jdk和Hadoop发送到新建的三台虚拟机(记得先停掉hadoop的那些进程)： [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop102:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop103:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop104:/opt/ 改变传过去目录的所有者： [fseast@hadoop102 opt]$ sudo chown fseast:fseast -R module/ rsync 远程同步工具 rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。 实例： 把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录： [fseast@hadoop101 opt]$ sudo rsync -av /opt/software/ hadoop102:/opt/software 拷贝环境变量配置文件： [fseast@hadoop101 etc]$ sudo rsync -av /etc/profile hadoop102:/etc/profile 使环境变量生效：source /etc/profile 脚本实现： 目的：后面在hadoop102节点上修改了某些文件时，不需要一个个传到另外两个节点，启动 shell 脚本时加上参数即可： （a）在/home/fseast目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下： [fseast@hadoop102 ~]$ mkdir bin [fseast@hadoop102 ~]$ cd bin/ [fseast@hadoop102 bin]$ touch xsync [fseast@hadoop102 bin]$ vim xsync 在该文件中编写如下代码： #!/bin/bash #1 获取输入参数个数，如果没有参数，直接退出 pcount=$# if ((pcount==0)); then echo no args; exit; fi #2 获取文件名称 p1=$1 fname=`basename $p1` echo fname=$fname #3 获取上级目录到绝对路径 pdir=`cd -P $(dirname $p1); pwd` echo pdir=$pdir #4 获取当前用户名称 user=`whoami` #5 循环 for((host=103; host&lt;105; host++)); do echo ------------------- hadoop$host -------------- rsync -av $pdir/$fname $user@hadoop$host:$pdir done （b）修改脚本 xsync 具有执行权限 [fseast@hadoop102 bin]$ chmod 777 xsync （c）调用脚本形式：xsync 文件名称 如： 把/home/fseast/bin同步到其他两台节点： [fseast@hadoop102 bin]$ xsync /home/fseast/bin 注意：如果将xsync放到/home/fseast/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。出现不能使用的情况，大多是全局变量PATH没有/home/fseast/bin路径。 3.3集群配置 以下的完全分布式配置是完整的配置，也就是默认没有配置伪分布式情况下的。 配置文件三个.env结尾的文件都只是配了 JAVA_HOME ，所以也可不配，只需要在/home/fseast/.bashrc文件中加上 source /etc/profile NameNode，ResourceManager，SecondaryNameNode三个节点比较耗资源，最好不要放在同一台机器。 集群部署规划 SSH免密登录配置 (1) 生成公钥和私钥： [fseast@hadoop102 ~]$ ssh-keygen -t rsa 然后按三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥） (2) 将公钥拷贝到要免密登录的目标机器上 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop102 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop103 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop104 在hadoop103也要做相同操作，这里hadoop104可以操作也可以不做。 配置集群 配置集群的文件在hadoop102节点配置，配置完后再使用上面的脚本同步就好。 这里是按照没有配伪分布式情况下的配置文件，在前面配过伪分布式那么有些配过了那就不需要重复配了。 所用需要配置的文件都在目录： /opt/module/hadoop-2.7.2/etc/hadoop/slaves （1）核心配置文件 配置core-site.xml（伪分布式配过，只需要修改NameNode的节点名即可。）： &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop102:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; （2）HDFS配置文件 配置hadoop-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置hdfs-site.xml（副本数量伪分布式配过，不过需要修改）： &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt; &lt;/property&gt; （3）YARN配置文件 配置yarn-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置yarn-site.xml（伪分布式配过，需要修改ResourceManager的地址，前面配的日志聚集也可保留）： &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt; &lt;/property&gt; （4）MapReduce配置文件 配置mapred-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置mapred-site.xml（伪分布配过，没配过的需要复制mapred-site.xml.template文件并改名为mapred-site.xml再配置）： &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop102:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop102:19888&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定MR运行在Yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; （5）配置slaves（没有配过）： 为了群起集群的时候，知道哪台节点是从节点 hadoop102 hadoop103 hadoop104 在集群上分发配置好的Hadoop配置文件 [fseast@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/ 群起集群 （1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） hdfs namenode -format （2）启动HDFS 在hadoop102（NameNode）执行： start-dfs.sh （3）启动YARN 在hadoop103（ResourceManager）执行： start-yarn.sh （4）Web端查看SecondaryNameNode： http://hadoop104:50090 集群启动/停止方式总结 各个服务组件逐一启动/停止 （1）分别启动/停止HDFS组件 hadoop-daemon.sh start / stop namenode / datanode / secondarynamenode hadoop-daemon.sh start / stop datanode hadoop-daemon.sh start / stop secondarynamenode （2）启动/停止YARN yarn-daemon.sh start / stop resourcemanager yarn-daemon.sh start / stop nodemanager 各个模块分开启动/停止（配置ssh是前提） （1）整体启动/停止HDFS start-dfs.sh / stop-dfs.sh （2）整体启动/停止YARN start-yarn.sh / stop-yarn.sh 下一篇：阿里云服务器上的Hadoop伪分布式和完全分布式的搭建" />
<link rel="canonical" href="https://uzzz.org/2019/08/22/794188.html" />
<meta property="og:url" content="https://uzzz.org/2019/08/22/794188.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-22T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 一、Hadoop 1.Hadoop的组成 1.1HDFS架构概述 1.2YARN架构概述 1.3MapReduce架构概述 二、Hadoop的搭建 1.运行环境 1.1安装JDK 1.2安装Hadoop 2.伪分布式运行模式 2.1配置文件说明 2.2启动HDFS并运行MapReduce程序 2.3启动YARN并运行MapReduce程序 2.4配置历史服务器 2.5配置日志的聚集 3.完全分布式运行模式 3.1虚拟机准备 3.2编写集群分发脚本 3.3集群配置 集群启动/停止方式总结 一、Hadoop 1.Hadoop的组成 简单了解一下Hadoop2.x时代的组成： HDFS 负责数据存储 Yarn 负责资源调度 MapReduce 负责计算 Common 辅助工具 1.1HDFS架构概述 HDFS(Hadoop Distributed File System) （1）NameNode (nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和块所在的DataNode等。 （2）DataNode (dn)：在本地文件系统存储文件块数据，以及块数据的校验和。 （3）Secondary NameNode (2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 1.2YARN架构概述 ResourceManager（RM）主要作用如下： （1）处理客户端请求 （2）监控NodeManager （3）启动或监控ApplicationMaster （4）资源的分配与调度 NodeManger（NM）主要作用如下： （1）管理单个节点上的资源 （2）处理来自ResourceManager的命令 （3）处理来自ApplicationMaster的命令 ApplicationMaster（AM）作用如下： （1）负责数据的切分 （2）为应用程序申请资源并分配给内部的任务。 （3）任务的监控与容错。 Container Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。 1.3MapReduce架构概述 MapReduce 将计算过程分为两个阶段：Map和Reduce： （1）Map阶段并行处理输入数据。 （2）Reduce阶段对Map结果进行汇总 二、Hadoop的搭建 1.运行环境 前期准备这一部分看需求进行配置 修改 vim /etc/udev/rules.d/70-persistent-net.rules , 拷贝mac地址 修改 vim /etc/sysconfig/network-scripts/ifcfg-eth0 , 修改mac地址以及IP地址 修改 vim /etc/sysconfig/network 修改主机名 修改 vim /etc/hosts ,配置 IP与主机名的映射. 修改主机名 vim /etc/sysconfig/network 配置IP与主机名的映射： vim /etc/hosts 添加如下内容： 192.168.17.101 hadoop101 192.168.17.102 hadoop102 192.168.17.103 hadoop103 192.168.17.104 hadoop104 关闭防火墙 查看防火墙状态： service iptables status 临时关闭防火墙： service iptables stop 开机时关闭防火墙： chkconfig iptables off 创建Linux用户 这里添加了名为 fseast 的新用户： useradd fseast passwd fseast 配置Linux用户具有root权限 对/etc/sudoers文件添加： fseast ALL=(ALL) NOPASSWD:ALL 接下来的操作都将使用fseast用户操作 创建文件夹 在/opt下创建 software 和 module 两个目录，一个存放软件包，一个放解压后的文件。（使用fseast用户创建要使用sudo） 改变这两个目录所有者： chown fseast:fseast 目录 关闭图形化界面： 修改 /etc/inittab id:3:initdefault: 1.1安装JDK 这里使用的Linux版本是Centos6.8， JDK版本是1.8， Hadoop版本是2.7.2 安装JDK 先把软件包上传到software 目录 解压： tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/ 配置环境变量： 在/etc/profile文件加上： #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 export PATH=$PATH:$JAVA_HOME/bin 使其生效： source /etc/profile 测试jdk是否安装成功： java -version 1.2安装Hadoop Hadoop下载地址： https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/ 上传安装包到software，解压： tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/ 解压后查看目录结构： （1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本 （2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件 （3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能） （4）sbin目录：存放启动或停止Hadoop相关服务的脚本 （5）share目录：存放Hadoop的依赖jar包、文档、和官方案例 将Hadoop添加到环境变量： 在/etc/profile文件添加： export HADOOP_HOME=/opt/module/hadoop-2.7.2 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 使其生效： source /etc/profile 测试是否安装成功： hadoop version 2.伪分布式运行模式 2.1配置文件说明 Hadoop配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。 （1）默认配置文件： （2）自定义配置文件: core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。 2.2启动HDFS并运行MapReduce程序 (1). 修改配置文件： 进入/opt/module/hadoop-2.7.2/etc/hadoop 目录 （a）配置：hadoop-env.sh 修改改配置文件的JAVA_HOME路径（其实单台节点不配JAVA_HOME也可以读的到该变量）： export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置：core-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; （c）配置：hdfs-site.xml &lt;configuration&gt; &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; (2). 启动集群 （a）格式化NameNode（第一次启动时格式化，以后就不要总格式化，原因下面说） bin/hdfs namenode -format （b）启动NameNode hadoop-daemon.sh start namenode （c）启动DataNode hadoop-daemon.sh start datanode (3). 查看集群 （a）查看是否启动成功 [fseast@hadoop101 hadoop-2.7.2]$ jps 5203 DataNode 5353 Jps 5102 NameNode （b）web端查看HDFS文件系统 http://hadoop101:50070/ 使用hadoop101的话需要配置Windows的hosts文件。 成功进入： （c）查看产生的Log日志 要习惯根据日志提示信息去分析问题、解决Bug。 这里日志文件目录为：/opt/module/hadoop-2.7.2/logs (4). 操作集群： （a）在HDFS文件系统上创建一个input文件夹 hdfs dfs -mkdir -p /user/fseast/input （b）将测试文件内容上传到文件系统上 先在本地创建一个文件wc.input，并写入一些单词，然后上传到文件系统上： hdfs dfs -put wc.input /user/fseast/input （c）运行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input/ /user/fseast/output 这个 /user/fseast/output目录不用提前在HDFS创建。 （d）查看输出结果 hdfs dfs -cat /user/fseast/output/* 浏览器查看： 【为什么不能重复格式化NameNode？】 Hadoop的NameNode和DataNode有对应的clusterID，NameNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/VERSION文件中，DataNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/VERSION文件中，正常情况下这NameNode和DataNode的cID要一致。当重复格式化NameNode的时候，会导致NameNode的clusterID与DataNode的clusterID不一致。启动的时候便会出现问题。 所以，以后一定要格式化的时候，先关闭进程，删除/opt/module/hadoop-2.7.2下的data和logs这两个目录。 我截了NameNode的clusterID与DataNode的clusterID： 2.3启动YARN并运行MapReduce程序 （1）配置集群 （a）配置yarn-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （b）配置yarn-site.xml &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop101&lt;/value&gt; &lt;/property&gt; （c）配置：mapred-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144 （d）配置： (对mapred-site.xml.template复制一份并重新命名为) mapred-site.xml &lt;!-- 指定MR运行在YARN上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 切记上面的配置都要在 &lt;configuration&gt;&lt;/configuration&gt; 内 （2）启动集群 （a）启动前必须保证NameNode和DataNode已经启动 （b）启动ResourceManager yarn-daemon.sh start resourcemanager （c）启动NodeManager yarn-daemon.sh start nodemanager 截图： （3）集群操作 （a）YARN的浏览器页面查看：http://hadoop101:8088 如图所示： （b）删除文件系统上的output文件 hdfs dfs -rm -R /user/fseast/output （c）执行MapReduce程序 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 执行MapReduce程序的时候，如果你一直刷新页面，就可以看的到变化： 2.4配置历史服务器 为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下： 配置mapred-site.xml: &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop101:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop101:19888&lt;/value&gt; &lt;/property&gt; 启动历史服务器 mr-jobhistory-daemon.sh start historyserver 查看历史服务器是否启动： 查看JobHistory：http://hadoop101:19888/jobhistory 如图所示： 点击上方圈起来的位置： 再点击圈起来的地方： 他说没有开启聚集，那就开启一下日志的聚集： 2.5配置日志的聚集 配置yarn-site.xml: &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; 关闭NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh stop nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh stop historyserver 启动NodeManager 、ResourceManager和HistoryServer [fseast@hadoop101 hadoop]$ yarn-daemon.sh start resourcemanager [fseast@hadoop101 hadoop]$ yarn-daemon.sh start nodemanager [fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh start historyserver 删除HDFS上已经存在的输出文件 hdfs dfs -rm -R /user/fseast/output 执行WordCount程序 [fseast@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output 再按照上面，查看日志， 先进JobHistory，http://hadoop101:19888/jobhistory 3.完全分布式运行模式 3.1虚拟机准备 再准备三台虚拟机：hadoop102、hadoop103、hadoop104，修改主机名，IP地址，配置/etc/hosts文件， 3.2编写集群分发脚本 scp（secure copy）安全拷贝 把上面安装好的jdk和Hadoop发送到新建的三台虚拟机(记得先停掉hadoop的那些进程)： [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop102:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop103:/opt/ [fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop104:/opt/ 改变传过去目录的所有者： [fseast@hadoop102 opt]$ sudo chown fseast:fseast -R module/ rsync 远程同步工具 rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。 实例： 把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录： [fseast@hadoop101 opt]$ sudo rsync -av /opt/software/ hadoop102:/opt/software 拷贝环境变量配置文件： [fseast@hadoop101 etc]$ sudo rsync -av /etc/profile hadoop102:/etc/profile 使环境变量生效：source /etc/profile 脚本实现： 目的：后面在hadoop102节点上修改了某些文件时，不需要一个个传到另外两个节点，启动 shell 脚本时加上参数即可： （a）在/home/fseast目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下： [fseast@hadoop102 ~]$ mkdir bin [fseast@hadoop102 ~]$ cd bin/ [fseast@hadoop102 bin]$ touch xsync [fseast@hadoop102 bin]$ vim xsync 在该文件中编写如下代码： #!/bin/bash #1 获取输入参数个数，如果没有参数，直接退出 pcount=$# if ((pcount==0)); then echo no args; exit; fi #2 获取文件名称 p1=$1 fname=`basename $p1` echo fname=$fname #3 获取上级目录到绝对路径 pdir=`cd -P $(dirname $p1); pwd` echo pdir=$pdir #4 获取当前用户名称 user=`whoami` #5 循环 for((host=103; host&lt;105; host++)); do echo ------------------- hadoop$host -------------- rsync -av $pdir/$fname $user@hadoop$host:$pdir done （b）修改脚本 xsync 具有执行权限 [fseast@hadoop102 bin]$ chmod 777 xsync （c）调用脚本形式：xsync 文件名称 如： 把/home/fseast/bin同步到其他两台节点： [fseast@hadoop102 bin]$ xsync /home/fseast/bin 注意：如果将xsync放到/home/fseast/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。出现不能使用的情况，大多是全局变量PATH没有/home/fseast/bin路径。 3.3集群配置 以下的完全分布式配置是完整的配置，也就是默认没有配置伪分布式情况下的。 配置文件三个.env结尾的文件都只是配了 JAVA_HOME ，所以也可不配，只需要在/home/fseast/.bashrc文件中加上 source /etc/profile NameNode，ResourceManager，SecondaryNameNode三个节点比较耗资源，最好不要放在同一台机器。 集群部署规划 SSH免密登录配置 (1) 生成公钥和私钥： [fseast@hadoop102 ~]$ ssh-keygen -t rsa 然后按三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥） (2) 将公钥拷贝到要免密登录的目标机器上 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop102 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop103 [fseast@hadoop102 .ssh]$ ssh-copy-id hadoop104 在hadoop103也要做相同操作，这里hadoop104可以操作也可以不做。 配置集群 配置集群的文件在hadoop102节点配置，配置完后再使用上面的脚本同步就好。 这里是按照没有配伪分布式情况下的配置文件，在前面配过伪分布式那么有些配过了那就不需要重复配了。 所用需要配置的文件都在目录： /opt/module/hadoop-2.7.2/etc/hadoop/slaves （1）核心配置文件 配置core-site.xml（伪分布式配过，只需要修改NameNode的节点名即可。）： &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop102:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt; （2）HDFS配置文件 配置hadoop-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置hdfs-site.xml（副本数量伪分布式配过，不过需要修改）： &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt; &lt;/property&gt; （3）YARN配置文件 配置yarn-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置yarn-site.xml（伪分布式配过，需要修改ResourceManager的地址，前面配的日志聚集也可保留）： &lt;!-- 日志聚集功能使能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保留时间设置7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt; &lt;/property&gt; &lt;!-- Reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt; &lt;/property&gt; （4）MapReduce配置文件 配置mapred-env.sh（伪分布式配过）： export JAVA_HOME=/opt/module/jdk1.8.0_144 配置mapred-site.xml（伪分布配过，没配过的需要复制mapred-site.xml.template文件并改名为mapred-site.xml再配置）： &lt;!-- 历史服务器端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop102:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop102:19888&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定MR运行在Yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; （5）配置slaves（没有配过）： 为了群起集群的时候，知道哪台节点是从节点 hadoop102 hadoop103 hadoop104 在集群上分发配置好的Hadoop配置文件 [fseast@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/ 群起集群 （1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） hdfs namenode -format （2）启动HDFS 在hadoop102（NameNode）执行： start-dfs.sh （3）启动YARN 在hadoop103（ResourceManager）执行： start-yarn.sh （4）Web端查看SecondaryNameNode： http://hadoop104:50090 集群启动/停止方式总结 各个服务组件逐一启动/停止 （1）分别启动/停止HDFS组件 hadoop-daemon.sh start / stop namenode / datanode / secondarynamenode hadoop-daemon.sh start / stop datanode hadoop-daemon.sh start / stop secondarynamenode （2）启动/停止YARN yarn-daemon.sh start / stop resourcemanager yarn-daemon.sh start / stop nodemanager 各个模块分开启动/停止（配置ssh是前提） （1）整体启动/停止HDFS start-dfs.sh / stop-dfs.sh （2）整体启动/停止YARN start-yarn.sh / stop-yarn.sh 下一篇：阿里云服务器上的Hadoop伪分布式和完全分布式的搭建","@type":"BlogPosting","url":"https://uzzz.org/2019/08/22/794188.html","headline":"虚拟机上的Hadoop伪分布式和完全分布式的搭建","dateModified":"2019-08-22T00:00:00+08:00","datePublished":"2019-08-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzzz.org/2019/08/22/794188.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>虚拟机上的Hadoop伪分布式和完全分布式的搭建</h1>
        
        
        <ul style="display: block;">
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
 	    <li><a href="/donate/" style="line-height: unset;" target="_blank"><strong>Donate</strong></a></li>
        </ul>
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
<!-- match content ads -->
	        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
			<ins class="adsbygoogle"
			     style="display:block"
			     data-ad-format="autorelaxed"
			     data-ad-client="ca-pub-8889449066804352"
			     data-ad-slot="1928667997"></ins>
			<script>
			     (adsbygoogle = window.adsbygoogle || []).push({});
			</script>	



        <div id="article_content" class="article_content clearfix">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p></p>
  <div class="toc">
   <h3>目录</h3>
   <ul>
    <ul>
     <li><a href="#Hadoop_2" rel="nofollow" data-token="a77d80c385579369bd5998ea9671ad9c">一、Hadoop</a></li>
     <ul>
      <li><a href="#1Hadoop_3" rel="nofollow" data-token="ead225a59cbdabc3716bb2db60a6486f">1.Hadoop的组成</a></li>
      <ul>
       <li><a href="#11HDFS_9" rel="nofollow" data-token="79253706c7b77996ec32bc995488892e">1.1HDFS架构概述</a></li>
       <li><a href="#12YARN_15" rel="nofollow" data-token="1740b2cb7291791d7d7c8587d3434f61">1.2YARN架构概述</a></li>
       <li><a href="#13MapReduce_34" rel="nofollow" data-token="714464586ecdb259209149262a015808">1.3MapReduce架构概述</a></li>
      </ul>
     </ul>
     <li><a href="#Hadoop_38" rel="nofollow" data-token="7db49e137c35c3a4f0964d63a7fea54d">二、Hadoop的搭建</a></li>
     <ul>
      <li><a href="#1_40" rel="nofollow" data-token="e06c6f0849fc6cd985f7021ab0b3d04c">1.运行环境</a></li>
      <ul>
       <li><a href="#11JDK_112" rel="nofollow" data-token="b181cb0d75cefbab0fcb16fb025556b5">1.1安装JDK</a></li>
       <li><a href="#12Hadoop_142" rel="nofollow" data-token="0df660a6407da846b5deb7861356e328">1.2安装Hadoop</a></li>
      </ul>
      <li><a href="#2_172" rel="nofollow" data-token="97dd54c3e00097e8b2717c39e2203849">2.伪分布式运行模式</a></li>
      <ul>
       <li><a href="#21_173" rel="nofollow" data-token="8c996b027a5aac8192acc3b1defccfb7">2.1配置文件说明</a></li>
       <li><a href="#22HDFSMapReduce_181" rel="nofollow" data-token="0787c7a06fec082fff6cdb90000dcf2d">2.2启动HDFS并运行MapReduce程序</a></li>
       <li><a href="#23YARNMapReduce_274" rel="nofollow" data-token="ac47ba1c79d429460d1d6f2f565e98dd">2.3启动YARN并运行MapReduce程序</a></li>
       <li><a href="#24_341" rel="nofollow" data-token="a037e749af93a06ec9722862d7cb8c0f">2.4配置历史服务器</a></li>
       <li><a href="#25_371" rel="nofollow" data-token="ef41f8a256ac18bf2286b4d3e703714f">2.5配置日志的聚集</a></li>
      </ul>
      <li><a href="#3_415" rel="nofollow" data-token="6f8512f098c36b952f811a44e18d0e9f">3.完全分布式运行模式</a></li>
      <ul>
       <li><a href="#31_416" rel="nofollow" data-token="5e477f6aaa5e1888faab105d14d99ac3">3.1虚拟机准备</a></li>
       <li><a href="#32_419" rel="nofollow" data-token="04ab90fb1cd0d511da8c94b70cb52b39">3.2编写集群分发脚本</a></li>
       <li><a href="#33_509" rel="nofollow" data-token="c1b20c680a750e04260612e00bf51725">3.3集群配置</a></li>
       <ul>
        <li><a href="#_684" rel="nofollow" data-token="6e74ad9570ba102304aa614c72a25abb">集群启动/停止方式总结</a></li>
       </ul>
      </ul>
     </ul>
    </ul>
   </ul>
  </div>
  <p></p> 
  <h2><a id="Hadoop_2"></a>一、Hadoop</h2> 
  <h3><a id="1Hadoop_3"></a>1.Hadoop的组成</h3> 
  <p>简单了解一下Hadoop2.x时代的组成：<br> HDFS 负责数据存储<br> Yarn 负责资源调度<br> MapReduce 负责计算<br> Common 辅助工具</p> 
  <h4><a id="11HDFS_9"></a>1.1HDFS架构概述</h4> 
  <p>HDFS(Hadoop Distributed File System)<br> （1）NameNode (nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和块所在的DataNode等。<br> （2）DataNode (dn)：在本地文件系统存储文件块数据，以及块数据的校验和。<br> （3）Secondary NameNode (2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p> 
  <h4><a id="12YARN_15"></a>1.2YARN架构概述</h4> 
  <ol> 
   <li>ResourceManager（RM）主要作用如下：<br> （1）处理客户端请求<br> （2）监控NodeManager<br> （3）启动或监控ApplicationMaster<br> （4）资源的分配与调度</li> 
   <li>NodeManger（NM）主要作用如下：<br> （1）管理单个节点上的资源<br> （2）处理来自ResourceManager的命令<br> （3）处理来自ApplicationMaster的命令</li> 
   <li>ApplicationMaster（AM）作用如下：<br> （1）负责数据的切分<br> （2）为应用程序申请资源并分配给内部的任务。<br> （3）任务的监控与容错。</li> 
   <li>Container<br> Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190822152546302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li> 
  </ol> 
  <h4><a id="13MapReduce_34"></a>1.3MapReduce架构概述</h4> 
  <p>MapReduce 将计算过程分为两个阶段：Map和Reduce：<br> （1）Map阶段并行处理输入数据。<br> （2）Reduce阶段对Map结果进行汇总</p> 
  <h2><a id="Hadoop_38"></a>二、Hadoop的搭建</h2> 
  <h3><a id="1_40"></a>1.运行环境</h3> 
  <p>前期准备这一部分看需求进行配置</p> 
  <pre><code>   修改 vim /etc/udev/rules.d/70-persistent-net.rules , 拷贝mac地址
   修改 vim /etc/sysconfig/network-scripts/ifcfg-eth0 , 修改mac地址以及IP地址
   修改 vim /etc/sysconfig/network  修改主机名
   修改 vim /etc/hosts ,配置 IP与主机名的映射.
</code></pre> 
  <ol> 
   <li>修改主机名</li> 
  </ol> 
  <pre><code> vim /etc/sysconfig/network
</code></pre> 
  <p>配置IP与主机名的映射：</p> 
  <pre><code>vim /etc/hosts
</code></pre> 
  <p>添加如下内容：</p> 
  <pre><code>192.168.17.101 hadoop101
192.168.17.102 hadoop102
192.168.17.103 hadoop103
192.168.17.104 hadoop104
</code></pre> 
  <ol start="2"> 
   <li>关闭防火墙<br> 查看防火墙状态：</li> 
  </ol> 
  <pre><code>service iptables status
</code></pre> 
  <p>临时关闭防火墙：</p> 
  <pre><code>service iptables stop
</code></pre> 
  <p>开机时关闭防火墙：</p> 
  <pre><code>chkconfig iptables off
</code></pre> 
  <ol start="3"> 
   <li>创建Linux用户<br> 这里添加了名为 fseast 的新用户：</li> 
  </ol> 
  <pre><code>useradd fseast
passwd fseast
</code></pre> 
  <ol start="4"> 
   <li>配置Linux用户具有root权限<br> 对/etc/sudoers文件添加：</li> 
  </ol> 
  <pre><code>fseast ALL=(ALL)       NOPASSWD:ALL
</code></pre> 
  <p>接下来的操作都将使用fseast用户操作</p> 
  <ol start="5"> 
   <li>创建文件夹<br> 在/opt下创建 software 和 module 两个目录，一个存放软件包，一个放解压后的文件。（使用fseast用户创建要使用sudo）<br> 改变这两个目录所有者：</li> 
  </ol> 
  <pre><code> chown fseast:fseast 目录
</code></pre> 
  <p>关闭图形化界面：<br> 修改 /etc/inittab</p> 
  <pre><code>id:3:initdefault:
</code></pre> 
  <h4><a id="11JDK_112"></a>1.1安装JDK</h4> 
  <p>这里使用的Linux版本是Centos6.8，<br> JDK版本是1.8，<br> Hadoop版本是2.7.2</p> 
  <ol> 
   <li>安装JDK<br> 先把软件包上传到software 目录<br> 解压：</li> 
  </ol> 
  <pre><code>tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/
</code></pre> 
  <p>配置环境变量：<br> 在/etc/profile文件加上：</p> 
  <pre><code>#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_144
export PATH=$PATH:$JAVA_HOME/bin

</code></pre> 
  <p>使其生效：</p> 
  <pre><code>source /etc/profile
</code></pre> 
  <p>测试jdk是否安装成功：</p> 
  <pre><code>java -version
</code></pre> 
  <h4><a id="12Hadoop_142"></a>1.2安装Hadoop</h4> 
  <p>Hadoop下载地址：<br> https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</p> 
  <ol> 
   <li>上传安装包到software，解压：</li> 
  </ol> 
  <pre><code>tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/
</code></pre> 
  <p>解压后查看目录结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716190919341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> （1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本<br> （2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件<br> （3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）<br> （4）sbin目录：存放启动或停止Hadoop相关服务的脚本<br> （5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p> 
  <ol start="2"> 
   <li>将Hadoop添加到环境变量：<br> 在/etc/profile文件添加：</li> 
  </ol> 
  <pre><code>export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
</code></pre> 
  <p>使其生效：</p> 
  <pre><code>source /etc/profile
</code></pre> 
  <p>测试是否安装成功：</p> 
  <pre><code> hadoop version
</code></pre> 
  <h3><a id="2_172"></a>2.伪分布式运行模式</h3> 
  <h4><a id="21_173"></a>2.1配置文件说明</h4> 
  <p>Hadoop配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。<br> （1）默认配置文件：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190720204355548.png" alt="在这里插入图片描述"><br> （2）自定义配置文件:<br> core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p> 
  <h4><a id="22HDFSMapReduce_181"></a>2.2启动HDFS并运行MapReduce程序</h4> 
  <p>(1). 修改配置文件：<br> 进入<code>/opt/module/hadoop-2.7.2/etc/hadoop</code> 目录<br> <font size="3" color="DeepSkyBlue">（a）配置：hadoop-env.sh</font><br> 修改改配置文件的JAVA_HOME路径（其实单台节点不配JAVA_HOME也可以读的到该变量）：</p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">（b）配置：core-site.xml</font></p> 
  <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop101:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/opt/module/hadoop-2.7.2/data/tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">（c）配置：hdfs-site.xml</font></p> 
  <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>(2). 启动集群<br> （a）格式化NameNode（第一次启动时格式化，以后就不要总格式化，原因下面说）</p> 
  <pre><code>bin/hdfs namenode -format
</code></pre> 
  <p>（b）启动NameNode</p> 
  <pre><code>hadoop-daemon.sh start namenode
</code></pre> 
  <p>（c）启动DataNode</p> 
  <pre><code>hadoop-daemon.sh start datanode
</code></pre> 
  <p>(3). 查看集群<br> （a）查看是否启动成功</p> 
  <pre><code>[fseast@hadoop101 hadoop-2.7.2]$ jps
5203 DataNode
5353 Jps
5102 NameNode
</code></pre> 
  <p>（b）web端查看HDFS文件系统<br> http://hadoop101:50070/<br> 使用hadoop101的话需要配置Windows的hosts文件。<br> 成功进入：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716204830465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">（c）查看产生的Log日志<br> 要习惯根据日志提示信息去分析问题、解决Bug。<br> 这里日志文件目录为：/opt/module/hadoop-2.7.2/logs</p> 
  <p>(4). 操作集群：<br> （a）在HDFS文件系统上创建一个input文件夹</p> 
  <pre><code>hdfs dfs -mkdir -p /user/fseast/input
</code></pre> 
  <p>（b）将测试文件内容上传到文件系统上<br> 先在本地创建一个文件wc.input，并写入一些单词，然后上传到文件系统上：</p> 
  <pre><code>hdfs dfs -put wc.input /user/fseast/input
</code></pre> 
  <p>（c）运行MapReduce程序</p> 
  <pre><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input/ /user/fseast/output
</code></pre> 
  <p>这个 /user/fseast/output目录不用提前在HDFS创建。</p> 
  <p>（d）查看输出结果</p> 
  <pre><code>hdfs dfs -cat /user/fseast/output/*
</code></pre> 
  <p>浏览器查看：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716212843546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p><strong>【为什么不能重复格式化NameNode？】</strong><br> Hadoop的NameNode和DataNode有对应的clusterID，NameNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/VERSION文件中，DataNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/VERSION文件中，正常情况下这NameNode和DataNode的cID要一致。当重复格式化NameNode的时候，会导致NameNode的clusterID与DataNode的clusterID不一致。启动的时候便会出现问题。<br> 所以，以后一定要格式化的时候，先关闭进程，删除/opt/module/hadoop-2.7.2下的data和logs这两个目录。<br> 我截了NameNode的clusterID与DataNode的clusterID：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716203810635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190716204001540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h4><a id="23YARNMapReduce_274"></a>2.3启动YARN并运行MapReduce程序</h4> 
  <p>（1）配置集群<br> <font size="3" color="DeepSkyBlue">（a）配置yarn-env.sh</font></p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">（b）配置yarn-site.xml</font></p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- Reducer获取数据的方式 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
 		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
 		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop101<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p><font size="3" color="DeepSkyBlue">（c）配置：mapred-env.sh</font></p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">（d）配置： (对mapred-site.xml.template复制一份并重新命名为) mapred-site.xml</font></p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>切记上面的配置都要在 <code>&lt;configuration&gt;&lt;/configuration&gt;</code> 内</p> 
  <p>（2）启动集群<br> （a）启动前必须保证NameNode和DataNode已经启动<br> （b）启动ResourceManager</p> 
  <pre><code>yarn-daemon.sh start resourcemanager
</code></pre> 
  <p>（c）启动NodeManager</p> 
  <pre><code>yarn-daemon.sh start nodemanager
</code></pre> 
  <p>截图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717163826446.png" alt="在这里插入图片描述"><br> （3）集群操作<br> （a）YARN的浏览器页面查看：http://hadoop101:8088<br> 如图所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717164054991.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">（b）删除文件系统上的output文件</p> 
  <pre><code>hdfs dfs -rm -R /user/fseast/output
</code></pre> 
  <p>（c）执行MapReduce程序</p> 
  <pre><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output
</code></pre> 
  <p>执行MapReduce程序的时候，如果你一直刷新页面，就可以看的到变化：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717165519297.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717165554655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h4><a id="24_341"></a>2.4配置历史服务器</h4> 
  <p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p> 
  <ol> 
   <li><font size="3" color="DeepSkyBlue">配置mapred-site.xml:</font></li> 
  </ol> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 历史服务器端地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop101:10020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- 历史服务器web端地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop101:19888<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <ol start="2"> 
   <li>启动历史服务器</li> 
  </ol> 
  <pre><code>mr-jobhistory-daemon.sh start historyserver
</code></pre> 
  <ol start="3"> 
   <li> <p>查看历史服务器是否启动：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717181121553.png" alt="hadoop历史服务器"></p> </li> 
   <li> <p>查看JobHistory：http://hadoop101:19888/jobhistory<br> 如图所示：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717181700122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">点击上方圈起来的位置：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717181837376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">再点击圈起来的地方：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717181913114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">他说没有开启聚集，那就开启一下日志的聚集：</p> </li> 
  </ol> 
  <h4><a id="25_371"></a>2.5配置日志的聚集</h4> 
  <ol> 
   <li><font size="3" color="DeepSkyBlue">配置yarn-site.xml:</font></li> 
  </ol> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 日志聚集功能使能 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation-enable<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 日志保留时间设置7天 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation.retain-seconds<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>604800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <ol start="2"> 
   <li>关闭NodeManager 、ResourceManager和HistoryServer</li> 
  </ol> 
  <pre><code>[fseast@hadoop101 hadoop]$ yarn-daemon.sh stop resourcemanager
[fseast@hadoop101 hadoop]$ yarn-daemon.sh stop nodemanager
[fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh stop historyserver
</code></pre> 
  <ol start="3"> 
   <li>启动NodeManager 、ResourceManager和HistoryServer</li> 
  </ol> 
  <pre><code>[fseast@hadoop101 hadoop]$ yarn-daemon.sh start resourcemanager
[fseast@hadoop101 hadoop]$ yarn-daemon.sh start nodemanager
[fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh start historyserver
</code></pre> 
  <ol start="4"> 
   <li>删除HDFS上已经存在的输出文件</li> 
  </ol> 
  <pre><code>hdfs dfs -rm -R /user/fseast/output
</code></pre> 
  <ol start="5"> 
   <li>执行WordCount程序</li> 
  </ol> 
  <pre><code>[fseast@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output
</code></pre> 
  <p>再按照上面，查看日志，<br> 先进JobHistory，http://hadoop101:19888/jobhistory<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717183938407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717184001971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717184115874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717184200523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h3><a id="3_415"></a>3.完全分布式运行模式</h3> 
  <h4><a id="31_416"></a>3.1虚拟机准备</h4> 
  <p>再准备三台虚拟机：hadoop102、hadoop103、hadoop104，修改主机名，IP地址，配置/etc/hosts文件，</p> 
  <h4><a id="32_419"></a>3.2编写集群分发脚本</h4> 
  <ol> 
   <li>scp（secure copy）安全拷贝<br> 把上面安装好的jdk和Hadoop发送到新建的三台虚拟机(记得先停掉hadoop的那些进程)：</li> 
  </ol> 
  <pre><code>[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop102:/opt/
[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop103:/opt/
[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop104:/opt/
</code></pre> 
  <p>改变传过去目录的所有者：</p> 
  <pre><code>[fseast@hadoop102 opt]$ sudo chown fseast:fseast -R module/
</code></pre> 
  <ol start="2"> 
   <li>rsync 远程同步工具<br> rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br> rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</li> 
  </ol> 
  <p>实例：<br> 把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录：</p> 
  <pre><code>[fseast@hadoop101 opt]$ sudo rsync -av /opt/software/ hadoop102:/opt/software
</code></pre> 
  <p>拷贝环境变量配置文件：</p> 
  <pre><code>[fseast@hadoop101 etc]$ sudo rsync -av /etc/profile hadoop102:/etc/profile
</code></pre> 
  <p>使环境变量生效：<code>source /etc/profile</code></p> 
  <p><strong>脚本实现：</strong><br> 目的：后面在hadoop102节点上修改了某些文件时，不需要一个个传到另外两个节点，启动 shell 脚本时加上参数即可：<br> （a）在/home/fseast目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：</p> 
  <pre><code>[fseast@hadoop102 ~]$ mkdir bin
[fseast@hadoop102 ~]$ cd bin/
[fseast@hadoop102 bin]$ touch xsync
[fseast@hadoop102 bin]$ vim xsync
</code></pre> 
  <p>在该文件中编写如下代码：</p> 
  <pre><code class="prism language-shell"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment">#1 获取输入参数个数，如果没有参数，直接退出</span>
pcount<span class="token operator">=</span>$<span class="token comment">#</span>
<span class="token keyword">if</span> <span class="token variable"><span class="token punctuation">((</span>pcount<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">))</span></span><span class="token punctuation">;</span> <span class="token keyword">then</span>
<span class="token keyword">echo</span> no args<span class="token punctuation">;</span>
<span class="token keyword">exit</span><span class="token punctuation">;</span>
<span class="token keyword">fi</span>

<span class="token comment">#2 获取文件名称</span>
p1<span class="token operator">=</span><span class="token variable">$1</span>
fname<span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">basename</span> $p1<span class="token variable">`</span></span>
<span class="token keyword">echo</span> fname<span class="token operator">=</span><span class="token variable">$fname</span>

<span class="token comment">#3 获取上级目录到绝对路径</span>
pdir<span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">cd</span> -P <span class="token punctuation">$(</span>dirname $p1<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">pwd</span><span class="token variable">`</span></span>
<span class="token keyword">echo</span> pdir<span class="token operator">=</span><span class="token variable">$pdir</span>

<span class="token comment">#4 获取当前用户名称</span>
user<span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">whoami</span><span class="token variable">`</span></span>

<span class="token comment">#5 循环</span>
<span class="token keyword">for</span><span class="token variable"><span class="token punctuation">((</span>host<span class="token operator">=</span><span class="token number">103</span><span class="token punctuation">;</span> host<span class="token operator">&lt;</span><span class="token number">105</span><span class="token punctuation">;</span> host<span class="token operator">++</span><span class="token punctuation">))</span></span><span class="token punctuation">;</span> <span class="token keyword">do</span>
        <span class="token keyword">echo</span> ------------------- hadoop<span class="token variable">$host</span> --------------
        <span class="token function">rsync</span> -av <span class="token variable">$pdir</span>/<span class="token variable">$fname</span> <span class="token variable">$user@hadoop</span><span class="token variable">$host</span><span class="token keyword">:</span><span class="token variable">$pdir</span>
<span class="token keyword">done</span>

</code></pre> 
  <p>（b）修改脚本 xsync 具有执行权限</p> 
  <pre><code>[fseast@hadoop102 bin]$ chmod 777 xsync
</code></pre> 
  <p>（c）调用脚本形式：xsync 文件名称<br> 如：<br> 把/home/fseast/bin同步到其他两台节点：</p> 
  <pre><code>[fseast@hadoop102 bin]$ xsync /home/fseast/bin
</code></pre> 
  <p>注意：如果将xsync放到/home/fseast/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。出现不能使用的情况，大多是全局变量PATH没有/home/fseast/bin路径。</p> 
  <h4><a id="33_509"></a>3.3集群配置</h4> 
  <p><font size="3" color="Red">以下的完全分布式配置是完整的配置，也就是默认没有配置伪分布式情况下的。</font></p> 
  <table>
   <tbody>
    <tr align="left">
     <td bgcolor="#F0FFF0">配置文件三个.env结尾的文件都只是配了 JAVA_HOME ，所以也可不配，只需要在/home/fseast/.bashrc文件中加上 source /etc/profile</td>
    </tr>
   </tbody>
  </table> NameNode，ResourceManager，SecondaryNameNode三个节点比较耗资源，最好不要放在同一台机器。 
  <ol> 
   <li>集群部署规划<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717203826723.png" alt="在这里插入图片描述"></li> 
   <li>SSH免密登录配置<br> (1) 生成公钥和私钥：</li> 
  </ol> 
  <pre><code>[fseast@hadoop102 ~]$ ssh-keygen -t rsa
</code></pre> 
  <p>然后按三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p> 
  <p>(2) 将公钥拷贝到要免密登录的目标机器上</p> 
  <pre><code>[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop102
[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop103
[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop104

</code></pre> 
  <p>在hadoop103也要做相同操作，这里hadoop104可以操作也可以不做。</p> 
  <ol start="3"> 
   <li>配置集群<br> 配置集群的文件在hadoop102节点配置，配置完后再使用上面的脚本同步就好。<br> 这里是按照没有配伪分布式情况下的配置文件，在前面配过伪分布式那么有些配过了那就不需要重复配了。<br> 所用需要配置的文件都在目录：<br> /opt/module/hadoop-2.7.2/etc/hadoop/slaves</li> 
  </ol> 
  <p>（1）核心配置文件<br> <font size="3" color="DeepSkyBlue">配置core-site.xml</font>（伪分布式配过，只需要修改NameNode的节点名即可。）：</p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop102:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/opt/module/hadoop-2.7.2/data/tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>（2）HDFS配置文件<br> <font size="3" color="DeepSkyBlue">配置hadoop-env.sh</font>（伪分布式配过）：</p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">配置hdfs-site.xml</font>（副本数量伪分布式配过，不过需要修改）：</p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop104:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>（3）YARN配置文件<br> <font size="3" color="DeepSkyBlue">配置yarn-env.sh</font>（伪分布式配过）：</p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">配置yarn-site.xml</font>（伪分布式配过，需要修改ResourceManager的地址，前面配的日志聚集也可保留）：</p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 日志聚集功能使能 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation-enable<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 日志保留时间设置7天 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation.retain-seconds<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>604800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- Reducer获取数据的方式 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop103<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>（4）MapReduce配置文件<br> <font size="3" color="DeepSkyBlue">配置mapred-env.sh</font>（伪分布式配过）：</p> 
  <pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144
</code></pre> 
  <p><font size="3" color="DeepSkyBlue">配置mapred-site.xml</font>（伪分布配过，没配过的需要复制mapred-site.xml.template文件并改名为mapred-site.xml再配置）：</p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- 历史服务器端地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop102:10020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- 历史服务器web端地址 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop102:19888<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
  <p>（5）<font size="3" color="DeepSkyBlue">配置slaves</font>（没有配过）：<br> 为了群起集群的时候，知道哪台节点是从节点</p> 
  <pre><code>hadoop102
hadoop103
hadoop104
</code></pre> 
  <ol start="4"> 
   <li>在集群上分发配置好的Hadoop配置文件</li> 
  </ol> 
  <pre><code>[fseast@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/
</code></pre> 
  <ol start="5"> 
   <li>群起集群<br> （1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</li> 
  </ol> 
  <pre><code>hdfs namenode -format
</code></pre> 
  <p>（2）启动HDFS<br> 在hadoop102（NameNode）执行：</p> 
  <pre><code>start-dfs.sh
</code></pre> 
  <p>（3）启动YARN<br> 在hadoop103（ResourceManager）执行：</p> 
  <pre><code>start-yarn.sh
</code></pre> 
  <p>（4）Web端查看SecondaryNameNode：<br> http://hadoop104:50090</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190717225014645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h5><a id="_684"></a>集群启动/停止方式总结</h5> 
  <ol> 
   <li> <p>各个服务组件逐一启动/停止<br> （1）分别启动/停止HDFS组件<br> hadoop-daemon.sh start / stop namenode / datanode / secondarynamenode<br> hadoop-daemon.sh start / stop datanode<br> hadoop-daemon.sh start / stop secondarynamenode<br> （2）启动/停止YARN<br> yarn-daemon.sh start / stop resourcemanager<br> yarn-daemon.sh start / stop nodemanager</p> </li> 
   <li> <p>各个模块分开启动/停止（配置ssh是前提）<br> （1）整体启动/停止HDFS</p> </li> 
  </ol> 
  <pre><code>start-dfs.sh   /  stop-dfs.sh
</code></pre> 
  <p>（2）整体启动/停止YARN</p> 
  <pre><code> start-yarn.sh  /  stop-yarn.sh
</code></pre> 
  <p><a href="https://blog.csdn.net/fseast/article/details/96432838" rel="nofollow" data-token="e9bb70c4122afde3ad31c4dbfefa51ba">下一篇：阿里云服务器上的Hadoop伪分布式和完全分布式的搭建</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e44c3c0e64.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
