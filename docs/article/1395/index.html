<!DOCTYPE html>
<html lang="en-US">

<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>【论文阅读笔记】Learning to see in the dark - 有组织在!</title>


<meta name="robots" content="max-snippet:-1, max-image-preview:large, max-video-preview:-1">
<link rel="canonical" href="https://uzzz.org/article/1395/">
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读笔记】Learning to see in the dark - 有组织在!">
<meta property="og:description" content="     本文是CVPR2018论文，主要提出一种通过FCN方法将在黑暗环境中进行的拍摄还原的方法，实现让机器让机器“看破”黑暗。本文的主要创新点为：       1.提出了一个新的照片数据集，包含原始的short-exposure low-light图像，并附有long-exposure reference图像作为Groud truth，以往类似的研究使用的都是人工合成的图像；        2.与以往方法使用相机拍摄出的sRGB图像进行复原不同，本文使用的是原始的传感器数据。        3.提出了一种端到端的学习方法，通过训练一个全卷积网络FCN来直接处理快速成像系统中的低亮度图像。结构如图：       本文最后提出了该模型待改进的几个地方：       1.数据集中目前不包含人和运动物体；       2.模型中的放大率amplification ratio是人工选择的，如果能根据图像自动选择，效果会更好。       3.可以进行进一步的运行时优化，目前处理一幅照片的时间不能满足实时处理的时限要求。 …………………………………………………………………………………………………………………………………………………………………………………. 下面的内容转载自：https://blog.csdn.net/linchunmian/article/details/80291921，个人认为是对本文比较好的一篇翻译： 整理下最近一篇论文的学习笔记。这是由UIUC的陈晨和Intel Labs的陈启峰、许佳、Vladlen Koltun 合作提出的一种在黑暗中也能快速、清晰的成像系统，让机器“看破”黑暗。以下是论文的主要部分。 摘要 在暗光条件下，受到低信噪比和低亮度的影响，图片的质量会受到很大的影响。此外，低曝光率的照片会出现很多噪声，而长曝光时间会让照片变得模糊、不真实。目前，很多关于去噪、去模糊、图像增强等技术的研究已被相继提出，但是在一些极端条件下，这些技术的作用就很有限了。为了发展基于学习的低亮度图像处理技术，本文提出了一种在黑暗中也能快速、清晰的成像系统，效果令人非常惊讶。此外，我们引入了一个数据集，包含有原始的低曝光率、低亮度图片，同时还有对应的长曝光率图像。利用该数据集，提出了一种端到端训练模式的全卷积网络结构，用于处理低亮度图像。该网络直接使用原始传感器数据，并替代了大量的传统图像处理流程。最终，实验结果表明这种网络结构在新数据集上能够表现出出色的性能，并在未来工作中有很大前途。 简介 任何的图像成像系统都存在噪声，但这很大地影响在弱光条件下图像的质量。高ISO 可以用于增加亮度，但它同时也会放大噪音。诸如缩放或直方图拉伸等图像后处理可以缓解这种噪声影响，但这并不能从根本上解决低信噪比 (SNR) 问题。在物理学上，这可以解释为在弱光条件下增加SNR，包括开放光圈，延长曝光时间以及使用闪光灯等，但这些也都有其自身的缺陷。例如，曝光时间的延长可能会引起相机抖动或物体运动模糊。 众所周知，暗光条件下的快速成像系统一直都是计算摄影界的一大挑战，也是一直以来开放性的研究领域。目前，许多关于图像去噪，去模糊和低光图像增强等技术相继提出，但这些技术通常假设这些在昏暗环境下捕获到的图像带有中等程度的噪音。相反，我们更感兴趣的是在极端低光条件下，如光照严重受限 (例如月光) 和短时间曝光 (理想情况下是视频率) 等条件下的图像成像系统。在这种情况下，传统相机的处理方式显然已不适用，图像必须根据原始的传感器数据来重建。 为此，本文提出了一种新的图像处理技术：通过一种数据驱动的方法来解决极端低光条件下快速成像系统的挑战。具体来说，我们训练深度神经网络来学习低光照条件下原始数据的图像处理技术，包括颜色转换，去马赛克，降噪和图像增强等。我们通过端对端的训练方式来避免放大噪声，还能表征这种环境下传统相机处理的累积误差。 据我们所知，现有用于处理低光图像的方法，在合成数据或真实的低光图像上测试都缺乏事实根据。此外，用于处理不同真实环境下的低光图像数据集也相当匮乏。因此，我们收集了一个在低光条件下快速曝光的原始图像数据集。每个低光图像都有对应的长曝光时间的高质量图像用于参考。在新的数据集上我们的方法表现出不出色的结果：将低光图像放大300倍，成功减少了图像中的噪音并正确实现了颜色转换。我们系统地分析方法中的关键要素并讨论未来的研究方向。 下图1展示了我们的设置。我们可以看到，在很高的ISO 8,000条件下，尽管使用全帧的索尼高光灵敏度相机，但相机仍会产生全黑的图像。在ISO 409,600条件下，图像仍会产生朦胧，嘈杂，颜色扭曲等现象。换而言之，即使是当前最先进的图像去噪技术也无法消除这种噪音，也无法解决颜色偏差问题。而我们提出的全卷积网络结构能够有效地克服这些问题。 图1卷积网络下的极端低光成像。黑暗的室内环境：:相机的照度 <0.1 lux。Sony α7S II传感器曝光1/30秒。左图：ISO 8,000相机产生的图像。中间图：ISO 409,600相机产生的图像，图像受到噪声和颜色偏差的影响。右图：由我们的全卷积网络生生的图像。 数据集 (SID) 我们收集了一个新的数据集，用于原始低光图像的训练和基准测试。See-in-the-Dark(SID) 数据集包含5094张原始的短曝光图像，每张都有相应的长曝光时间的参考图像。值得注意的是，多张短曝光的图像可以对应于相同的长曝光时间的参考图像。例如，我们收集了短时间曝光图像用于评估去燥方法。序列中的每张图像都可视为一张独特的低光图像，这样包含真实世界伪像的图片能够更有利于模型的训练和培训测试。SID 数据集中长时间曝光的参考图像是424。 此外，我们的数据集包含了室内和室外图像。室外图像通常是在月光或街道照明条件下拍摄。在室外场景下，相机的亮度一般在0.2 lux 和5 lux 之间。室内图像通常更暗。在室内场景中的相机亮度一般在0.03 lux 和0.3 lux 之间。输入图像的曝光时间设置为1/30和1/10秒。相应的参考图像 (真实图像) 的曝光时间通常会延长100到300倍：即10至30秒。各数据集的具体情况如下表1中所示。 表1. SID 数据集包含5094个原始的短曝光率图像，每张图像都有一个长曝光的参考图像。图像由顶部和底部两台相机收集得到。表中的指标参数分别是(从左到右)：输入与参考图像之间的曝光时间率，滤波器阵列，输入图像的曝光时间以及在每种条件下的图像数量。 下图2显示了数据集中一部分的参考图像。在每种条件下，我们随机选择大约20％的图像是组成测试集，另外选定10％的数据用于模型验证。 图2 SID 数据库的实例。前两行是SID 数据集中室外的图像，底部两行是室内的图像。长曝光时间的参考图像 (地面实况) 显示在前面。短曝光的输入图像(基本上是黑色) 显示在背部。室外场景下相机的亮度一般在0.2到5 lux，而室内的相机亮度在0.03和0.3 lux 之间。 数据采集时，相机固定在三脚架上。我们用无反光镜相机来避免由于镜面拍打引起的振动。在每个场景中，相机设置 (如光圈，ISO，焦距和焦距) 进行了调整，以最大限度地提高参考图像(长曝光时间)的质量。此外，利用远程的智能手机 app 将曝光时间缩短一倍缩小后的曝光时间为100至300。该相机专门用于参考图像 (长曝光时间) 的拍摄，而没有触及短曝光的图像。我们收集了一系列短曝光的图像用于方法的比较和评估，以突出我们方法的优势。 虽然，数据集中的参考图像仍可能存在一些噪音，但感知质量足够高。我们目的是为了在光线不足的条件下产生在感知良好的图像，而不是彻底删除图像中所有噪音或最大化图像对比度。因此，这种参考图像的存在不会影响我们的方法评估。 方法 从成像传感器中得到原始数据后，传统图像处理过程会应用一系列模块，例如白平衡、去马赛克、去噪、增加图像锐度、 γ 矫正等等。而这些图像处理模块只在某些特定相机中才有。一些研究提出使用局部线性、可学习的L3 过滤器来模拟现代成像系统中复杂的非线性流程，但是这些方法都无法成功解决在低光条件中快速成像的问题，也无法解决极低的SNR 问题。此外，通过智能手机相机拍摄的照片，利用bursting imaging成像方法，结合多张图像也可以生成效果较好的图像，但是这种方法的复杂程度较高。 因此，我们提出了的端到端的学习方法，即训练一个全卷积网络FCN 来直接处理快速成像系统中的低亮度图像。纯粹的FCN 结构可以有效地代表许多图像处理算法。受此启发，我们调查并研究这种方法在极端低光条件下成像系统的应用。相比于传统图像处理方法使用的sRGB 图像，在这里我们使用原始传感器数据。下图3展示了我们所提出的方法结构。 图3 我们提出的图像处理方法 对于 Bayer 数组，我们将输入打包为四个通道并在每个通道上将空间分辨率降低一半。对于X-Trans 数组(图中未显示出)，原始数据以6×6排列块组成;我们通过交换相邻通道元素的方法将36个通道的数组打包成9个通道。此外，我们消除黑色像素并按照期望的倍数缩放数据(例如，x100或x300)。将处理后数据作为 FCN 模型的输入，输出是一个带12通道的图像，其空间分辨率只有输入的一半。 我们将两个标准的 FCN 结构作为我们模型的核心架构：用于快速图像处理的多尺度上下文聚合网络 (CAN) 和U-net 网络。影响我们模型选择的另一个因素是内存消耗：在 GPU 中，我们选择的模型结构可以处理全分辨率的图像(例如，在4240×2832或6000×4000分辨率)。同时，我们避免使用完全连接结构及模型集成方式。我们的默认架构是 U-net。 放大比率决定了模型的亮度输出。在我们的方法中，放大比率设置在外部指定并作为输入提供给模型，这类似于相机中的 ISO 设置。下图4显示了不同放大比率的影响。用户可以通过设置不同的放大率来调整输出图像的亮度。在测试时间，我们的方法能够抑制盲点噪声并实现颜色转换，并在sRGB 空间网络直接处理图像，得到网络的输出。 图4 SID 数据集中放大系数对室内图像 (Sony x100子集) 的影响。类似于摄像机中的ISO设置，这里的放大系数是作为外部输入提供给我们的模型。更高的放大倍数可以产生更明亮的图像。我们在我们的方法中引入了不同的放大因子，并展示了模型的输出图像。 模型训练 我们使用 L1 损失和 Adam 优化器，从零开始训练我们的网络。在训练期间，网络输入是原始的短曝光图像，在 sRGB 空间中的真实数据是相应的长曝光时间图像(由一个原始图像处理库 libraw 处理过得参考图像)。我们为每台相机训练一个网络，并将原始图像和参考图像之间曝光时间的倍数差作为我们的放大因子(例如，x100，x250，或x300)。在每次训练迭代中，我们随机裁剪一个512×512的补丁用于训练并利用翻转、旋转等操作来随机增强数据。初始学习率设定为0.0001，在2000次迭代后学习率降为0.00001，训练一共进行4000次迭代。 实验结果分析 首先，与传统方法的对比，我们提出的方法具有放大的功能。如下图5,6,7所示，传统的图像处理方法在极端低光条件下容易受到严重的噪声影响，导致生成图像颜色失真。我们提出的方法能够有效地抑制图像噪声，生成色彩均衡、逼真的图像。此外，由于在数据集中对齐数据序列，我们的方法也更优于 post-hocdenoising、brust denoising 等图像去燥方法 图5 (a) 由富士胶片 X-T2 相机拍摄的夜间图像，ISO 800，光圈f / 7.1，曝光时间1/30s，相机亮度约为1 lux。(b) 传统的图像处理方法不能有效处理原始数据中的噪声和颜色偏差。(c) 基于相同的数据，我们方法处理的结果。 图6 将 SID 数据集训练好的模型应用于用 iPhone 6s智能手机拍摄的原始低光图像。(a) iPhone 6s 在夜间所拍摄的原始图像，ISO 400，光圈f/2.2，曝光时间0. 05s。经传统的图像处理方法处理后的图像及缩放到相匹配的亮度的参考图像。(b)我们提出的方法处理后的结果 图7 Sony">
<meta property="og:url" content="https://uzzz.org/article/1395/">
<meta property="og:site_name" content="有组织在!">
<meta property="article:section" content="DeepLearning">
<meta property="article:published_time" content="2018-05-31T03:15:59+00:00">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:description" content="     本文是CVPR2018论文，主要提出一种通过FCN方法将在黑暗环境中进行的拍摄还原的方法，实现让机器让机器“看破”黑暗。本文的主要创新点为：       1.提出了一个新的照片数据集，包含原始的short-exposure low-light图像，并附有long-exposure reference图像作为Groud truth，以往类似的研究使用的都是人工合成的图像；        2.与以往方法使用相机拍摄出的sRGB图像进行复原不同，本文使用的是原始的传感器数据。        3.提出了一种端到端的学习方法，通过训练一个全卷积网络FCN来直接处理快速成像系统中的低亮度图像。结构如图：       本文最后提出了该模型待改进的几个地方：       1.数据集中目前不包含人和运动物体；       2.模型中的放大率amplification ratio是人工选择的，如果能根据图像自动选择，效果会更好。       3.可以进行进一步的运行时优化，目前处理一幅照片的时间不能满足实时处理的时限要求。 …………………………………………………………………………………………………………………………………………………………………………………. 下面的内容转载自：https://blog.csdn.net/linchunmian/article/details/80291921，个人认为是对本文比较好的一篇翻译： 整理下最近一篇论文的学习笔记。这是由UIUC的陈晨和Intel Labs的陈启峰、许佳、Vladlen Koltun 合作提出的一种在黑暗中也能快速、清晰的成像系统，让机器“看破”黑暗。以下是论文的主要部分。 摘要 在暗光条件下，受到低信噪比和低亮度的影响，图片的质量会受到很大的影响。此外，低曝光率的照片会出现很多噪声，而长曝光时间会让照片变得模糊、不真实。目前，很多关于去噪、去模糊、图像增强等技术的研究已被相继提出，但是在一些极端条件下，这些技术的作用就很有限了。为了发展基于学习的低亮度图像处理技术，本文提出了一种在黑暗中也能快速、清晰的成像系统，效果令人非常惊讶。此外，我们引入了一个数据集，包含有原始的低曝光率、低亮度图片，同时还有对应的长曝光率图像。利用该数据集，提出了一种端到端训练模式的全卷积网络结构，用于处理低亮度图像。该网络直接使用原始传感器数据，并替代了大量的传统图像处理流程。最终，实验结果表明这种网络结构在新数据集上能够表现出出色的性能，并在未来工作中有很大前途。 简介 任何的图像成像系统都存在噪声，但这很大地影响在弱光条件下图像的质量。高ISO 可以用于增加亮度，但它同时也会放大噪音。诸如缩放或直方图拉伸等图像后处理可以缓解这种噪声影响，但这并不能从根本上解决低信噪比 (SNR) 问题。在物理学上，这可以解释为在弱光条件下增加SNR，包括开放光圈，延长曝光时间以及使用闪光灯等，但这些也都有其自身的缺陷。例如，曝光时间的延长可能会引起相机抖动或物体运动模糊。 众所周知，暗光条件下的快速成像系统一直都是计算摄影界的一大挑战，也是一直以来开放性的研究领域。目前，许多关于图像去噪，去模糊和低光图像增强等技术相继提出，但这些技术通常假设这些在昏暗环境下捕获到的图像带有中等程度的噪音。相反，我们更感兴趣的是在极端低光条件下，如光照严重受限 (例如月光) 和短时间曝光 (理想情况下是视频率) 等条件下的图像成像系统。在这种情况下，传统相机的处理方式显然已不适用，图像必须根据原始的传感器数据来重建。 为此，本文提出了一种新的图像处理技术：通过一种数据驱动的方法来解决极端低光条件下快速成像系统的挑战。具体来说，我们训练深度神经网络来学习低光照条件下原始数据的图像处理技术，包括颜色转换，去马赛克，降噪和图像增强等。我们通过端对端的训练方式来避免放大噪声，还能表征这种环境下传统相机处理的累积误差。 据我们所知，现有用于处理低光图像的方法，在合成数据或真实的低光图像上测试都缺乏事实根据。此外，用于处理不同真实环境下的低光图像数据集也相当匮乏。因此，我们收集了一个在低光条件下快速曝光的原始图像数据集。每个低光图像都有对应的长曝光时间的高质量图像用于参考。在新的数据集上我们的方法表现出不出色的结果：将低光图像放大300倍，成功减少了图像中的噪音并正确实现了颜色转换。我们系统地分析方法中的关键要素并讨论未来的研究方向。 下图1展示了我们的设置。我们可以看到，在很高的ISO 8,000条件下，尽管使用全帧的索尼高光灵敏度相机，但相机仍会产生全黑的图像。在ISO 409,600条件下，图像仍会产生朦胧，嘈杂，颜色扭曲等现象。换而言之，即使是当前最先进的图像去噪技术也无法消除这种噪音，也无法解决颜色偏差问题。而我们提出的全卷积网络结构能够有效地克服这些问题。 图1卷积网络下的极端低光成像。黑暗的室内环境：:相机的照度 <0.1 lux。Sony α7S II传感器曝光1/30秒。左图：ISO 8,000相机产生的图像。中间图：ISO 409,600相机产生的图像，图像受到噪声和颜色偏差的影响。右图：由我们的全卷积网络生生的图像。 数据集 (SID) 我们收集了一个新的数据集，用于原始低光图像的训练和基准测试。See-in-the-Dark(SID) 数据集包含5094张原始的短曝光图像，每张都有相应的长曝光时间的参考图像。值得注意的是，多张短曝光的图像可以对应于相同的长曝光时间的参考图像。例如，我们收集了短时间曝光图像用于评估去燥方法。序列中的每张图像都可视为一张独特的低光图像，这样包含真实世界伪像的图片能够更有利于模型的训练和培训测试。SID 数据集中长时间曝光的参考图像是424。 此外，我们的数据集包含了室内和室外图像。室外图像通常是在月光或街道照明条件下拍摄。在室外场景下，相机的亮度一般在0.2 lux 和5 lux 之间。室内图像通常更暗。在室内场景中的相机亮度一般在0.03 lux 和0.3 lux 之间。输入图像的曝光时间设置为1/30和1/10秒。相应的参考图像 (真实图像) 的曝光时间通常会延长100到300倍：即10至30秒。各数据集的具体情况如下表1中所示。 表1. SID 数据集包含5094个原始的短曝光率图像，每张图像都有一个长曝光的参考图像。图像由顶部和底部两台相机收集得到。表中的指标参数分别是(从左到右)：输入与参考图像之间的曝光时间率，滤波器阵列，输入图像的曝光时间以及在每种条件下的图像数量。 下图2显示了数据集中一部分的参考图像。在每种条件下，我们随机选择大约20％的图像是组成测试集，另外选定10％的数据用于模型验证。 图2 SID 数据库的实例。前两行是SID 数据集中室外的图像，底部两行是室内的图像。长曝光时间的参考图像 (地面实况) 显示在前面。短曝光的输入图像(基本上是黑色) 显示在背部。室外场景下相机的亮度一般在0.2到5 lux，而室内的相机亮度在0.03和0.3 lux 之间。 数据采集时，相机固定在三脚架上。我们用无反光镜相机来避免由于镜面拍打引起的振动。在每个场景中，相机设置 (如光圈，ISO，焦距和焦距) 进行了调整，以最大限度地提高参考图像(长曝光时间)的质量。此外，利用远程的智能手机 app 将曝光时间缩短一倍缩小后的曝光时间为100至300。该相机专门用于参考图像 (长曝光时间) 的拍摄，而没有触及短曝光的图像。我们收集了一系列短曝光的图像用于方法的比较和评估，以突出我们方法的优势。 虽然，数据集中的参考图像仍可能存在一些噪音，但感知质量足够高。我们目的是为了在光线不足的条件下产生在感知良好的图像，而不是彻底删除图像中所有噪音或最大化图像对比度。因此，这种参考图像的存在不会影响我们的方法评估。 方法 从成像传感器中得到原始数据后，传统图像处理过程会应用一系列模块，例如白平衡、去马赛克、去噪、增加图像锐度、 γ 矫正等等。而这些图像处理模块只在某些特定相机中才有。一些研究提出使用局部线性、可学习的L3 过滤器来模拟现代成像系统中复杂的非线性流程，但是这些方法都无法成功解决在低光条件中快速成像的问题，也无法解决极低的SNR 问题。此外，通过智能手机相机拍摄的照片，利用bursting imaging成像方法，结合多张图像也可以生成效果较好的图像，但是这种方法的复杂程度较高。 因此，我们提出了的端到端的学习方法，即训练一个全卷积网络FCN 来直接处理快速成像系统中的低亮度图像。纯粹的FCN 结构可以有效地代表许多图像处理算法。受此启发，我们调查并研究这种方法在极端低光条件下成像系统的应用。相比于传统图像处理方法使用的sRGB 图像，在这里我们使用原始传感器数据。下图3展示了我们所提出的方法结构。 图3 我们提出的图像处理方法 对于 Bayer 数组，我们将输入打包为四个通道并在每个通道上将空间分辨率降低一半。对于X-Trans 数组(图中未显示出)，原始数据以6×6排列块组成;我们通过交换相邻通道元素的方法将36个通道的数组打包成9个通道。此外，我们消除黑色像素并按照期望的倍数缩放数据(例如，x100或x300)。将处理后数据作为 FCN 模型的输入，输出是一个带12通道的图像，其空间分辨率只有输入的一半。 我们将两个标准的 FCN 结构作为我们模型的核心架构：用于快速图像处理的多尺度上下文聚合网络 (CAN) 和U-net 网络。影响我们模型选择的另一个因素是内存消耗：在 GPU 中，我们选择的模型结构可以处理全分辨率的图像(例如，在4240×2832或6000×4000分辨率)。同时，我们避免使用完全连接结构及模型集成方式。我们的默认架构是 U-net。 放大比率决定了模型的亮度输出。在我们的方法中，放大比率设置在外部指定并作为输入提供给模型，这类似于相机中的 ISO 设置。下图4显示了不同放大比率的影响。用户可以通过设置不同的放大率来调整输出图像的亮度。在测试时间，我们的方法能够抑制盲点噪声并实现颜色转换，并在sRGB 空间网络直接处理图像，得到网络的输出。 图4 SID 数据集中放大系数对室内图像 (Sony x100子集) 的影响。类似于摄像机中的ISO设置，这里的放大系数是作为外部输入提供给我们的模型。更高的放大倍数可以产生更明亮的图像。我们在我们的方法中引入了不同的放大因子，并展示了模型的输出图像。 模型训练 我们使用 L1 损失和 Adam 优化器，从零开始训练我们的网络。在训练期间，网络输入是原始的短曝光图像，在 sRGB 空间中的真实数据是相应的长曝光时间图像(由一个原始图像处理库 libraw 处理过得参考图像)。我们为每台相机训练一个网络，并将原始图像和参考图像之间曝光时间的倍数差作为我们的放大因子(例如，x100，x250，或x300)。在每次训练迭代中，我们随机裁剪一个512×512的补丁用于训练并利用翻转、旋转等操作来随机增强数据。初始学习率设定为0.0001，在2000次迭代后学习率降为0.00001，训练一共进行4000次迭代。 实验结果分析 首先，与传统方法的对比，我们提出的方法具有放大的功能。如下图5,6,7所示，传统的图像处理方法在极端低光条件下容易受到严重的噪声影响，导致生成图像颜色失真。我们提出的方法能够有效地抑制图像噪声，生成色彩均衡、逼真的图像。此外，由于在数据集中对齐数据序列，我们的方法也更优于 post-hocdenoising、brust denoising 等图像去燥方法 图5 (a) 由富士胶片 X-T2 相机拍摄的夜间图像，ISO 800，光圈f / 7.1，曝光时间1/30s，相机亮度约为1 lux。(b) 传统的图像处理方法不能有效处理原始数据中的噪声和颜色偏差。(c) 基于相同的数据，我们方法处理的结果。 图6 将 SID 数据集训练好的模型应用于用 iPhone 6s智能手机拍摄的原始低光图像。(a) iPhone 6s 在夜间所拍摄的原始图像，ISO 400，光圈f/2.2，曝光时间0. 05s。经传统的图像处理方法处理后的图像及缩放到相匹配的亮度的参考图像。(b)我们提出的方法处理后的结果 图7 Sony">
<meta name="twitter:title" content="【论文阅读笔记】Learning to see in the dark - 有组织在!">
<meta name="twitter:image" content="https://uzshare.com/_p?https://img-blog.csdn.net/20180531110855773">
<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/1395/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdn.net/20180531110855773"},{"@type":"WebPage","@id":"https://uzzz.org/article/1395/#webpage","url":"https://uzzz.org/article/1395/","inLanguage":"en-US","name":"\u3010\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0\u3011Learning to see in the dark - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/1395/#primaryimage"},"datePublished":"2018-05-31T03:15:59+00:00","dateModified":"2018-05-31T03:15:59+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>


<link rel="dns-prefetch" href="//s.w.org">
<link rel="alternate" type="application/rss+xml" title="有组织在! » Feed" href="https://uzzz.org/feed/">
<link rel="alternate" type="application/rss+xml" title="有组织在! » Comments Feed" href="https://uzzz.org/comments/feed/">
<link rel="stylesheet" id="tortuga-custom-fonts-css" href="https://uzzz.org/wp-content/themes/tortuga/assets/css/custom-fonts.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-block-library-css" href="https://uzzz.org/wp-includes/css/dist/block-library/style.min.css" type="text/css" media="all">
<link rel="stylesheet" id="tortuga-stylesheet-css" href="https://uzzz.org/wp-content/themes/tortuga/style.css" type="text/css" media="all">
<style id="tortuga-stylesheet-inline-css" type="text/css">
.site-title, .site-description { position: absolute; clip: rect(1px, 1px, 1px, 1px); width: 1px; height: 1px; overflow: hidden; }
</style>
<link rel="stylesheet" id="genericons-css" href="https://uzzz.org/wp-content/themes/tortuga/assets/genericons/genericons.css" type="text/css" media="all">
<link rel="stylesheet" id="themezee-related-posts-css" href="https://uzzz.org/wp-content/themes/tortuga/assets/css/themezee-related-posts.css" type="text/css" media="all">

<script type="text/javascript" src="https://uzzz.org/wp-includes/js/jquery/jquery.js"></script>
<script type="text/javascript" src="https://uzzz.org/wp-includes/js/jquery/jquery-migrate.min.js"></script>
<script type="text/javascript" src="https://uzzz.org/wp-content/themes/tortuga/assets/js/navigation.js"></script>
<link rel="https://api.w.org/" href="https://uzzz.org/wp-json/">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://uzzz.org/xmlrpc.php">

<link rel="shortlink" href="https://uzzz.org/">
<link rel="alternate" type="application/json+oembed" href="https://uzzz.org/wp-json/oembed/1.0/embed">
<link rel="alternate" type="text/xml+oembed" href="https://uzzz.org/wp-json/oembed/1.0/embed">
<link rel="amphtml" href="https://uzzz.org/article/1395/amp/"><link rel="icon" href="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" sizes="32x32">
<link rel="icon" href="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-192x192.png" sizes="192x192">
<link rel="apple-touch-icon-precomposed" href="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-180x180.png">
<meta name="msapplication-TileImage" content="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-270x270.png">
		<style type="text/css" id="wp-custom-css">
			.header-main {
	display: none;
}

#article_content, .entry-content{
	overflow-wrap: break-word;
}		</style>
			<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?d293c49e1e4bfe8f276695a5aa953300";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>
	<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	</head>

<body class="post-template-default single single-post postid-1395 single-format-standard wp-embed-responsive author-hidden comments-hidden">

	<div id="page" class="hfeed site">

		<a class="skip-link screen-reader-text" href="#content">Skip to content</a>

		
		<header id="masthead" class="site-header clearfix" role="banner">

			<div class="header-main container clearfix">

				<div id="logo" class="site-branding clearfix">

										
			<p class="site-title"><a href="https://uzzz.org/" rel="home">有组织在!</a></p>

							
				</div>

				<div class="header-widgets clearfix">

					
				</div>

			</div>

			<div id="main-navigation-wrap" class="primary-navigation-wrap">

				<nav id="main-navigation" class="primary-navigation navigation container clearfix" role="navigation">

					
					<ul id="menu-daohang" class="main-navigation-menu"><li id="menu-item-12" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-12"><a href="/">首页-有组织在！</a></li>
<li id="menu-item-1755" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1755"><a target="_blank" rel="noopener noreferrer" href="/index2.html">旧版首页</a></li>
<li id="menu-item-17" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-17"><a target="_blank" rel="noopener noreferrer" href="https://uzshare.com">柚子社区</a></li>
<li id="menu-item-18" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-18"><a target="_blank" rel="noopener noreferrer" href="https://inkeast.com">笔墨东方</a></li>
<li id="menu-item-19" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-19"><a target="_blank" rel="noopener noreferrer" href="https://swantrip.net">天鹅之旅</a></li>
<li id="menu-item-20" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-20"><a target="_blank" rel="noopener noreferrer" href="https://vlanguage.cn">V语言中文社区</a></li>
<li id="menu-item-65" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-65"><a target="_blank" rel="noopener noreferrer" href="/donate/">Donate</a></li>
</ul>				</nav>

			</div>

		</header>

		
		
		<div id="content" class="site-content container clearfix">

	<section id="primary" class="content-single content-area">
		<main id="main" class="site-main" role="main">
				
		<div id="magazine-homepage-widgets" class="widget-area clearfix">

			<div id="custom_html-3" class="widget_text widget widget_custom_html"><div class="textwidget custom-html-widget">

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-8889449066804352" data-ad-slot="6054387901" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
				
				</div></div>
		</div>

<article id="post-1395" class="post-1395 post type-post status-publish format-standard hentry category-deeplearning">

	
	<header class="entry-header">

		<h1 class="entry-title">【论文阅读笔记】Learning to see in the dark</h1>
		<div class="entry-meta"><span class="meta-date"><a href="https://uzzz.org/article/1395/" title="am11:15" rel="bookmark"><time class="entry-date published updated" datetime="2018-05-31T11:15:59+08:00">2018/5/31</time></a></span><span class="meta-category"> <a href="https://uzzz.org/category/deeplearning/" rel="category tag">DeepLearning</a></span></div>
	</header>

	<div class="entry-content clearfix">

		<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div class="htmledit_views" id="content_views">
<p>     本文是CVPR2018论文，主要提出一种通过FCN方法将在黑暗环境中进行的拍摄还原的方法，实现让机器<span style="color:#666666;">让机器“看破”黑暗。本文的主要创新点为：</span></p>

<p><span style="color:#666666;">      1.提出了一个新的照片数据集，包含原始的</span><span style="color:rgb(102,102,102);">short-exposure low-light图像，并附有</span><span style="color:rgb(102,102,102);">long-exposure reference图像作为Groud truth，以往类似的研究使用的都是人工合成的图像；</span></p>
<p><span style="color:rgb(102,102,102);">       2.与以往方法使用相机拍摄出的sRGB图像进行复原不同，本文使用的是原始的传感器数据。</span></p>
<p><span style="color:rgb(102,102,102);">       3.<span style="color:#666666;">提出了一种端到端的学习方法，通过训练一个全卷积网络FCN</span>来直接处理快速成像系统中的低亮度图像。结构如图：</span></p>
<p><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180531110855773" alt=""><br></span></p>
<p><span style="color:rgb(102,102,102);">      本文最后提出了该模型待改进的几个地方：</span></p>
<p><span style="color:rgb(102,102,102);">      1.数据集中目前不包含人和运动物体；</span></p>
<p><span style="color:rgb(102,102,102);">      2.模型中的放大率amplification ratio是人工选择的，如果能根据图像自动选择，效果会更好。</span></p>
<p><span style="color:rgb(102,102,102);">      3.可以进行进一步的运行时优化，目前处理一幅照片的时间不能满足实时处理的时限要求。</span></p>
<p><span style="color:#666666;">………………………………………………………………………………………………………………………………………………………………………………….</span></p>

<p><span style="color:#666666;">下面的内容转载自：</span><a href="https://blog.csdn.net/linchunmian/article/details/80291921" rel="nofollow" data-token="41360b0a5552a1423ce411fbc87bbcd0">https://blog.csdn.net/linchunmian/article/details/80291921</a>，个人认为是对本文比较好的一篇翻译：</p>

<p style="background-color:rgb(255,255,255);"><span style="color:rgb(102,102,102);">整理下最近一篇论文的学习笔记。这是由UIUC的陈晨和Intel Labs的陈启峰、许佳、Vladlen Koltun 合作提出的一种在黑暗中也能快速、清晰的成像系统，让机器“看破”黑暗。以下是论文的主要部分。</span></p>
<p style="background-color:rgb(255,255,255);">
</p><p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><span style="font-weight:700;">摘要</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">在暗光条件下，受到低信噪比和低亮度的影响，图片的质量会受到很大的影响。此外，低曝光率的照片会出现很多噪声，而长曝光时间会让照片变得模糊、不真实。目前，很多关于去噪、去模糊、图像增强等技术的研究已被相继提出，但是在一些极端条件下，这些技术的作用就很有限了。为了发展基于学习的低亮度图像处理技术，本文提出了一种在黑暗中也能快速、清晰的成像系统，效果令人非常惊讶。此外，我们引入了一个数据集，包含有原始的低曝光率、低亮度图片，同时还有对应的长曝光率图像。利用该数据集，提出了一种端到端训练模式的全卷积网络结构，用于处理低亮度图像。该网络直接使用原始传感器数据，并替代了大量的传统图像处理流程。最终，实验结果表明这种网络结构在新数据集上能够表现出出色的性能，并在未来工作中有很大前途。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><span style="font-weight:700;">简介</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">任何的图像成像系统都存在噪声，但这很大地影响在弱光条件下图像的质量。高ISO 可以用于增加亮度，但它同时也会放大噪音。诸如缩放或直方图拉伸等图像后处理可以缓解这种噪声影响，但这并不能从根本上解决低信噪比 (SNR) 问题。在物理学上，这可以解释为在弱光条件下增加SNR，包括开放光圈，延长曝光时间以及使用闪光灯等，但这些也都有其自身的缺陷。例如，曝光时间的延长可能会引起相机抖动或物体运动模糊。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">众所周知，暗光条件下的快速成像系统一直都是计算摄影界的一大挑战，也是一直以来开放性的研究领域。目前，许多关于图像去噪，去模糊和低光图像增强等技术相继提出，但这些技术通常假设这些在昏暗环境下捕获到的图像带有中等程度的噪音。相反，我们更感兴趣的是在极端低光条件下，如光照严重受限 (例如月光) 和短时间曝光 (理想情况下是视频率) 等条件下的图像成像系统。在这种情况下，传统相机的处理方式显然已不适用，图像必须根据原始的传感器数据来重建。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">为此，本文提出了一种新的图像处理技术：通过一种数据驱动的方法来解决极端低光条件下快速成像系统的挑战。具体来说，我们训练深度神经网络来学习低光照条件下原始数据的图像处理技术，包括颜色转换，去马赛克，降噪和图像增强等。我们通过端对端的训练方式来避免放大噪声，还能表征这种环境下传统相机处理的累积误差。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">据我们所知，现有用于处理低光图像的方法，在合成数据或真实的低光图像上测试都缺乏事实根据。此外，用于处理不同真实环境下的低光图像数据集也相当匮乏。因此，我们收集了一个在低光条件下快速曝光的原始图像数据集。每个低光图像都有对应的长曝光时间的高质量图像用于参考。在新的数据集上我们的方法表现出不出色的结果：将低光图像放大300倍，成功减少了图像中的噪音并正确实现了颜色转换。我们系统地分析方法中的关键要素并讨论未来的研究方向。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">下图1展示了我们的设置。我们可以看到，在很高的ISO 8,000条件下，尽管使用全帧的索尼高光灵敏度相机，但相机仍会产生全黑的图像。在ISO 409,600条件下，图像仍会产生朦胧，嘈杂，颜色扭曲等现象。换而言之，即使是当前最先进的图像去噪技术也无法消除这种噪音，也无法解决颜色偏差问题。而我们提出的全卷积网络结构能够有效地克服这些问题。</span></p>
<p align="left" style="text-align:center;background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153439309?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<pre style="padding-right:0px;padding-left:0px;font-size:14px;line-height:22px;text-align:center;background:rgb(255,255,255);"><span style="font-size:12px;"><span style="color:rgb(102,102,102);">图1卷积网络下的极端低光成像。黑暗的室内环境：:相机的照度 <0.1 lux。Sony α7S II传感器曝光1/30秒。</span>左图：<span style="color:rgb(102,102,102);">ISO 8,000</span><span style="color:rgb(102,102,102);">相机产生的图像。中间图：</span><span style="color:rgb(102,102,102);">ISO 409,600</span><span style="color:rgb(102,102,102);">相机产生的图像，图像受到噪声和颜色偏差的影响。右图：由我们的全卷积网络生生的图像。</span></span></pre>
<p align="left" style="background:rgb(255,255,255);"><span style="font-weight:700;"><span style="color:rgb(102,102,102);">数据集 (SID)</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">我们收集了一个新的数据集，用于原始低光图像的训练和基准测试。See-in-the-Dark(SID) 数据集包含5094张原始的短曝光图像，每张都有相应的长曝光时间的参考图像。值得注意的是，多张短曝光的图像可以对应于相同的长曝光时间的参考图像。例如，我们收集了短时间曝光图像用于评估去燥方法。序列中的每张图像都可视为一张独特的低光图像，这样包含真实世界伪像的图片能够更有利于模型的训练和培训测试。SID 数据集中长时间曝光的参考图像是424。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">此外，我们的数据集包含了室内和室外图像。室外图像通常是在月光或街道照明条件下拍摄。在室外场景下，相机的亮度一般在0.2 lux 和5 lux 之间。室内图像通常更暗。在室内场景中的相机亮度一般在0.03 lux 和0.3 lux 之间。输入图像的曝光时间设置为1/30和1/10秒。相应的参考图像 (真实图像) 的曝光时间通常会延长100到300倍：即10至30秒。各数据集的具体情况如下表1中所示。</span></p>
<p align="left" style="text-align:center;background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153544352?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">表1. SID 数据集包含5094个原始的短曝光率图像，每张图像都有一个长曝光的参考图像。图像由顶部和底部两台相机收集得到。表中的指标参数分别是(从左到右)：输入与参考图像之间的曝光时间率，滤波器阵列，输入图像的曝光时间以及在每种条件下的图像数量。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">下图2显示了数据集中一部分的参考图像。在每种条件下，我们随机选择大约20％的图像是组成测试集，另外选定10％的数据用于模型验证。</span></p>
<p align="left" style="text-align:center;background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153622727?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图2 SID 数据库的实例。前两行是SID 数据集中室外的图像，底部两行是室内的图像。长曝光时间的参考图像 (地面实况) 显示在前面。短曝光的输入图像(基本上是黑色) 显示在背部。室外场景下相机的亮度一般在0.2到5 lux，而室内的相机亮度在0.03和0.3 lux 之间。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">数据采集时，相机固定在三脚架上。我们用无反光镜相机来避免由于镜面拍打引起的振动。在每个场景中，相机设置 (如光圈，ISO，焦距和焦距) 进行了调整，以最大限度地提高参考图像(长曝光时间)的质量。此外，利用远程的智能手机 app 将曝光时间缩短一倍缩小后的曝光时间为100至300。该相机专门用于参考图像 (长曝光时间) 的拍摄，而没有触及短曝光的图像。我们收集了一系列短曝光的图像用于方法的比较和评估，以突出我们方法的优势。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">虽然，数据集中的参考图像仍可能存在一些噪音，但感知质量足够高。我们目的是为了在光线不足的条件下产生在感知良好的图像，而不是彻底删除图像中所有噪音或最大化图像对比度。因此，这种参考图像的存在不会影响我们的方法评估。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="font-weight:700;"><span style="color:rgb(102,102,102);">方法</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">从成像传感器中得到原始数据后，传统图像处理过程会应用一系列模块，例如白平衡、去马赛克、去噪、增加图像锐度、 γ 矫正等等。而这些图像处理模块只在某些特定相机中才有。一些研究提出使用局部线性、可学习的L3 过滤器来模拟现代成像系统中复杂的非线性流程，但是这些方法都无法成功解决在低光条件中快速成像的问题，也无法解决极低的SNR 问题。此外，通过智能手机相机拍摄的照片，利用bursting imaging成像方法，结合多张图像也可以生成效果较好的图像，但是这种方法的复杂程度较高。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">因此，我们提出了的端到端的学习方法，即训练一个全卷积网络FCN 来直接处理快速成像系统中的低亮度图像。纯粹的FCN 结构可以有效地代表许多图像处理算法。受此启发，我们调查并研究这种方法在极端低光条件下成像系统的应用。相比于传统图像处理方法使用的sRGB 图像，在这里我们使用原始传感器数据。下图3展示了我们所提出的方法结构。</span></p>
<p align="left" style="text-align:center;background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153658118?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图3 我们提出的图像处理方法</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">对于 Bayer 数组，我们将输入打包为四个通道并在每个通道上将空间分辨率降低一半。对于X-Trans 数组(图中未显示出)，原始数据以6×6排列块组成;我们通过交换相邻通道元素的方法将36个通道的数组打包成9个通道。此外，我们消除黑色像素并按照期望的倍数缩放数据(例如，x100或x300)。将处理后数据作为 FCN 模型的输入，输出是一个带12通道的图像，其空间分辨率只有输入的一半。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">我们将两个标准的 FCN 结构作为我们模型的核心架构：用于快速图像处理的多尺度上下文聚合网络 (CAN) 和U-net 网络。影响我们模型选择的另一个因素是内存消耗：在 GPU 中，我们选择的模型结构可以处理全分辨率的图像(例如，在4240×2832或6000×4000分辨率)。同时，我们避免使用完全连接结构及模型集成方式。我们的默认架构是 U-net。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">放大比率决定了模型的亮度输出。在我们的方法中，放大比率设置在外部指定并作为输入提供给模型，这类似于相机中的 ISO 设置。下图4显示了不同放大比率的影响。用户可以通过设置不同的放大率来调整输出图像的亮度。在测试时间，我们的方法能够抑制盲点噪声并实现颜色转换，并在sRGB 空间网络直接处理图像，得到网络的输出。</span></p>
<p align="left" style="text-align:center;background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153724857?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图4 SID 数据集中放大系数对室内图像 (Sony x100子集) 的影响。类似于摄像机中的ISO设置，这里的放大系数是作为外部输入提供给我们的模型。更高的放大倍数可以产生更明亮的图像。我们在我们的方法中引入了不同的放大因子，并展示了模型的输出图像。</span></p>
<p style="background:rgb(255,255,255);"><span style="font-weight:700;"><span style="color:rgb(102,102,102);">模型训练</span></span></p>
<p style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">我们使用 L1 损失和 Adam 优化器，从零开始训练我们的网络。在训练期间，网络输入是原始的短曝光图像，在 sRGB 空间中的真实数据是相应的长曝光时间图像(由一个原始图像处理库 libraw 处理过得参考图像)。我们为每台相机训练一个网络，并将原始图像和参考图像之间曝光时间的倍数差作为我们的放大因子(例如，x100，x250，或x300)。在每次训练迭代中，我们随机裁剪一个512×512的补丁用于训练并利用翻转、旋转等操作来随机增强数据。初始学习率设定为0.0001，在2000次迭代后学习率降为0.00001，训练一共进行4000次迭代。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="font-weight:700;"><span style="color:rgb(102,102,102);">实验结果分析</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">首先，与传统方法的对比，我们提出的方法具有放大的功能。如下图5,6,7所示，传统的图像处理方法在极端低光条件下容易受到严重的噪声影响，导致生成图像颜色失真。我们提出的方法能够有效地抑制图像噪声，生成色彩均衡、逼真的图像。此外，由于在数据集中对齐数据序列，我们的方法也更优于 post-hocdenoising、brust denoising 等图像去燥方法</span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153750652?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图5 (a) 由富士胶片 X-T2 相机拍摄的夜间图像，ISO 800，光圈f / 7.1，曝光时间1/30s，相机亮度约为1 lux。(b) 传统的图像处理方法不能有效处理原始数据中的噪声和颜色偏差。(c) 基于相同的数据，我们方法处理的结果。</span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153810914?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图6 将 SID 数据集训练好的模型应用于用 iPhone 6s智能手机拍摄的原始低光图像。(a) iPhone 6s 在夜间所拍摄的原始图像，ISO 400，光圈f/2.2，曝光时间0. 05s。经传统的图像处理方法处理后的图像及缩放到相匹配的亮度的参考图像。</span><span style="color:rgb(102,102,102);font-size:12px;">(b)</span><span style="color:rgb(102,102,102);font-size:12px;">我们提出的方法处理后的结果</span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);font-size:12px;"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180512153840238?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmNodW5taWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br></span></p>
<p align="center" style="background:rgb(255,255,255);"><span style="font-size:12px;color:rgb(102,102,102);">图7 Sony x300拍摄的图像。(a) 由传统图像处理方法处理的低光图像及其线性缩放的结果。(b) 同样用传统方法，并通过 BM3D 去噪方法处理后的结果。 (c) 我们提出的方法处理后的结果。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">此外，我们还进行了一系列的控制实验，来分析方法中各组分对模型性能的影响，包括模型结构，输入的颜色空间，损失函数，数据排列，图像后处理等因素。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="font-weight:700;"><span style="color:rgb(102,102,102);">结语</span></span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">由于图像低光子数和低信噪比的影响，快速低光成像系统是一个艰巨的挑战。黑暗中快速成像系统更是被认为是一种不切实际、与传统的信号处理相悖的技术。在本文中，我们创建了一个黑暗中的图像数据集 (SID) 以支持数据驱动方法的研究。利用 SID 数据集，我们提出一种基于 FCN 模型结构，通过端到端训练，改善了传统的处理低光图像的方法。实验结果表明我们的方法能够成功抑制噪声并正确地实现颜色转换，表现出不错的性能，并展现了不错的研究前景。未来的工作我们可以进一步研究低光成像网络的泛化能力。此外，对于模型的性能优化也是值得研究的一个热点方向。我们还将在未来的工作中进一步改善图像质量，如通过系统优化网络架构和训练程序。我们希望SID 数据集和我们的实验结果可以支持并刺激未来该领域的研究。</span></p>
<p align="left" style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">原文链接：</span><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.01934" rel="nofollow noopener noreferrer" data-token="10354b74d4deff9e5f377b2ee3e5bfbf">arxiv.org/abs/1805.01934</a></p>
<p style="background:rgb(255,255,255);"><span style="color:rgb(102,102,102);">项目地址：<a href="https://link.zhihu.com/?target=http%3A//web.engr.illinois.edu/~cchen156/SID.html" rel="nofollow noopener noreferrer" data-token="0d2205017e859bc5979af930e9998c38">web.engr.illinois.edu/~cchen156/SID.html</a></span></p>
<p style="background-color:rgb(255,255,255);"><span style="color:rgb(102,102,102);">GitHub地址：<a href="https://link.zhihu.com/?target=https%3A//github.com/cchen156/Learning-to-See-in-the-Dark" rel="nofollow noopener noreferrer" data-token="1e92eca0f5ba1ab05c99e2ebc61066ef">github.com/cchen156/Learning-to-See-in-the-Dark</a></span></p>
<p style="background-color:rgb(255,255,255);"><span style="color:rgb(102,102,102);">以上是这篇论文解读的内容。欢迎指点补充。</span></p>
<p>
  <span style="color:#666666;"></span></p>
</div>
</div>

		
	</div>

	<footer class="entry-footer">

						
	<nav class="navigation post-navigation" role="navigation">
		<h2 class="screen-reader-text">Post navigation</h2>
		<div class="nav-links"><div class="nav-previous"><a href="https://uzzz.org/article/3333/" rel="prev"><span class="screen-reader-text">Previous Post:</span>php判断两张图片是否相同以及相似度</a></div><div class="nav-next"><a href="https://uzzz.org/article/2527/" rel="next"><span class="screen-reader-text">Next Post:</span>学信网信息可以修改吗/如何修改学信网信息-百度-经验</a></div></div>
	</nav>
	</footer>

</article>
			
			<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">	</script>
			<ins class="adsbygoogle" style="display:block" data-ad-format="autorelaxed" data-ad-client="ca-pub-8889449066804352" data-ad-slot="1928667997"></ins>
			<script>
				 (adsbygoogle = window.adsbygoogle || []).push({});
			</script>
		
		</main>
	</section>
	
	
	<section id="secondary" class="sidebar widget-area clearfix" role="complementary">

		<div class="widget_text widget-wrap"><aside id="custom_html-5" class="widget_text widget widget_custom_html clearfix"><div class="textwidget custom-html-widget"><script async src="https://cse.google.com/cse.js?cx=004431708863642777669:dt5gmztovfo"></script>
<div class="gcse-search"></div>
<style>
td.gsc-search-button {
    width: 90px;
}
.gsc-control-cse table{
	margin: 0;
}
.gsc-control-cse th, td {
	border: none;
}
	
	td.gsib_b {
		
    width: 36px;

	}
	.gscb_a {
		width: 94%;
    line-height: 20px;
		font-size: 20px;
}
	.gsst_b {
		font-size: 12px;
	}
	#custom_html-5 {
		padding: 0;
	}
	.cse .gsc-control-cse, .gsc-control-cse {
    border: none;
}
	.cse .gsc-control-cse, .gsc-control-cse {
    padding: 4px 4px 0px 4px;
}
</style></div></aside></div>		<div class="widget-wrap"><aside id="recent-posts-2" class="widget widget_recent_entries clearfix">		<div class="widget-header"><h3 class="widget-title">Recent Posts</h3></div>		<ul>
											<li>
					<a href="https://uzzz.org/article/4661/">暗网网址导航大全（2021年12月更新）</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4658/">暗网网址合集 暗网链接 Deep Web Link Director</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4656/">全球十大暗网搜索引擎</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4649/">最详细的暗网教程——tor洋葱浏览器的安装和使用方法</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4646/">最新darkweb暗网搜索引擎——Tordex | The Uncensored Tor Search Engine</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4642/">顶级保密暗网网址分享</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4638/">如何进入暗网？教程+工具 Tor 洋葱浏览器</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4635/">如何进入暗网详细步骤（暗网网桥获取方法）</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4630/">什么是“暗网”？我们该如何访问?</a>
									</li>
											<li>
					<a href="https://uzzz.org/article/4466/">Deep Web / Dark Web 大全</a>
									</li>
					</ul>
		</aside></div><div class="widget_text widget-wrap"><aside id="custom_html-8" class="widget_text widget widget_custom_html clearfix"><div class="textwidget custom-html-widget"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-8889449066804352" data-ad-slot="6054387901" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></div></aside></div><div class="widget-wrap"><aside id="tag_cloud-3" class="widget widget_tag_cloud clearfix"><div class="widget-header"><h3 class="widget-title">Tags</h3></div><div class="tagcloud"><a href="https://uzzz.org/tag/android/" class="tag-cloud-link tag-link-945 tag-link-position-1" style="font-size: 13.5pt;" aria-label="android (10 items)">android<span class="tag-link-count"> (10)</span></a>
<a href="https://uzzz.org/tag/application/" class="tag-cloud-link tag-link-419 tag-link-position-2" style="font-size: 10.25pt;" aria-label="application (5 items)">application<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/google/" class="tag-cloud-link tag-link-243 tag-link-position-3" style="font-size: 11.75pt;" aria-label="google (7 items)">google<span class="tag-link-count"> (7)</span></a>
<a href="https://uzzz.org/tag/hacker/" class="tag-cloud-link tag-link-1884 tag-link-position-4" style="font-size: 10.25pt;" aria-label="hacker (5 items)">hacker<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/internet/" class="tag-cloud-link tag-link-202 tag-link-position-5" style="font-size: 10.25pt;" aria-label="internet (5 items)">internet<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/java/" class="tag-cloud-link tag-link-621 tag-link-position-6" style="font-size: 11.75pt;" aria-label="java (7 items)">java<span class="tag-link-count"> (7)</span></a>
<a href="https://uzzz.org/tag/linux/" class="tag-cloud-link tag-link-342 tag-link-position-7" style="font-size: 15.875pt;" aria-label="Linux (16 items)">Linux<span class="tag-link-count"> (16)</span></a>
<a href="https://uzzz.org/tag/network/" class="tag-cloud-link tag-link-204 tag-link-position-8" style="font-size: 11.125pt;" aria-label="network (6 items)">network<span class="tag-link-count"> (6)</span></a>
<a href="https://uzzz.org/tag/qq/" class="tag-cloud-link tag-link-2012 tag-link-position-9" style="font-size: 9.25pt;" aria-label="qq (4 items)">qq<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/source-code-analysis/" class="tag-cloud-link tag-link-2051 tag-link-position-10" style="font-size: 15.5pt;" aria-label="Source Code Analysis (15 items)">Source Code Analysis<span class="tag-link-count"> (15)</span></a>
<a href="https://uzzz.org/tag/tor/" class="tag-cloud-link tag-link-181 tag-link-position-11" style="font-size: 21.125pt;" aria-label="tor (44 items)">tor<span class="tag-link-count"> (44)</span></a>
<a href="https://uzzz.org/tag/ubuntu/" class="tag-cloud-link tag-link-387 tag-link-position-12" style="font-size: 15.25pt;" aria-label="ubuntu (14 items)">ubuntu<span class="tag-link-count"> (14)</span></a>
<a href="https://uzzz.org/tag/web/" class="tag-cloud-link tag-link-457 tag-link-position-13" style="font-size: 17.25pt;" aria-label="web (21 items)">web<span class="tag-link-count"> (21)</span></a>
<a href="https://uzzz.org/tag/windows/" class="tag-cloud-link tag-link-366 tag-link-position-14" style="font-size: 13pt;" aria-label="windows (9 items)">windows<span class="tag-link-count"> (9)</span></a>
<a href="https://uzzz.org/tag/hulianwang/" class="tag-cloud-link tag-link-242 tag-link-position-15" style="font-size: 11.75pt;" aria-label="互联网 (7 items)">互联网<span class="tag-link-count"> (7)</span></a>
<a href="https://uzzz.org/tag/chanpin/" class="tag-cloud-link tag-link-1162 tag-link-position-16" style="font-size: 11.125pt;" aria-label="产品 (6 items)">产品<span class="tag-link-count"> (6)</span></a>
<a href="https://uzzz.org/tag/dailifuwuqi/" class="tag-cloud-link tag-link-341 tag-link-position-17" style="font-size: 10.25pt;" aria-label="代理服务器 (5 items)">代理服务器<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/xinxianquan/" class="tag-cloud-link tag-link-870 tag-link-position-18" style="font-size: 9.25pt;" aria-label="信息安全 (4 items)">信息安全<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/qita/" class="tag-cloud-link tag-link-1887 tag-link-position-19" style="font-size: 11.75pt;" aria-label="其他 (7 items)">其他<span class="tag-link-count"> (7)</span></a>
<a href="https://uzzz.org/tag/qukuailian/" class="tag-cloud-link tag-link-299 tag-link-position-20" style="font-size: 9.25pt;" aria-label="区块链 (4 items)">区块链<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/cunchu/" class="tag-cloud-link tag-link-206 tag-link-position-21" style="font-size: 9.25pt;" aria-label="存储 (4 items)">存储<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/anquan/" class="tag-cloud-link tag-link-188 tag-link-position-22" style="font-size: 14pt;" aria-label="安全 (11 items)">安全<span class="tag-link-count"> (11)</span></a>
<a href="https://uzzz.org/tag/gongzuo/" class="tag-cloud-link tag-link-485 tag-link-position-23" style="font-size: 17pt;" aria-label="工作 (20 items)">工作<span class="tag-link-count"> (20)</span></a>
<a href="https://uzzz.org/tag/gongju/" class="tag-cloud-link tag-link-205 tag-link-position-24" style="font-size: 13.5pt;" aria-label="工具 (10 items)">工具<span class="tag-link-count"> (10)</span></a>
<a href="https://uzzz.org/tag/shouji/" class="tag-cloud-link tag-link-1157 tag-link-position-25" style="font-size: 13pt;" aria-label="手机 (9 items)">手机<span class="tag-link-count"> (9)</span></a>
<a href="https://uzzz.org/tag/sousuoyinqing/" class="tag-cloud-link tag-link-637 tag-link-position-26" style="font-size: 10.25pt;" aria-label="搜索引擎 (5 items)">搜索引擎<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/anwang/" class="tag-cloud-link tag-link-164 tag-link-position-27" style="font-size: 15.875pt;" aria-label="暗网 (16 items)">暗网<span class="tag-link-count"> (16)</span></a>
<a href="https://uzzz.org/tag/fuwuqi/" class="tag-cloud-link tag-link-256 tag-link-position-28" style="font-size: 13.5pt;" aria-label="服务器 (10 items)">服务器<span class="tag-link-count"> (10)</span></a>
<a href="https://uzzz.org/tag/zaxiang/" class="tag-cloud-link tag-link-1936 tag-link-position-29" style="font-size: 16.25pt;" aria-label="杂项 (17 items)">杂项<span class="tag-link-count"> (17)</span></a>
<a href="https://uzzz.org/tag/huodong/" class="tag-cloud-link tag-link-915 tag-link-position-30" style="font-size: 14.375pt;" aria-label="活动 (12 items)">活动<span class="tag-link-count"> (12)</span></a>
<a href="https://uzzz.org/tag/ceshi/" class="tag-cloud-link tag-link-455 tag-link-position-31" style="font-size: 10.25pt;" aria-label="测试 (5 items)">测试<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/liulanqi/" class="tag-cloud-link tag-link-336 tag-link-position-32" style="font-size: 16.75pt;" aria-label="浏览器 (19 items)">浏览器<span class="tag-link-count"> (19)</span></a>
<a href="https://uzzz.org/tag/shenduxuexi/" class="tag-cloud-link tag-link-713 tag-link-position-33" style="font-size: 10.25pt;" aria-label="深度学习 (5 items)">深度学习<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/zhaopian/" class="tag-cloud-link tag-link-1160 tag-link-position-34" style="font-size: 11.125pt;" aria-label="照片 (6 items)">照片<span class="tag-link-count"> (6)</span></a>
<a href="https://uzzz.org/tag/pachong/" class="tag-cloud-link tag-link-179 tag-link-position-35" style="font-size: 11.75pt;" aria-label="爬虫 (7 items)">爬虫<span class="tag-link-count"> (7)</span></a>
<a href="https://uzzz.org/tag/wulixuecaixiang/" class="tag-cloud-link tag-link-1923 tag-link-position-36" style="font-size: 13.5pt;" aria-label="物理学猜想 (10 items)">物理学猜想<span class="tag-link-count"> (10)</span></a>
<a href="https://uzzz.org/tag/huanjingdajian/" class="tag-cloud-link tag-link-2066 tag-link-position-37" style="font-size: 8pt;" aria-label="环境搭建 (3 items)">环境搭建<span class="tag-link-count"> (3)</span></a>
<a href="https://uzzz.org/tag/shenghuo/" class="tag-cloud-link tag-link-861 tag-link-position-38" style="font-size: 17.75pt;" aria-label="生活 (23 items)">生活<span class="tag-link-count"> (23)</span></a>
<a href="https://uzzz.org/tag/dianxin/" class="tag-cloud-link tag-link-421 tag-link-position-39" style="font-size: 9.25pt;" aria-label="电信 (4 items)">电信<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/dianhua/" class="tag-cloud-link tag-link-1115 tag-link-position-40" style="font-size: 10.25pt;" aria-label="电话 (5 items)">电话<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/baidu/" class="tag-cloud-link tag-link-876 tag-link-position-41" style="font-size: 9.25pt;" aria-label="百度 (4 items)">百度<span class="tag-link-count"> (4)</span></a>
<a href="https://uzzz.org/tag/suanfa/" class="tag-cloud-link tag-link-628 tag-link-position-42" style="font-size: 10.25pt;" aria-label="算法 (5 items)">算法<span class="tag-link-count"> (5)</span></a>
<a href="https://uzzz.org/tag/wangluo/" class="tag-cloud-link tag-link-176 tag-link-position-43" style="font-size: 22pt;" aria-label="网络 (52 items)">网络<span class="tag-link-count"> (52)</span></a>
<a href="https://uzzz.org/tag/wangluoanquan/" class="tag-cloud-link tag-link-230 tag-link-position-44" style="font-size: 16.5pt;" aria-label="网络安全 (18 items)">网络安全<span class="tag-link-count"> (18)</span></a>
<a href="https://uzzz.org/tag/wangluoanquanzhishi/" class="tag-cloud-link tag-link-1929 tag-link-position-45" style="font-size: 11.125pt;" aria-label="网络安全知识 (6 items)">网络安全知识<span class="tag-link-count"> (6)</span></a></div>
</aside></div><div class="widget_text widget-wrap"><aside id="custom_html-9" class="widget_text widget widget_custom_html clearfix"><div class="textwidget custom-html-widget"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-8889449066804352" data-ad-slot="6054387901" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></div></aside></div><div class="widget-wrap"><aside id="categories-2" class="widget widget_categories clearfix"><div class="widget-header"><h3 class="widget-title">Categories</h3></div>		<ul>
				<li class="cat-item cat-item-1856"><a href="https://uzzz.org/category/ai/">AI</a> (5)
</li>
	<li class="cat-item cat-item-1400"><a href="https://uzzz.org/category/altium-designer/">AltiumDesigner</a> (7)
</li>
	<li class="cat-item cat-item-742"><a href="https://uzzz.org/category/btc/">BTC</a> (6)
</li>
	<li class="cat-item cat-item-528"><a href="https://uzzz.org/category/darknet/">darknet</a> (25)
</li>
	<li class="cat-item cat-item-1850"><a href="https://uzzz.org/category/database/">Database</a> (3)
</li>
	<li class="cat-item cat-item-1859"><a href="https://uzzz.org/category/deeplearning/">DeepLearning</a> (78)
</li>
	<li class="cat-item cat-item-961"><a href="https://uzzz.org/category/docker/">Docker</a> (1)
</li>
	<li class="cat-item cat-item-738"><a href="https://uzzz.org/category/gis/">GIS</a> (9)
</li>
	<li class="cat-item cat-item-1191"><a href="https://uzzz.org/category/google/">Google</a> (2)
</li>
	<li class="cat-item cat-item-447"><a href="https://uzzz.org/category/ios/">iOS</a> (7)
</li>
	<li class="cat-item cat-item-1308"><a href="https://uzzz.org/category/it/">IT</a> (7)
</li>
	<li class="cat-item cat-item-228"><a href="https://uzzz.org/category/java/">java</a> (37)
</li>
	<li class="cat-item cat-item-741"><a href="https://uzzz.org/category/life/">Life</a> (93)
</li>
	<li class="cat-item cat-item-253"><a href="https://uzzz.org/category/linux/">linux</a> (86)
</li>
	<li class="cat-item cat-item-1717"><a href="https://uzzz.org/category/lpc/">LPC</a> (11)
</li>
	<li class="cat-item cat-item-1843"><a href="https://uzzz.org/category/macos/">macOS</a> (6)
</li>
	<li class="cat-item cat-item-1417"><a href="https://uzzz.org/category/mysql/">mysql</a> (5)
</li>
	<li class="cat-item cat-item-214"><a href="https://uzzz.org/category/python/">Python</a> (52)
</li>
	<li class="cat-item cat-item-1196"><a href="https://uzzz.org/category/qt/">qt</a> (5)
</li>
	<li class="cat-item cat-item-284"><a href="https://uzzz.org/category/seo/">SEO</a> (2)
</li>
	<li class="cat-item cat-item-1403"><a href="https://uzzz.org/category/threejs/">threejs</a> (5)
</li>
	<li class="cat-item cat-item-1305"><a href="https://uzzz.org/category/unity/">Unity</a> (19)
</li>
	<li class="cat-item cat-item-1851"><a href="https://uzzz.org/category/chanpinsheji/">产品设计</a> (15)
</li>
	<li class="cat-item cat-item-751"><a href="https://uzzz.org/category/rengongzhineng/">人工智能</a> (12)
</li>
	<li class="cat-item cat-item-250"><a href="https://uzzz.org/category/xinxianquan/">信息安全</a> (36)
</li>
	<li class="cat-item cat-item-515"><a href="https://uzzz.org/category/qianduan/">前端</a> (128)
</li>
	<li class="cat-item cat-item-231"><a href="https://uzzz.org/category/qukuailian/">区块链</a> (14)
</li>
	<li class="cat-item cat-item-259"><a href="https://uzzz.org/category/tuxiangchuli/">图像处理</a> (59)
</li>
	<li class="cat-item cat-item-1849"><a href="https://uzzz.org/category/tuxingshipin/">图形视频</a> (36)
</li>
	<li class="cat-item cat-item-746"><a href="https://uzzz.org/category/dashuju/">大数据</a> (15)
</li>
	<li class="cat-item cat-item-1144"><a href="https://uzzz.org/category/qianrushi/">嵌入式</a> (7)
</li>
	<li class="cat-item cat-item-254"><a href="https://uzzz.org/category/gongju/">工具</a> (45)
</li>
	<li class="cat-item cat-item-743"><a href="https://uzzz.org/category/kaifa/">开发</a> (57)
</li>
	<li class="cat-item cat-item-1327"><a href="https://uzzz.org/category/xingnengyouhua/">性能优化</a> (2)
</li>
	<li class="cat-item cat-item-750"><a href="https://uzzz.org/category/jishu/">技术</a> (18)
</li>
	<li class="cat-item cat-item-1848"><a href="https://uzzz.org/category/sousuo/">搜索</a> (10)
</li>
	<li class="cat-item cat-item-753"><a href="https://uzzz.org/category/caozuoxitong/">操作系统</a> (35)
</li>
	<li class="cat-item cat-item-1759"><a href="https://uzzz.org/category/jiaochengzhishi/">教程知识</a> (1)
</li>
	<li class="cat-item cat-item-191"><a href="https://uzzz.org/category/jiaoyu/">教育</a> (2)
</li>
	<li class="cat-item cat-item-1028"><a href="https://uzzz.org/category/shuzituxiangchuli/">数字图像处理</a> (3)
</li>
	<li class="cat-item cat-item-1855"><a href="https://uzzz.org/category/shujufenxi/">数据分析</a> (2)
</li>
	<li class="cat-item cat-item-752"><a href="https://uzzz.org/category/shujuku/">数据库</a> (4)
</li>
	<li class="cat-item cat-item-990"><a href="https://uzzz.org/category/shujujiegou/">数据结构</a> (3)
</li>
	<li class="cat-item cat-item-1229"><a href="https://uzzz.org/category/shulun/">数论</a> (1)
</li>
	<li class="cat-item cat-item-1491"><a href="https://uzzz.org/category/xiankaqudong/">显卡驱动</a> (1)
</li>
	<li class="cat-item cat-item-192"><a href="https://uzzz.org/category/zhinengsousuojishu/">智能搜索技术</a> (3)
</li>
	<li class="cat-item cat-item-1"><a href="https://uzzz.org/category/uncategorized/">未分类</a> (496)
</li>
	<li class="cat-item cat-item-1029"><a href="https://uzzz.org/category/jiqixuexi/">机器学习</a> (23)
</li>
	<li class="cat-item cat-item-1055"><a href="https://uzzz.org/category/moxingyasuo/">模型压缩</a> (2)
</li>
	<li class="cat-item cat-item-1791"><a href="https://uzzz.org/category/monidianlu/">模拟电路</a> (1)
</li>
	<li class="cat-item cat-item-1223"><a href="https://uzzz.org/category/moniti/">模拟题</a> (1)
</li>
	<li class="cat-item cat-item-770"><a href="https://uzzz.org/category/bitebi/">比特币</a> (3)
</li>
	<li class="cat-item cat-item-1493"><a href="https://uzzz.org/category/shuixiatuxiangzengqiang/">水下图像增强</a> (1)
</li>
	<li class="cat-item cat-item-408"><a href="https://uzzz.org/category/ceshi/">测试</a> (4)
</li>
	<li class="cat-item cat-item-948"><a href="https://uzzz.org/category/liulanqi/">浏览器</a> (1)
</li>
	<li class="cat-item cat-item-240"><a href="https://uzzz.org/category/shenwang/">深网</a> (2)
</li>
	<li class="cat-item cat-item-1039"><a href="https://uzzz.org/category/shentouceshi/">渗透测试</a> (4)
</li>
	<li class="cat-item cat-item-1854"><a href="https://uzzz.org/category/youxi/">游戏</a> (2)
</li>
	<li class="cat-item cat-item-1751"><a href="https://uzzz.org/category/youxikaifa/">游戏开发</a> (16)
</li>
	<li class="cat-item cat-item-789"><a href="https://uzzz.org/category/pachong/">爬虫</a> (6)
</li>
	<li class="cat-item cat-item-1038"><a href="https://uzzz.org/category/huanjingdajian/">环境搭建</a> (2)
</li>
	<li class="cat-item cat-item-747"><a href="https://uzzz.org/category/shenghuo/">生活</a> (5)
</li>
	<li class="cat-item cat-item-1230"><a href="https://uzzz.org/category/dianzishangwu/">电子商务</a> (1)
</li>
	<li class="cat-item cat-item-1268"><a href="https://uzzz.org/category/yingjiansheji/">硬件设计</a> (1)
</li>
	<li class="cat-item cat-item-1004"><a href="https://uzzz.org/category/shegongku/">社工库</a> (1)
</li>
	<li class="cat-item cat-item-1738"><a href="https://uzzz.org/category/shenjingjizhi/">神经机制</a> (1)
</li>
	<li class="cat-item cat-item-1489"><a href="https://uzzz.org/category/yidongweb/">移动web</a> (1)
</li>
	<li class="cat-item cat-item-660"><a href="https://uzzz.org/category/yidongkaifa/">移动开发</a> (76)
</li>
	<li class="cat-item cat-item-858"><a href="https://uzzz.org/category/chengxuyuan/">程序员</a> (6)
</li>
	<li class="cat-item cat-item-1246"><a href="https://uzzz.org/category/zhanchang/">站长</a> (1)
</li>
	<li class="cat-item cat-item-965"><a href="https://uzzz.org/category/suanfa/">算法</a> (9)
</li>
	<li class="cat-item cat-item-1857"><a href="https://uzzz.org/category/tongjisousuo/">统计搜索</a> (9)
</li>
	<li class="cat-item cat-item-1860"><a href="https://uzzz.org/category/wangluoyouhua/">网络优化</a> (7)
</li>
	<li class="cat-item cat-item-749"><a href="https://uzzz.org/category/wangluoanquan/">网络安全</a> (80)
</li>
	<li class="cat-item cat-item-1391"><a href="https://uzzz.org/category/shijue/">视觉</a> (4)
</li>
	<li class="cat-item cat-item-734"><a href="https://uzzz.org/category/jisuanji/">计算机</a> (31)
</li>
	<li class="cat-item cat-item-735"><a href="https://uzzz.org/category/lunwen/">论文</a> (8)
</li>
	<li class="cat-item cat-item-1243"><a href="https://uzzz.org/category/sheji/">设计</a> (6)
</li>
	<li class="cat-item cat-item-1021"><a href="https://uzzz.org/category/ziyuansouji/">资源搜集</a> (1)
</li>
	<li class="cat-item cat-item-246"><a href="https://uzzz.org/category/zixun/">资讯</a> (34)
</li>
	<li class="cat-item cat-item-1842"><a href="https://uzzz.org/category/ruanjiangongju/">软件工具</a> (15)
</li>
	<li class="cat-item cat-item-1846"><a href="https://uzzz.org/category/ruanjiankaifa/">软件开发</a> (26)
</li>
	<li class="cat-item cat-item-1853"><a href="https://uzzz.org/category/yunwei/">运维</a> (21)
</li>
	<li class="cat-item cat-item-788"><a href="https://uzzz.org/category/nixiang/">逆向</a> (2)
</li>
	<li class="cat-item cat-item-1147"><a href="https://uzzz.org/category/xiangmuguanli/">项目管理</a> (4)
</li>
		</ul>
			</aside></div><div class="widget-wrap"><aside id="archives-2" class="widget widget_archive clearfix"><div class="widget-header"><h3 class="widget-title">Archives</h3></div>		<ul>
				<li><a href="https://uzzz.org/article/date/2021/12/">December 2021</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2021/08/">August 2021</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2020/04/">April 2020</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2020/03/">March 2020</a> (63)</li>
	<li><a href="https://uzzz.org/article/date/2020/02/">February 2020</a> (154)</li>
	<li><a href="https://uzzz.org/article/date/2020/01/">January 2020</a> (134)</li>
	<li><a href="https://uzzz.org/article/date/2019/12/">December 2019</a> (14)</li>
	<li><a href="https://uzzz.org/article/date/2019/11/">November 2019</a> (25)</li>
	<li><a href="https://uzzz.org/article/date/2019/10/">October 2019</a> (27)</li>
	<li><a href="https://uzzz.org/article/date/2019/09/">September 2019</a> (43)</li>
	<li><a href="https://uzzz.org/article/date/2019/08/">August 2019</a> (32)</li>
	<li><a href="https://uzzz.org/article/date/2019/07/">July 2019</a> (51)</li>
	<li><a href="https://uzzz.org/article/date/2019/06/">June 2019</a> (49)</li>
	<li><a href="https://uzzz.org/article/date/2019/05/">May 2019</a> (65)</li>
	<li><a href="https://uzzz.org/article/date/2019/04/">April 2019</a> (64)</li>
	<li><a href="https://uzzz.org/article/date/2019/03/">March 2019</a> (97)</li>
	<li><a href="https://uzzz.org/article/date/2019/02/">February 2019</a> (49)</li>
	<li><a href="https://uzzz.org/article/date/2019/01/">January 2019</a> (78)</li>
	<li><a href="https://uzzz.org/article/date/2018/12/">December 2018</a> (70)</li>
	<li><a href="https://uzzz.org/article/date/2018/11/">November 2018</a> (69)</li>
	<li><a href="https://uzzz.org/article/date/2018/10/">October 2018</a> (31)</li>
	<li><a href="https://uzzz.org/article/date/2018/09/">September 2018</a> (73)</li>
	<li><a href="https://uzzz.org/article/date/2018/08/">August 2018</a> (109)</li>
	<li><a href="https://uzzz.org/article/date/2018/07/">July 2018</a> (70)</li>
	<li><a href="https://uzzz.org/article/date/2018/06/">June 2018</a> (58)</li>
	<li><a href="https://uzzz.org/article/date/2018/05/">May 2018</a> (51)</li>
	<li><a href="https://uzzz.org/article/date/2018/04/">April 2018</a> (52)</li>
	<li><a href="https://uzzz.org/article/date/2018/03/">March 2018</a> (52)</li>
	<li><a href="https://uzzz.org/article/date/2018/02/">February 2018</a> (19)</li>
	<li><a href="https://uzzz.org/article/date/2018/01/">January 2018</a> (25)</li>
	<li><a href="https://uzzz.org/article/date/2017/12/">December 2017</a> (39)</li>
	<li><a href="https://uzzz.org/article/date/2017/11/">November 2017</a> (31)</li>
	<li><a href="https://uzzz.org/article/date/2017/10/">October 2017</a> (26)</li>
	<li><a href="https://uzzz.org/article/date/2017/09/">September 2017</a> (42)</li>
	<li><a href="https://uzzz.org/article/date/2017/08/">August 2017</a> (46)</li>
	<li><a href="https://uzzz.org/article/date/2017/07/">July 2017</a> (50)</li>
	<li><a href="https://uzzz.org/article/date/2017/06/">June 2017</a> (71)</li>
	<li><a href="https://uzzz.org/article/date/2017/05/">May 2017</a> (32)</li>
	<li><a href="https://uzzz.org/article/date/2017/04/">April 2017</a> (29)</li>
	<li><a href="https://uzzz.org/article/date/2017/03/">March 2017</a> (36)</li>
	<li><a href="https://uzzz.org/article/date/2017/02/">February 2017</a> (18)</li>
	<li><a href="https://uzzz.org/article/date/2017/01/">January 2017</a> (25)</li>
	<li><a href="https://uzzz.org/article/date/2016/12/">December 2016</a> (20)</li>
	<li><a href="https://uzzz.org/article/date/2016/11/">November 2016</a> (17)</li>
	<li><a href="https://uzzz.org/article/date/2016/10/">October 2016</a> (19)</li>
	<li><a href="https://uzzz.org/article/date/2016/09/">September 2016</a> (14)</li>
	<li><a href="https://uzzz.org/article/date/2016/08/">August 2016</a> (23)</li>
	<li><a href="https://uzzz.org/article/date/2016/07/">July 2016</a> (26)</li>
	<li><a href="https://uzzz.org/article/date/2016/06/">June 2016</a> (15)</li>
	<li><a href="https://uzzz.org/article/date/2016/05/">May 2016</a> (11)</li>
	<li><a href="https://uzzz.org/article/date/2016/04/">April 2016</a> (21)</li>
	<li><a href="https://uzzz.org/article/date/2016/03/">March 2016</a> (18)</li>
	<li><a href="https://uzzz.org/article/date/2016/02/">February 2016</a> (21)</li>
	<li><a href="https://uzzz.org/article/date/2016/01/">January 2016</a> (14)</li>
	<li><a href="https://uzzz.org/article/date/2015/12/">December 2015</a> (13)</li>
	<li><a href="https://uzzz.org/article/date/2015/11/">November 2015</a> (13)</li>
	<li><a href="https://uzzz.org/article/date/2015/10/">October 2015</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2015/09/">September 2015</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2015/08/">August 2015</a> (12)</li>
	<li><a href="https://uzzz.org/article/date/2015/07/">July 2015</a> (11)</li>
	<li><a href="https://uzzz.org/article/date/2015/06/">June 2015</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2015/05/">May 2015</a> (9)</li>
	<li><a href="https://uzzz.org/article/date/2015/04/">April 2015</a> (12)</li>
	<li><a href="https://uzzz.org/article/date/2015/03/">March 2015</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2015/02/">February 2015</a> (10)</li>
	<li><a href="https://uzzz.org/article/date/2015/01/">January 2015</a> (10)</li>
	<li><a href="https://uzzz.org/article/date/2014/12/">December 2014</a> (14)</li>
	<li><a href="https://uzzz.org/article/date/2014/11/">November 2014</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2014/10/">October 2014</a> (10)</li>
	<li><a href="https://uzzz.org/article/date/2014/09/">September 2014</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2014/08/">August 2014</a> (10)</li>
	<li><a href="https://uzzz.org/article/date/2014/07/">July 2014</a> (11)</li>
	<li><a href="https://uzzz.org/article/date/2014/06/">June 2014</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2014/05/">May 2014</a> (9)</li>
	<li><a href="https://uzzz.org/article/date/2014/04/">April 2014</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2014/03/">March 2014</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2014/02/">February 2014</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2014/01/">January 2014</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2013/12/">December 2013</a> (12)</li>
	<li><a href="https://uzzz.org/article/date/2013/11/">November 2013</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2013/10/">October 2013</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2013/09/">September 2013</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2013/08/">August 2013</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2013/07/">July 2013</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2013/06/">June 2013</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2013/05/">May 2013</a> (28)</li>
	<li><a href="https://uzzz.org/article/date/2013/04/">April 2013</a> (17)</li>
	<li><a href="https://uzzz.org/article/date/2013/03/">March 2013</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2013/02/">February 2013</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2013/01/">January 2013</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2012/12/">December 2012</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2012/11/">November 2012</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2012/10/">October 2012</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2012/09/">September 2012</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2012/08/">August 2012</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2012/07/">July 2012</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2012/06/">June 2012</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2012/05/">May 2012</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2012/04/">April 2012</a> (15)</li>
	<li><a href="https://uzzz.org/article/date/2012/03/">March 2012</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2012/02/">February 2012</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2012/01/">January 2012</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2011/12/">December 2011</a> (9)</li>
	<li><a href="https://uzzz.org/article/date/2011/11/">November 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/10/">October 2011</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2011/09/">September 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/08/">August 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/07/">July 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/06/">June 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/05/">May 2011</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2011/04/">April 2011</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2011/03/">March 2011</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2011/02/">February 2011</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2011/01/">January 2011</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2010/12/">December 2010</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2010/11/">November 2010</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2010/10/">October 2010</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2010/09/">September 2010</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2010/08/">August 2010</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2010/07/">July 2010</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2010/06/">June 2010</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2010/05/">May 2010</a> (14)</li>
	<li><a href="https://uzzz.org/article/date/2010/04/">April 2010</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2010/02/">February 2010</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2010/01/">January 2010</a> (11)</li>
	<li><a href="https://uzzz.org/article/date/2009/12/">December 2009</a> (8)</li>
	<li><a href="https://uzzz.org/article/date/2009/11/">November 2009</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2009/10/">October 2009</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2009/09/">September 2009</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2009/07/">July 2009</a> (7)</li>
	<li><a href="https://uzzz.org/article/date/2009/04/">April 2009</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2009/03/">March 2009</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2009/02/">February 2009</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2009/01/">January 2009</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2008/12/">December 2008</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2008/11/">November 2008</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2008/10/">October 2008</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2008/09/">September 2008</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2008/08/">August 2008</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2008/07/">July 2008</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2008/06/">June 2008</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2008/05/">May 2008</a> (9)</li>
	<li><a href="https://uzzz.org/article/date/2008/04/">April 2008</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2008/03/">March 2008</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2008/02/">February 2008</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2008/01/">January 2008</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2007/12/">December 2007</a> (6)</li>
	<li><a href="https://uzzz.org/article/date/2007/11/">November 2007</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2007/10/">October 2007</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2007/09/">September 2007</a> (5)</li>
	<li><a href="https://uzzz.org/article/date/2007/08/">August 2007</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2007/07/">July 2007</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2007/06/">June 2007</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2007/05/">May 2007</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2007/04/">April 2007</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2007/03/">March 2007</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2007/02/">February 2007</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2007/01/">January 2007</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/12/">December 2006</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2006/11/">November 2006</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/09/">September 2006</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/07/">July 2006</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2006/06/">June 2006</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/05/">May 2006</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/04/">April 2006</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2006/03/">March 2006</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2006/02/">February 2006</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2006/01/">January 2006</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2005/12/">December 2005</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2005/11/">November 2005</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2005/09/">September 2005</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2005/08/">August 2005</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2005/07/">July 2005</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2005/04/">April 2005</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2005/03/">March 2005</a> (3)</li>
	<li><a href="https://uzzz.org/article/date/2005/02/">February 2005</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2005/01/">January 2005</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2004/12/">December 2004</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2004/11/">November 2004</a> (4)</li>
	<li><a href="https://uzzz.org/article/date/2004/09/">September 2004</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2004/08/">August 2004</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2004/07/">July 2004</a> (2)</li>
	<li><a href="https://uzzz.org/article/date/2003/09/">September 2003</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2002/05/">May 2002</a> (1)</li>
	<li><a href="https://uzzz.org/article/date/2002/03/">March 2002</a> (1)</li>
		</ul>
			</aside></div>
	</section>

	

	</div>

	
	<div id="footer" class="footer-wrap">

		<footer id="colophon" class="site-footer container clearfix" role="contentinfo">

			
			<div id="footer-text" class="site-info">
				
	<span class="credit-link">
		Copyright ©️uzzz.org	</span>

				</div>

		</footer>

	</div>

</div>



<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-1');
</script>



</body>
</html>
