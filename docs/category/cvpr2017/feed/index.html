<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>CVPR2017 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/cvpr2017/feed" rel="self" type="application/rss+xml" />
	<link>http://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Wed, 19 Jul 2017 03:33:10 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>CVPR2017 &#8211; 有组织在!</title>
	<link>http://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>车辆密度估计&#8211;Understanding Traffic Density from Large-Scale Web Camera Data</title>
		<link>https://uzzz.org/article/1723.html</link>
				<pubDate>Wed, 19 Jul 2017 03:33:10 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[CVPR2017]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/1723.html</guid>
				<description><![CDATA[Understanding Traffic Density from Large-Scale Web Camera Data CVPR2017 https://arxiv.org/abs/1703.05868 本文介绍了两个算法用于车辆密度估计：1）OPT-RC 根据背景差得到车辆运动区域，对于图像的不同区域学习到一个对应的权值矩阵用于估计车辆密度 2）FCN-MT 使用 FCN 分割框架来进行车辆密度估计 车辆密度估计问题还是比较难的，类似于人群密度估计 Optimization Based Vehicle Density Estimation with RankConstraint(OPT-RC) we propose a regression model to learn different weights for different blocks to increase the degrees of freedom on the weights, and embed geometry information 用一个回归模型来学习图像区域对应不同的密度估计权值矩阵，嵌入了几何信息 FCN Based Multi-Task Learning for Vehicle Counting (FCN-MT) 网络分为 convolution network, decovolution network , 将卷积层各个层的特征融合起来，输入到反卷积网络中进行特征图放大 the large buses/trucks (oversized vehicles) in close view induce sporadically large errors in the counting results. To solve this problem, we propose a deep multi-task learning framework based on FCN to jointly learn vehicle density map and vehicle count. 为了解决个别大型车辆在图像中占有大面积导致车辆数估计有大的错误，这里使用了多目标学习 Experiments 这里我们建立了一个数据库 WebCamT]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>Understanding Traffic Density from Large-Scale Web Camera Data <br /> CVPR2017 <br /> <a href="https://arxiv.org/abs/1703.05868" rel="nofollow" data-token="0c665e318071041442e1005be9a219d5">https://arxiv.org/abs/1703.05868</a></p>
<p>本文介绍了两个算法用于车辆密度估计：1）OPT-RC 根据背景差得到车辆运动区域，对于图像的不同区域学习到一个对应的权值矩阵用于估计车辆密度 <br /> 2）FCN-MT 使用 FCN 分割框架来进行车辆密度估计</p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719112116972?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br /> 车辆密度估计问题还是比较难的，类似于人群密度估计</p>
<p>Optimization Based Vehicle Density Estimation with RankConstraint(OPT-RC) <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719112047261?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>we propose a regression model to learn different weights for different blocks to increase the degrees of freedom on the weights, and embed geometry information <br /> 用一个回归模型来学习图像区域对应不同的密度估计权值矩阵，嵌入了几何信息</p>
<p>FCN Based Multi-Task Learning for Vehicle Counting (FCN-MT) <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719112436503?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>网络分为 convolution network, decovolution network , 将卷积层各个层的特征融合起来，输入到反卷积网络中进行特征图放大</p>
<p>the large buses/trucks (oversized vehicles) in close view induce sporadically large errors in the counting results. To solve this problem, we propose a deep multi-task learning framework based on FCN to jointly learn vehicle density map and vehicle count. <br /> 为了解决个别大型车辆在图像中占有大面积导致车辆数估计有大的错误，这里使用了多目标学习</p>
<ol>
<li>Experiments <br /> 这里我们建立了一个数据库 WebCamT <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719113127361?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719113237949?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></li>
</ol>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170719113204483?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>深度抠图&#8211;Deep Image Matting</title>
		<link>https://uzzz.org/article/1697.html</link>
				<pubDate>Mon, 20 Mar 2017 06:25:14 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[CVPR2017]]></category>
		<category><![CDATA[深度学习应用]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/1697.html</guid>
				<description><![CDATA[CVPR2017 https://arxiv.org/abs/1703.03872 GitHub: https://github.com/Joker316701882/Deep-Image-Matting 抠图问题还是比较难的，简单的用一个公式表达如下： 左边是图像位置 i 的 RGB 值，右边是 前景和背景的线性组合。 matte estimation alpha 是未知的。对于每个像素，有3个已知量，7个未知量，所以这个一个 underconstrained 问题，即变量个数大于方程个数。 当前针对抠图问题的方法主要有两个问题： 1）当前方法将 matting equation 设计为两个颜色的线性组合，即将抠图看做一个 color problem染色问题，这种方法基于一个假设就是颜色是一个可区分的特征，distinguishing feature（通常还加入了位置信息）。但是当背景和前景的颜色空间分布重叠时，这种方法的效果就不是很好了。 2） 当前基于抠图的数据库很小。 the alphamatting.com dataset 只有27张训练图像，8张测试图像。 本文解决了上述两个问题。针对数据库问题，我们建立了一个大的抠图数据库。建立方式如下： 找一些背景比较单一的图像，这些图像的真值比较容易得到。将人扣出来，然后再将其放到背景比较复杂的图中去。 4 Our method 整个网络分两个部分，一个是 deep convolutional encoder-decoder network，is penalized by the alpha prediction loss and a novel compositional loss 输入图像块和对应的 trimap，输出 alpha prediction。第二部分是一个小的卷积网络用于 refines 前面个网络的输出 alpha prediction。 4.1. Matting encoder-decoder stage Losses: 我们这里设计了两个 Losses： 第一个loss 是 the alpha-prediction loss，是 预测的 alpha values 和alpha values的真值的绝对差。第二个loss是 the compositional loss ，预测的RGB颜色值和对应的真值绝对差。. On an modern i7 CPU, it takes approximately 20 seconds for a medium-sized image (e.g. 1K×1K) and 1 minutes for a large image (e.g. 2K×2K). 4.2. Matting refinement stage Network structure: 4个卷积层，输入是 图像块和预测的 alpha prediction。]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>CVPR2017 <br /> <a href="https://arxiv.org/abs/1703.03872" rel="nofollow" data-token="1d6ff74390fed05f57f413a27143963e">https://arxiv.org/abs/1703.03872</a></p>
<p>GitHub: <a href="https://github.com/Joker316701882/Deep-Image-Matting" rel="nofollow" data-token="3be3207d53b6fe611205a68511b2502a">https://github.com/Joker316701882/Deep-Image-Matting</a></p>
<p>抠图问题还是比较难的，简单的用一个公式表达如下： <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320095513186?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br /> 左边是图像位置 i 的 RGB 值，右边是 前景和背景的线性组合。 matte estimation alpha 是未知的。对于每个像素，有3个已知量，7个未知量，所以这个一个 underconstrained 问题，即变量个数大于方程个数。</p>
<p>当前针对抠图问题的方法主要有两个问题： <br /> 1）当前方法将 matting equation 设计为两个颜色的线性组合，即将抠图看做一个 color problem染色问题，这种方法基于一个假设就是颜色是一个可区分的特征，distinguishing feature（通常还加入了位置信息）。但是当背景和前景的颜色空间分布重叠时，这种方法的效果就不是很好了。</p>
<p>2） 当前基于抠图的数据库很小。 the alphamatting.com dataset 只有27张训练图像，8张测试图像。</p>
<p>本文解决了上述两个问题。针对数据库问题，我们建立了一个大的抠图数据库。建立方式如下： <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320102131988?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>找一些背景比较单一的图像，这些图像的真值比较容易得到。将人扣出来，然后再将其放到背景比较复杂的图中去。</p>
<p>4 Our method <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320111820487?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>整个网络分两个部分，一个是 deep convolutional encoder-decoder network，is penalized by the alpha prediction loss and a novel compositional loss 输入图像块和对应的 trimap，输出 alpha prediction。第二部分是一个小的卷积网络用于 refines 前面个网络的输出 alpha prediction。</p>
<p>4.1. Matting encoder-decoder stage</p>
<p>Losses: 我们这里设计了两个 Losses： 第一个loss 是 the alpha-prediction loss，是 预测的 alpha values 和alpha values的真值的绝对差。第二个loss是 the compositional loss ，预测的RGB颜色值和对应的真值绝对差。.</p>
<p>On an modern i7 CPU, it takes approximately 20 seconds for a medium-sized image (e.g. 1K×1K) <br /> and 1 minutes for a large image (e.g. 2K×2K).</p>
<p>4.2. Matting refinement stage <br /> Network structure: 4个卷积层，输入是 图像块和预测的 alpha prediction。 <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142241478?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142415746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142446700?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
