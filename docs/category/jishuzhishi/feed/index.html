<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>技术知识 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/jishuzhishi/feed" rel="self" type="application/rss+xml" />
	<link>http://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Wed, 26 Apr 2017 00:53:56 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>技术知识 &#8211; 有组织在!</title>
	<link>http://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>好玩的API调用之&#8212;天气预报的API调用与爬虫</title>
		<link>https://uzzz.org/article/1459.html</link>
				<pubDate>Wed, 26 Apr 2017 00:53:56 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[技术知识]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/1459.html</guid>
				<description><![CDATA[更多技术文章请访问我的个人博客http://www.rain1024.com 好玩的API调用之—天气预报的API调用与爬虫 平时写程序经常需要用到一些服务，像翻译，天气预报，星座什么的，我一般都是用Python写个爬虫去提供这些服务的网站爬数据，但是有些网站对爬虫有很多限制，一些关键字会定时更改，就像中国天气网经常变更HTML标签的class值，这就需要时常维护爬虫，而聚合数据API只对普通用户提供一个免费API接口，简直垃圾，而网上的一些网站其实有开放的API供开发者调用，所以我想着把自己发现的好玩的API和自己写的爬虫写个博客专题供大家参考，我会继续补充和维护。 第四个专题是关于天气预报的API调用与爬虫，聚合数据里的天气预报接口还收费，真是lj，我一开始用爬虫爬中国天气网里的数据进行分析，后来发现了和风天气这个良心网站，不仅提供免费的接口，而且天气预报数据也很多很丰富。今天就写中国天气网的爬虫和和风天气的api调用。 1.中国天气网的网址http://www.weather.com.cn/，先在里面找到自己的城市，然后把网址复制下来，就像我的是呼和浩特市http://www.weather.com.cn/weather1d/101080101.shtml，就是下图这样的。 下面是我爬虫的代码，就不做详细解释。 #-*- coding=utf8 -*- import sys reload(sys) sys.setdefaultencoding( "utf-8" ) import urllib2 from bs4 import BeautifulSoup import time def download(url,headers): try: request = urllib2.Request(url,headers=headers) html = urllib2.urlopen(request).read() # html = urllib2.urlopen(url).read() except urllib2.URLError as e: print "error" print e.code #可以打印出来错误代号如404。 print e.reason #可以捕获异常 html = None return html def save(html): f = open('thefile.txt', 'w') f.write(html) f.close() def read_file(): f = open('thefile.txt', 'r') html = f.read() f.close() return html def get_html(url): User_agent = 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0' headers = {'User_agent': User_agent} html = download(url, headers) save(html) def weather(): url = 'http://www.weather.com.cn/weather/101080101.shtml' get_html(url) html = read_file() soup = BeautifulSoup(html) text = "" text = text + "明天的天气是：" + soup.find('li', class_='sky skyid lv1').p.string + "\n" text = text + "最高温度：" + soup.find('li', class_='sky skyid lv1').span.string + "最低温度：" + soup.find('li', class_='sky skyid lv1').i.string + "\n" # print soup.find('li',class_='sky skyid lv2').p.string # print soup.find('li',class_='sky skyid lv2').span.string # print soup.find('li',class_='sky skyid lv2').i.string html = soup.find('li', class_='sky skyid lv1') html2 = soup.find_all('div', class_='hide')[1] soup = BeautifulSoup(str(html)) text = text + "明天的风是：" + soup.find_all('i')[1].string + '\n' # print soup.find_all('i')[1].string]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p><a href="http://www.rain1024.com" rel="nofollow noopener noreferrer" title="更多技术文章请访问我的个人博客" target="_blank" data-token="cb10340b0ad323ca65a93d39bd6b8353">更多技术文章请访问我的个人博客http://www.rain1024.com</a></p>
<h2 id="好玩的api调用之天气预报的api调用与爬虫">好玩的API调用之—天气预报的API调用与爬虫</h2>
<h3 id="平时写程序经常需要用到一些服务像翻译天气预报星座什么的我一般都是用python写个爬虫去提供这些服务的网站爬数据但是有些网站对爬虫有很多限制一些关键字会定时更改就像中国天气网经常变更html标签的class值这就需要时常维护爬虫而聚合数据api只对普通用户提供一个免费api接口简直垃圾而网上的一些网站其实有开放的api供开发者调用所以我想着把自己发现的好玩的api和自己写的爬虫写个博客专题供大家参考我会继续补充和维护">平时写程序经常需要用到一些服务，像翻译，天气预报，星座什么的，我一般都是用Python写个爬虫去提供这些服务的网站爬数据，但是有些网站对爬虫有很多限制，一些关键字会定时更改，就像中国天气网经常变更HTML标签的class值，这就需要时常维护爬虫，而聚合数据API只对普通用户提供一个免费API接口，简直垃圾，而网上的一些网站其实有开放的API供开发者调用，所以我想着把自己发现的好玩的API和自己写的爬虫写个博客专题供大家参考，我会继续补充和维护。</h3>
<h2 id="第四个专题是关于天气预报的api调用与爬虫聚合数据里的天气预报接口还收费真是lj我一开始用爬虫爬中国天气网里的数据进行分析后来发现了和风天气这个良心网站不仅提供免费的接口而且天气预报数据也很多很丰富今天就写中国天气网的爬虫和和风天气的api调用">第四个专题是关于天气预报的API调用与爬虫，聚合数据里的天气预报接口还收费，真是lj，我一开始用爬虫爬中国天气网里的数据进行分析，后来发现了和风天气这个良心网站，不仅提供免费的接口，而且天气预报数据也很多很丰富。今天就写中国天气网的爬虫和和风天气的api调用。</h2>
<h2 id="1中国天气网的网址httpwwwweathercomcn先在里面找到自己的城市然后把网址复制下来就像我的是呼和浩特市httpwwwweathercomcnweather1d101080101shtml就是下图这样的">1.中国天气网的网址<a href="http://www.weather.com.cn/" rel="nofollow noopener noreferrer" target="_blank" data-token="63df38e0b49c93fb7ccb8c84531e07a9">http://www.weather.com.cn/</a>，先在里面找到自己的城市，然后把网址复制下来，就像我的是呼和浩特市<a href="http://www.weather.com.cn/weather1d/101080101.shtml" rel="nofollow noopener noreferrer" target="_blank" data-token="1b9447bcb206118c80b2e2a01ec5e1ee">http://www.weather.com.cn/weather1d/101080101.shtml</a>，就是下图这样的。</h2>
<p><img src="http://blog-1252406596.costj.myqcloud.com/blog/web17.jpg" alt="" title=""></p>
<h2 id="下面是我爬虫的代码就不做详细解释">下面是我爬虫的代码，就不做详细解释。</h2>
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#-*- coding=utf8 -*-</span>
<span class="hljs-keyword">import</span> sys
reload(sys)
sys.setdefaultencoding( <span class="hljs-string">"utf-8"</span> )
<span class="hljs-keyword">import</span> urllib2
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> time
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span><span class="hljs-params">(url,headers)</span>:</span>
    <span class="hljs-keyword">try</span>:
        request = urllib2.Request(url,headers=headers)
        html = urllib2.urlopen(request).read()
        <span class="hljs-comment"># html = urllib2.urlopen(url).read()</span>
    <span class="hljs-keyword">except</span> urllib2.URLError <span class="hljs-keyword">as</span> e:
        <span class="hljs-keyword">print</span> <span class="hljs-string">"error"</span>
        <span class="hljs-keyword">print</span> e.code   <span class="hljs-comment">#可以打印出来错误代号如404。</span>
        <span class="hljs-keyword">print</span> e.reason  <span class="hljs-comment">#可以捕获异常</span>
        html = <span class="hljs-keyword">None</span>
    <span class="hljs-keyword">return</span> html
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(html)</span>:</span>
    f = open(<span class="hljs-string">'thefile.txt'</span>, <span class="hljs-string">'w'</span>)
    f.write(html)
    f.close()
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read_file</span><span class="hljs-params">()</span>:</span>
    f = open(<span class="hljs-string">'thefile.txt'</span>, <span class="hljs-string">'r'</span>)
    html = f.read()
    f.close()
    <span class="hljs-keyword">return</span> html
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_html</span><span class="hljs-params">(url)</span>:</span>
    User_agent = <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'</span>
    headers = {<span class="hljs-string">'User_agent'</span>: User_agent}
    html = download(url, headers)
    save(html)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weather</span><span class="hljs-params">()</span>:</span>
    url = <span class="hljs-string">'http://www.weather.com.cn/weather/101080101.shtml'</span>
    get_html(url)
    html = read_file()
    soup = BeautifulSoup(html)
    text = <span class="hljs-string">""</span>
    text = text + <span class="hljs-string">"明天的天气是："</span> + soup.find(<span class="hljs-string">'li'</span>, class_=<span class="hljs-string">'sky skyid lv1'</span>).p.string + <span class="hljs-string">"\n"</span>
    text = text + <span class="hljs-string">"最高温度："</span> + soup.find(<span class="hljs-string">'li'</span>, class_=<span class="hljs-string">'sky skyid lv1'</span>).span.string + <span class="hljs-string">"最低温度："</span> + soup.find(<span class="hljs-string">'li'</span>,
                                                                                                      class_=<span class="hljs-string">'sky skyid lv1'</span>).i.string + <span class="hljs-string">"\n"</span>

    <span class="hljs-comment"># print soup.find('li',class_='sky skyid lv2').p.string</span>
    <span class="hljs-comment"># print soup.find('li',class_='sky skyid lv2').span.string</span>
    <span class="hljs-comment"># print soup.find('li',class_='sky skyid lv2').i.string</span>
    html = soup.find(<span class="hljs-string">'li'</span>, class_=<span class="hljs-string">'sky skyid lv1'</span>)
    html2 = soup.find_all(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'hide'</span>)[<span class="hljs-number">1</span>]
    soup = BeautifulSoup(str(html))
    text = text + <span class="hljs-string">"明天的风是："</span> + soup.find_all(<span class="hljs-string">'i'</span>)[<span class="hljs-number">1</span>].string + <span class="hljs-string">'\n'</span>
    <span class="hljs-comment"># print soup.find_all('i')[1].string</span>
    soup = BeautifulSoup(str(html2))
    text = text + <span class="hljs-string">"而紫外线指数是："</span> + soup.find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">0</span>].string + <span class="hljs-string">" 建议："</span> + soup.find_all(<span class="hljs-string">'p'</span>)[<span class="hljs-number">0</span>].string + <span class="hljs-string">'\n'</span>
    text = text + <span class="hljs-string">"当然还有感冒指数："</span> + soup.find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">1</span>].string + <span class="hljs-string">" 建议："</span> + soup.find_all(<span class="hljs-string">'p'</span>)[<span class="hljs-number">1</span>].string + <span class="hljs-string">'\n'</span>
    text = text + <span class="hljs-string">"最后是穿衣指数："</span> + soup.find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">2</span>].string + <span class="hljs-string">" "</span> + soup.find_all(<span class="hljs-string">'p'</span>)[<span class="hljs-number">2</span>].string + <span class="hljs-string">'\n'</span>
     <span class="hljs-comment"># print soup.find_all('span')[1].string</span>
    <span class="hljs-comment"># print soup.find_all('span')[0].string</span>
    <span class="hljs-comment"># print soup.find_all('p')[0].string</span>
    <span class="hljs-keyword">return</span> text
<span class="hljs-keyword">if</span> __name__==<span class="hljs-string">'__main__'</span>:
    weather_text = weather()
</code></pre>
<h2 id="2打开和风网站网址是这个httpswwwheweathercom然后注册账号找到自己的key再打开这个api说明">2.打开和风网站，网址是这个<a href="https://www.heweather.com" rel="nofollow noopener noreferrer" target="_blank" data-token="a527a0ec409136217b7eca73a8e60481">https://www.heweather.com</a>，然后注册账号，找到自己的KEY，再打开这个API说明。</h2>
<p><img src="http://blog-1252406596.costj.myqcloud.com/blog/web16.jpg" alt="" title=""></p>
<h2 id="可以自己参考api这几种数据我只使用的3-10天气预报和生活指数还有天气图片因为和风网站返回的是json格式数据如下图">可以自己参考API这几种数据，我只使用的3-10天气预报和生活指数，还有天气图片。因为和风网站返回的是json格式数据，如下图。</h2>
<p><img src="http://blog-1252406596.costj.myqcloud.com/blog/web13.jpg" alt="" title=""> <br /> <img src="http://blog-1252406596.costj.myqcloud.com/blog/web14.jpg" alt="" title=""></p>
<h2 id="我是使用python做数据的解析各种数据已经提取出来后面都有注释下面是代码">我是使用Python做数据的解析，各种数据已经提取出来，后面都有注释，下面是代码</h2>
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#-*- coding=utf8 -*-</span>
<span class="hljs-keyword">import</span> sys
reload(sys)
sys.setdefaultencoding( <span class="hljs-string">"utf-8"</span> )
<span class="hljs-keyword">import</span> urllib2
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> re
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span><span class="hljs-params">(url)</span>:</span>
    html = urllib2.urlopen(url)
    <span class="hljs-keyword">return</span> html.read()
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weather</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># all全部的天气数据</span>
    all_url = <span class="hljs-string">'https://free-api.heweather.com/v5/weather?city=CN101080101&amp;key=5c043b56de9f4371b0c7f8bee8f5b75e'</span>
    <span class="hljs-comment"># 3天预报</span>
    forecast_url = <span class="hljs-string">'https://free-api.heweather.com/v5/forecast?city=CN101080101&amp;key=5c043b56de9f4371b0c7f8bee8f5b75e'</span>
    <span class="hljs-comment">#生活指数</span>
    sugg_url = <span class="hljs-string">'https://free-api.heweather.com/v5/suggestion?city=CN101080101&amp;key=5c043b56de9f4371b0c7f8bee8f5b75e'</span>
    <span class="hljs-comment"># 天气图标</span>
    photo_url = <span class="hljs-string">'https://cdn.heweather.com/cond_icon/100.png'</span>

    <span class="hljs-comment">#天气情况的内容提取------------开始</span>
    html = download(forecast_url)
    max_tmp = re.findall(<span class="hljs-string">'max":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>]  <span class="hljs-comment">#最高温度</span>
    min_tmp = re.findall(<span class="hljs-string">'min":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>]  <span class="hljs-comment">#最低温度</span>
    photo = re.findall(<span class="hljs-string">'code_d":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>] <span class="hljs-comment">#天气图片</span>
    txt_d = re.findall(<span class="hljs-string">'txt_d":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>] <span class="hljs-comment">#天气情况</span>
    dir = re.findall(<span class="hljs-string">'dir":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 风向</span>
    sc = re.findall(<span class="hljs-string">'sc":"(.*?)"'</span>, html)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 风力</span>
    <span class="hljs-keyword">print</span> max_tmp,min_tmp,photo,txt_d,dir,sc

    <span class="hljs-comment">#生活指数等内容的提取-----------开始</span>
    html = download(sugg_url)
    brf = re.findall(<span class="hljs-string">'brf":"(.*?)"'</span>, html)
    txt = re.findall(<span class="hljs-string">'txt":"(.*?)"'</span>, html)
    comf_brf = brf[<span class="hljs-number">0</span>]<span class="hljs-comment">#舒适度指数</span>
    comf_txt = txt[<span class="hljs-number">0</span>]
    cw_brf = brf[<span class="hljs-number">1</span>]<span class="hljs-comment">#洗车指数</span>
    cw_txt = txt[<span class="hljs-number">1</span>]
    drsg_brf = brf[<span class="hljs-number">2</span>]<span class="hljs-comment">#穿衣指数</span>
    drsg_txt = txt[<span class="hljs-number">2</span>]
    flu_brf = brf[<span class="hljs-number">3</span>]<span class="hljs-comment">#感冒指数</span>
    flu_txt = txt[<span class="hljs-number">3</span>]
    sport_brf = brf[<span class="hljs-number">4</span>]<span class="hljs-comment">#运动指数</span>
    sport_txt = txt[<span class="hljs-number">4</span>]
    trav_brf = brf[<span class="hljs-number">5</span>]<span class="hljs-comment">#旅游指数</span>
    trav_txt = txt[<span class="hljs-number">5</span>]
    uv_brf = brf[<span class="hljs-number">6</span>]<span class="hljs-comment"># 紫外线指数</span>
    uv_txt = txt[<span class="hljs-number">6</span>]
    <span class="hljs-keyword">print</span> comf_brf,comf_txt
    <span class="hljs-keyword">print</span> cw_brf,cw_txt
    <span class="hljs-keyword">print</span> drsg_brf,drsg_txt
    <span class="hljs-keyword">print</span> flu_brf,flu_txt
    <span class="hljs-keyword">print</span> sport_brf,sport_txt
    <span class="hljs-keyword">print</span> trav_brf,trav_txt
    <span class="hljs-keyword">print</span> uv_brf,uv_txt
    <span class="hljs-comment"># brf = brf[0].decode('utf-8')</span>
    <span class="hljs-comment"># dict_html = dict(result)</span>
    <span class="hljs-comment"># print dict_html</span>
    <span class="hljs-comment">#json格式无法提取</span>
    <span class="hljs-comment"># json_html = json.loads(html)</span>
    <span class="hljs-comment"># print json_html</span>
    <span class="hljs-comment"># html = str(json_html['HeWeather5'])</span>
    <span class="hljs-comment"># json_html = json.loads(html)</span>
    <span class="hljs-comment"># print json_html['basic']</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    weather()
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    main()</code></pre>
<h2 id="数据处理以后的效果">数据处理以后的效果</h2>
<p><img src="http://blog-1252406596.costj.myqcloud.com/blog/web15.jpg" alt="" title=""></p>
<h2 id="最后还有webserver也提供服务但需要注册返回的数据也没有和风天气返回的数据丰富所以我没使用有兴趣的可以参考这是网址httpwebservice36wucomweatherserviceasmx">最后还有webServer也提供服务，但需要注册，返回的数据也没有和风天气返回的数据丰富，所以我没使用，有兴趣的可以参考。这是网址<a href="http://webservice.36wu.com/weatherService.asmx" rel="nofollow" data-token="27f67d827ab720ed7435382309b7c243">http://webservice.36wu.com/weatherService.asmx</a></h2>
<p><img src="http://blog-1252406596.costj.myqcloud.com/blog/web18.jpg" alt="" title=""></p>
<p><a href="http://www.rain1024.com" rel="nofollow" title="更多技术文章请访问我的个人博客" data-token="cb10340b0ad323ca65a93d39bd6b8353">更多技术文章请访问我的个人博客http://www.rain1024.com</a></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
