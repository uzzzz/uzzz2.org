<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>人群分析 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/renqunfenxi/feed" rel="self" type="application/rss+xml" />
	<link>http://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Sat, 30 Sep 2017 02:26:47 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>人群分析 &#8211; 有组织在!</title>
	<link>http://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>人车密度估计&#8211;Towards perspective-free object counting with deep learning</title>
		<link>https://uzzz.org/article/1692.html</link>
				<pubDate>Sat, 30 Sep 2017 02:26:47 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[人群分析]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/1692.html</guid>
				<description><![CDATA[Towards perspective-free object counting with deep learning ECCV2016 https://github.com/gramuah/ccnn 本文针对人车密度估计问题，主要做了两个工作：1）提出了一个 novel convolutional neural network：Counting CNN (CCNN)，将图像块回归到密度图，2）第二个工作就是 提出了一个 scale-aware counting model，Hydra CNN，用于学习 multiscale non-linear regression model 这里我们将人车密度估计问题转为回归问题 3 Deep learning to count objects 3.1 Counting objects model ground truth density map D 真值密度图 由 高斯核对人车位置进行卷积得到，有了密度图通过积分得到图像中总的人车数 3.2 The Counting CNN 这个网络使用了两个 max-pooling，输入尺寸是 72&#215;72 ，输出的密度图尺寸是18&#215;18 变为原来的 1/4 Given a test image, we first densely extract image patches 给定一张测试图像，我们从图像中提出很多重叠的图像块，对图像块进行密度估计，再有这些图像块密度图组合为完整图像的密度估计图 3.3 The Hydra CNN 对于一般的基于回归的计数模型，通常需要对输入特征进行 geometric correction， using an annotated perspective map of the scene 为什么需要这个矫正了？ 主要还是 perspective distortion Technically, the perspective distortion exhibited by an image, causes that features extracted from the same object but at different scene depths would have a huge difference in values. As a consequence, erroneous results are expected by models which uses a single regression function 这里我们提出一个多尺度CNN组合学习网络 这个网络结构的设计参考了文献【24】 4 Experiments Vehicle counting results UCSD dataset UCSD dataset UCF CC 50 dataset]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>Towards perspective-free object counting with deep learning <br /> ECCV2016 <br /> <a href="https://github.com/gramuah/ccnn" rel="nofollow" data-token="0eddc39c90e509b1d20c52be9892d235">https://github.com/gramuah/ccnn</a></p>
<p>本文针对人车密度估计问题，主要做了两个工作：1）提出了一个 novel convolutional neural network：Counting CNN (CCNN)，将图像块回归到密度图，2）第二个工作就是 提出了一个 scale-aware counting model，Hydra CNN，用于学习 multiscale non-linear regression model </p>
<p>这里我们将人车密度估计问题转为回归问题 <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930100740476?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>3 Deep learning to count objects <br /> 3.1 Counting objects model <br /> ground truth density map D 真值密度图 由 高斯核对人车位置进行卷积得到，有了密度图通过积分得到图像中总的人车数</p>
<p>3.2 The Counting CNN <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930101053260?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>这个网络使用了两个 max-pooling，输入尺寸是 72&#215;72 ，输出的密度图尺寸是18&#215;18 变为原来的 1/4</p>
<p>Given a test image, we first densely extract image patches <br /> 给定一张测试图像，我们从图像中提出很多重叠的图像块，对图像块进行密度估计，再有这些图像块密度图组合为完整图像的密度估计图</p>
<p>3.3 The Hydra CNN <br /> 对于一般的基于回归的计数模型，通常需要对输入特征进行 geometric correction， using an annotated perspective map of the scene <br /> 为什么需要这个矫正了？ 主要还是 perspective distortion <br /> Technically, the perspective distortion exhibited by an image, causes that features extracted from the same object but at different scene depths would have <br /> a huge difference in values. As a consequence, erroneous results are expected by models which uses a single regression function</p>
<p>这里我们提出一个多尺度CNN组合学习网络 <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102122984?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>这个网络结构的设计参考了文献【24】</p>
<p>4 Experiments <br /> Vehicle counting results <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102304149?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102327712?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>UCSD dataset <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102352138?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br /> UCSD dataset <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102421338?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102513546?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>UCF CC 50 dataset <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102552629?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170930102625742?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
