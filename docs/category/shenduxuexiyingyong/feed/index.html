<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>深度学习应用 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/shenduxuexiyingyong/feed" rel="self" type="application/rss+xml" />
	<link>http://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Mon, 20 Mar 2017 06:25:14 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>深度学习应用 &#8211; 有组织在!</title>
	<link>http://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>深度抠图&#8211;Deep Image Matting</title>
		<link>https://uzzz.org/article/1697.html</link>
				<pubDate>Mon, 20 Mar 2017 06:25:14 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[CVPR2017]]></category>
		<category><![CDATA[深度学习应用]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/1697.html</guid>
				<description><![CDATA[CVPR2017 https://arxiv.org/abs/1703.03872 GitHub: https://github.com/Joker316701882/Deep-Image-Matting 抠图问题还是比较难的，简单的用一个公式表达如下： 左边是图像位置 i 的 RGB 值，右边是 前景和背景的线性组合。 matte estimation alpha 是未知的。对于每个像素，有3个已知量，7个未知量，所以这个一个 underconstrained 问题，即变量个数大于方程个数。 当前针对抠图问题的方法主要有两个问题： 1）当前方法将 matting equation 设计为两个颜色的线性组合，即将抠图看做一个 color problem染色问题，这种方法基于一个假设就是颜色是一个可区分的特征，distinguishing feature（通常还加入了位置信息）。但是当背景和前景的颜色空间分布重叠时，这种方法的效果就不是很好了。 2） 当前基于抠图的数据库很小。 the alphamatting.com dataset 只有27张训练图像，8张测试图像。 本文解决了上述两个问题。针对数据库问题，我们建立了一个大的抠图数据库。建立方式如下： 找一些背景比较单一的图像，这些图像的真值比较容易得到。将人扣出来，然后再将其放到背景比较复杂的图中去。 4 Our method 整个网络分两个部分，一个是 deep convolutional encoder-decoder network，is penalized by the alpha prediction loss and a novel compositional loss 输入图像块和对应的 trimap，输出 alpha prediction。第二部分是一个小的卷积网络用于 refines 前面个网络的输出 alpha prediction。 4.1. Matting encoder-decoder stage Losses: 我们这里设计了两个 Losses： 第一个loss 是 the alpha-prediction loss，是 预测的 alpha values 和alpha values的真值的绝对差。第二个loss是 the compositional loss ，预测的RGB颜色值和对应的真值绝对差。. On an modern i7 CPU, it takes approximately 20 seconds for a medium-sized image (e.g. 1K×1K) and 1 minutes for a large image (e.g. 2K×2K). 4.2. Matting refinement stage Network structure: 4个卷积层，输入是 图像块和预测的 alpha prediction。]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>CVPR2017 <br /> <a href="https://arxiv.org/abs/1703.03872" rel="nofollow" data-token="1d6ff74390fed05f57f413a27143963e">https://arxiv.org/abs/1703.03872</a></p>
<p>GitHub: <a href="https://github.com/Joker316701882/Deep-Image-Matting" rel="nofollow" data-token="3be3207d53b6fe611205a68511b2502a">https://github.com/Joker316701882/Deep-Image-Matting</a></p>
<p>抠图问题还是比较难的，简单的用一个公式表达如下： <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320095513186?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br /> 左边是图像位置 i 的 RGB 值，右边是 前景和背景的线性组合。 matte estimation alpha 是未知的。对于每个像素，有3个已知量，7个未知量，所以这个一个 underconstrained 问题，即变量个数大于方程个数。</p>
<p>当前针对抠图问题的方法主要有两个问题： <br /> 1）当前方法将 matting equation 设计为两个颜色的线性组合，即将抠图看做一个 color problem染色问题，这种方法基于一个假设就是颜色是一个可区分的特征，distinguishing feature（通常还加入了位置信息）。但是当背景和前景的颜色空间分布重叠时，这种方法的效果就不是很好了。</p>
<p>2） 当前基于抠图的数据库很小。 the alphamatting.com dataset 只有27张训练图像，8张测试图像。</p>
<p>本文解决了上述两个问题。针对数据库问题，我们建立了一个大的抠图数据库。建立方式如下： <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320102131988?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>找一些背景比较单一的图像，这些图像的真值比较容易得到。将人扣出来，然后再将其放到背景比较复杂的图中去。</p>
<p>4 Our method <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320111820487?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p>整个网络分两个部分，一个是 deep convolutional encoder-decoder network，is penalized by the alpha prediction loss and a novel compositional loss 输入图像块和对应的 trimap，输出 alpha prediction。第二部分是一个小的卷积网络用于 refines 前面个网络的输出 alpha prediction。</p>
<p>4.1. Matting encoder-decoder stage</p>
<p>Losses: 我们这里设计了两个 Losses： 第一个loss 是 the alpha-prediction loss，是 预测的 alpha values 和alpha values的真值的绝对差。第二个loss是 the compositional loss ，预测的RGB颜色值和对应的真值绝对差。.</p>
<p>On an modern i7 CPU, it takes approximately 20 seconds for a medium-sized image (e.g. 1K×1K) <br /> and 1 minutes for a large image (e.g. 2K×2K).</p>
<p>4.2. Matting refinement stage <br /> Network structure: 4个卷积层，输入是 图像块和预测的 alpha prediction。 <br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142241478?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142415746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170320142446700?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
