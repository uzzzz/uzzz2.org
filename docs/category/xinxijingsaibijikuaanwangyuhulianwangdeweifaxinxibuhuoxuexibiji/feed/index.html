<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>【信息竞赛笔记】跨暗网与互联网的违法信息捕获【学习笔记】 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/xinxijingsaibijikuaanwangyuhulianwangdeweifaxinxibuhuoxuexibiji/feed" rel="self" type="application/rss+xml" />
	<link>http://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Wed, 24 May 2017 14:25:19 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>【信息竞赛笔记】跨暗网与互联网的违法信息捕获【学习笔记】 &#8211; 有组织在!</title>
	<link>http://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>(二)暗网信息爬取（python）</title>
		<link>https://uzzz.org/article/732.html</link>
				<pubDate>Wed, 24 May 2017 14:25:19 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[【信息竞赛笔记】跨暗网与互联网的违法信息捕获【学习笔记】]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[tor]]></category>
		<category><![CDATA[暗网]]></category>
		<category><![CDATA[爬虫]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/732.html</guid>
				<description><![CDATA[首先要感谢舍友大佬提供的ShadowsocksR以及相应配置。感谢在本阶段帮助过我的学长学姐，谢谢。 暗网（深网，不可见网，隐藏网）是指那些储存在网络数据库里、不能通过超链接访问而需要通过动态网页技术访问的资源集合，不属于那些可以被标准搜索引擎索引的表面网络。 动态网页的url不固定，但可以被爬虫爬取，这是第一个点。 由于相关法律风险，本暗网爬虫代码不开源，但我会将我所理解的核心内容记录。 代码环境为ubuntu，使用语言python，使用库urllib2，socks, socket。 这里不用requests库，在参考许多教程如https://github.com/kennethreitz/requests/issues/3863/ 后发现，requests似乎无法使用socks5的代理端口，遂弃之 进入暗网的“门”为TorBrowser或者Tor 注意：torbrowser和tor并非一个东西，torbrowser是基于火狐浏览器的洋葱浏览器，通常用来做暗网入口，而且一般情况下已经足够了，但由于需要代码环境，我使用了纯Tor 以下是我的搭建步骤： 一，安装配置Tor 在ubuntu命令行输入 sudo apt-get install tor /etc/init.d/tor restart 启动后socks监听9050端口。 tor --hash-password mypassword 用来输入你的密码 编辑/etc/tor/torrc 在其中加上 ControlPort 9051 RunAsDaemon 1 Socks5Proxy 127.0.0.1:1080 HashedControlPassword 16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C 让ControlPort监听9051端口，后边那个16:开头的hash就是上一步得到的。Socks5Proxy是可以使shadowsocks为tor的前端代理（我使用的shadowsocks的端口为1080） 最后重启tor /etc/init.d/tor restart （经过曲折的一番探索，可以基本断定，python的stem库控制tor，并不是控制tor浏览器，而是可以利用tor作为自己的匿名代理，或者监视tor的流量走向。stem库目测不能为暗网爬虫做出什么贡献） 二，设置前端代理shadowsocks 这一段本应该放在最前面，但由于本人的shadowsocks完全依靠了舍友的鼎力帮助，这一段还需要往后自己探索。 就本人理解，shadowsocks作为前端代理最主要的功能就是翻墙。。。 对外提供端口为1080。 三，利用Tor的9050端口爬取暗网。 使用urllib2库，socks库作为socks5代理，示例代码如下： import socket import socks import urllib2 ipcheck_url = 'http://checkip.amazonaws.com/' # Actual IP. print(urllib2.urlopen(ipcheck_url).read()) # Tor IP. socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, '127.0.0.1', 9050) socket.socket = socks.socksocket print(urllib2.urlopen(ipcheck_url).read() 该代码引用自https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python 四，总结 tor的本质也是一种socks5代理。所以爬取暗网信息的一个流程就是： 1，我们使用Tor的9050端口（如果你使用的是TorBrowser的话，对外监听端口为9150） 2，Tor使用shadowsocks的1080端口（翻墙） 3，代码环境，爬取内容。 参考博客、论文如下： 【1】http://zzi.io/?p=328 【2】https://github.com/kennethreitz/requests/issues/3863 【3】https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python 【4】http://blog.csdn.net/yanzi1225627/article/details/51285075]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div id="content_views" class="markdown_views prism-atom-one-light">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p><strong>首先要感谢舍友大佬提供的ShadowsocksR以及相应配置。感谢在本阶段帮助过我的学长学姐，谢谢。</strong></p>
<p>暗网（深网，不可见网，隐藏网）是指那些储存在网络数据库里、不能通过超链接访问而需要通过动态网页技术访问的资源集合，不属于那些可以被标准搜索引擎索引的表面网络。 <br /> <strong>动态网页的url不固定，但可以被爬虫爬取，这是第一个点。</strong> <br /> <strong>由于相关法律风险，本暗网爬虫代码不开源，但我会将我所理解的核心内容记录。</strong> <br /> 代码环境为ubuntu，使用语言python，使用库urllib2，socks, socket。 <br /> <strong>这里不用requests库，在参考许多教程如<a href="https://github.com/kennethreitz/requests/issues/3863/" rel="nofollow noopener noreferrer" target="_blank" data-token="23a7d91076f3b3630fc41fa42a7413e6">https://github.com/kennethreitz/requests/issues/3863/</a> 后发现，requests似乎无法使用socks5的代理端口，遂弃之</strong> <br /> 进入暗网的“门”为TorBrowser或者Tor <br /> 注意：<strong>torbrowser和tor并非一个东西，torbrowser是基于火狐浏览器的洋葱浏览器，通常用来做暗网入口，而且一般情况下已经足够了，但由于需要代码环境，我使用了纯Tor</strong> <br /> 以下是我的搭建步骤： <br /> 一，安装配置Tor <br /> 在ubuntu命令行输入</p>
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">sudo</span> apt-get install tor
/etc/init.d/tor restart</code></pre>
<p>启动后socks监听9050端口。</p>
<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">tor</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">hash</span><span class="hljs-literal">-</span><span class="hljs-comment">password</span> <span class="hljs-comment">mypassword</span></code></pre>
<p>用来输入你的密码 <br /> 编辑<code>/etc/tor/torrc</code> <br /> 在其中加上</p>
<pre class="prettyprint"><code class=" hljs css"><span class="hljs-tag">ControlPort</span> 9051
<span class="hljs-tag">RunAsDaemon</span> 1
<span class="hljs-tag">Socks5Proxy</span> 127<span class="hljs-class">.0</span><span class="hljs-class">.0</span><span class="hljs-class">.1</span><span class="hljs-pseudo">:1080</span>
<span class="hljs-tag">HashedControlPassword</span> 16<span class="hljs-pseudo">:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C</span></code></pre>
<p>让ControlPort监听9051端口，后边那个16:开头的hash就是上一步得到的。Socks5Proxy是可以使shadowsocks为tor的前端代理（我使用的shadowsocks的端口为1080） <br /> 最后重启tor</p>
<pre class="prettyprint"><code class=" hljs avrasm">/etc/init<span class="hljs-preprocessor">.d</span>/tor restart</code></pre>
<p><em>（经过曲折的一番探索，可以基本断定，python的stem库控制tor，并不是控制tor浏览器，而是可以利用tor作为自己的匿名代理，或者监视tor的流量走向。stem库目测不能为暗网爬虫做出什么贡献）</em></p>
<p>二，设置前端代理shadowsocks <br /> 这一段本应该放在最前面，但由于本人的shadowsocks完全依靠了舍友的鼎力帮助，这一段还需要往后自己探索。 <br /> 就本人理解，shadowsocks作为前端代理最主要的功能就是翻墙。。。 <br /> 对外提供端口为1080。</p>
<p>三，利用Tor的9050端口爬取暗网。 <br /> 使用urllib2库，socks库作为socks5代理，示例代码如下：</p>
<pre class="prettyprint"><code class=" hljs perl">import <span class="hljs-keyword">socket</span>
import socks
import urllib2

ipcheck_url = <span class="hljs-string">'http://checkip.amazonaws.com/'</span>

<span class="hljs-comment"># Actual IP.</span>
<span class="hljs-keyword">print</span>(urllib2.urlopen(ipcheck_url).<span class="hljs-keyword">read</span>())

<span class="hljs-comment"># Tor IP.</span>
socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, <span class="hljs-string">'127.0.0.1'</span>, <span class="hljs-number">9050</span>)
<span class="hljs-keyword">socket</span>.<span class="hljs-keyword">socket</span> = socks.socksocket
<span class="hljs-keyword">print</span>(urllib2.urlopen(ipcheck_url).<span class="hljs-keyword">read</span>()</code></pre>
<p>该代码引用自<a href="https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python" rel="nofollow noopener noreferrer" target="_blank" data-token="773ff4f77a33f9d38677a0bf80d4065a">https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python</a></p>
<p>四，总结 <br /> tor的本质也是一种socks5代理。所以爬取暗网信息的一个流程就是： <br /> 1，我们使用Tor的9050端口（如果你使用的是TorBrowser的话，对外监听端口为9150） <br /> 2，Tor使用shadowsocks的1080端口（翻墙） <br /> 3，代码环境，爬取内容。</p>
<p>参考博客、论文如下： <br /> 【1】<a href="http://zzi.io/?p=328" rel="nofollow noopener noreferrer" target="_blank" data-token="d8d16b8bb9adb235c347f5da1ef9d6f1">http://zzi.io/?p=328</a> <br /> 【2】<a href="https://github.com/kennethreitz/requests/issues/3863" rel="nofollow noopener noreferrer" target="_blank" data-token="37a6ebd4037b25bf47ea97211adcd25b">https://github.com/kennethreitz/requests/issues/3863</a> <br /> 【3】<a href="https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python" rel="nofollow noopener noreferrer" target="_blank" data-token="773ff4f77a33f9d38677a0bf80d4065a">https://stackoverflow.com/questions/1096379/how-to-make-urllib2-requests-through-tor-in-python</a> <br /> 【4】<a href="http://blog.csdn.net/yanzi1225627/article/details/51285075" rel="nofollow noopener noreferrer" target="_blank" data-token="3761da43e68a4eb5c0ef568bb327da0c">http://blog.csdn.net/yanzi1225627/article/details/51285075</a></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>（一）表层网络信息获取（Python引擎爬虫）</title>
		<link>https://uzzz.org/article/863.html</link>
				<pubDate>Wed, 24 May 2017 14:00:52 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[【信息竞赛笔记】跨暗网与互联网的违法信息捕获【学习笔记】]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/863.html</guid>
				<description><![CDATA[项目整体的流程在初步分为三步： 1，表层网络信息获取 2，暗网信息爬取（第一个难点，目前已经解决） 3，信息相似度匹配，机器学习分析。 表层网络信息获取原本打算使用百度、google、bing等搜索引擎。暗网大多数内容为英文，而英文搜索又是百度搜索的短板，遂放弃百度。 google需要翻墙，bing的搜索又不够简洁。 于是找到了了元搜索引擎。 “元搜索引擎又称多搜索引擎，通过一个统一的用户界面帮助用户在多个搜索引擎中选择和利用合适的（甚至是同时利用若干个）搜索引擎来实现检索操作，是对分布于网络的多种检索工具的全局控制机制”——百度百科 简而言之，元搜索引擎可以集百家之长，给用户更大的选择。我选择的元搜索引擎为searX，该搜索引擎已在github上开源，强烈推荐，甚至可以搭建自己的searX元搜索引擎。 使用Python requests和lxml下载了searX上的链接，存入本地。 核心代码如下： if not os.path.exists(word): os.mkdir(word) print '[+]searching '+word headers = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, compress', 'Accept-Language': 'en-us;q=0.5,en;q=0.3', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:22.0) Gecko/20100101 Firefox/22.0' } for pagecount in range(1, 11): url = 'https://searx.me/?q='+word+'&#38;categories=general&#38;pageno=' + str(pagecount)+'&#38;time_range=None' html = requests.get(url=url,headers=headers) print '[+]'+url path = etree.HTML(html.content) flag=11 if pagecount==1: flag=22 for i in range(1,flag): tempword = "" for j in path.xpath('.//*[@id="main_results"]/div[%d]/h4/a//text()'%i): tempword+=j pageurl = path.xpath(".//*[@id='main_results']/div[%d]/h4/a/@href"%i) github传送门： https://github.com/gongpx20069/searX]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">
<div class="htmledit_views" id="content_views">
<p><strong>项目整体的流程在初步分为三步：</strong></p>
<p><strong>1，表层网络信息获取</strong></p>
<p><strong>2，暗网信息爬取（第一个难点，目前已经解决）</strong></p>
<p><strong>3，信息相似度匹配，机器学习分析。</strong></p>
<p></p>
<p>表层网络信息获取原本打算使用百度、google、bing等搜索引擎。暗网大多数内容为英文，而英文搜索又是百度搜索的短板，遂放弃百度。</p>
<p>google需要翻墙，bing的搜索又不够简洁。</p>
<p>于是找到了了元搜索引擎。</p>
<p>“元搜索引擎又称多搜索引擎，通过一个统一的用户界面帮助用户在多个搜索引擎中选择和利用合适的（甚至是同时利用若干个）搜索引擎来实现检索操作，是对分布于网络的多种检索工具的全局控制机制”——百度百科</p>
<p>简而言之，元搜索引擎可以集百家之长，给用户更大的选择。我选择的元搜索引擎为searX，该搜索引擎已在github上开源，强烈推荐，甚至可以搭建自己的searX元搜索引擎。</p>
<p>使用Python requests和lxml下载了searX上的链接，存入本地。</p>
<p><strong>核心代码如下：</strong></p>
</p>
<pre><code class="language-python">    if not os.path.exists(word):
    	os.mkdir(word)
    print '[+]searching '+word
    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Encoding': 'gzip, deflate, compress',
        'Accept-Language': 'en-us;q=0.5,en;q=0.3',
        'Cache-Control': 'max-age=0',
        'Connection': 'keep-alive',
        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:22.0) Gecko/20100101 Firefox/22.0'
        }
    for pagecount in range(1, 11):
        url = 'https://searx.me/?q='+word+'&amp;categories=general&amp;pageno=' + str(pagecount)+'&amp;time_range=None'
        html = requests.get(url=url,headers=headers)
        print '[+]'+url
        path = etree.HTML(html.content)
        flag=11
        if pagecount==1:
            flag=22
        for i in range(1,flag):
            tempword = ""
            for j in path.xpath('.//*[@id="main_results"]/div[%d]/h4/a//text()'%i):
                tempword+=j
            pageurl = path.xpath(".//*[@id='main_results']/div[%d]/h4/a/@href"%i)</code></pre>
<p> github传送门：<br />
  <a href="https://github.com/gongpx20069/searX" rel="nofollow" data-token="bd3ed6421317ec44bf1bfeb33a31079c">https://github.com/gongpx20069/searX</a><br />
  </p>
</p></div>
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
